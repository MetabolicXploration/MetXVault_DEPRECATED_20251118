![](_page_0_Picture_0.jpeg)

![](_page_1_Figure_0.jpeg)

# Thermal Physics

![](_page_3_Figure_0.jpeg)

# Thermal Physics

# Thermodynamics and Statistical Mechanics for Scientists and Engineers

### Robert F. Sekerka

Carnegie Mellon University Pittsburgh, PA 15213, USA

![](_page_3_Picture_5.jpeg)

AMSTERDAM • BOSTON • HEIDELBERG • LONDON • NEW YORK • OXFORD PARIS • SAN DIEGO • SAN FRANCISCO • SINGAPORE • SYDNEY • TOKYO

Elsevier Radarweg 29, PO Box 211, 1000 AE Amsterdam, Netherlands The Boulevard, Langford Lane, Kidlington, Oxford OX5 1GB, UK 225 Wyman Street, Waltham, MA 02451, USA

Copyright © 2015 Elsevier Inc. All rights reserved.

No part of this publication may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or any information storage and retrieval system, without permission in writing from the publisher. Details on how to seek permission, further information about the Publisher's permissions policies and our arrangements with organizations such as the Copyright Clearance Center and the Copyright Licensing Agency, can be found at our website: www.elsevier.com/permissions.

This book and the individual contributions contained in it are protected under copyright by the Publisher (other than as may be noted herein).

### **Notices**

Knowledge and best practice in this field are constantly changing. As new research and experience broaden our understanding, changes in research methods, professional practices, or medical treatment may become necessary.

Practitioners and researchers must always rely on their own experience and knowledge in evaluating and using any information, methods, compounds, or experiments described herein. In using such information or methods they should be mindful of their own safety and the safety of others, including parties for whom they have a professional responsibility.

To the fullest extent of the law, neither the Publisher nor the authors, contributors, or editors, assume any liability for any injury and/or damage to persons or property as a matter of products liability, negligence or otherwise, or from any use or operation of any methods, products, instructions, or ideas contained in the material herein.

### **Library of Congress Cataloging-in-Publication Data**

A catalog record for this book is available from the Library of Congress

### **British Library Cataloguing in Publication Data**

A catalogue record for this book is available from the British Library

For information on all Elsevier publications visit our website at http://store.elsevier.com/

ISBN: 978-0-12-803304-3

![](_page_4_Picture_14.jpeg)

![](_page_5_Picture_0.jpeg)

# Dedication

*To Care . . . .*

*who cared about every word and helped me write what I meant to say rather than what I had written*

![](_page_7_Figure_0.jpeg)

# **Table of Contents**

### About the Cover xv Preface XVII

|   | PART I                           | Thermodynamic<br>s                             | 1  |
|---|----------------------------------|------------------------------------------------|----|
| 1 | Intr<br>oduct<br>ion             |                                                | 3  |
|   | 1.1                              | Temper<br>ature                                | 3  |
|   | 1.2                              | Thermodynamics<br>Versus Statistical Mechanics | 5  |
|   | 1.3                              | Classification of State Variabl<br>es          | 6  |
|   | 1.4                              | Energy in Mechanics                            | 8  |
|   | 1.5                              | Elementary Kinetic Theory                      | 12 |
| 2 |                                  | First Law of Thermodynamics                    | 15 |
|   | 2.1                              | Statement of the First Law                     | 15 |
|   | 2.2                              | Quasistatic Work                               | 17 |
|   | 2.3                              | Heat Capacities                                | 19 |
|   | 2.4                              | Work Due to Expansion of an Ideal Gas          | 24 |
|   | 2.5                              | Enthalpy                                       | 28 |
| 3 | Second Law of Thermod<br>ynamics |                                                | 31 |
|   | 3.1                              | Statement of the Second Law                    | 32 |
|   | 3.2                              | Carnot Cycle and Engines                       | 35 |
|   | 3.3                              | Calculation of th<br>e Entropy Chang<br>e      | 39 |
|   | 3.4                              | Combined First and Second Laws                 | 41 |
|   | 3.5                              | Statistical Interpretation<br>of Entrop<br>y   | 47 |

| 4 | Third Law of Thermodynamics |                                                 | 49  |
|---|-----------------------------|-------------------------------------------------|-----|
|   | 4.1                         | Statement<br>of the Third Law                   | 49  |
|   | 4.2                         | Implications<br>of the Third Law                | 50  |
| 5 |                             | Open Systems                                    | 53  |
|   | 5.1                         | Single Component<br>Open System                 | 53  |
|   | 5.2                         | Multicomponent<br>Open Systems                  | 55  |
|   | 5.3                         | Euler Theorem of Homogeneous<br>Functions       | 59  |
|   | 5.4                         | Chemical Potential of Real Gases, Fugacity      | 64  |
|   | 5.5                         | Legen<br>dre Transformations                    | 67  |
|   | 5.6                         | Partial Molar Quantities                        | 71  |
|   | 5.7                         | Entropy of Chemical Reaction                    | 75  |
| 6 | Equilibrium                 | 79                                              |     |
|   | 6.1                         | Entropy Criterion                               | 79  |
|   | 6.2                         | Energy Criterion                                | 84  |
|   | 6.3                         | Other Equilibrium<br>Criteria                   | 88  |
|   | 6.4                         | Summary of Criteria                             | 92  |
| 7 |                             | Requirements for Stabi<br>lity                  | 95  |
|   | 7.1                         | Stability Requirements<br>for Entrop<br>y       | 95  |
|   | 7.2                         | Stability Requirements<br>for Internal Energy   | 100 |
|   | 7.3                         | Stability Requirements<br>for Other Potentials  | 102 |
|   | 7.4                         | Consequences<br>of Stability Requiremen<br>ts   | 105 |
|   | 7.5                         | Extension to Many Variables                     | 106 |
|   | 7.6                         | Principles of Le Chatlier and Le Chatlier-Braun | 107 |
| 8 |                             | Monocomponent<br>Phase Equi<br>librium          | 109 |
|   | 8.1                         | Clausius-Clapeyron<br>Equation                  | 110 |
|   | 8.2                         | Sketches of the Thermodynamic<br>Function<br>s  | 115 |
|   | 8.3                         | e Diagram in the v, p Plane<br>Phas             | 118 |

| 9  | Two<br>-Phase Equilibrium<br>for a van der Waa<br>ls Fluid |                                                      | 121 |
|----|------------------------------------------------------------|------------------------------------------------------|-----|
|    | 9.1                                                        | van der Waals Equation of State                      | 121 |
|    | 9.2                                                        | Thermodynamic<br>Functions                           | 124 |
|    | 9.3                                                        | Phase Equilibrium and Miscibility Gap                | 127 |
|    | 9.4                                                        | Gibbs Free Energy                                    | 131 |
| 10 |                                                            | Binary Solutions                                     | 137 |
|    | 10.1                                                       | Thermodynamics<br>of Binary Solutions                | 137 |
|    | 10.2                                                       | Ideal Soluti<br>ons                                  | 142 |
|    | 10.3                                                       | Phase Diagram for an Ideal Solid and an Ideal Liquid | 145 |
|    | 10.4                                                       | Regular Solution                                     | 148 |
|    | 10.5                                                       | General Binary Solutions                             | 153 |
| 11 | Externa                                                    | l Forces and Rotating Coordinate<br>Systems          | 155 |
|    | 11.1                                                       | Conditions for Equilibrium                           | 155 |
|    | 11.2                                                       | Uniform Gravitational Field                          | 157 |
|    | 11.3                                                       | Non-Uniform Gravitational Field                      | 164 |
|    | 11.4                                                       | Rotating Systems                                     | 164 |
|    | 11.5                                                       | Electric Fields                                      | 166 |
| 12 | Chemica                                                    | l Reactions                                          | 167 |
|    | 12.1                                                       | Reactions at Constant Volume or Pressure             | 168 |
|    | 12.2                                                       | Standard States                                      | 171 |
|    | 12.3                                                       | Equilibr<br>ium and Affinity                         | 173 |
|    | 12.4                                                       | Explicit Equilibrium Conditions                      | 175 |
|    | 12.5                                                       | Simul<br>taneous Reactions                           | 182 |
| 13 |                                                            | Thermodynam<br>ics of Fluid-Fluid Interf<br>aces     | 185 |
|    | 13.1                                                       | Planar Interfaces in Fluids                          | 186 |
|    | 13.2                                                       | Curved Interfaces in Fluids                          | 197 |

### x Table of Contents

|    | 13.3                              | Interface Junctions and Contact Angles              | 202     |
|----|-----------------------------------|-----------------------------------------------------|---------|
|    | 13.4                              | Liquid Surface Shape in Gravity                     | 205     |
| 14 |                                   | Thermodynamics<br>of Solid-Flu<br>iid Interfaces    | 215     |
|    | 14.1                              | Planar Solid-Fluid Interfaces                       | 216     |
|    | 14.2                              | Anisotropy of y                                     | 22<br>1 |
|    | 14.3                              | Curved Solid-Fluid Interfaces                       | 227     |
|    | 14.4                              | Faceting of a Large Planar Face                     | 233     |
|    | 14.5                              | Equilibrium Shape from the~ -Vector                 | 236     |
|    | 14.6                              | Herring Formula                                     | 240     |
|    | 14.7                              | Legendre Transform of the Equilibrium Shape         | 241     |
|    | 14.8                              | Remarks About Solid-Solid Interfaces                | 242     |
|    | PART II                           | Statistical Mechanics                               | 245     |
| 15 | Entropy and Information<br>Theory |                                                     | 247     |
|    | 15.1                              | Entropy as a Measure of Disorder                    | 247     |
|    | 15.2                              | Boltzmann Eta Theorem                               | 251     |
| 16 |                                   | Microcanonical<br>Ensemble                          | 257     |
|    | 16.1                              | Fundamenta<br>l Hypothesis of Statistical Mechanics | 258     |
|    | 16.2                              | Two-Stat<br>e Subsystems                            | 261     |
|    | 16.3                              | Harmonic Oscillators                                | 265     |
|    | 16.4                              | Ideal Gas                                           | 267     |
|    | 16.5                              | Multicomponent<br>Ideal Gas                         | 273     |
| 17 |                                   | Classical Microcanonical<br>Ensemble                | 277     |
|    | 17.1                              | Liouville's Theorem                                 | 278     |
|    | 17.2                              | Classical Microcanonical<br>Ensemble                | 280     |

| 18 | Distinguishable<br>Part<br>icles with Negligible<br>Interaction<br>Energies |                                                 |     |
|----|-----------------------------------------------------------------------------|-------------------------------------------------|-----|
|    | 18.1                                                                        | Derivation of the Boltzmann Distribution        | 285 |
|    | 18.2                                                                        | Two-State Subsystems                            | 289 |
|    | 18.3                                                                        | Harmonic Oscillators                            | 293 |
|    | 18.4                                                                        | Rigid Linear Rotator                            | 303 |
| 19 |                                                                             | Canonical Ensemble                              | 305 |
|    | 19.<br>1                                                                    | Three Derivations                               | 305 |
|    | 19.2                                                                        | Factorizat<br>ion Theorem                       | 312 |
|    | 19.3                                                                        | Classica<br>l Idea<br>l Gas                     | 313 |
|    | 19.4                                                                        | Maxwell-Boltzmann<br>Distribution               | 317 |
|    | 19.5                                                                        | Energy Dispersion                               | 320 |
|    | 19.6                                                                        | Paramagnetism                                   | 321 |
|    | 19.7                                                                        | Partition Function and Densit<br>y of States    | 330 |
| 20 |                                                                             | Classical Canonical Ensemble                    | 337 |
|    | 20.1                                                                        | Classical Ideal Gas                             | 338 |
|    | 20.2                                                                        | Law of Dulong and Petit                         | 342 |
|    | 20.3                                                                        | Averaging Theorem and Equipartition             | 343 |
|    | 20.4                                                                        | Virial Theorem                                  | 346 |
|    | 20.5                                                                        | Virial Coefficients                             | 348 |
|    | 20.6                                                                        | Use of Canonical Transforma<br>tions            | 354 |
|    | 20.7                                                                        | Rotating Rigid Polya<br>tomi<br>c Molecu<br>les | 356 |
| 21 |                                                                             | Grand Canonical Ensemble                        | 359 |
|    | 21.1                                                                        | Derivation from Microcanonical<br>Ensemble      | 360 |
|    | 21.2                                                                        | Ideal Systems: Orbitals and Factorization       | 368 |

### xii Table of Contents

|    | 21.3    | Classical Ideal Gas with Internal Structure                        | 380 |
|----|---------|--------------------------------------------------------------------|-----|
|    | 21.4    | Multicomponent<br>Systems                                          | 388 |
|    | 21.5    | Pressure Ensemb<br>le                                              | 389 |
|    |         |                                                                    |     |
| 22 |         | Entropy for Any Ensemb<br>le                                       | 397 |
|    | 22.1    | General Ensemble                                                   | 397 |
|    | 22.2    | Summation<br>over Energy Levels                                    | 402 |
| 23 |         | Unified Treatment<br>of Idea<br>l Fermi, Bose, and Classical Gases | 405 |
|    | 23.1    | Integr<br>al Formulae                                              | 406 |
|    | 23.2    | The Functions hv(A, a)                                             | 408 |
|    | 23.3    | Virial Expansio<br>ns for Ideal Fermi and Bose Gases               | 410 |
|    | 23.4    | Heat Capacity                                                      | 412 |
|    |         |                                                                    |     |
| 24 |         | Bose Condensat<br>ion                                              | 413 |
|    | 24.l    | Bosons at Low Temperatures                                         | 413 |
|    | 24.2    | Thermodynamic<br>Functions                                         | 416 |
|    | 24.3    | Condensate<br>Region                                               | 421 |
| 25 |         | Degenerate<br>Fermi Gas                                            | 425 |
|    | 25.1    | Ideal Fermi Gas at Low Temperatures                                | 425 |
|    | 25.2    | Free Electron Model of a Metal                                     | 428 |
|    | 25.3    | Thermal Activation of Electrons                                    | 429 |
|    | 25.4    | Pauli Paramagnetism                                                | 433 |
|    | 25.5    | Landau Diamagnetism                                                | 436 |
|    | 25.6    | Thermionic Emission                                                | 439 |
|    | 25.7    | Semiconductors                                                     | 442 |
|    |         |                                                                    |     |
| 26 | Quantum | Statistics                                                         | 451 |
|    | 26.1    | Pure States                                                        | 451 |
|    | 26.2    | Statistical States                                                 | 453 |

|    | 26.3                                            | Random Phases and External Influ<br>ence        | 454 |  |
|----|-------------------------------------------------|-------------------------------------------------|-----|--|
|    | 26.4                                            | Time Evoluti<br>on                              | 455 |  |
|    | 26.5                                            | Densit<br>y Operators for Specific Ensembles    | 456 |  |
|    | 26.6                                            | Examp<br>les of th<br>e Density Matrix          | 459 |  |
|    | 26.7                                            | Indistinguishable<br>Particles                  | 465 |  |
| 27 |                                                 | Ising Model                                     | 469 |  |
|    | 27.1                                            | Ising Model, Mean Fie<br>ld Treatment           | 470 |  |
|    |                                                 |                                                 |     |  |
|    | 27.2                                            | Pair Sta<br>tistics                             | 477 |  |
|    | 27.3                                            | Soluti<br>on in One Dimension<br>for Zero Field | 479 |  |
|    | 27.4                                            | Transfer Matrix                                 | 480 |  |
|    | 27.5                                            | Oth<br>er Methods of Soluti<br>on               | 483 |  |
|    | 27.6                                            | Monte Carlo Simulation                          | 484 |  |
|    | PART Ill                                        | Appendices                                      | 495 |  |
| A  | Stirl                                           | ing<br>'s Approximation                         | 497 |  |
|    | A.l                                             | Elem<br>entary Motivation ofEq. (A.l<br>)       | 498 |  |
|    | A.2                                             | Asymptotic Series                               | 499 |  |
| B  | Use of Jacobians to Convert Partial Derivatives | 503                                             |     |  |
|    | B.l                                             | Properties<br>of Jacobians                      | 503 |  |
|    | B.2                                             | Connect<br>ion to Thermody<br>namic<br>s        | 504 |  |
| C  | Differential                                    | 509                                             |     |  |
|    |                                                 |                                                 |     |  |
|    | C.l                                             | Alterna<br>tive Formulae for<br>~ Vector        | 509 |  |
|    | C.2                                             | Surface Differe<br>nti<br>al Geome<br>try       | 511 |  |
|    | C.3                                             | ~ Vector for Genera<br>l Surfaces               | 516 |  |
|    | C.4                                             | Herring Form<br>ula                             | 518 |  |
| D  | 523<br>Equi<br>librium of Two-State Systems     |                                                 |     |  |

### xiv Table of Contents

| E          |      | Aspects of Canonical Transformations           |     |  |  |
|------------|------|------------------------------------------------|-----|--|--|
|            | E.1  | Necessary and Sufficient Conditions            | 530 |  |  |
|            | E.2  | Restricted Canonical Transformations           | 534 |  |  |
| F          |      | Rotation of Rigid Bodies                       | 537 |  |  |
|            | El   | Moment oflnertia                               | 537 |  |  |
|            | F.2  | Angular Momentum                               | 539 |  |  |
|            | F.3  | Kinetic Energy                                 | 540 |  |  |
|            | F.4  | Time Derivatives                               | 540 |  |  |
|            | F.5  | Rotating Coordinate System                     | 541 |  |  |
|            | F.6  | Matrix Formulation                             | 544 |  |  |
|            | F. 7 | Canonical Variables                            | 546 |  |  |
|            | F.8  | Quantum<br>Energy Levels for Diatomic Molecule | 547 |  |  |
| G          |      | Thermodynamic<br>Perturbation<br>Theory        | 549 |  |  |
|            | G .1 | Classical Case                                 | 549 |  |  |
|            | G.2  | Quantum<br>Case                                | 550 |  |  |
| H          |      | Selected Mathematical<br>Relations             |     |  |  |
|            | H.1  | Bernoulli Numbers and Polynomials              | 553 |  |  |
|            | H.2  | Euler-Maclaur<br>in Sum Formula                | 554 |  |  |
|            |      | Creation and Annihilation<br>Operators         | 559 |  |  |
|            | 1.1  | Harmonic Oscillator                            | 559 |  |  |
|            | 1.2  | Boson Operators                                | 560 |  |  |
|            | 1.3  | Fermion Operators                              | 562 |  |  |
|            | 1.4  | Boson and Fermion Number Operators             | 563 |  |  |
| References |      |                                                | 565 |  |  |
| Index      |      |                                                | 569 |  |  |

![](_page_15_Figure_0.jpeg)

# About the Cover

To represent the many scientists who have made major contributions to the foundations of thermodynamics and statistical mechanics, the cover of this book depicts four significant scientists along with some equations and graphs associated with each of them.

- James Clerk Maxwell (1831-1879) for his work on thermodynamics and especially the kinetic theory of gases, including the Maxwell relations derived from perfect differentials and the Maxwell-Boltzmann Gaussian distribution of gas velocities, a precursor of ensemble theory (see Sections 5.2, 19.4, and 20.1).
- Ludwig Boltzmann (1844-1906) for his statistical approach to mechanics of many particle systems, including his Eta function that describes the decay to equilibrium and his formula showing that the entropy of thermodynamics is proportional to the logarithm of the number of microscopic realizations of a macrosystem (see Chapters 15–17).
- J. Willard Gibbs (1839-1903) for his systematic theoretical development of the thermodynamics of heterogeneous systems and their interfaces, including the definition of chemical potentials and free energy that revolutionized physical chemistry, as well as his development of the ensemble theory of statistical mechanics, including the canonical and grand canonical ensembles. The contributions of Gibbs are ubiquitous in this book, but see especially Chapters 5–8, 12–14, 17, 20, and 21.
- Max Planck (1858-1947, Nobel Prize 1918) for his quantum hypothesis of the energy of cavity radiation (hohlraum blackbody radiation) that connected statistical mechanics to what later became quantum mechanics (see Section 18.3.2); the Planck distribution of radiation flux versus frequency for a temperature 2.725 K describes the cosmic microwave background, first discovered in 1964 as a remnant of the Big Bang and later measured by the COBE satellite launched by NASA in 1989.

The following is a partial list of many others who have also made major contributions to the field, all deceased. Recipients of a Nobel Prize (first awarded in 1901) are denoted by the letter "N" followed by the award year. For brief historical introductions to thermodynamic and statistical mechanics, see Cropper [11, pp. 41-136] and Pathria and Beale [9, pp. xxi-xxvi], respectively. The scientists are listed in the order of their year of birth:

Sadi Carnot (1796-1832); Julius von Mayer (1814-1878); James Joule (1818-1889); Hermann von Helmholtz (1821-1894); Rudolf Clausius (1822-1888); William Thomson, Lord Kelvin (1824-1907); Johannes van der Waals (1837-1923, N1910); Jacobus van't Hoff (1852-1911, N1901); Wilhelm Wien (1864-1928, N1911); Walther Nernst (1864- 1941, N1920); Arnold Sommerfeld (1868-1951); Théophile de Donder (1872-1957); Albert Einstein (1879-1955, N1921); Irving Langmuir (1881-1957, N1932); Erwin Schrödinger (1887-1961, N1933); Satyendra Bose (1894-1974); Pyotr Kapitsa (1894-1984, N1978); William Giauque (1895-1982, N1949); John van Vleck (1899-1980, N1977); Wolfgang Pauli (1900-1958, N1945); Enrico Fermi (1901-1954, N1938); Paul Dirac (1902-1984, N1933); Lars Onsager (1903-1976, N1968); John von Neumann (1903-1957); Lev Landau (1908- 1968, N1962); Claude Shannon (1916-2001); Ilya Prigogine (1917-2003, N1977); Kenneth Wilson (1936-2013, N1982).

# Preface

This book is based on lectures in courses that I taught from 2000 to 2011 in the Department of Physics at Carnegie Mellon University to undergraduates (mostly juniors and seniors) and graduate students (mostly first and second year). Portions are also based on a course that I taught to undergraduate engineers (mostly juniors) in the Department of Metallurgical Engineering and Materials Science in the early 1970s. It began as class notes but started to be organized as a book in 2004. As a work in progress, I made it available on my website as a pdf, password protected for use by my students and a few interested colleagues.

It is my version of what I learned from my own research and self-study of numerous books and papers in preparation for my lectures. Prominent among these sources were the books by Fermi [1], Callen [2], Gibbs [3, 4], Lupis [5], Kittel and Kroemer [6], Landau and Lifshitz [7], and Pathria [8, 9], which are listed in the bibliography. Explicit references to these and other sources are made throughout, but the source of much information is beyond my memory.

Initially it was my intent to give an integrated mixture of thermodynamics and statistical mechanics, but it soon became clear that most students had only a cursory understanding of thermodynamics, having encountered only a brief exposure in introductory physics and chemistry courses. Moreover, I believe that thermodynamics can stand on its own as a discipline based on only a few postulates, or so-called laws, that have stood the test of time experimentally. Although statistical concepts can be used to motivate thermodynamics, it still takes a bold leap to appreciate that thermodynamics is valid, within its intended scope, independent of any statistical mechanical model. As stated by Albert Einstein in Autobiographical Notes (1946) [10]:

*"A theory is the more impressive the greater the simplicity of its premises is, the more different kinds of things it relates, and the more extended is its area of applicability. Therefore the deep impression which classical thermodynamics made on me. It is the only physical theory of universal content concerning which I am convinced that within the framework of the applicability of its basic concepts, it will never be overthrown."*

Of course thermodynamics only allows one to relate various measurable quantities to one another and must appeal to experimental data to get actual values. In that respect, models based on statistical mechanics can greatly enhance thermodynamics by providing values that are independent of experimental measurements. But in the last analysis, any model must be compatible with the laws of thermodynamics in the appropriate limit of sufficiently large systems. Statistical mechanics, however, has the potential to treat smaller systems for which thermodynamics is not applicable.

Consequently, I finally decided to present thermodynamics first, with only a few connections to statistical concepts, and then present statistical mechanics in that context. That allowed me to better treat reversible and irreversible processes as well as to give a thermodynamic treatment of such subjects as phase diagrams, chemical reactions, and anisotropic surfaces and interfaces that are especially valuable to materials scientists and engineers.

The treatment of statistical mechanics begins with a mathematicalmeasure of disorder, quantified by Shannon [48, 49] in the context of information theory. This measure is put forward as a candidate for the entropy, which is formally developed in the context of the microcanonical, canonical, and grand canonical ensembles. Ensembles are first treated from the viewpoint of quantum mechanics, which allows for explicit counting of states. Subsequently, classical versions of the microcanonical and canonical ensembles are presented in which integration over phase space replaces counting of states. Thus, information is lost unless one establishes the number of states to be associated with a phase space volume by requiring agreement with quantum treatments in the limit of high temperatures. This is counter to the historical development of the subject, which was in the context of classical mechanics. Later in the book I discuss the foundation of the quantum mechanical treatment by means of the density operator to represent pure and statistical (mixed) quantum states.

Throughout the book, a number of example problems are presented, immediately followed by their solutions. This serves to clarify and reinforce the presentation but also allows students to develop problem-solving techniques. For several reasons I did not provide lists of problems for students to solve. Many such problems can be found in textbooks now in print, and most of their solutions are on the internet. I leave it to teachers to assign modifications of some of those problems or, even better, to devise new problems whose solutions cannot yet be found on the internet.

The book also contains a number of appendices, mostly to make it self-contained but also to cover technical items whose treatment in the chapters would tend to interrupt the flow of the presentation.

I view this book as an intermediate contribution to the vast subjects of thermodynamics and statistical mechanics. Its level of presentation is intentionally more rigorous and demanding than in introductory books. Its coverage of statistical mechanics is much less extensive than in books that specialize in statistical mechanics, such as the recent third edition of Pathria's book, now authored by Pathria and Beale [9], that contains several new and advanced topics. I suspect the present book will be useful for scientists, particularly physicists and chemists, as well as engineers, particularly materials, chemical, and mechanical engineers. If used as a textbook, many advanced topics can be omitted to suit a one- or two-semester undergraduate course. If used as a graduate text, it could easily provide for a one- or two-semester course. The level of mathematics needed in most parts of the book is advanced calculus, particularly a strong grasp of functions of several variables, partial derivatives, and infinite series as well as an elementary knowledge of differential equations and their solutions. For the treatment of anisotropic surfaces and interfaces, necessary relations of differential geometry are presented in an appendix. For the statistical mechanics part, an appreciation of stationary quantum states, including degenerate states, is essential, but the calculation of such states is not needed. In a few places, I use the notation of the Dirac vector space, bras and kets, to represent quantum states, but always with reference to other representations; the only exceptions are Chapter 26, Quantum Statistics, where the Dirac notation is used to treat the density operator, and Appendix I, where creation and annihilation operators are treated.

I had originally considered additional information for this book, including more of my own research on the thermodynamics of inhomogeneously stressed crystals and a few more chapters on the statistical mechanical aspects of phase transformations. Treatment of the liquid state, foams, and very small systems were other possibilities. I do not address many-body theory, which I leave to other works. There is an introduction to Monte Carlo simulation at the end of Chapter 27, which treats the Ising model. The renormalization group approach is described briefly but not covered in detail. Perhaps I will address some of these topics in later writings, but for now I choose not to add to the already considerable bulk of this work.

Over the years that I shared versions of this book with students, I received some valuable feedback that stimulated revision or augmentation of topics. I thank all those students. A few faculty at other universities used versions for self-study in connection with courses they taught, and also gave me some valuable feedback. I thank these colleagues as well. I am also grateful to my research friends and co-workers at NIST, where I have been a consultant for nearly 45 years, whose questions and comments stimulated a lot of critical thinking; the same applies to many stimulating discussions with my colleagues at Carnegie-Mellon and throughout the world. Singular among those was my friend and fellow CMU faculty member Prof. William W. Mullins who taught me by example the love, joy and methodologies of science. There are other people I could thank individually for contributing in some way to the content of this book but I will not attempt to present such a list. Nevertheless, I alone am responsible for any misconceptions or outright errors that remain in this book and would be grateful to anyone who would bring them to my attention.

In bringing this book to fruition, I would especially like to thank my wife Carolyn for her patience and encouragement and her meticulous proofreading. She is an attorney, not a scientist, but the logic and intellect she brought to the task resulted in my rewriting a number of obtuse sentences and even correcting a number of embarrassing typos and inconsistent notation in the equations. I would also like to thank my friends Susan and John of Cosgrove Communications for their guidance with respect to several aesthetic aspects of this book. Thanks are also due to the folks at my publisher Elsevier: Acquisitions Editor Dr. Anita Koch, who believed in the product and shepherded it through technical review, marketing and finance committees to obtain publication approval; Editorial Project Manager Amy Clark, who guided me though cover and format design as well as the creation of marketing material; and Production Project Manager Paul Prasad Chandramohan, who patiently managed to respond positively to my requests for changes in style and figure placements, as well as my last-minute corrections. Finally, I thank Carnegie Mellon University for providing me with an intellectual home and the freedom to undertake this work.

> Robert F. Sekerka *Pittsburgh, PA*

![](_page_21_Picture_0.jpeg)

# 1

# Introduction

Thermal physics deals with the quantitative physical analysis of macroscopic systems. Such systems consist of a very large number, *N* , of atoms, typically *N* ∼ 1023. According to classical mechanics, a detailed knowledge of the microscopic state of motion (say, position **r***i* and velocity **v***i*) of each atom, *i* = 1, 2, ... , *N* , at some time *t*, even if attainable, would constitute an overwhelmingly huge database that would be practically useless. More useful quantities would be averages, such as the average kinetic energy of an atom in the system, which would be independent of time if the system were in equilibrium. We might also be interested in knowing such things as the volume *V* of the system or the pressure *p* that it exerts on the walls of a containing vessel. In other words, a useful description of a macroscopic system is necessarily statistical and consists of knowledge of a few macroscopic variables that describe the system to our satisfaction.

We shall be concerned primarily with macroscopic systems in a state of equilibrium. An equilibrium state is one whose macroscopic parameters, which we shall call state variables, do not change with time. We accept the proposition, in accord with our experience, that any macroscopic system subject to suitable constraints, such as confinement to a volume and isolation from external forces or sources of matter and energy, will eventually come to a state of equilibrium. Our concept, or model, of the system will dictate the number of state variables that constitute a complete description—a complete set of state variables—of that system. For example, a gas consisting of a single atomic species might be described by three state variables, its energy *U*, its volume *V*, and its number of atoms *N* . Instead of its number of atoms, we usually avoid large numbers and specify its number of moles, *N* := *N* /*N A* where *NA* = 6.02×1023 molecules/mol is Avogadro's number.[1](#page-23-0) The state of a gas consisting of two atomic species, denoted by subscripts 1 and 2, would require four variables, *U*, *V*, *N*1, and *N*2. A simple model of a crystalline solid consisting of one atomic species would require eight variables; these could be taken to be *U*, *V*, *N*, and five more variables needed to describe its state of shear strain[.2](#page-23-1)

### 1.1 Temperature

A price we pay to describe a macroscopic system is the introduction of a state variable, known as the temperature, that is related to statistical concepts and has no counterpart in simple mechanical systems. For the moment, we shall regard the temperature to be an

<span id="page-23-1"></span><span id="page-23-0"></span><sup>1</sup>The notation *A* := *B* means *A* is defined to be equal to *B*, and can be written alternatively as *B* =: *A*.

<sup>2</sup>This is true if the total number of unit cells of the crystal is able to adjust freely, for instance by means of vacancy diffusion; otherwise, a total of nine variables is required because one must add the volume per unit cell to the list of variables. More complex macroscopic systems require more state variables for a complete description, but usually the necessary number of state variables is small.

### 4 THERMAL PHYSICS

empirical quantity, measured by a thermometer, such that temperature is proportional to the expansion that occurs whenever energy is added to matter by means of heat transfer. Examples of thermometers include thermal expansion of mercury in a long glass tube, bending of a bimetallic strip, or expansion of a gas under the constraint of constant pressure. Various thermometers can result in different scales of temperature corresponding to the same physical states, but they can be calibrated to produce a correspondence. If two systems are able to freely exchange energy with one another such that their temperatures are equal and their other macroscopic state variables do not change with time, they are said to be in equilibrium.

From a theoretical point of view, the most important of these empirical temperatures is the temperature θ measured by a gas thermometer consisting of a fixed number of moles *N* of a dilute gas at volume *V* and low pressure *p*. This temperature θ is defined to be proportional to the volume at fixed *p* and *N* by the equation

<span id="page-24-0"></span>
$$\theta := \frac{p}{RN}V,\tag{1.1}$$

where *R* is a constant. For variable *p*, Eq. [(1.1)](#page-24-0) also embodies the laws of Boyle, Charles, and Gay-Lussac. Provided that the gas is sufficiently dilute (small enough *N*/*V*), experiment shows that θ is independent of the particular gas that is used. A gas under such conditions is known as an ideal gas. The temperature θ is called an absolute temperature because it is proportional to *V*, not just linear in *V*. If the constant *R* = 8.314 J/(mol K), then θ is measured in degrees Kelvin, for which one uses the symbol K. On this scale, the freezing point of water at one standard atmosphere of pressure is 273.15 K. Later, in connection with the second law of thermodynamics, we will introduce a unique thermodynamic definition of a temperature, *T*, that is independent of any particular thermometer. Fermi [1, p. 42] uses a Carnot cycle that is based on an ideal gas as a working substance to show that *T* = θ, so henceforth we shall use the symbol *T* for the absolute temperature.[3](#page-24-1)

**Example Problem 1.1.** The Fahrenheit scale ◦F, which is commonly used in the United States, the United Kingdom, and some other related countries, is based on a smaller temperature interval. At one standard atmosphere of pressure, the freezing point of water is 32 ◦F and the boiling point of water is 212 ◦F. How large is the Fahrenheit degree compared to the Celsius degree?

The Rankine scale R is an absolute temperature scale but based on the Fahrenheit degree. At one standard atmosphere of pressure, what are the freezing and boiling points of water on the Rankine scale? What is the value of the triple point of water on the Rankine scale, the Fahrenheit scale and the Celsius scale? What is the value of absolute zero in ◦F?

<span id="page-24-1"></span>3The Kelvin scale is defined such that the triple point of water (solid-liquid-vapor equilibrium) is exactly 273.16 K. The Celsius scale, for which the unit is denoted ◦C, is defined by *T*(◦C) = *T*(K) − 273.15.

*Chapter 1* • Introduction 5

**Solution 1.1.** The temperature interval between the boiling and freezing points of water at one standard atmosphere is 100 ◦C or 212 − 32 = 180 ◦F. Therefore, 1 ◦F = 100/180 = 5/9 ◦C = (5/9)K. The freezing and boiling points of water are 273.15 × (9/5) = 491.67 R and 373.15 × (9/5) = 671.67 R. The triple point of water is 273.16 × (9/5) = 491.688 R = 32.018 ◦F = 0.01 ◦C. The value of absolute zero in ◦F is −(491.67 − 32) = −459.67 ◦F. In the process of introducing temperature, we alluded to the intuitive concept of heat transfer. At this stage, it suffices to say that if two bodies at different temperatures are brought into "thermal contact," a process known as heat conduction can occur that enables energy to be transferred between the bodies even though the bodies exchange no matter and do no mechanical work on one another. This process results in a new equilibrium state and a new common temperature for the combined body. It is common to say that this process involves a "transfer of heat" from the hotter body (higher initial temperature) to the colder body (lower initial temperature). This terminology, however, can be misleading because a conserved quantity known as "heat" does not exist.4 We should really replace the term "transfer of heat" by the longer phrase "transfer of energy by means of a process known as heat transfer that does not involve mechanical work" but we use the shorter phrase for simplicity, in agreement with common usage. The first law of thermodynamics will be used to quantify the amount of energy that can be transferred between bodies without doing mechanical work. The second law of thermodynamics will

### (loosely, "heat") that can be transformed into mechanical work by some process. This second law will involve a new state variable, the entropy *S*, which like the temperature

then be introduced to quantify the maximum amount of energy due to heat transfer

is entirely statistical in nature and has no mechanical counterpart. 1.2 Thermodynamics Versus Statistical Mechanics Thermodynamics is the branch of thermal physics that deals with the interrelationship of macroscopic state variables. It is traditionally based on three so-called laws (or a number of postulates that lead to the same results, see Callen [2, chapter 1]). Based on these laws, thermodynamics is independent of detailed models involving atoms and molecules. It results in criteria involving state variables that must be true of systems that are in equilibrium with one another. It allows us to develop relationships among measurable quantities (e.g., thermal expansion, heat capacity, compressibility) that can be represented by state variables and their derivatives. It also results in inequalities that must be obeyed by any naturally occurring process. It does not, however, provide *values* of the quantities with which it deals, only their interrelationship. Values must be provided by experiments or by models based on statistical mechanics. For an historical introduction to thermodynamics,

4Such a quantity was once thought to exist and was called caloric.

see Cropper [11, p. 41].

### 6 THERMAL PHYSICS

Statistical mechanics is based on the application of statistics to large numbers of atoms (or particles) that obey the laws of mechanics, strictly speaking quantum mechanics, but in limiting cases, classical mechanics. It is based on postulates that relate certain types of averages, known as ensemble averages, to measurable quantities and to thermodynamic state variables, such as entropy mentioned above. Statistical mechanics can be used to rationalize the laws of thermodynamics, although it is based on its own postulates which were motivated by thermodynamics. By using statistical mechanics, specific models can be analyzed to provide values of the quantities employed by thermodynamics and measured by experiments. In this sense, statistical mechanics appears to be more complete; however, it must be borne in mind that the validity of its results depends on the validity of the models. Statistical mechanics can, however, be used to describe systems that are too small for thermodynamics to be applicable. For an excellent historical introduction to statistical mechanics, see Pathria and Beale [9, pp. xxi-xxvi].

A crude analogy with aspects of mathematics may be helpful here: thermodynamics is to statistical mechanics as Euclidean geometry is to analytic geometry and trigonometry. Given the few postulates of Euclidean geometry, which allow things such as lengths and angles to be compared but never measured, one can prove very useful and general theorems involving the interrelationships of geometric forms, for example, congruence, similarity, bisections, conditions for lines to be parallel or perpendicular, and conditions for common tangency. But one cannot assign numbers to these geometrical quantities. Analytic geometry and trigonometry provide quantitative measures of the ingredients of Euclidean geometry. These measures must be compatible with Euclidean geometry but they also supply precise information about such things as the length of a line or the size of an angle. Moreover, trigonometric identities can be quite complicated and transcend simple geometrical construction.

### 1.3 Classification of State Variables

Much of our treatment will be concerned with homogeneous bulk systems in a state of equilibrium. By bulk systems, we refer to large systems for which surfaces, either external or internal, make negligible contributions. As a simple example, consider a sample in the shape of a sphere of radius *R* and having volume *V* = (4/3)π*R*3 and surface area *A* = 4π*R*2. If each atom in the sample occupies a volume *a*3, then for *a R*, the ratio of the number of surface atoms to the number of bulk atoms is approximately

$$\sigma = \frac{4\pi (R/a)^2}{(4/3)\pi (R/a)^3 - 4\pi (R/a)^2} \sim 3(a/R) \ll 1. \tag{1.2}$$

For a sufficiently large sphere, the number of surface atoms is completely negligible compared to the number of bulk atoms, and so presumably is their energy and other properties. More generally, for a bulk sample having *N* atoms, roughly *N* 2/3 are near the surface, so the ratio of surface to bulk atoms is roughly *r* ∼ *N* −1/3. For a mole of atoms, we have *N* ∼ 6 × 1023 and *r* ∼ 10−8. In defining bulk samples, we must be careful to *Chapter 1* • Introduction 7

exclude samples such as thin films or thin rods for which one or more dimension is small compared to others. Thus, a thin film of area *L*[2](#page-27-0) and thickness *H L* contains roughly *N* ∼ *L*2*H*/*a*3 atoms, but about 2*L*2/*a*2 of these are on its surfaces. Thus, the ratio of surface to bulk atoms is *r* ∼ *a*/*H* which will not be negligible for a sufficiently thin film. We must also exclude samples that are finely subdivided, such as those containing many internal cavities. From the considerations of the preceding paragraph, atoms of bulk samples can be regarded as being equivalent to one another, independent of location. It follows that certain state variables needed to describe such systems are proportional to the number of atoms. For example, for a homogeneous sample, total energy *U* ∝ *N* and total volume *V* ∝ *N* , provided we agree to exclude from consideration small values of *N* that

would violate the idealization of a bulk sample.5 State variables of a homogeneous bulk thermodynamic system that are proportional to its number of atoms are called **extensive** variables. They are proportional to the "extent" or "size" of the sample. For a homogeneous gas consisting of three atomic species, a complete set of extensive state variables could be taken to be *U*, *V*, *N*1, *N*2, and *N*3, where the *Ni* are the number of moles of atomic species *i*. There is a second kind of state variable that is independent of the "extent" of the sample. Such a variable is known as an **intensive** variable. An example of such a variable would

$$\frac{\mathrm{d}U}{\mathrm{d}V} = \lim_{\Delta V \to 0} \frac{U(V + \Delta V) - U(V)}{\Delta V}. \tag{1.3}$$

extensive variable with respect to some other extensive variable. This follows because a derivative is defined to be a limit of a ratio, for example, d*U* d*V* = lim *V*→0 *U*(*V* + *V*) − *U*(*V*) *V* . (1.3) If other quantities are held constant during this differentiation, the result is a partial

$$p = -\frac{\partial U}{\partial V} \tag{1.4}$$

<span id="page-27-0"></span>state variable, can be expressed as *p* = −∂*U* ∂*V* (1.4) provided that certain other variables are held constant; these variables are the entropy *S*, an extensive variable alluded to previously, as well as all other extensive variables of a remaining complete set. Another important intensive variable is the absolute temperature

*T*, which we shall see can also be expressed as a partial derivative of *U* with respect to the entropy *S* while holding constant all other extensive variables of a remaining complete set. Since the intensive variables are ratios or derivatives involving extensive variables, we will not be surprised to learn that the total number of *independent intensive* variables is

one less than the total number of *independent extensive* variables. The total number of

5The symbol ∝ means "proportional to."

8 THERMAL PHYSICS

### independent intensive variables of a thermodynamic system is known as its number of **degrees of freedom**, usually a small number which should not be confused with the huge

will be important in thermodynamics.

number of microscopic degrees of freedom 6*N* for *N* particles that one would treat by classical statistical mechanics. In Chapter 5, we shall return to a systematic treatment of extensive and intensive variables and their treatment via Euler's theorem of homogeneous functions.

### 1.4 Energy in Mechanics

The concept of energy is usually introduced in the context of classical mechanics. We

<span id="page-28-1"></span>*m*

*m* d*x* d*t*

d*t*

2

$$m\frac{\mathbf{d}^2x}{\mathbf{d}t^2} = F,\tag{1.5}$$

1.4.1 Single Particle in One Dimension A single particle of mass *m* moving in one dimension, *x*, obeys Newton's la[w](#page-28-0)

<span id="page-28-0"></span>
$$V(\mathbf{x}) = -\int_{\mathbf{x}_0}^{\mathbf{x}} F(\mathbf{u}) \, \mathbf{d}u,\tag{1.6}$$

where *t* is the time and *F*(*x*) is the force acting on the particle when it is at position *x*. We introduce the potential energy function *V*(*x*) = − *x x*0 *F*(*u*) d*u*, (1.6) which is the negative of the work don[e by](#page-28-1) the force on the particle when the particle

$$m\frac{d\mathbf{x}}{dt}\frac{d^2\mathbf{x}}{dt^2} + \frac{\mathbf{d}V}{\mathbf{d}x}\frac{d\mathbf{x}}{dt} = \mathbf{0},\tag{1.7}$$

to obtain

<span id="page-28-2"></span>
$$\frac{\mathbf{d}}{\mathbf{d}t} \left[ \frac{1}{2} m v^2 + V \right] = \mathbf{0},\tag{1.8}$$

which can be rewritten as d 1 *mv* 2 + *V* = 0, (1.8)

$$
\frac{1}{2}mv^2 + V = E,\tag{1.9}
$$

1 2 *mv* 2 + *V* = *E*, (1.9) where *E* is independent of time and known as the total energy. The first term in Eq. (1.9) is known as the kinetic energy and the equation states that the sum of the kinetic and potential energy is some constant, independent of time. It is important to note, however, that the value of *E* is undetermined up to an additive constant. This arises as follows: If some constant *V*0 is added to the potential energy *V*(*x*)to form a new potential*V*˜ := *V*+*V*0, the same force results because

$$-\frac{d\tilde{V}}{dx} = -\frac{d}{dx}(V + V_0) = -\frac{dV}{dx} = F.\tag{1.10}$$

$$
\frac{1}{2}mv^2 + \tilde{V} = \tilde{E},
\tag{1.11}
$$

*Chapter 1* • Introduction 9 − d*V*˜ d*x* = − d d*x* (*V* + *V*0) = −d*V* d*x* = *F*. (1.10) Thus, Eq. (1.9) could equally well be written 1 2 *mv* 2 + *V*˜ = *E*˜, (1.11) where *E*˜ is a new constant. Comparison of Eq. (1.11) with Eq. (1.9) shows that *E*˜ = *E* + *V*0,

so the total energy shifts by the constant amount *V*0. Therefore, only differences in energy have physical meaning; to obtain a numerical value of the energy, one must always measure energy relative to some well-defined state of the particle or, what amounts to the same thing[, ado](#page-28-2)pt the *convention* that the energy in some well-defined state is equal to zero. In view of Eq. (1.6), the potential energy *V*(*x*) will be zero when *x* = *x*0, but the choice of *x*0 is arbitrary. In classical mechanics, it is possible to consider more general force laws such as *F*(*x*,*t*) in which case the force at point *x* depends *explicitly* on the time that the particle is at point *x*. In that case, we can obtain (d/d*t*)(1/2)*mv* 2 = *Fv* where *Fv* is the power supplied

### <span id="page-29-0"></span>explicitly on velocity as well as time. In such cases, one must solve the problem explicitly for the functions *x*(*t*) and *v*(*t*) before the power can be evaluated. In these cases, the total

energy of the system changes with time and it is not possible to obtain an energy integral as given by Eq. (1.9). 1.4.2 Single Particle in Three Dimensions

by the force. Similar considerations apply for forces of [the](#page-28-0) form *F*(*x*, *v*,*t*) that can depend

$$m\frac{\mathbf{d}^2 \mathbf{r}}{\mathbf{d}t^2} = \mathbf{F},\tag{1.12}$$
 
$$\mathbf{d} = \begin{bmatrix} \mathbf{d} \\ \mathbf{d} \end{bmatrix} \begin{bmatrix} \mathbf{d} \\ \mathbf{d} \end{bmatrix} = \mathbf{F},\tag{1.12}$$

the vector **r** with Cartesian coordinates *x*, *y*, and *z*, Eq. (1.5) takes the form *m* d2**r**

d*t*2 = **F**, (1.12) where **F**(**r**) is now a vector force at the point **r**. The mechanical work done by the force on the particle *along a specified path* leading from **r***A* to **r***B* is now given by

*W***r***A* to **r***B* = - **F** · d**r**. (1.13)

$$
\int (\nabla \times \mathbf{F}) \cdot \mathbf{dA} = \oint \mathbf{F} \cdot \mathbf{dr}, \quad \text{closed loop}, \tag{1.14}
$$

-(**∇** × **F**) · d**A** = **F** · d**r**, closed loop, (1.14) where the integral on the right is a line integral around a closed loop and the integral on the left is over an area that subtends that loop. For a force such that **∇** × **F** = **0**, we see that the line integral around any closed loop is equal to zero. Thus, if we integrate from *A* to *B* along path 1 and from *B* back to *A* along some other path 2 we get zero. But the latter integral is just the negative of the integral from *A* to *B* along path 2, so the integral from *A*

to *B* is the same along path 1 as along path 2. For such a force, it follows that the work

$$W_{AB} = \int_{\mathbf{r}_A}^{\mathbf{r}_B} \mathbf{F} \cdot \mathbf{dr}, \quad \text{any path}, \tag{1.15}$$

is independent of path and depends only on the end points. Such a force is called a conservative force and may be represented as the gradient of a potential

$$V(\mathbf{r}) = -\int_{\mathbf{r}_0}^{\mathbf{r}} \mathbf{F}(\mathbf{r}') \cdot \mathbf{dr}' \tag{1.16}$$

such that **F** = −∇*V*. In this case, it follows that the work

$$\mathcal{W}_{AB} = -\int_{\mathbf{r}_A}^{\mathbf{r}_B} \nabla V \cdot \mathbf{dr} = -\int_{\mathbf{r}_A}^{\mathbf{r}_B} \mathbf{d}V = V(\mathbf{r}_A) - V(\mathbf{r}_B). \tag{1.17}$$

For such a conservative force, we can dot the vector **v** := d**r**/d*t* into Eq. [(1.12)](#page-29-0) to obtain

$$m\frac{\mathbf{dr}}{\mathbf{d}t} \cdot \frac{\mathbf{d}^2 \mathbf{r}}{\mathbf{d}t^2} + \frac{\mathbf{dr}}{\mathbf{d}t} \cdot \nabla V = 0.\tag{1.18}$$

Then by noting that

$$\frac{\mathbf{d}}{\mathbf{d}t}(1/2)m\mathbf{v}\cdot\mathbf{v} = m\frac{\mathbf{d}\mathbf{r}}{\mathbf{d}t}\cdot\frac{\mathbf{d}^2\mathbf{r}}{\mathbf{d}t^2} \quad \text{and} \quad \frac{\mathbf{d}V}{\mathbf{d}t} = \frac{\mathbf{d}\mathbf{r}}{\mathbf{d}t}\cdot\nabla V,\tag{1.19}$$

we are led immediately to Eq. [(1.8)](#page-28-1) and its energy integral Eq. [(1.9)](#page-28-2) just as in one dimension, except now *v* 2 = **v** · **v** in the kinetic energy.

### 1.4.3 System of Particles

We next consider a system of particles, *k* = 1, 2, ... , *N* , having masses *mk*, positions **r***k*, and velocities **v***k* = d**r***k*/d*t*. Each particle is assumed to be subjected to a conservative force

$$\mathbf{F}_k = -\nabla_k V(\mathbf{r}_1, \mathbf{r}_2, \dots, \mathbf{r}_N), \tag{1.20}$$

where ∇*k* is a gradient operator that acts only on **r***k*. Then by writing Newton's equations in the form of Eq. [(1.12)](#page-29-0) for each value of *k*, summing over *k* and proceeding as above, we obtain

<span id="page-30-0"></span>
$$\frac{\mathbf{d}}{\mathbf{d}t}[\mathcal{T}+V] = \mathbf{0},\tag{1.21}$$

where the total kinetic energy

$$\mathcal{T} \coloneqq \sum_{k=1}^{N} \frac{1}{2} m_k \mathbf{v}_k \cdot \mathbf{v}_k \tag{1.22}$$

and

$$\frac{\mathbf{d}V}{\mathbf{d}t} = \sum_{k=1}^{N} \frac{\mathbf{d}\mathbf{r}_k}{\mathbf{d}t} \cdot \nabla_k V. \tag{1.23}$$

Furthermore, we can suppose that the forces on each particle can be decomposed into internal forces **F**i due to the other particles in the system and to external forces **F**e, that is, **F** = **F**i + **F**e. Since these forces are additive, we also have a decomposition of the potential, *V* = *V*i + *V*e, into internal and external parts. The integral of Eq. [(1.21)](#page-30-0) can therefore be written in the form

<span id="page-31-2"></span>
$$\mathcal{T} + V^{\dagger} + V^{\mathbf{e}} = E,\tag{1.24}$$

where *E* is the total energy constant. This suggests a related decomposition of *T* which we proceed to explore.

We introduce the position vector of the center of mass of the system of particles, defined by

$$\mathbf{R} := \frac{1}{M} \sum_{k=1}^{N} m_k \mathbf{r}_{k^*} \tag{1.25}$$

where *M* := *N k*=1 *mk* is the total mass of the system. The velocity of the center of mass is

<span id="page-31-1"></span>
$$\mathbf{V} \coloneqq \frac{\mathbf{dR}}{\mathbf{d}t} = \frac{1}{M} \sum_{k=1}^{N} m_k \mathbf{v}_k. \tag{1.26}$$

The kinetic energy relative to the center of mass, namely *T* i , can be written

<span id="page-31-0"></span>
$$\mathcal{T}^{\dagger} := \frac{1}{2} \sum_{k=1}^{N} m_k (\mathbf{v}_k - \mathbf{V}) \cdot (\mathbf{v}_k - \mathbf{V}) = \mathcal{T} - \frac{1}{2} M V^2. \tag{1.27}$$

Eq. [(1.27)](#page-31-0) may be verified readily by expanding the left-hand side to obtain four terms and then using Eq. [(1.26)](#page-31-1). The term (1/2)*MV*2 is recognized as the kinetic energy associated with motion of the center of mass of the system. Equation [(1.24)](#page-31-2) can therefore be written

$$V\mathcal{T}^{\mathbb{L}} + V^{\mathbb{L}} + \frac{1}{2}MV^2 + V^{\mathbb{e}} = E. \tag{1.28}$$

The portion of this energy exclusive of the kinetic energy of the center of mass and the external forces, namely *U* = *T* i + *V*i , is an internal energy of the system of particles and is the energy usually dealt with in thermodynamics. Thus, when energies of a thermodynamic system are compared, they are compared under the assumption that the state of overall motion of the system, and hence its overall motional kinetic energy, (1/2)*MV*2, is unchanged. This is equivalent to supposing that the system is originally at rest and remains at rest. Moreover, it is usually assumed that there are no external forces so the interaction energy *V*e is just a constant. Thus, the energy integral is usually viewed in the form

$$U = \colon \mathcal{T}^{\mathbb{L}} + V^{\mathbb{L}} = E - \frac{1}{2}MV^2 - V^{\mathbb{e}} =: U_0,\tag{1.29}$$

where *U*0 is a new constant. If such a system does interact with its environment, *U* is no longer a constant. Indeed, if the system does work or if there is heat transfer from its environment, *U* will change according to the first law of thermodynamics, which is taken up in Chapter 2.

Sometimes one chooses to include conservative external forces in the energy used in thermodynamics. Such treatments require the use of a generalized energy that includes potential energy due to conservative external forces, such as those associated with gravity or an external electric field. In that case, one deals with the quantity

$$
\tilde{U} = \colon \mathcal{T}^{\mathsf{I}} + V^{\mathsf{I}} + V^{\mathsf{e}} = E - \frac{1}{2}MV^2. \tag{1.30}
$$

In terms of chemical potentials, which we shall discuss in Chapter 12, such external forces give rise to gravitational chemical potentials and electrochemical potentials that play the role [6, p. 122] of intrinsic chemical potentials when external fields are present. It is also possible to treat uniformly rotating coordinate systems by including in the thermodynamic energy the effective potential associated with fictitious centrifugal forces [7, p. 72].

### 1.5 Elementary Kinetic Theory

More insight into the state variables temperature *T* and pressure *p* can be gained by considering the elementary kinetic theory of gases. We consider a monatomic ideal gas having particles of mass *m* that do not interact and whose center of mass remains at rest. Its kinetic energy is

$$\mathcal{T} = \frac{1}{2} \sum_{k=1}^{N} m \frac{\mathbf{d} \mathbf{r}_k}{\mathbf{d}t} \cdot \frac{\mathbf{d} \mathbf{r}_k}{\mathbf{d}t} = \frac{1}{2} \sum_{k=1}^{N} m \mathbf{v}_k^2. \tag{1.31}$$

If the gas is in equilibrium, the time average *T* of this kinetic energy is a constant. This kinetic energy represents the vigor of motion of the atoms, so it is natural to suppose that it increases with temperature because temperature can be increased by adding energy due to heat transfer. A simple and fruitful assumption is to assume that *T* is proportional to the temperature. In particular, we postulate that the time average kinetic energy per atom is related to the temperature b[y6](#page-32-0)

<span id="page-32-1"></span>
$$\frac{1}{N}\overline{\mathcal{T}} = \frac{1}{2N}\overline{\sum_{k=1}^{N}m\mathbf{v}_k^2} = \frac{3}{2}k_B T,\tag{1.32}$$

where *k*B is a constant known as Boltzmann's constant. In fact, *k*B = *R*/*NA* where *R* is the gas constant introduced in Eq. [(1.1)](#page-24-0) and *NA* is Avogadro's number. We shall see that Eq. [(1.32)](#page-32-1) makes sense by considering the pressure of an ideal gas.

The pressure *p* of an ideal gas is the force per unit area exerted on the walls of a containing box. For simplicity, we treat a monatomic gas and assume for now that each atom of the gas has the same speed *v*, although we know that there is really a distribution of speeds given by the Maxwell distribution, to be discussed in Chapter 19. We consider

<span id="page-32-0"></span>6If the center of mass of the gas were not at rest, Eq. [(1.27)](#page-31-0) would apply and *T* would have to be replaced by *T* i . In other words, the kinetic energy (1/2)*MV*2 of the center of mass makes no contribution to the temperature. an infinitesimal area d*A* of a wall perpendicular to the *x* direction and gas atoms with velocities that make an angle of θ with respect to the positive *x* direction. In a time d*t*, all atoms in a volume *v* d*t* d*A* cos θ will strike the wall at d*A*, provided that 0 < θ < π/2. Each atom will collide with the wall with momentum *m v* cos θ and be reflected with the same momentum,[7](#page-33-0) so each collision will contribute a force (1/d*t*)2*m v* cos θ, which is the time rate of change of momentum. The total pressure (force per unit area) is therefore

$$p = \frac{1}{2} \left\langle \frac{n(v \,\mathrm{d}t \,\mathrm{d}A \cos\theta)(2m \, v \cos\theta)}{\mathrm{d}A \,\mathrm{d}t} \right\rangle = nm(v^2 \cos^2\theta) = nm(v_x^2),\tag{1.33}$$

where *n* is the number of atoms per unit volume and the angular brackets denote an average over time and all θ. The factor of 1/2 arises because of the restriction 0 < θ < π/2. Since the gas is isotropic, *v* 2 *x* = *v* 2 *y* = *v* 2 *z* = (1/3) *v* 2 . Therefore[,8](#page-33-1)

<span id="page-33-2"></span>
$$p = \frac{1}{3}nm(v^2) = \frac{2}{3}n\frac{\overline{\mathcal{T}}}{\mathcal{N}} = nk_B T = \frac{NR}{V}T,\tag{1.34}$$

where Eq. [(1.32)](#page-32-1) has been used. Equation [(1.34)](#page-33-2) is the well-known ideal gas law, in agreement with Eq. [(1.1)](#page-24-0) if the absolute temperature is denoted by *T*. In the case of an ideal gas, all of the internal energy is kinetic, so the total internal energy is *U* = *T* . Eq. [(1.34)](#page-33-2) therefore leads to *p* = (2/3)(*U*/*V*), which is also true for an ideal monatomic gas.

These simple relations from elementary kinetic theory are often used in thermodynamic examples and are borne out by statistical mechanics.

<span id="page-33-0"></span><sup>7</sup>Reflection with the same momentum would require specular reflection from perfectly reflecting walls, but irrespective of the nature of actual walls, one must have reflection with the same momentum *on average* to avoid a net exchange of energy.

<span id="page-33-1"></span><sup>8</sup>If we had accounted for a Maxwell distribution of speeds, this result would still hold provided that we interpret *v* 2 to be an average of the square of the velocity with respect to that distribution. See Eqs. (20.28-20.30) for details.

![](_page_35_Picture_0.jpeg)

# First Law of Thermodynamics

The first law of thermodynamics extends the concept of energy from mechanical systems to thermodynamic systems, specifically recognizing that a process known as heat transfer can result in a transfer of energy to the system in addition to energy transferred by mechanical work. We first state the law and then discuss the terminology used to express it. As stated below, the law applies to a **chemically closed system**, by which we mean that the system can exchange energy with its environment by means of heat transfer and work but cannot exchange mass of any chemical species with its environment. This definition is used by most chemists; many physicists and engineers use it as well but it is not universal. Some authors, such as Callen [2] and Chandler [12], regard a closed system as one that can exchange nothing with its environment. In this book, we refer to a system that can exchange nothing with its environment as an **isolated system**.

### 2.1 Statement of the First Law

For a thermodynamic system, there exists an extensive function of state, *U*, called the **internal energy**. Every equilibrium state of a system can be described by a complete set of (macroscopic) *state variables*. The number of such state variables depends on the complexity of the system and is usually small. For now we can suppose that *U* depends on the temperature *T* and additional extensive state variables needed to form a complete set.[1](#page-35-0) Alternatively, any equilibrium state can be described by a complete set of extensive state variables that includes *U*. For a chemically closed system, the change -*U* from an initial to a final state is equal to the heat, *Q*, added *to the system* minus the work, *W*, done *by the system*, resulting in[2](#page-35-1)

<span id="page-35-2"></span>
$$
\Delta U = Q - \mathcal{W}.\tag{2.1}
$$

*Q* and *W* are not functions of state because they depend on the path taken during the process that brings about the change, not on just the initial and final states. Eq. [(2.1)](#page-35-2)

<span id="page-35-0"></span>1There are other possible choices of a complete set of state variables. For example, a homogeneous isotropic fluid composed a single chemical component can be described by three extensive variables, the internal energy *U*, the volume *V*, and the number of moles *N*. One could also choose state variables *T*, *V*, and *N* and express *U* as a function of them, and hence a function of state. Alternatively, *U* could be expressed as a function of *T*, the pressure *p*, and *N*. In Chapter 3, we introduce an extensive state variable *S*, the entropy, in which case *U* can be expressed as a function of a complete set of extensive variables including *S*, known as a fundamental equation.

<span id="page-35-1"></span>2In agreement with common usage, we use the terminology "heat transferred to the system" or "heat added to the system" in place of the longer phrase "energy transferred to the system by means of a process known as heat transfer that does not involve mechanical work."

16 THERMAL PHYSICS

to live with it.

$$
\delta U = \delta Q - \delta \mathcal{W}, \quad \text{infinitesimal change.} \tag{2.2}
$$

actually defines *Q*, since -*U* and *W* can be measured independently, as will be discussed

### in detail in Section 2.1.1. If there is an infinitesimal amount of heat δ*Q* transferred to the system and the system

does an infinitesimal amount of work δ*W*, the change in the internal energy is d*U* = δ*Q* − δ*W*, infinitesimal change. (2.2) For an isolated system, -*U* = 0, and for such a system, the internal energy is a constant. 2.1.1 Discussion of the First Law As explained in Chapter 1, the term internal energy usually excludes kinetic energy of motion of the center of mass of the entire [m](#page-36-0)acroscopic system, as well as energy associated with overall rotation (total angular momentum). The internal energy also usually excludes

the energy due to the presence of external fields, although it is sometimes redefined to include conservative potentials. We will only treat thermodynamic systems that are at rest with respect to the observer (zero kinetic energy due to motion of the center of mass or total angular momentum). For further discussion of this point, see Landau and Lifshitz

[7, p. 34]. We emphasize that *W* is positive if work is done by the system on its environment. Many authors, however, state the first law in terms of the work *W* = −*W* done by the environment on the system by some external agent. In this case, the first law would read -*U* = *Q* + *W*. This is especially common3 in Europe [14] and Russia [7]. The symbol applied to any **state function** means the value of that function in the final state (after some process) minus the value of that function in the initial state. Specifically, -*U* := *U*(final state) − *U*(initial state). As mentioned above, *Q* and *W* are *not* state functions, although their difference is a state function. As will be illustrated below, *Q* and *W* depend on the details of the *process* used to change the state function *U*. In other words, *Q* and *W* depend on the *path* followed during a process. Therefore, it makes no sense to

<span id="page-36-0"></span>apply the symbol or the differential symbol d to *Q* or *W*. We use δ*Q* and δ*W* to denote *infinitesimal transfers* of energy to remind ourselves that *Q* and *W* are not state functions. Some authors [6, 12] use a d with a superimposed strikethrough (d) instead of δ. The first law of thermodynamics is a theoretical generalization based on many experiments. Particularly noteworthy are the experiments of Joule who found that for two states of a closed thermodynamic system, say *A* and *B*, it is always possible to cause a

transition that connects *A* to *B* by a process in which the system is thermally insulated, so

δ*Q* = 0 at every stage of the process. This also means that *Q* = 0 for the whole process. 3Fermi [1] uses the symbol *L* for the work done by the system; note that the Italian word for work is 'lavoro' (cognate labor). The introductory physics textbook by Young and Freedman [13] also states the first law of thermodynamics in terms of the work done by the system. Landau and Lifshitz [7] use the symbol *R* ≡ −*W* ('rabota') to denote the work done on the system. Chandler [12] and Kittel and Kroemer [6] use *W* ≡ −*W* to denote the work done on the system. This matter of notation and conventions can cause confusion, but we have *Chapter 2* • First Law of Thermodynamics 17

Thus by work alone, either the transformation *A* → *B* or the transformation *B* → *A* is possible. Since the energy change due to work alone is well defined in terms of mechanical concepts, it is possible to establish either the energy difference *UA* − *UB* or its negative *UB* − *UA*. The fact that one of these transformations might be impossible is related to concepts of irreversibility, which we will discuss later in the context of the second law of thermodynamics. According to the first law, as recognized by Rudolf Clausius in 1850, **heat transfer** accounts for energy received by the system in forms other than work. Since -*U* can be

measured and *W* can be determined for any mechanical process, *Q* is actually *defined* by Eq. (2.1). It is common to measure the amount of energy due to heat transfer in units of calories. One calorie is the amount of heat necessary to raise the temperature of one gram (10−3 kg) of water from 14 ◦C to 15 ◦C at standard atmospheric pressure. The mechanical equivalent of this heat is 1 calorie = 4.184 J = 4.184×107 erg. The amount of heat required to raise the temperature by -*T* of an arbitrary amount of water is proportional to its mass. It was once believed that heat was a conserved quantity called caloric, and hence the unit calorie, but no such conserved quantity exists. This discovery is usually attributed to Count Rumford who noticed that water used to cool a cannon during boring would be brought to a boil more easily when the boring tool became dull, resulting in even [less remova](#page-39-0)l of metal. Thus, "heat" appears to be able to be produced in virtually unlimited amounts by doing mechanical work, and thus cannot be a conserved quantity. Therefore, we must bear in mind that heat transfer refers to a *process* for energy transfer and that there is actually no identifiable quantity, "heat," that is transported. From an atomistic [po](#page-37-0)int of view, we can think of conducted heat as energy transferred by means

of microscopic atomic or molecular collisions in processes that occur without the transfer of matter and without changing the macroscopic physical boundaries of the system under consideration. Heat can also be transferred by radiation that is emitted or absorbed by a system. We can enclose a system of interest and a heat source of known heat capacity (see Section 2.3) by insulation to form a calorimeter, assumed to be an isolated system, and allow the combined system to come to equilibrium. The temperature change of the heat source will allow determination of the amount of energy transferred from it (or to it) by

### <span id="page-37-0"></span>means of heat transfer and this will equal the increase (or decrease) in energy of the system of interest.4

taken into account.

2.2 Quasistatic Work If a thermodynamic system changes its volume *V* by an amount d*V* and does work against

$$
\delta \mathcal{W} = \mathfrak{p}_{\text{ext}} \,\mathrm{d}V.\tag{2.3}
$$

<span id="page-37-1"></span>δ*W* = *p*ext d*V*. (2.3)

4If the heat source changes volume, it could exchange work with its environment and this would have to be

part of [a sys](#page-38-0)tem by a rope.

18 THERMAL PHYSICS This external pressure can be established by purely mechanical means. For example, an

external force *F*ext acting on a piston of area *A* would give rise to an external pressure *p*ext = *F*ext/*A*. Note that Eq. (2.3) is valid for a fluid system even if the process being considered is so rapid and violent that an internal pressure of the system cannot be defined during the process. This equation can also be generalized for a more complex system as long as one uses actual mechanical external forces and the distances through which they displace portions of the system, for example, pushing on part of the system by a rod or pulling on

<span id="page-38-2"></span><span id="page-38-0"></span>
$$
\delta \mathcal{W} = p \, \mathbf{d} \, V, \quad \text{quasistatic work.} \tag{2.4}
$$

gas) expands or contracts sufficiently slowly (hence the term "quasistatic") that the sy[stem](#page-37-1) is practically in equilibrium at each instant of time, it will have a well-defined internal

If an isotropic system (same in all directions, as would be true for a fluid, a liquid or a

pressure *p*. Under such conditions, *p* ≈ *p*ext and the system will do an infinitesimal amount of work δ*W* = *p* d*V*, quasistatic work. (2.4) Note that δ*W* and d*V* are positive if work is done by the system and both are negative if

$$
\delta \mathcal{W} < \mathbf{p} \,\mathrm{d}V,\quad\text{actual process.}\tag{2.5}
$$

need *p* to be at least slightly different from *p*ext to provide a net force in the prop[er](#page-38-1) direction. This requir[es](#page-38-0) (*p* − *p*ext) d*[V](#page-38-2)* > 0. Thus *p*ext d*V* < *p* d*V* which, in view of Eq. (2.3), may be written δ*W* < *p* d*V*, actual process. (2.5) For the case of quasistatic work, it will be necessary for *p* to be slightly greater than *p*ext for the system to expand (d*V* > 0); conversely, it will be necessary for *p* to be slightly less than *p*ext for the system to contract. These small differences are assumed to be second order and are ignored in writing Eq. (2.4). Consistent with this idealization, a process of

$$
\delta \mathcal{W} \le p \,\mathrm{d}V \tag{2.6}
$$

We can combine Eq. (2.4) with Eq. (2.5) to obtain δ*W* ≤ *p* d*V* (2.6)

<span id="page-38-1"></span>with the understanding that the inequality applies to all actual processes (which are irre-

of the system. It makes no sense to write this expression with lower and upper limits of

reversible. For example, an irreversible chemical reaction would be forbidden.

$$\mathcal{W} = \int_{\text{path}} p \, \text{d}V, \quad \text{quasisstatic work.} \tag{2.7}$$

*W* = path *p* d*V*, quasistatic work. (2.7) To evaluate this integral, we *must* specify the path that connects the initial and final states

5A process involving quasistatic work will be reversible only if all other processes that go on in the system are

<span id="page-39-1"></span>![](_page_39_Figure_1.jpeg)

*p V*1*, p*1 I

*V*

*V*1 *V*2

**FIGURE 2–1** Illustrat[ion](#page-39-1) [of](#page-39-1) [quasist](#page-39-1)atic work for a system whose states can be represented by points in the *V*, *p* plane. The system makes a quasistatic transition from a state at *V*1, *p*1 to a state *V*2, *p*2 by two different paths, I and II. According to Eq. (2.7), the quasistatic work is the area under each curve and is obviously greater for path II. The difference in work is the area between the paths. Since -*U* for the two paths is the same, the difference in the heat *Q* for the two paths is also equal to the area between the paths. integration unless the path is clearly specified. For a system whose equilibrium states

can be represented by points in the *V*, *p* plane, the quasistatic work is represented by the area under the curve that represents the path that connects the initial and final states, as illustrated in Figure 2–1. Since the areas under two curves that connect the same two end points can be different, the quasistatic work *W* clearly depends on the path. Since *Q* = -*U* + *W* and -*U* is independent of path, *Q* also depends on path. If work and heat are exchanged with a system, it is important to recognize that the internal energy of the system will not be partitioned in any way that allows part of it to be associated with heat and part with work. That is because work and heat refer to *processes* for changing the energy of a system and lose their identity once equilibrium is attained and the energy of the system is established. On the other hand, other state variables of the system can differ depending on the relative amounts of heat and work that bring about the same change of internal energy. For example, consider two alternative processes in which the internal energy of [an i](#page-38-0)deal gas is increased by exactly the same amount, the first by means of only work done by a constant external pressure *p*ext and the second by means of only heat transfer. In the case of only work, the volume of the gas will necessarily be decreased but in the case of only heat transfer, the volume of the system will not

## though both result in the same internal energy.

2.3 Heat Capacities We can define heat capacities for changes in which the work done by the system is the

<span id="page-39-2"></span><span id="page-39-0"></span>be changed. Therefore, the two processes result in different thermodynamic states, even

$$\mathbf{d}U = \delta Q - p\mathbf{d}V.\tag{2.8}$$

20 THERMAL PHYSICS

<span id="page-40-1"></span><span id="page-40-0"></span>
$$C_V := \left(\frac{\delta Q}{\delta T}\right)_V = \left(\frac{\partial U}{\partial T}\right)_V,\tag{2.9}$$

**The heat capacity at constant volume**, *CV* , is defined to be the ratio of the infinitesimal

amount of heat δ*Q* needed to raise the temperature by an infinitesimal amount d*T* while holding the volume constant, namely *CV* := δ*Q* d*T V* = ∂*U* ∂*[T](#page-39-2) V* , (2.9)

$$\mathbf{C}_{p} \coloneqq \left(\frac{\delta Q}{\delta T}\right)_{p} = \left(\frac{\partial U}{\partial T}\right)_{p} + p\left(\frac{\partial V}{\partial T}\right)_{p},\tag{2.10}$$

<span id="page-40-3"></span>**The heat capacity at constant pressure**, *Cp*, is defined to be the ratio of the infinitesimal amount of heat δ*Q* needed to raise the temperature by an infinitesimal amount d*T* while holding the pressure constant, namely

$$
\left(\frac{\partial U}{\partial T}\right)_p = \left(\frac{\partial U}{\partial T}\right)_V + \left(\frac{\partial U}{\partial V}\right)_T \left(\frac{\partial V}{\partial T}\right)_p. \tag{2.11}
$$

![](_page_40_Picture_8.jpeg)

∂*U* ∂*T p* = ∂*U* ∂*T V* + ∂*U* ∂*V T* ∂*V* ∂*T p* . (2.11)

**Example Problem 2.1.** The specific heat of silver at 20 ◦C is 0.0558 cal g−1 K−1. Here we ignore the small difference between constant volume and constant pressure for this condensed phase. What is the heat capacity of 3 kg of silver? How many Joules of energy are needed to raise the temperature of 3 kg of silver from 15 ◦C to 25 ◦C?

<span id="page-40-2"></span>**Solution 2.1.** The heat capacity of 3 kg of silver is 3000 × 0.0558 = 167 cal K−1. [The](#page-40-2) [t](#page-40-2)emperature interval is 10 K so the energy required is 1670 cal × 4.184 J/cal = 6990 J. We only keep three

*V*2 − *V*1 was initially evacuated (see Figure 3–2). In these experiments, *Q* = 0 because the

### significant figures because the specific heat was only given to three figures.

$$pV = RT,\quad\text{one mole of ideal gas,}\tag{2.12}$$

One mole of an ideal gas obeys the equation of state *pV* = *RT*, one mole of ideal gas, (2.12) where *T* is the absolute temperature and *R* is the gas constant. Equation (2.12) is essentially a definition of an ideal gas, based on experiments for real dilute gases that obey Eq. (1.1) that was used to define the empirical temperature θ. For such a real dilute gas, Joule conducted experiments in which the gas was confined originally to a subvolume *V*1 of an insulated rigid container having overall volume *V*2. The remainder of the volume,

*Chapter 2* • First Law of Thermodynamics 21 container is insulated and *W* = 0 because the overall container having volume *V*2 is rigid. Therefore, by the fi[rst la](#page-40-2)[w,](#page-41-0) the internal energy *U* remains constant. In the experiments, the gas was allowed to expand *internally* from *V*1 to *V*2. Joule observed that the tempe[rature](#page-40-3) *T* of the gas remained practically unchanged [durin](#page-40-1)g the process. More accurate experi[ment](#page-40-2)s were perfo[rm](#page-41-1)ed later by Thomson (Lord Kelvin) and Joule by causing the gas to expand

through a porous plug until a steady state is reached and measuring the temperature of the exiting gas directly. For hydrogen, there was hardly appreciable change in temperature; see the treatise by Planck [15, p. 50] for details. Therefore, the internal energy of such a dilute gas is practically independent of its volume. For an ideal gas, we shall assume that *U* is

$$C_{\mathcal{V}} = C\boldsymbol{\gamma} + R,\quad \text{one mole of ideal gas.}\tag{2.13}$$

gas that obeys Eq. (2.12).7 Therefore, for an ideal gas, the second term on the right-hand side of Eq. (2.11) is zero. The second term on the right of Eq. (2.10) can be evaluated by means of Eq. (2.12), resulting in8 *Cp* = *CV* + *R*, one mole of ideal gas. (2.13) We observe that *Cp* is larger than *CV* by an amount neede[d](#page-41-2) to supply the work *p* d*V* done by the gas as it expands at constant pressure. The value of *CV* depends on the type of gas under consideration and can be derived by means of statistical mechanics. For a mole of gas, we shall see that each translational or rotational degree of freedom of a gas molecule, made up of atoms that are [considered](#page-42-0) to be point particles, contributes an amount *R*/2 to *CV* . For a monatomic gas, each atom has three translational degrees of freedom, translation along *x*, *y*, and *z*, so *CV* = 3*R*/2. A diatomic gas molecule would have six total degrees of freedom (three translational degrees for each atom) but the distance of separation of the two atoms remains practically constant due to strong chemical bonds. The atoms of a dia[tom](#page-40-0)ic [gas c](#page-40-1)an execute vibrations along the line joining them, but these vibrations are hardly excited except at very high temperatures.9 Thus only five degrees of freedom are usually active (three translational and two rotational) and *CV* = 5*R*/2 for a diatomic gas. Similarly, if we neglect vibrational degrees of freedom for polyatomic gases,

*CV* = 3*R*. This leads to the values listed in Table 2–1. 7By calculating derivatives of the entropy, it can be shown that *dU* = *CV dT* + (*T*α/κ*T* − *p*)*dV*, where α is the

<span id="page-41-2"></span><span id="page-41-1"></span><span id="page-41-0"></span>six degrees of freedom are usually active (three translational and three rotational) and

degrees of freedom are concerned. See Section 21.3 for a detailed discussion of ideal gases with internal structure.

isobaric compressibility and κ is the isothermal compressibility. From the ideal gas law, α = 1/*T* and β = 1/*p*, so the coefficient of *dV* vanishes and *U* depends only on *T*. 8As defined by Eqs. (2.9) and (2.10), the heat capacities *CV* and *Cp* are extensive. Thus they depend not only on the substance under consideration but also on the amount of that substance. One can obtain intensive quantities by dividing by the number of moles or the mass. These intensive quantities depend only on the substance under

consideration. Here we deal with one mole, which is equivalent to dividing the extensive heat capacities by the number of moles being considered. 9If partially excited, the contribution of a vibrational degree of freedom would depend on temperature. If fully excited, a vibrational degree of freedom would contribute *R*/2 for kinetic energy and *R*/2 for potential energy, for a total of *R*. Polyatomic gases with linear molecules behave somewhat like diatomic molecules insofar as rotational <span id="page-42-0"></span>22 THERMAL PHYSICS

| Molecule   | CV   | Cp   | γ = Cp/CV     |  |  |  |
|------------|------|------|---------------|--|--|--|
| monatomic  | 3R/2 | 5R/2 | 5/3 ≈<br>1.67 |  |  |  |
| diatomic   | 5R/2 | 7R/2 | 7/5 =<br>1.40 |  |  |  |
| polyatomic | 3R   | 4R   | 4/3 ≈<br>1.33 |  |  |  |

**Table 2–1** Heat Capacities per Mole of Ideal Gases **Molecule** *CV Cp γ* **=** *Cp/CV*

<span id="page-42-1"></span>monatomic 3*R*/2 5R/2 5/3 ≈ 1.67

### diatomic 5*R*/2 7R/2 7/5 = 1.40 polyatomic 3*R* 4*R* 4/3 ≈ 1.33

It is assumed that the atoms are point particles, translational and rotational degrees of freedom are totally excited, and vibrational degrees of freedom of diatomic and polyatomic gases are not excited.

2.3.2 General Relationship of *Cp* to *CV*

$$a := \frac{1}{V} \left(\frac{\partial V}{\partial T}\right)_p,\tag{2.14}$$

measur[abl](#page-42-3)e quantities: **isobaric coefficient of thermal expansion:**

example, for water below about 4 ◦C.

<span id="page-42-4"></span><span id="page-42-2"></span>
$$\kappa_T := -\frac{1}{V} \left( \frac{\partial V}{\partial p} \right)_T. \tag{2.15}$$

**isothermal compressibility:** [κ](#page-42-4)*T* := − 1 ∂*V* . (2.15)

$$\mathbf{C}_{p} = \mathbf{C}_{V} + \frac{T\mathbf{V}a^{2}}{\kappa_{T}}.\tag{2.16}$$

<span id="page-42-3"></span>positive.10 The general result (see Eq. (5.32)) is *Cp* = *CV* + *TV*α2 κ*T* . (2.16) From the form of Eq. (2.16), we observe that *Cp* ≥ *CV* for any substance, which is not obvious from their definitions. From stability considerations, it will be shown in Section 7.4 that *Cp* ≥ *CV* ≥ 0. For an ideal gas, we readily calculate from Eq. (2.12) that α = 1/*T* and κ*T* = 1/*p*, in which case Eq. (2.16) becomes Eq. (2.13) for *N* = 1 mole of gas. For condensed phases, |α| 1/*T* and κ*T* 1/*p*, but the second term in Eq. (2.16) is quadratic in α so the difference between *Cp* and *CV* is very small. Thus, the difference between *Cp* and *CV* is very important for gases but small and often negligible for liquids and

solids. 10This agrees with our intuition and with experiment. It can be proven from general thermodynamic stability considerations (see Chapter 7) that κ*T* is positive. α is usually positive but negative values of α are possible, for

**Example Problem 2.2.** The equation of state for one mole of a van der Waals fluid is

$$(p + a/v^2)(v - b) = RT,$$

where *p* is the pressure, *v* is the volume per mole, *T* is the temperature, and *a* and *b* are constants. Calculate the following quantities and show that they agree with the results for an ideal gas in the limit *a* = *b* = 0:

- (a) The isothermal compressibility, κ*T* = −(1/*v*)(∂*v*/∂*p*)*T*
- (b) The isobaric coefficient of thermal expansion, α = (1/*v*)(∂*v*/∂*T*)*p*
- (c) The molar heat capacity difference, (*Cp* − *CV* )/*N*
- (d) Show directly that (∂*p*/∂*T*)*v* = α/κ*T* . Why is this true?

**Solution 2.2.** We first take the differential of the given equation to obtain

$$\operatorname{d}p\,\left(v-b\right) + \left(p - \frac{a}{v^2} + \frac{2\operatorname{a}b}{v^3}\right)\operatorname{d}v = R\,\operatorname{d}T.$$

(a)

$$\kappa_T = -\frac{1}{v} \left( \frac{\partial v}{\partial p} \right)_T = \frac{1}{v} \left( v - b \right) \left( p - \frac{a}{v^2} + \frac{2 \, a \, b}{v^3} \right)^{-1} \to \frac{1}{p} \quad \text{for an ideal gas, } v$$

(b)

$$a = \frac{1}{v} \left(\frac{\partial v}{\partial T}\right)_p = \frac{R}{v} \left(p - \frac{a}{v^2} + \frac{2ab}{v^3}\right)^{-1} \to \frac{R}{pv} = \frac{1}{T} \quad \text{for an ideal gas,}$$

(c)

$$(\mathbf{C}_p - \mathbf{C}_V)/N = \frac{Tva^2}{\kappa_T} = \frac{R^2T}{\left(v - b\right)} \left(p - \frac{a}{v^2} + \frac{2\,ab}{v^3}\right)^{-1} \to \frac{R^2T}{pv} = R \quad \text{for an ideal gas,} $$

(d)

$$\left(\frac{\partial p}{\partial T}\right)_v = \frac{R}{v-b} = -\left(\frac{\partial v}{\partial T}\right)_p / \left(\frac{\partial v}{\partial p}\right)_T = \frac{\alpha}{\kappa_T}.$$

This relation is generally true, not just true for the van der Waals fluid, as can be seen from the differential

$$\mathbf{d}v = \left(\frac{\partial v}{\partial T}\right)_P \mathbf{d}T + \left(\frac{\partial v}{\partial p}\right)_T \mathbf{d}p.$$

24 THERMAL PHYSICS

$$\mathbf{d} \, \mathbf{d}U = \mathbf{C}_V \, \mathbf{d}T; \quad U = \mathbf{C}_V \, T + \text{constant}.\tag{2.17}$$

### 2.4 Work Due to Expansion of an Ideal Gas

<span id="page-44-0"></span>*T*= constant

<span id="page-44-1"></span>We calculate the work due to expansion of one mole of an ideal gas that obeys the equation of state Eq. (2.12). For simplicity, we will further assume that the gas has a constant heat capacity *CV* at constant volume. According to Eq. (2.9), this results in

$$\mathcal{W} = \int_{T=\text{constant}} p \,\text{d}V = RT \int_{V_1}^{V_2} \frac{\text{d}V}{V} = RT \ln(V_2/V_1), \quad \text{one mole.} \tag{2.18}$$

For a reversible isothermal process, the path in the *V*, *p* plane is an equilateral hyperbola, *pV* = constant, where the value of the constant depends on *T*. We assume that this path joins two states that satisfy *p*1*V*1 = *p*2*V*2, so the quasistatic work is *W* = - *p* d*V* = *RT* - *V*2 d*V V* = *RT* ln(*V*2/*V*1), one mo[le. (](#page-45-0)2.18)

### For *V*2 > *V*1 the gas expands and does positive work, as shown in Figure 2–2. For the reverse

*V*1

transformation from *V*2 to *V*1, the gas contracts and does negative work; in this case, the environment of the gas does positive work on the gas. Since *U* depends only on *T*, we have *U*1 = *U*2 so -*U* = 0. Therefore, by the first law, *Q* = *W* for this process. 2.4.2 Reversible Isobaric Expansion Followed by Isochoric Transformation

$$\mathcal{W} = p_1 \int_{V_1}^{V_2} \mathbf{d}V + \int_{V_2}^{V_2} p \mathbf{d}V = p_1(V_2 - V_1) \tag{2.19}$$

quasistatic work i[s](#page-44-1) *W* = *p*1 - *V*2 *V*1 d*V* + - *V*2 *V*2 *p* d*V* = *p*1(*V*2 − *V*1) (2.19) because the second integral is zero. The temperature will change throughout this process. In general, the end points will have different temperatures, *T*1 = *p*1*V*1/*R* and *T*2 = *p*2*V*2/*R*, and the change in internal energy will be -*U* = *CV* (*T*2 − *T*1). If the end points happen to satisfy *p*1*V*1 = *p*2*V*2, then *T*1 = *T*2, but *during* the process *T* will not be constant. In general, *Q* = -*U* + *W*, b[ut if](#page-45-0) *T*1 = *T*2, then -*U* = 0 and *Q* = *W*. Then the work given by Eq. (2.19) can also be written as *RT*1(*V*2 − *V*1)/*V*1 = *RT*2(*V*2 − *V*1)/*V*1 and is greater than

### mathematically. 2.4.3 Isochoric Transformation Followed by Reversible Isobaric

that given by Eq. (2.18) with *T* = *T*1 = *T*2. The reader is invited to prove this statement

Expansion We assume the path to consist of lowering the pressure to *p*2 at constant volume *V*1 followed by reversible expansion from *V*1 to *V*2 at constant pressure *p*2. This is illustrated by the dot-dashed line in Figure 2–3. The quasistatic work is

<span id="page-45-0"></span>![](_page_45_Figure_1.jpeg)

*p V*2*, p*2

<span id="page-45-1"></span>*V*

*V*1 *V*2

**FIGURE 2–2** Illustration of quasistatic work for isothermal expansion of one mole of an ideal gas. The system makes a quasistatic transition from a state

the curve.

![](_page_45_Figure_3.jpeg)

*V p V*1 *V*2 *V*2*, p*2 **FIGURE 2–3** Illustration of quasistatic work for one

$$\mathcal{W} = \int_{V_1}^{V_1} p\,\mathrm{d}V + p_2 \int_{V_1}^{V_2} \mathrm{d}V = p_2(V_2 - V_1),\tag{2.20}$$

m[ole of](#page-44-0) an ideal gas. The dashed line represents an isobaric expansion at pressure *p*1 followed by an

*V*1, *p*1 to *V*2, *p*2, which is only possible if *V*1*p*1 = *V*2*p*2. *W* = - *V*1 *V*1 *p* d*V* + *p*2 - *V*2 *V*1 d*V* = *p*2(*V*2 − *V*1), (2.20)

which is clearly smaller than that given by Eq. (2.19). If the end points happen to be at

### the same temperature, the work given by Eq. (2.20) can be written *RT*1(*V*2 − *V*1)/*V*2 = *RT*2(*V*2 − *V*1)/*V*[2](#page-40-2) and is less than that given by Eq. (2.18) with *T* = *T*1 = *T*2.

<span id="page-45-2"></span>2.4.4 Reversible Adiabatic Expansion We assume that the gas is perfectly insulated from its surroundings so that δ*Q* = 0 at each stage of the process. Such processes are called **adiabatic** processes.11 We allow the

$$\mathbf{C}_{V}\mathbf{d}T = -p\mathbf{d}V,\tag{2.21}$$

Applying the first law to each stage of this process gives

*CV* d*T T* + *R*d*V*

the entropy change of an adiabatic process.

$$C_V \frac{\mathbf{d}T}{T} + R \frac{\mathbf{d}V}{V} = \mathbf{0}, \quad \text{one mole of ideal gas.} \tag{2.22}$$

*V* = 0, one mole of ideal gas. (2.22)

<sup>11</sup>Some authors use the word adiabatic to mean that δ*Q* = 0 *and* that the process is reversible, but we use adiabatic to mean only δ*Q* = 0. An irreversible adiabatic process is illustrated in Section 2.4.5. See Eq. (3.13) for

to obtain

circled point.

*p*

$$C_V \frac{\mathbf{d}p}{p} + (C_V + R)\frac{\mathbf{d}V}{V} = \mathbf{0}.\tag{2.23}$$

26 THERMAL PHYSICS

$$
\ln p + \gamma \ln V = \text{constant},
\tag{2.24}
$$

Eq. (2.22) to be recast in the form

<span id="page-46-0"></span>
$$pV^{\gamma} = p_2V_2^{\gamma} = p_3V_3^{\gamma} = \pounds = \text{constant.}\tag{2.25}$$

Eq. (2.23) is a differential equation for the path in the *V*, *p* plane. It can be integrated to give

$$\mathcal{W} = \mathcal{K} \int_{V_2}^{V_3} V^{-\gamma} \, \mathrm{d}V = \mathcal{K} \frac{V^{1-\gamma}}{1-\gamma} \Big|_{V_2}^{V_3} = \frac{(p_3V_3 - p_2V_2)}{1-\gamma} = \mathrm{C}_V(T_2 - T_3). \tag{2.26}$$

*pV*γ = *p*2*V*γ 2 = *p*3*V*γ 3 = *K* = constant. [(2.25)](#page-45-2) The path of the system is represented by the solid line in Figure 2–4. [The q](#page-40-2)uasistatic [work](#page-46-0) is therefore

*W* = *K* - *V*3 *V*2 *V* −γ d*V* = *K V*1−γ 1 − γ *V*3 *V*2 = *p*3*V*3 − *p*2*V*2 1 − γ = *CV* (*T*2 − *T*3). (2.26) We have labored to produce this result which, however, could have been derived simply by applying the first law with *Q* = 0 to give *W* = −-*U* = −*CV* (*T*3 − *T*2). Nevertheless, we see clearly how the quasistatic work integral depends on path.

is the differential equation of the path in the *T*, *V* plane. It could be integrated directly, but the same result can be obtained by substitution of Eq. (2.12) into Eq. (2.25)

$$TV^{\gamma - 1} = \text{constant}.\tag{2.27}$$

![](_page_46_Figure_12.jpeg)

*V V*3 *V* ∗ 3 *V*3*, p*3 **FIGURE 2–4** The solid line represents a reversible adiabatic expansion for one mole of an ideal gas for γ = 5/3. The dotted line represents, for the sake of comparison, an isothermal expansion from the same initial state. The point at *V*∗ 3 , *p*3 is the final state for an irreversible adiabatic expansion at constant *external* pressure *p*3. In this irreversible case, the system starts in the state *V*2, *p*2, "leaves the page" as it progresses through non-equilibrium states, and "reenters the page," ultimately coming to equilibrium at the state *V*∗ 3 , *p*3, which is represented by a

<span id="page-47-1"></span>
$$\frac{T}{p^{(\gamma -1)/\gamma}} = \text{constant.}\tag{2.28}$$

### *Chapter 2* • First Law of Thermodynamics 27

-

*T*∗

We shall see that *T*∗

3 /*T*2 and shows that *T*∗

Note that γ − 1 = *R*/*CV* , consistent with Eq. (2.22). Similarly, *T p*(γ −1)/γ = constant. (2.28) 2.4.5 Irreversible Adiabatic Expansion Here again we assume that the gas is perfectly insulated from its surroundings so that δ*Q* = 0 at each stage of the process. We start out at the same state *V*2, *p*2 as for the reversible adiabatic process treated above, but we allow the gas to expand suddenly against a co[nstan](#page-40-2)t reduced *external* pressure *p*3 that is chosen to have the same val[ue](#page-47-0) [as](#page-47-0) *p*3 for the final state of the reversible adiabatic expansion considered above. During this

$$p_3(V_3^*-V_2) = C_V(T_2 - T_3^*).\tag{2.29}$$

in a state having temperature *T*∗ 3 and volume *V*∗ 3 different from t[hose](#page-47-1) for the reversible case. The work done will be *W* = *p*3(*V*∗ 3 − *V*2) and the change in internal energy will be *U* = *CV* (*T*∗ 3 − *T*2). Since *Q* = 0 we will have *W* = −-*U*, which becomes

<span id="page-47-0"></span>
$$\frac{T_3^*}{T_2} = \frac{C_V + R \, p_3/p_2}{C_V + R} = 1 - q + qr,\tag{2.30}$$

= *rq*. (2.31)

By using Eq. (2.12), we can write *p*3*V*∗ 3 = *RT*∗ 3 a[nd](#page-47-2) *p*3*V*2 = *RT*2*p*3/*p*2, in which case Eq. (2.29) can be written in the form *T*∗ = *CV* + *R p*3/*p*2

<span id="page-47-2"></span>
$$\frac{T_3}{T_2} = r^q. \tag{2.31}$$

adiabatic expansion leads to *T*3

3 *T*2

0.8

3 > *T*3 for *r* = 1.

1.2

1.4

![](_page_47_Figure_11.jpeg)

0.6 **FIGURE 2–5** Graphs of *T*3/*T*2 for a reversible adiabatic process, Eq. (2.30), and *T*∗ 3 /*T*2 for an irreversible adiabatic process, Eq. (2.31), versus *r* = *p*3/*p*2 for *q* = 2/5, which corresponds to γ = 5/3. The straight line corresponds to

$$\frac{\mathrm{d}}{\mathrm{d}r}\left(\frac{T_3^*}{T_2}\right) = q; \quad \frac{\mathrm{d}}{\mathrm{d}r}\left(\frac{T_3}{T_2}\right) = qr^{q-1}.\tag{2.32}$$

28 THERMAL PHYSICS We first note for *r* = 1 that *T*∗ 3 = *T*3 = *T*2 as expected. Then we take derivatives with respect to *r* to obtain d d*r T*∗ 3 *T*2 = *q*; d d*r T*3 *T*2 = *qrq*−1. (2.32) These derivatives are also equal for *r* = 1, so the curve represented by Eq. (2.31) is tangent to the line represented by Eq. (2.30) at *r* = 1. Since *q* − 1 = −1/γ is negative, we see that the slope of a graph of *T*∗ 3 versus *r* is less than that of *T*3 versus *r* for any *r* < 1. Moreover,

$$\frac{V_3^*}{V_3} = \frac{T_3^*}{T_3}.\tag{2.33}$$

would be true for contraction, in which case *V*3 < *V*2 and *r* > 1. For the end points of the two processes, Eq. (2.12) can be written *p*3*V*3 = *RT*3 and *p*3*V*∗ 3 = *RT*∗ 3 . Taking the ratio of these equations gives *V*∗ 3 *V*3 = *T*∗ 3 *T*3 . (2.33)

<span id="page-48-1"></span>3 > *V*3. In summary, irreversible adiabatic expansion or

### contraction against a constant external pressure *p*3 results in a different final state (larger temperature and volume) than a reversible adiabatic expansion to a final state12 having

From this result, we see that *V*∗

the slope of a graph of *T*∗

*T*∗

pressure *p*3.

$$H \coloneqq U + \mathbf{p}V.\tag{2.34}$$

2.5 Enthalpy The **enthalpy** (sometimes called the **heat function**) is defined by

$$\mathbf{d}H = \mathbf{d}U + p\,\mathrm{d}V + V\,\mathrm{d}p.\tag{2.35}$$

Since *U*, *p*, and *V* are all functions of state, *H* is also a function of state. In general,

*Cp* :=

a reversible adiabatic process is zero but that for an irreversible adiabatic process is positive.

d*T*

*p* =

$$\mathbf{d}H = \delta Q + V \,\mathrm{d}p.\tag{2.36}$$

<span id="page-48-0"></span>For quasistatic work such that Eq. (2.8) holds, Eq. (2.35) becomes d*H* = δ*Q* + *V* d*p*. (2.36)

$$\mathbf{C}_{p} := \left(\frac{\delta Q}{\mathbf{d}T}\right)_{p} = \left(\frac{\delta H}{\delta T}\right)_{p}. \tag{2.37}$$

. (2.37)

12The final state depends on the details of the irreversible process. Here we have considered only a specific case and demonstrated that the final state is different from that for a reversible adiabatic process. Later we shall introduce a new state variable *S*, the entropy, in which case it can be shown that the entropy change for

∂*T*

*p*

*Chapter 2* • First Law of Thermodynamics 29 Comparison of Eq. (2.37) with Eq. (2.9) shows that *H* plays the same role at constant *p* as *U* does at constant *V*. We will see that this role is very general after developing the second law

$$
\Delta (U + p_V V) = 0.\tag{2.38}
$$

is conserved and *U* is a constant. From Eq. (2.36) we see that for δ*Q* = 0 and constant *p* we have d*H* = 0, so *H* is a constant. Actually, a less restrictive condition than constant *p* suffices for finite changes. If *Q* = 0 and the *only* work done by the system is against a

<span id="page-49-1"></span>-

∂*p*

*T*

<span id="page-49-2"></span>∂*V*

∂*p*

*T*

only on *T*. Differentiation with respect to *T* gives our former result *Cp* = *CV* + *R*.

$$
\Delta H = 0; \quad Q = 0 \text{ and } p = p_l \text{ in initial and final states.} \tag{2.39}
$$

<span id="page-49-0"></span>(*U* + *prV*) = 0. (2.38)

be written in the form

*V* = *NRT*/*p* [we](#page-48-1) [ob](#page-48-1)tain

Then if *p* = *pr* in the initial and final states of the [syste](#page-48-1)m, Eq. (2.38) becomes -*H* = 0; *Q* = 0 and *p* = *pr* in initial and final states. (2.39)

**Example Problem 2.3.** We saw above that the internal energy, *U*, of an ideal gas was inde-

$$
\left(\frac{\partial H}{\partial p}\right)_T = \left(\frac{\partial U}{\partial V}\right)_T \left(\frac{\partial V}{\partial p}\right)_T + V + p \left(\frac{\partial V}{\partial p}\right)_T.\tag{2.40}
$$

**Solution 2.3.** We take the partial derivativ[e](#page-49-1) [of](#page-49-1) [E](#page-49-1)q. (2.34) while holding *T* constant to obtain ∂*H* = ∂*U* ∂*V* + *V* + *p* ∂*V* . (2.40)

$$\left(\frac{\partial V}{\partial p}\right)_T = -\frac{NRT}{p^2} = -\frac{V}{p}.\tag{2.41}$$

∂*V* = −*NRT p*2 = −*V*

melted. The heat needed to melt the ice is 80 cal/g. How much does the enthalpy change if one

$$\left(\frac{\partial H}{\partial p}\right)_T = 0, \quad \text{ideal gas.}\tag{2.42}$$

∂*H* ∂*p T* = 0, ideal gas. (2.42) Actually, Eq. (2.42) follows from more elementary considerations. Substitution of the ideal gas law into Eq. (2.34) for one mole gives *H* = *U*(*T*) + *RT*, so we see immediately that *H* depends

**Example Problem 2.4.** As heat is supplied to ice at temperature 0 ◦C and atmospheric pressure, the ice melts to become water, still at its melting point 0 ◦C, until all of the ice has delta function at the melting point.

-

*p*-

transition, -

So for evaporation, *p*-

the difference between -

30 THERMAL PHYSICS mole of ice is melted? Show that this is equivalent to an effective heat capacity t[hat is](#page-50-0) a Dirac

<span id="page-50-0"></span>
$$C_p^{\text{eff}} = \Delta H \,\delta(T - T_{\text{M}}),\tag{2.43}$$

*U* ≈ -

*H* for melting

*H* = 9720 cal/mol so

*U* and what would that change be? **Solution 2.4.** [Int](#page-42-2)egration of Eq. (2.36) at constant *p* gives an enthalpy change -*H* = *Q*. One mole of ice has a mass of 18 g, so -*H* = 18 g/mol × 80 cal/g = 1440 cal/mol. Since the temperature does not change during melting, an effective heat capacity can be defined

formally by *C*eff *p* = -*H* δ(*T* − *T*M), (2.43) where *T*M is the melting point and δ(*T* − *T*M) is the Dirac delta function. Equation (2.43) can be justified by integration from *T*M − to *T*M + . From a different perspective, a graph of *H* versus *T* has a discontinuous step at *T*M whose formal derivative is a delta function. See Section 3.4.1 for a more thorough discussion. From Eq. (2.15) at constant *p* we obtain -*U* = -*H* − *p*-*V* so we would have to know *V* to evaluate -*U*. We can estimate -*V* as follows: The volume of ice shrinks about 9% on melting and its density is about 1 g/cm3. So for one mole, -*V* ≈ −0.09 × 1 cm3/g × 18 g/mol = −1.6 cm3/mol = −1.6 × 10−6 m3/mol. One standard atmosphere is *p* = 1.01 × 105 N/m2. Thus

*V* = −0.16 J/mol = −0.04 cal/mol, which is a negligible correction. So -

*U* and -

of ice. This is typical for melting of condensed phases. On the other hand, for the water-steam

*V* ≈ 6 cal/mol. But for the evaporation transition, -

*V* ≈ 2.24×10−2 m3/mol, roughly 1000 times larger in magnitude than for melting.

*H* is larger but still practically negligible.

![](_page_51_Picture_0.jpeg)

3 Second Law of Thermodynamics Even though the first law of thermodynamics is obeyed, there are additional limitations on processes that can occur naturally. The second law of thermodynamics deals quantitatively with these limitations and is expressed in terms of an inequality that is obeyed by changes of a new state function, the **entropy** *S*, which is postulated to exist. These limitations are due to the fact that all natural processes in thermodynamic systems are irreversible. The boundary between natural processes and processes that are forbidden by thermodynamics can be characterized in terms of idealized processes that are reversible.

For an idealized reversible process, which is hypothetical, the entropy change obeys an equality and this allows the entropy change to be calculated. If a system, by virtue of suitable constraints, is such that all natural processes are forbidden by the second law, it is in a state of thermodynamic equilibrium. This leads to a criterion for thermodynamic equilibrium in terms of the entropy. Historically, the entropy function was discovered by studying limitations that occur during the process of transformation of heat into work, even though energy is con-

served. Theoretically, these processes were imagined to be accomplished by engines

that exchange heat with external heat sources, do mechanical work, and return to their original thermodynamic state after each cycle. These processes were assumed to obey the following postulates [1, p. 30]:

*Postulate of Kelvin: "A transformation whose only final result [is](#page-51-0) to transfer into work heat extracted from a source which is at the same temperature throughout is impossible."*

<span id="page-51-0"></span>*Postulate of Clausius: "A transformation whose only final result is to transfer heat from a body at a given temperature to a body at a higher temperature is impossible."* These historical postulates forbid the existence of a process in which a virtually infinite amount o[f](http://dx.doi.org/10.1016/B978-0-12-803304-3.00003-X) [work](http://dx.doi.org/10.1016/B978-0-12-803304-3.00003-X) [can](http://dx.doi.org/10.1016/B978-0-12-803304-3.00003-X) [be](http://dx.doi.org/10.1016/B978-0-12-803304-3.00003-X) [obtained](http://dx.doi.org/10.1016/B978-0-12-803304-3.00003-X) [by](http://dx.doi.org/10.1016/B978-0-12-803304-3.00003-X) [extract](http://dx.doi.org/10.1016/B978-0-12-803304-3.00003-X)ing with 100% efficiency heat from a huge thermal source (e.g., the ocean). An engine that would accomplish such a process is sometimes called a perpetual motion machine of the second kind.1 In fact, many people have come up with clever ideas and claims of such perpetual motion machines and have

attempted to patent them, but careful analysis has always shown that some irreversible

which is already ruled out by the first law of thermodynamics.

<sup>1</sup>A perpetual motion machine of the first kind is one that would violate the conservation of energy itself,

32 THERMAL PHYSICS process occurs such that their efficiency cannot exceed the theoretical efficiency (see Eq. (3.27)) allowed by the second law.

Fermi [1, pp. 31-34] has shown that the postulates of Kelvin and Clausius are equivalent. The key phrase in each of them is "only final result." One can certainly transfer heat from a refrigerator to a room at higher temperature, but other things must change in the process,

### for example, work must be expended by a motor. Based on these postulates, a Carnot engine, which is a hypothetical reversible engine, and other imagined irreversible engines can be used [1, chapter IV] to develop a logical process that leads to a classical formula for

[1, p. 45] for a related discussion in terms of the Carnot cycle.

the entropy (see Eq. (3.33)). Rather than dwell on this historical justification of the second law, we shall state it as a postulate in very general terms and then relate it to its historical roots. 3.1 Statement of the Second Law For a thermodynamic system, there exists a function of state, *S*, called the entropy. *S* is a

<span id="page-52-0"></span>function of a complete set of extensive state variables that includes the internal energy, *U*. For all *other* extensive variables held fixed, *S* is a monotonically increasing function of the internal energy *U*. For a homogeneous system, *S* is an extensive function and its slope ∂*S*/∂*U* = 1/*T*, where the positive quantity *T* is the absolute tempe[ratu](#page-52-0)re.2 If the system is

$$
\Delta S \ge 0,\quad\text{isolated system, allowed changes,}\tag{3.1}
$$

An **isolated system** is a chemically closed system for which δ*Q* = 0 and δ*W* = 0, so d*U* = 0 and *U* is a constant. Therefore also *Q* = 0, *W* = 0, and *U* =0. For an isolated system, changes of *S* obey the inequality

*S* ≥ 0, isolated system, allowed changes, (3.1) where the inequality corresponds to a natural irreversible process and the equality corresponds to a hypothetical idealized reversible process.

If the entropy of an isolated system is a maximum subject to its internal and external constraints, all natural irreversible processes are forbidden by Eq. (3.1) so the system is in a state of equilibrium. This leads to the following equilibrium criterion: **Entropy criterion for equilibrium:** The criterion for an isolated thermodynamic system to be in internal equilibrium is that its total entropy be a maximum with respect to variation of its *internal extensive* parameters, subject to external constraints and any remaining internal constraints. Isolation constitutes the external constraints of chemical closure,

perfect thermal insulation and zero external work, which require the internal energy to be constant. For example, consider an isolated composite system consisting of two subsystems

having different temperatures and separated by an insulating wall (internal constraint). If 2For a homogeneous system, the absolute thermodynamic temperature is *defined* by a partial derivative 1/*T* : = ∂*S*/∂*U* or alternatively by *T* = ∂*U*/∂*S*, where all other members of the complete set of extensive variables are held constant. Thus *T* exists independent of any particular measuring device (thermometer). See Fermi

*Chapter 3* • Second Law of Thermodynamics 33

*Ts*

the wall is then allowed to conduct heat (removal of an internal constraint), the energies of the two systems will change until the temperatures are equalized and a new equilibrium, corresponding to a state of higher entropy, is established. In Chapter 6 we will discuss the application of this entropy criterion for equilibrium and deduce from it several alternativ[e](#page-52-0) [and](#page-52-0) useful criteria for equilibrium. 3.1.1 Discussion of the Second Law The second law of thermodynamics is a postulate. The fact that it is believed to be true is based on extensive experimental testing. It can be rationalized on the basis of statistical

<span id="page-53-1"></span>mechanics, which of course is based on its own postulates. It can also be derived, as is done in classical thermodynamics for chemically closed systems, from other postulates of Kelvin or Clausius, as stated above. In order to make contact with the historical

$$
\Delta S_{\text{tot}} \ge 0, \quad \text{isolated system, allowed changes.} \tag{3.2}
$$

entropy, we first digress to apply Eq. (3.1) to a composite system consisting of sources of heat and work. We consider an isolated composite system having total entropy *S*tot and apply Eq. (3.1) in the form *S*tot ≥ 0, isolated system, allowed changes. (3.2)

$$\mathcal{S}_{00t} = \mathcal{S} + \mathcal{S}_t. \tag{3.3}$$

<span id="page-53-2"></span>having entropy *S*, a heat source having entropy *Ss*, and a pur[ely m](#page-53-1)echanical system capable only of exchanging work. By definition, there is no entropy associated with this purely mechanical system, so the total entropy of our composite system is *S*tot = *S* + *Ss*. (3.3) The heat source is assumed to be a homogeneous thermodynamic system whose only function is to exchange heat; it does no work, has a fixed number of moles of each chemical component, a temperature *Ts* and an internal energy *Us*. Thus d*Ss* = (1/*Ts*)d*Us* by

<span id="page-53-3"></span>
$$\text{dS} \ge \frac{\delta Q}{T_s}, \quad \text{chemically closed system, allowed changes.}\tag{3.4}$$

<span id="page-53-0"></span>d*S* ≥ δ*Q Ts* , chemically closed system, allowed changes. (3.4) In Eq. (3.4), the term chemically closed system pertains to the system of interest, having

$$\text{dS} > \frac{\delta Q}{T_s}, \quad \text{chemically closed system, natural irreversible changes.} \tag{3.5}$$

3δ*Q* is assumed to be so small and the heat source has, by definition, a sufficiently large heat capacity that it remains practically unchanged during this process.

, chemically closed system, natural irreversible changes. (3.5)

<span id="page-54-4"></span><span id="page-54-3"></span>
$$\text{AdS} = \frac{\delta Q}{T}, \quad \text{chemically closed system, idealized reversible changes.} \tag{3.6}$$

34 THERMAL PHYSICS

For reversible heat flow, which is an idealization that separates irreversible heat flow from forbidden heat flow, *Ts* can differ only infinitesimally from *T*, the temperature of the system, so we have d*S* = δ*Q T* , chemically closed system, idealized reversible changes. (3.6)

$$\mathrm{d}\mathrm{S}_{\mathrm{tot}} = \mathrm{d}\mathrm{S} + \mathrm{d}\mathrm{S}_{3} = \delta Q \left(\frac{1}{T} - \frac{1}{T_{\mathrm{s}}}\right) > \mathbf{0},\tag{3.7}$$

If our system of interest were simply an[othe](#page-53-2)r heat source capable of no other change, we would have d*S* = d*U*/*T* by definition of its absolute temperature. Then δ*W* =0 so d*U* = δ*Q* from the first law and we would have d*S* = δ*Q*/*T*. For spontaneous heat conduction, a natural irreversible process, we would need

<span id="page-54-0"></span>d*S*tot = d*S* + d*Ss* = δ*Q* - 1 *T* − 1 > 0, (3.7)

*S* ≥

 δ*Q Ts*

made arbitrarily small, and therefore zero for all practical purposes.

*Ts* which results in δ*Q*(*Ts* − *T*) > 0. This means that spontaneous heat conduction, with no other change, occur[s on](#page-54-0)ly from a higher temperature to a lower temperature, in agreement

with our intuition and the postulate of Clausius stated above. For finite changes, we can integrate Eq. (3.4) to obtain

<span id="page-54-2"></span>
$$\mathcal{W} = -\Delta U + \int \delta Q,\tag{3.9}$$

where the equality sign is for a reversible process and requires *Ts* = *T*. Our sy[ste](#page-54-1)m of interest can do wor[k](#page-54-0) [(on](#page-54-0) the mechanical subsystem) of amount *W* = −*U* + δ*Q*, (3.9) provided that Eq. (3.8) is satisfied. We emphasize that our system of interest is not isolated, so its entropy can be made to *decrease* by extracting heat reversibly. Therefore,

if a chemically closed system is not isolated, its entropy can increase or decrease, and the process that brings about th[is](#page-53-3) [c](#page-53-3)hange can be either reversible or irreversible, depending on the relationship of *S* to δ*Q*/*Ts* for that process. In classical thermodynamics, one often speaks of **heat reservoirs**. A heat reservoir is a heat source with such a large heat capacity that its temperature remains constant.5 If the

<span id="page-54-1"></span>
$$
\Delta S \ge \frac{Q_r}{T_I}, \quad \text{chemically closed system, allowed changes.}\tag{3.10}
$$

*S* ≥ *Qr Tr* , chemically closed system, allowed changes. (3.10) 4See the footnote on page 48 of Fermi [1] for further discussion of *Ts*. Some books [5, 16] write d*S* > δ*Q*/*T* which is more restrictive than Eq. (3.5); such an equation applies to a process in which the heat conduction

between the heat source and the system of interest is reversible but other processes that take place within the system of interest are irreversible. 5For example, if a heat source has a constant heat capacity *Cr* and an amount of heat *Qr* is extracted from it, its temperature would change by *Tr* = − *Qr*/*Cr* . For a reservoir, *Cr* is assumed to be so large that *Tr* can be

<span id="page-55-1"></span>
$$
\Delta S \ge \sum_{r} \frac{Q_r}{T_r}, \quad \text{chemically closed system, allowed changes} \tag{3.11}
$$

<span id="page-55-0"></span>
$$\mathcal{W} = -\Delta U + \sum_{r} Q_{r}.\tag{3.12}$$

If the heat source consists of a number [of su](#page-54-0)ch reservoirs, Eq. (3.8) becomes *S* ≥ *Qr*

*r Tr* , chemically closed system, allowed changes (3.11) and Eq. [(3.9](#page-54-2)) is replaced by

$$
\Delta S \ge 0,\quad \text{chemically closed adiabatic system, allowed changes.}\tag{3.13}
$$

*r* If the amounts of heat *Qr* in Eqs. (3.11) and (3.12) are very small, the sums can be replaced by integrals, and the result is essentially the same [as Eq](#page-55-1)s. (3.8) and (3.9). A system surrounded by perfectly insulating walls requires δ*Q* = 0 and is said to be **adiabatic**. For an adiabatic system, Eq. (3.8) becomes

*S* ≥ 0, chemically closed adiabatic system, allowed changes. (3.13) But Eq. (3.9) yields *W* = −*U*, so such a system is not isolated and can still do work. Chan-

<span id="page-55-2"></span>
$$0 \ge \sum_{r} \frac{Q_r}{T_r}, \quad \text{cyclic process, technically closed system, allowed changes.}\tag{3.14}$$

For a cyclic process, the system returns to its original state after each cycle. Since *S* is a

$$\mathbf{0} \ge \oint \frac{\delta Q}{T_I}, \quad \text{cyclic process, technically closed system, allowed changes.}\tag{3.15}$$

For a continuous distribution of reservoirs, 0 ≥ δ*Q Tr* , cyclic process, chemically closed system, allowed changes. (3.15)

For an adiabatic cyclic process, δ*Q* = 0, so Eq. (3.15) becomes 0 ≥ 0 and compatibili[ty](#page-55-3)

at a high temperature *T*2. Segment *BC* is a reversible adiabatic expansion. Segment *CD*

### would require the equality sign to hold, consistent with the fact [that an ad](#page-56-0)iabatic cyclic process is reversible.

<span id="page-55-3"></span>3.2 Carnot Cycle and Engines In classical thermodynamics, the second law of thermodynamics is usually rationalized by considering processes involving the conversion of work to heat by engines that return to their original thermodynamic state after one cycle. Comparison is made to a hypothetical engine, known as a Carnot engine, which is imagined to execute a reversible cycle. The **Carnot cycle** pertains to an idealized engine in which the working substance is one mole6 of an ideal gas. There are four segments to the cycle, as depicted in Figure 3–1. All segments involve reversible processes, so the whole cycle is reversible. Segment *AB* is a reversible isothermal expansion in which an amount of heat |*Q*2| = *Q*2 is extracted from a heat source

<sup>6</sup>We could also consider any fixed number of moles of an ideal gas.

<span id="page-56-0"></span>36 THERMAL PHYSICS

![](_page_56_Figure_1.jpeg)

*T*1 *C*

*V* **FIGURE 3–1** The Carnot cycle in the *V*, *p* plane. The working substance is an ideal gas and the cycle consists of four reversible segments. *AB* is isothermal expansion at temperature *T*2, *BC* is adiabatic expansion, *CD* is isothermal compression at temperature *T*1, and *DA* is adiabatic compression. The figure is drawn for γ = 5/3. is a reversible isothermal compression in which an amount of heat |*Q*1|= − *Q*1 is given

$$T_2 V_B^{\prime -1} = T_1 V_C^{\prime -1}; \quad T_2 V_A^{\prime -1} = T_1 V_D^{\prime -1}.\tag{3.16}$$

heat reservoirs, so their temperatures do not change. Finally, segment *DA* is a reversible adiabatic compression. In order for these segments to form a closed cycle, we can apply

$$\frac{V_A}{V_B} = \frac{V_D}{V_C}.\tag{3.17}$$

Division of one of these equations by the other and extraction of the γ − 1 root gives

*T*2*V*γ −1

<span id="page-56-1"></span>*B* = *T*1*V*γ −1

*p*

$$\frac{p_A}{p_B} = \frac{p_D}{p_C},\tag{3.18}$$

Combining Eq. (3.17) with the ideal gas law gives

<span id="page-56-4"></span><span id="page-56-3"></span><span id="page-56-2"></span>*VA VB*

*pA pB* = *pD pC* , (3.18) so the geo[metry](#page-56-1) of the cycle is completely known and simpl[e to e](#page-56-2)xpress. On the adiabatic segment *BC*, δ*Q* = 0 so we have *WBC* = − *UBC* = *CV* (*T*2 − *T*1). This exactly cancels the work *CV* (*T*1 − *T*2) done by the gas on the other adiabatic segment. The

$$|Qz| = RT_2 \ln(V_B/V_A). \tag{3.19}$$

|*Q*2| = *RT*2 ln(*VB*/*VA*). (3.19)

|*Q*1| *T*1

$$|\mathrm{Qn}| = -RT_1 \ln(V_{\mathrm{D}}/V_C) = RT_1 \ln(V_{\mathrm{B}}/V_{\mathrm{A}}),\tag{3.20}$$

|*Q*1|=−*RT*1 ln(*VD*/*VC*) = *RT*1 ln(*VB*/*VA*), (3.20)

$$\frac{|Q_1|}{T_1} = \frac{|Q_2|}{T_2}.\tag{3.21}$$

$$\eta := \frac{\mathcal{W}}{|Q_2|} = 1 - \frac{|Q_1|}{|Q_2|} = 1 - \frac{T_1}{T_2}.\tag{3.22}$$

*[Cha](#page-56-3)pter 3* • Second Law of Thermodynamics 37

For the entire cycle, *U* = 0 so the total work done by the gas during the cycle is *W* = |*Q*2|− |*Q*1|. The efficiency of the cycle is therefore η := *W* = 1 − *T*1

Oum 1: \"covariance of\" and\", we obtain:\

$$0 = \frac{Q_2}{T_2} + \frac{Q_1}{T_1} = \frac{|Q_2|}{T_2} - \frac{|Q_1|}{T_1}\tag{3.23}$$

deemed to be impossible. Let us examine the meaning of Eq. (3.21) in terms of the second law. Since the entropy

It follows that the *ratio* |*Q*

1|, resulting in

<span id="page-57-0"></span>1|, so

|*Q*

|*Q*i

2|−|*Q*i

2|−|*Q*

is a function of state, we have *S* = 0 for a cycle. Applying Eq. (3.11) with the equality, for our reversible cycle, we obtain 0 = *Q*2 *T*2 + *Q*1 *T*1 = |*Q*2| *T*2 − |*Q*1| *T*1 (3.23)

- in agreement with Eq. (3.21). Beginning with the Carnot cycle, Fermi [1, chapter IV] proves a number of other things based on the Kelvin/Clausius postulates. These are used to rationalize the existence of the entropy and to formulate the second law. Here, we take the opposite approach by quoting the main resu[lts](#page-55-0) [an](#page-55-0)d demonstrating how they follow from the second law.

$$\mathbf{0} = \frac{Q_2'}{T_2} + \frac{Q_1'}{T_1} = \frac{|Q_2'|}{T_2} - \frac{|Q_1'|}{T_1}.\tag{3.24}$$

those for a Carnot engine. Thus we obtain 0 = *Q* 2 *T*2 + *Q* 1 *T*1 = |*Q* 2| *T*2 − |*Q* 1| *T*1 . (3.24)

$$\eta' := \frac{\mathcal{W}'}{|Q'_2|} = 1 - \frac{|Q'_1|}{|Q'_2|} = 1 - \frac{T_1}{T_2} = \eta. \tag{3.25}$$

- η := *W* |*Q* 2| = 1 − |*Q* 1| |*Q* 2| = 1 − *T*1 *T*2 = η. (3.25) • *Any irreversible engine working between the same two temperatures T*2 *and T*1 *has a*

$$0 > \frac{Q_2^l}{T_2} + \frac{Q_1^l}{T_1} = \frac{|Q_2^l|}{T_2} - \frac{|Q_1^l|}{T_1},\tag{3.26}$$

0 > *Q*i 2 *T*2 + *Q*i 1 *T*1 = |*Q*i *T*2 − |*Q*i *T*1 , (3.26) which leads to |*Q*i 1|/|*Q*i 2| > *T*1/*T*2. The amount of work done in the cycle is now *W*i =

$$\eta^{\mathbb{I}} := \frac{\mathcal{W}^{\mathbb{I}}}{|Q_2^{\mathbb{I}}|} = 1 - \frac{|Q_1^{\mathbb{I}}|}{|Q_2^{\mathbb{I}}|} < \eta. \tag{3.27}$$

- 
<span id="page-58-0"></span>
$$
\oint \frac{\delta Q}{T} = 0.\tag{3.28}
$$

38 THERMAL PH[YSICS](#page-58-0) • *In a cycle of any reversible engine that receives heat* δ*Q from a number of sources at temperature T,* δ*Q T* = 0. (3.28) This follows from Eq. (3.8) with the equality by recognizing that *S* = 0 for a cycle. In classical thermodynamics, Eq. (3.28) is d[educe](#page-58-1)d by arguing that any reversible cycle can

<span id="page-58-1"></span>
$$\left(\int_{A}^{B} \frac{\delta Q}{T}\right)_{\text{reversible path I}} = \left(\int_{A}^{B} \frac{\delta Q}{T}\right)_{\text{reversible path II}}.\tag{3.29}$$

the back again to *A* along some other reversible path, we create a reversible cycle. Since the integral from *B* to *A* along the return path is the negative of the integral from *A* to *B* along that path, it follows that

- *A T* reversible path I = *A T* reversible path II . (3.29) Since the values of the integrals in Eq. (3.29) depend only on their end points, their
δ*Q*

-*B*

• *In a cycle of any irreversible engine that receives heat* δ*Q from a number of sources at*

$$\begin{array}{c} \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots\\ \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \cdots \end{array} \oint \frac{\delta Q}{T_s} \times \mathbf{0}. \tag{3.30}$$

*[temp](#page-56-4)eratur[e](#page-56-3) [Ts,](#page-56-3)* δ*Q*

inequality |*Q*i

1|/*W* < *T*1/(*T*2 − *T*1).

-*B* δ*[Q](#page-55-1)*

<span id="page-58-2"></span>

*Ts* < 0. (3.30) This follows from Eq. (3.11) with the inequality by recognizing that *S* = 0 for a cycle. **Example Problem 3.1.** Analyze a Carnot refrigerator in which heat |*Q*1| = *Q*1 is extracted

(from the refrigerator) at a low temperature *T*1 and given to a Carnot engine running in reverse; then |*Q*2|= − *Q*2 is extracted from that Carnot engine and given to a sink at higher temperature *T*2.

$$\frac{|Q_1|}{W} = \frac{T_1}{T_2 - T_1}.\tag{3.31}$$

|*Q*1| *W* = *T*1 *T*2 − *T*1 . (3.31) We see that only a small amount of work *W* must be provided to extract |*Q*1| from the refrigerator provided that *T*1 is not too much lower than *T*2. Since an amount of heat |*Q*2|=|*Q*1|(*T*2/*T*1) must be given up to the source, the cooling of a refrigerator can result in a large amount of heat given up to the surrounding room. Of course the process that takes place in an actual refrigerator is irreversible, so even a larger ratio of the removed heat to the work *W* is required than given by Eq. (3.31). Indeed, by using Eq. (3.26) for an irreversible engine, we obtain the

$$\frac{|Q_2|}{W} = \frac{T_2}{T_2 - T_1}.\tag{3.32}$$

The considerations that led to Eq. (3.31) can also be applied to analyze a heat pump that adds an incremental amount of heat from an inexpensive source at temperature *T*1 to

### <span id="page-59-0"></span>|*Q*2| *W* = *T*2 *T*2 − *T*1 . (3.32)

heat a roo[m at](#page-58-1) temperature *T*2. In that case, a more meaningful quantity is

Thus the heat pump will require only a small amount of work to provide |*Q*2| if the source tempe[rature](#page-59-0) *T*1 is close to *T*2. For a real (irreversible) heat pump we would have |*Q*i 2|/*W* <

$$
\Delta S \equiv S(B) - S(A) = \int_A^B \frac{\delta Q}{T}, \quad \text{any reversible path connecting } A \text{ and } B. \tag{3.33}
$$

From Eq. (3.29) it follows that the c[hange](#page-59-0) in entropy of a system that begins in state *A* and ends in state *B* is given by *S* ≡ *S*(*B*) − *S*(*A*) = *B A* δ*Q T* , any reversible path connecting *A* and *B*. (3.33) In Eq. (3.33), we emphasize that the path of integration is *any reversible path*. Since *S* is function of state, the entropy change *S*(*B*)−*S*(*A*) will be the same no matter how the system changes from *A* to *B*, for example by an irreversible process, but it can only be calculated by using a reversible path. In practice, one uses some convenient reversible path to make

states. We could choose some standard state *O* and then calculate the differences *S*(*A*) − *S*(*O*) and *S*(*B*) − *S*(*O*). Later we will encounter the third law of thermodynamics, according

*T*2/(*T*2 − *T*1).

to which there is a standard state whose entropy can be taken to be zero.

$$\mathbf{C}\boldsymbol{\nu} = \mathbf{a} + b\mathbf{T} + c\mathbf{T}^2,\tag{3.34}$$

be represented empirically by an equation of the form *CV* = *a* + *bT* + *cT*2, (3.34)

where *a*, *b*, and *c* are constants. Calculate the change in internal energy and the change in

*T*1

*T*1

the computation simple. Equation (3.33) only defines the difference in entropy between

$$
\Delta U = U_2 - U_1 = \int_{T_1}^{T_2} C_V \,\mathrm{d}T = aT + bT^2/2 + cT^3/3\Big|_{T_1}^{T_2} \tag{3.35}
$$

and

 

*T*1

(3.35)

and

$$
\Delta S = S_2 - S_1 = \int_{T_1}^{T_2} C_V / T \, dT = a \ln T + bT + cT^2 / 2 \Big|_{T_1}^{T_2}.\tag{3.36}
$$

40 THERMAL PHYSICS

**Example Problem 3.3.** Consider an isolated composite system consisting of two subsystems, (1) and (2) respectively, having fixed volumes *V*1 and *V*2 and heat capacities at constant volume at temperature *T* of *C*1(*T*) and *C*2(*T*). Suppose that the subsystems are separated initially by an

2

*C*2(*T*) *T*

$$\mathbf{0} = \Delta(U) = \int_{T_1}^{T_1^*} \mathbf{C}_1(T) \, \mathrm{d}T + \int_{T_2}^{T_2^*} \mathbf{C}_2(T) \, \mathrm{d}T \tag{3.37}$$

entropy change until a maximum entropy has been reached.

will be given by

$$
\Delta(\mathbf{S}) = \int_{T_1}^{T_1^*} \frac{\mathbf{G}_1(T)}{T} \, \mathbf{d}T + \int_{T_2}^{T_2^*} \frac{\mathbf{G}_2(T)}{T} \, \mathbf{d}T \ge 0. \tag{3.38}
$$

0 = (*U*) = *T*1 *C*1(*T*) d*T* + *T*2 *C*2(*T*) d*T* (3.37)

> <span id="page-60-0"></span> *[T](#page-60-0)*∗ 1

1

*C*1(*T*) *T*

d*T* +

 *T*∗ 2

$$0 = C_1(T_1^*)\,\mathrm{d}T_1^* + C_2(T_2^*)\,\mathrm{d}T_2^* \tag{3.39}$$

d*T* ≥ 0. (3.38)

and

$$\operatorname{d}\Delta(\mathcal{S}) = \frac{C_1(T_1^*)}{T_1^*} \operatorname{d}T_1^* + \frac{C_2(T_2^*)}{T_2^*} \operatorname{d}T_2^* \ge 0. \tag{3.40}$$

and

0 = (*U*) =

(*S*) =

$$\mathbf{d}\Delta(\mathbf{S}) = \mathbf{C}_1(T_1^*) \left(\frac{1}{T_1^*} - \frac{1}{T_2^*}\right) \mathbf{d}T_1^* \ge \mathbf{0},\tag{3.41}$$

Substitution of Eq. (3.39) into Eq. (3.40) gives d(*S*) = *C*1(*T*∗ 1 ) - 1 *T*∗ 1 − 1 *T*∗ 2 d*T*∗ 1 ≥ 0, (3.41) which for positive d*T*∗ 1 requires (1/*T*∗ 1 − 1/*T*∗ 2 ) ≥ 0. In view of Eq. (3.37), this requires *T*1 < *T*∗ 1 ≤ *T*∗ 2 < *T*2 at each stage of the process. When *T*∗ 1 increases to *T*∗ 2 , d(*S*) = 0 and *S* will reach its maximum value at some new equilibrium temperature *T*∗ 1 = *T*∗ 2 = *T*eq. This can be seen in

$$0 = \Delta(U) = \int_{T_1}^{T_{\text{eq}}} \mathbf{C}_1(T) \, \mathbf{d}T + \int_{T_2}^{T_{\text{eq}}} \mathbf{C}_2(T) \, \mathbf{d}T \tag{3.42}$$
 
$$\text{and}$$

satisfy

and

and *C*2(*T*) to enable *T*∗

these calculations explicitly.

$$
\Delta(\mathbf{S}) = \int_{T_1}^{T_{\text{eq}}} \frac{C_1(T)}{T} \, \mathbf{d}T + \int_{T_2}^{T_{\text{eq}}} \frac{C_2(T)}{T} \, \mathbf{d}T > \mathbf{0}.\tag{3.43}
$$

*C*2(*T*) d*T* (3.42)

(*S*) = *T*1 *T* d*T* + *T*2 *T* d*T* > 0. (3.43) For the simple case when *C*1 and *C*2 are independent of *T*, the reader is invited to carry out

*C*1(*T*) d*T* +

<span id="page-61-3"></span><span id="page-61-1"></span>
$$
\delta \mathbf{d} U = \delta Q - \delta \mathcal{W}.\tag{3.44}
$$

*Chapter 3* • Second Law of Thermodynamics 41

$$\mathbf{d}U = \left(\frac{\partial U}{\partial S}\right)_V \mathbf{dS} + \left(\frac{\partial U}{\partial V}\right)_S \mathbf{d}V.\tag{3.45}$$
 
$$\dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots \qquad \dots$$

For a chemically cl[osed s](#page-61-0)ystem, t[he firs](#page-61-1)t law gives

$$
\delta Q = T \,\mathrm{d}S; \quad \delta \mathcal{W} = p \,\mathrm{d}V; \quad \text{reversible}.\tag{3.46}
$$

d*U* = -∂*U* d*S* + -∂*U*

<span id="page-61-2"></span><span id="page-61-0"></span>∂*S*

*V*

$$
\dot{\mathbf{d}}U = T\,\mathbf{dS} - p\,\mathbf{d}V.\tag{3.47}
$$

For a reversible transform[ation](#page-61-2) in this system, for which the only work is the quasistatic work, we have

true, we can eliminate d*U* to obtain

on a complete set of extensive state variables.

$$T = \left(\frac{\partial U}{\partial S}\right)_V; \quad -p = \left(\frac{\partial U}{\partial V}\right)_S. \tag{3.48}$$

d*U* = *T* d*S* − *p* d*V*. (3.47) We can therefore identify the derivatives *T* = -∂*U* ∂*S V* ; −*p* = -∂*U* ∂*V S* . (3.48) We emphasize that Eq. (3.47) holds for all infinitesimal changes of *U*(*S*, *V*) within the field of equilibrium states. Equation (3.46), which is only true for reversible processes, was only used to identify the derivatives in Eq. (3.45). Equations that give explicit forms of the functions *T*(*S*, *[V](#page-61-1)*) and *p*(*S*, *V*) are known as **equations of state**. If all8 equ[ation](#page-61-2)s of state are known, Eq. (3.47) can be integrated to recover the function *U*(*S*, *V*), except for an additive

$$
\left(\frac{\partial T}{\partial V}\right)_S = \frac{\partial^2 U}{\partial V \partial S} = \frac{\partial^2 U}{\partial S \partial V} = -\left(\frac{\partial p}{\partial S}\right)_V \tag{3.49}
$$

order of partial differentiation does not matter and we obtain [-](#page-61-2) ∂*T* ∂*V* = ∂2*U* ∂*V*∂*S* = ∂2*U* ∂*S*∂*V* = −-∂*p* ∂*S* . (3.49)

*S V* (∂*T*/∂*V*)*S* = − ∂*p*/∂*S V* is an example of a **Maxwell relation**. In Chapter 5 we will take up Maxwell relations for systems that depend on several variables.

$$p\,\mathrm{d}V - \delta\mathcal{W} = T\,\mathrm{d}S - \delta Q.\tag{3.50}$$

7Note that Eqs. (3.45) and (3.47) hold only for a chemically closed system in which no chemical reactions are occurring. If chemical reactions are allowed, *U* would depend on additional variables (progress variables

*p* d*V* − δ*W* = *T* d*S* − δ*Q*. (3.50)

of the reactions). Equation (3.6) would not hold if these reactions were irreversible. See Eq. (5.128) for further clarification. 8For open systems, one must include the numbers of moles of each chemical component, *N*1, *N*2, ... , *N*κ as additional variables in *U*, in which case there are more equations of state (see Chapter 5). In general, *U* depends

$$\frac{p\,\mathrm{d}V-\delta\mathcal{W}}{T} + \frac{\delta Q}{T} = \mathrm{d}\mathcal{S}.\tag{3.51}$$

42 THERMAL PHYSICS

$$\frac{p\,\mathrm{d}V-\delta\mathcal{W}}{T} + \delta\mathrm{Q}\left(\frac{1}{T} - \frac{1}{T_{\mathrm{s}}}\right) = \mathrm{d}\mathrm{S} - \frac{\delta\mathcal{Q}}{T_{\mathrm{s}}} > 0, \quad \text{natural, irreversible.} \tag{3.52}$$

leads to an interesting inequality. We divide Eq. (3.50) by *T* and rearrange to obtain *p* d*V* − δ*W T* + δ*Q T* = d*S*. (3.51) Then we subtract δ*Q*/*Ts* from both sides of Eq. (3.51) and apply Eq. (3.5) to obtain *p* d*V* − δ*W T* + δ*Q* - 1 *T* − 1 *Ts* = d*S* − δ*Q Ts* > 0, natural, irreversible. (3.52) The first term on the left of Eq. (3.52) is due to the process of irreversible work and the second term on the left is due to the irreversible process of heat conduction between the external source and the system. These terms can be regarded [16, pp. 95-95] as representing entropy production during independent irreversible processes and are *separately*

<span id="page-62-0"></span>positive. A positive value of the first term leads to the inequality *W* < *p* d*V*, in agreement

$$\mathbf{dS} = \frac{1}{T}\mathbf{d}U + \frac{p}{T}\mathbf{d}V\tag{3.53}$$

considered to be a heat source that could do no work.

system.

behave just like *V*.

$$\frac{1}{T} = \left(\frac{\partial S}{\partial U}\right)_V; \quad \frac{p}{T} = \left(\frac{\partial S}{\partial V}\right)_U. \tag{3.54}$$

*T T* from which it follows that 1 *T* = - ∂*S* ∂*U V* ; *p T* = - ∂*S* ∂*V U* . (3.54)

Equations that give 1/*T* and *p*/*T* as functions of *U* and *V* are also equations of state. If we know these functions, Eq. (3.53) can be integrated to recover *S*(*U*, *V*). We also have the Maxwell relation (∂(1/*T*)/∂*V*)*U* = ∂(*p*/*T*)/∂*U V* . Since the entropy is postulated to be a monotonically increasing function of the internal energy, the internal energy is also a monotonically increasing function of the entropy. The inverse transformation between *S*(*U*, *V*) and *U*(*S*, *V*) is therefore unique, and either of these functional forms can be chosen to give a complete representation of the thermodynamic system.9 One speaks of the entropy representation *S*(*U*, *V*) or the energy representation *U*(*S*, *V*). Either of these equations can be regarded as a **fun-**

**damental equation of the system** and either contains complete information about the

<sup>9</sup>For more complicated systems, both *S* and *U* depend on an additional set of extensive variables, but these

*Chapter 3* • Second Law of Thermodynamics 43

$$\mathbf{dS} = (\mathbf{A}/\mathbf{4})(V/U)^{3/4}\,\mathrm{d}U + (3\mathbf{A}/\mathbf{4})(U/V)^{1/4}\,\mathrm{d}V,\tag{3.55}$$

**Example Problem 3.4.** For a hypothetical thermodynamic system, *T* = (4/*A*)(*U*/*V*)3/4 and

*p* = 3*U*/*V*, where *A* is a constant. Find the fundamental equation in the entropy representation. **Solution 3.4.** We readily calculate 1/*T* = (*A*/4)(*V*/*[U](#page-63-0)*)3/4 and *p*/*T* = (3*A*/4)(*U*/*V*)1/4 so Eq. (3.53) takes the form d*S* = (*A*/4)(*V*/*U*) 3/4 d*U* + (3*A*/4)(*U*/*V*) 1/4 d*V*, (3.55) which integrates to give *S* = *AU*1/4*V*3/4 + *S*0, where *S*0 is a constant. **Example Problem 3.5.** This problem concerns one mole of an ideal monatomic gas that obeys the equation *pV* = *RT*, where *p* is the pressure, *V* is the volume, *T* is absolute temperature, and *R* is the universal gas constant. The gas has a heat capacity (per mole) at

constant volume of *CV* = (3/2)*R*. In its initial state, it is in equilibrium at temperature *T*1 and volume *V*1 in the left chamber of a box, as shown in Figure 3–2. The right chamber of the box, which has volume *V*2 − *V*1, is initially evacuated. The two chambers are surrounded by exterior

- walls that are rigid and impenetrable. The chambers are separated *initially* by an interior wall that is rigid, impenetrable, and insulating. Under various conditions detailed below, the gas is allowed to expand and finally comes to equilibrium in the total volume *V*2. Apply the first and second laws of thermodynamics, the definition of *CV* , the ideal gas
- <span id="page-63-0"></span>equation of state, and integration to answer the following questions. (a) Suppose, by whatever means, that the gas expands into the total volume *V*2 and comes to equilibrium at temperature *T*2. What is the change, *S*, in entropy of the gas from its initial to its final state? (b) The entire system is maintained at constant temperature *T*1 by contact with a heat reservoir. The gas is allowed to expand by means of an external agent that moves the internal wall separating the chambers very slowly (such that the gas is practically in equilibrium at each stage of the process) until the gas occupies the entire volume *V*2. What is the change, *U*, in its internal energy? How much external work, *W*, does the system do on

![](_page_63_Figure_9.jpeg)

the external agent that moves the wall? How much heat, *Q*, is added to the system during this process? Compare *Q* to the relevant *S* and deduce whether this process is reversible

or irreversible.

**FIGURE 3–2** A monatomic ideal gas at temperature *T*1 initially occupies the left chamber of the box. The right chamber of the box, which has volume *V*2 − *V*1, is evacuated. The interior wall that separates the gas from the

evacuated chamber is rigid, impenetrable and insulating, but can be moved or ruptured.

- 
- 44 THERMAL PHYSICS (c) The entire system is insulated and the wall separating the chambers is suddenly ruptured, allowing the gas to fill the entire volume *V*2. How much external work, *W*, does the system do? What is the final temperature of the gas? Compare *Q* to the relevant *S* and deduce

### whether this process is reversible or irreversible. (d) The entire system is insulated. The gas is allowed [to](#page-62-0) [e](#page-62-0)xpand by means of an external

irreversible.

**Solution 3.5.**

- agent which moves the internal wall separating the chambers very slowly (such that the gas is practically in equilibrium at each stage of the process) until the gas occupies the entire volume *V*2. What is the final temperature, *T*2, of the gas? Compare *Q* to the relevant *S* and deduce whether this process is reversible or

$$\mathbf{dS} = C_V \frac{\mathbf{d}T}{T} + R \frac{\mathbf{d}V}{V},\tag{3.56}$$

(a) Since *S* is a state function, *S* depends only on the initial and final states of the system,

$$
\Delta \mathbf{S} = \mathbf{C}_V \ln(T_2/T_1) + R \ln(V_2/V_1), \quad \text{one mole of ideal gas.} \tag{3.57}
$$

- d*S* = *CV* d*T T* + *R* d*V V* , (3.56) which integrates to give *S* = *CV* ln(*T*2/*T*1) + *R* ln(*V*2/*V*1), one mole of ideal gas. (3.57)

$$Q = \mathcal{W} = RT_1 \int_{V_1}^{V_2} \frac{dV}{V} = RT_1 \ln(V_2/V_1). \tag{3.58}$$

integral to obtain

*S* >

 *V*2 *V*1

d*V*

*Q* = *W* = *RT*1

$$
\Delta S = Q / T_1 \tag{3.59}
$$

Since *T*2 = *T*1 for this process, part (a) gives *S* = *R* ln(*V*2/*V*1) so *S* = *Q*/*T*1 (3.59) and the process is reversible (as expected for quasistatic work). Note that the entropy increases for this reversible process. In this case, entropy increase does not automatically

- imply irreversibility *because the system is not isolated*. Similarly, for reversible adiabatic contraction, both *Q* and *S* are negative, and the entropy of the system decreases. This does not violate Eq. (3.1) *because the system is not isolated*.
(c) *W* = 0 because the outer wall is rigid and there is no way to do mechanical work on the environment of the system. Since *Q* = 0, we conclude from the first law that *U* = 0. Since *U* depends only on *T*, we have *T*2 = *T*1. (During the process itself, which we shall see is irreversible, *T* is at best inhomogeneous and probably undefined.) The change in entropy, from part (a), is again *S* = *R* ln(*V*2/*V*1) > 0. Therefore, since δ*Q* = 0 at every stage

$$
\Delta S > \int \frac{\delta Q}{T} = 0,\tag{3.60}
$$

so the process is irreversible as expected.

of the process,

- 

$$R_V \ln(T_2/T_1) + R \ln(V_2/V_1) = 0.\tag{3.61}$$

$$
\Delta S = \int \frac{\delta Q}{T} = 0,
$$

this becomes *CV* d*T* + *RT* d*V*/*V* = 0. Division by *T* (which is *not* constant in this process) yields *CV* d*T*/*T* + *R* d*V*/*V* = 0 which integrates to give *CV* ln(*T*2/*T*1) + *R* ln(*V*2/*V*1) = 0. (3.61) Thus, *S* = 0 and

*S* =

 δ*Q T* = 0,

so the process is reversible and isentropic, as expected for this quasistatic process with adiabatic walls. By means of Eq. (2.27), the final temperature can be written more succinctly

### as *T*2 = *T*1(*V*1/*V*2)2/3, so the temperature drops, as expected, for this reversible adiabatic

expansion.

3.4.1 Latent Heat When a substance melts or evaporates, heat must be supplied to partially or totally break atomic bonds and rearrange structure, and hence to change the phase to a state of higher disorder, which we shall see later is a state of higher entropy. Melting and vaporization processes are generally carried out at constant pressure, for example, atmospheric pressure. The heat needed to change the phase reversibly at constant pressure and temperature is known as **latent heat**. Heat must be supplied when a solid melts to become a liquid (heat of melting); the same amount is given up when a liquid freezes to become a solid (latent heat of fusion). When a liquid becomes a gas, it is necessary to supply heat (heat

of vaporization); when a gas condenses to become a liquid, the same amount of heat is given up (latent heat of condensation). These are generally reported as positive quan[tities,](#page-61-2) usually per mole or per unit mass. Consider, for example, the melting of ice, which takes place at atmospheric pressure at a temperature of 0 ◦C = 273.15 K. As we supply heat to cold ice, it is warmed from below its melting point to 273.15 K where melting occurs and water begins to form. As heat continues to be supplied, the ice-water mixture remains at 273.15 K until all of the ice

melts. This requires 80 calories of heat per gram of ice, the latent heat of fusion. Further heating causes the temperature of the water to rise. Processes such as this, which take place at constant pressure, may be analyzed conveniently in terms of the enthalpy, *H* = *U* +*pV* previously introduced in connection with the first law (see Section 2.5). We saw that d*H* = d*U* + *p* d*V* + *V* d*p* which in view of Eq. (3.47)

<span id="page-65-1"></span><span id="page-65-0"></span>
$$\mathbf{d}H = T\,\mathbf{dS} + V\,\mathbf{d}p.\tag{3.62}$$

d*H* = *T* d*S* + *V* d*p*. (3.62)

But at constant pressure we have

becomes

$$\mathbf{d}H = \mathbf{C}_p \mathbf{d}T,\tag{3.63}$$

46 THERMAL PHYSICS

$$
\Delta H = \int_{T_1}^{T_\text{M}} \mathbf{C}_p(\mathbf{i}\mathbf{e}) \,\mathrm{d}T + \Delta H_\text{M} + \int_{T_\text{M}}^{T_\text{W}} \mathbf{C}_p(\mathbf{water}) \,\mathrm{d}T.\tag{3.64}
$$

where *Cp* is the heat capacity at constant pressure. Equation (3.63) applies in the absence of phase change, say [for](#page-65-0) *T*I ≤ *T* < *T*M [an](#page-65-1)d also for *T*M < *T* ≤ *T*W, where *T*I is the initial temperature of the ice, *T*M is the melting point and *T*W is the final temperature of the water. At *T* = *T*M, *H* increases by the amount *H*M, the latent heat of fusion. The total change in

*H* is therefore

$$\mathbf{dS} = \frac{C_p}{T} \,\mathrm{d}T,\tag{3.65}$$

*H* as a function of *T* is shown in Figure 3–3a. Formally, the effective heat capacity at the melting point can be represented as a delta function (the formal derivative of a step function) as shown in Example Problem 2.4. By combining Eq. (3.62) with [Eq. (3.63) at](#page-66-0) constant pressure, we obtain d*S* = *Cp*

$$
\Delta S = \int_{T_1}^{T_\text{M}} \frac{C_p(\text{ice})}{T} \,\text{d}T + \frac{\Delta H_\text{M}}{T_\text{M}} + \int_{T_\text{M}}^{T_\text{W}} \frac{C_p(\text{water})}{T} \,\text{d}T.\tag{3.66}
$$

<span id="page-66-0"></span>obtain *S*M = *H*M/*T*M, which is called the entropy of fusion. Therefore, the total change

by *H*M = *T*M*S*M. (a) Enthalpy *H* versus *T* and (b) Entropy *S* versus *T*.

*H* =

 *T*M *T*I

of entropy is given by *S* = *T*M *Cp*(ice) d*T* + *H*M + *T*W *Cp*(water) d*T*. (3.66)

If the range of temperature is not large, *Cp*(ice) and *Cp*(water) can be considered to be

$$
\Delta H \approx \mathcal{C}_{\mathcal{P}}(\text{ice})(T_{\text{M}} - T_{\text{l}}) + \Delta H_{\text{M}} + \mathcal{C}_{\mathcal{P}}(\text{water})(T_{\text{W}} - T_{\text{M}}) \tag{3.67}
$$

![](_page_66_Figure_11.jpeg)

265 270 275 280 285 290 295 (a) 265 270 275 280 285 290 295 (b) **FIGURE 3–3** (a) Enthalpy change *H* in cal/mol and (b) entropy change *S* in cal/(mol K) as a function of temperature *T* in K for melting of ice. The curvature of the logarithms in *S* is not apparent on this scale. The jumps are related

10We assume that the whole process is done slowly and carefully so that it is reversible.

$$
\Delta S \approx C_p(\text{ice}) \ln \frac{T_\text{M}}{T_\text{I}} + \frac{\Delta H_\text{M}}{T_\text{M}} + C_p(\text{water}) \ln \frac{T_W}{T_\text{M}}.\tag{3.68}
$$

*Chapter 3* • Second Law of Thermodynamics 47

$$
\Delta H = (189 + 1440 + 351) \,\text{cal/mol} = 1980 \,\text{cal/mol} \tag{3.69}
$$

and

$$
\Delta \text{S} = (0.67 + 5.27 + 1.27) \,\text{cal/K} \,\text{mol} = 7.21 \,\text{cal/K} \,\text{mol}.\tag{3.70}
$$

To get an idea of the magnitudes involved, we approximate *Cp*(ice)≈*Cp*(water)≈1 cal/g K, take *T*I = −10 ◦C and *T*W = 20 ◦C. Then for every mole of H2O (18 g/mol) we have *H* = (189 + 1440 + 351) cal/mol = 1980 cal/mol (3.69) and *S* = (0.67 + 5.27 + 1.27) cal/K mol = 7.21 cal/K mol. (3.70) For many monatomic substances, *S*M = *H*M/*T*M ∼ *R* ≈ 2 cal/K mol, an empirical rule known as **Richard's rule**. For ice, t[he en](#page-59-0)tropy of fusion is much larger (5.27 cal/K mol)

### known as **Trouton's rule** leads to the estimate *SV* = *HV* /*TV* ∼ 10.5*R* ≈ 21 cal/K mol, as compared to 26 cal/K mol for water. The fact that the entropy of [vap](#page-67-0)orization is larger

because of the complexity of the H2O molecule. For vaporization, a similar empirical rule

than the entropy of fusion is because essentially all atomic bonds must be broken for evaporation and because of the large volume change from liquid to gas. 3.5 Statistical Interpretation of Entropy The entropy *S* enters classical thermodynamics as a mysterious state function whose changes can be calculated from Eq. (3.33). Unlike other state variables such as the internal energy *U* or the pressure *p*, it has no roots in classical mechanics. Its e[xis](#page-67-1)tence is related to the fact that the absolute temperature *T* is regarded in thermodynamics to be a state variable, and the entropy *S* turns out to be its **conjugate variable**. 11 A more thorough

### understanding of entropy requires a statistical analysis. Later we will discuss entropy in the context of the formal postulates that underlie statistical mechanics. For now, we give a

actually countable. See Chapters 16 and 26 for details.

<span id="page-67-1"></span><span id="page-67-0"></span>brief statistical interpretation based on a few simple ideas. 3.5.1 Relationship of Entropy to Microstates In order to understand entropy, we must appreciate that for every macrostate of a system, which corresponds to a fixed energy and other extensive parameters, there are a number of compatible microstates, and the system could be in any one of them.12 In fact, it could progress through a number of compatible microstates as time evolves. If we assume that

$$S = f(\mathfrak{Q}).\tag{3.71}$$

*S* = *f*(). (3.71)

<sup>11</sup>In the differential d*U* = *T* d*S* − *p* d*V*, *T* is said to be conjugate to *S* and −*p* is conjugate to *V*. For a more

general definition of conjugate variables, see Section 5.5. 12According to quantum mechanics, the system will have a discrete set of energy eigenstates, which are

<span id="page-68-0"></span>48 THERMAL PHYSICS For an isolated system, natural processes are those that correspond to an increase in

$$\mathbf{S} = \mathbf{S}_1 + \mathbf{S}_2.\tag{3.72}$$

<span id="page-68-1"></span>anticipate that *f* () will be a monotonically increasing function of , which turns out to be the [case.](#page-68-1) Once Eq. (3.71) is accepted, the form of the function *f* () can be determined by

$$f(\Omega_1 \Omega_2) = f(\Omega_1) + f(\Omega_2). \tag{3.73}$$

*S*1 and *S*2. Since *S* is assumed to be additive for composite systems, w[e](#page-68-1) [have](#page-68-1)

$$f(\Omega_1) = f(\Omega_1) + f(1),\tag{3.74}$$

the number of microstates is 12. Therefore, Eq. (3.72) may be written *f* (12) = *f*(1) + *f* (2). (3.73)

$$
\Omega_1 f'(\Omega_1 \Omega_2) = f'(\Omega_2) \tag{3.75}
$$

<span id="page-68-2"></span>*f* (1) = *f* (1) + *f* (1), (3.74)

where *k* = *f*

In Eq. (3.73), we first set 2 = 1 to obtain

$$f'(\Omega_1) = \frac{k}{\Omega_1},\tag{3.76}$$

1*f* and again set 2 = 1 to get *f* (1) = *k* 1 , (3.76)

$$S = k \ln \Omega.\tag{3.77}$$

where *C* is a constant. Since *f* (1) = 0, we conclude that *C* = 0. Therefore, returning to our general notation, we have

*S* = *k* ln . (3.77) In order for *S* to be a monotonically increasing function of , we must choose *k* > 0. For an isolated system, Eq. (3.77) is a fundamental equation that relates entropy to statistical mechanical concepts. It states th[at th](#page-68-2)e entropy is proportional to the logarithm of the number of microstates that are compatible with a given macrostate. The constant of

$$k_{\rm B} = 1.381 \times 10^{-16} \,\text{erg/K} = 1.381 \times 10^{-23} \,\text{J/K} = 3.301 \times 10^{-24} \,\text{cal/K}.\tag{3.78}$$

*k*B = 1.381 × 10−16 erg/K = 1.381 × 10−23 J/K = 3.301 × 10−24 cal/K. (3.78) It is related to the gas constant *R* = *NAk*B where *N*A = 6.022 mol−1 is Avogadro's number

$$R = 8.314 \times 10^{-7} \text{ erg/(mol K)} = 8.314 \text{ J/(mol K)} = 1.987 \text{ cal/(mol K)}.\tag{3.79}$$

*R* = 8.314 × 10−7 erg/(mol K) = 8.314 J/(mol K) = 1.987 cal/(mol K). (3.79) For a more rigorous justification of Eq. (3.77) in the context of information theory and the microcanonical ensemble, see Chapter 15, particularly Eq. (15.14), and Chapter 16.

![](_page_69_Picture_0.jpeg)

4 Third Law of Thermodynamics

### The third law of thermodynamics is the latest of the three laws of thermodynamics to

be developed. It insures that the entropy remains well-defined at the absolute zero of temperature and allows one to define a zero of entropy that is consistent with statistical mechanics. This avoids having to deal with entropy differences; instead, we can deal with entropies as absolute quantities, analogous to absolute temperature but unlike energy. 4.1 Statement of the Third Law The entropy *S* of a thermodynamic system in internal equilibrium approaches a universal constant *S*0, independent of phase, as the absolute temperature *T* tends to zero. Alter-

### where {ext} stands for the remaining members of a complete set of extensive variables. By convention, and in agreement with statistical mechanics, the value of this universal

4.1.1 Discussion of the Third Law

constant *S* → *S*0 is taken to be zero. Since entropy is a monotonically increasing function of temperature, this convention results in the entropy being a positive quantity.

natively, one could say that *S* → *S*0 in a state for which the quantity (∂*U*/∂*S*){ext} → 0,

$$S = k_{\mathbb{B}} \ln \Omega,\tag{4.1}$$

According to statistical mechanics, as motivated by Eq. (3.77), the entropy of an isolated system is given by *S* = *k*B ln, (4.1) where *k*B is Boltzmann's constant and is the number of microstates that correspond to a given macrostate. If at absolute zero only a unique ground state of the system is occupied, then = 1 and *S* = 0. Possibly the ground state could be degenerate, in which case = 1 even at *T* = 0. But this degeneracy would have to be massive to make a significant difference in the entropy of a macroscopic system at *T* = 0. Indeed, to get a contribution *S* = 10−10*R* = 10−10*k*B*N*A for one mole at absolute zero would require the ground state degeneracy 0 [to satisfy 10](http://dx.doi.org/10.1016/B978-0-12-803304-3.00004-1)−10*N*A = ln 0, where *N*A is Avogadro's number. This yields 0 ∼ e6×1013 ∼ 102.6×1013. But such a huge degeneracy is contrary to experience. As the ground state of a quantum system is approached (as *T* → 0), the number of accessible quantum states decreases quite rapidly and is no longer of exponential order, even though there could still be a ground state of much smaller degeneracy. An illuminating discussion

of this point has been presented by Benjamin Widom [17, chapter 5]. The third "law" is an extension by Max Planck [15, p. 273] of the so-called Nernst postulate [2, p. 277] that was made in an attempt to justify an empirical rule of Thomsen

and Berthelot for chemical reactions that take place at constant temperature and pressure.

50 THERMAL PHYSICS Nernst conjectured that their empirical rule for equilibrium, which is equivalent to minimizing the enthalpy change *H* of the reaction, would be in agreement with the proper thermodynamic criterion obtained by minimizing an appropriate change in free energy1 of the reaction, provided that the entropy change *S* tends to zero as *T* → 0. This can be interpreted to mean that the entropy *S* itself tends to some constant, independent of the extent of the reaction, as *T* → 0. For convenience, Planck set this entropy constant to zero,

### [2, p. 30] states the third law as an independent postulate, namely that *S* = 0 in a state for which ∂*U*/∂*S* = 0 (which is true at absolute zero by definition of the thermodynamic

temperature). From the point of view of classical thermodynamics, one could deal with entropy differences and it would not be necessary to adopt a state of zero entropy; however, doing so leads to simplicity and builds a strong bridge to statistical mechanics. 4.2 Implications of the Third Law

which agrees with the convention used to define entropy in statistical mechanics. Callen

$$S(T_1, V) = \int_0^{T_1} \frac{C_V(T, V)}{T} \,\mathrm{d}T.\tag{4.2}$$

heat capacity at constant volume. The change in entropy at constant volume from one temperature to another is given by - *CV* /*T* d*T*. Thus *S*(*T*1, *V*) = *T*1 0 *CV* (*T*, *V*) *T* d*T*. (4.2) In order for this i[nte](#page-70-0)gral to converge, it is necessary for *CV* to depend on *T* in such a way that *CV* → 0 as *T* → 0. Recall that *CV* was taken to be a constant for an ideal gas; clearly such an ideal gas becomes impossible as *T* → 0. For insulating solids, one finds both theoretically and experimentally that *CV* ∝ *T*3 as *T* → 0. For metals, nearly free electrons

$$S(T_1, p) = \int_0^{T_1} \frac{C_p(T, p)}{T} \,\mathrm{d}T\tag{4.3}$$

 *T*1 *Cp*(*T*, *p*)

<span id="page-70-0"></span>*S*(*T*1, *p*) = 0 *T* d*T* (4.3) and it is necessary2 for *Cp* → 0 as *T* → 0. An interesting experimental verification of the third law has been discussed by Fermi [1, p. 146]. At temperatures below *T*0 = 292 K, gray tin (α, diamond cubic) is the stable form and above this temperature, white tin (β, tetragonal) is stable. These are allotropic forms of pure tin. It turns out, however, that white tin can exist (in internal equilibrium)

below 292 K, even though it is unstable with respect to transformation to gray tin. It is also

<sup>1</sup>This is the change *G* of the Gibbs free energy of the reaction, whose definition and properties we explore

later. 2In order for the integrals in Eqs. (4.2) and (4.3) to converge at *T* = 0, it will suffice for *CV* or *Cp* to go to zero very weakly as *T* → 0, for instance ∝ *T* where > 0.

<span id="page-71-0"></span>![](_page_71_Figure_1.jpeg)

Gray

<span id="page-71-2"></span>0 K 292 K *T* **FIGURE 4–1** Entropies *S* of gray and white tin as a functi[on](#page-71-0) [of](#page-71-0) [absolute](#page-71-0) temperature *T*. Below *T*0 = 292 K, gray tin is stable and above this temperature white tin is stable. The full curves denote stable phases and the dashed curves denote unstable phases. White tin can be supercooled below *T*0 so its heat capacity can be measured and its entropy can be calculated. The jump in entropy at *T*0 between gray tin and white tin is due to the latent heat of transformation. possible to measure the heat capacities of both forms of tin down to very low temperatures. One can therefore evaluate the entropy of white tin at 292 K in two different ways,

$$\text{S}_{\text{W}}(292\,\text{K}) = \int_{0}^{292\,\text{K}} \frac{\text{C}_{\text{W}}(T)}{T} \,\text{d}T = 12.30 \,\text{cal/mol}\,\text{K},\tag{4.4}$$

(with subscripts *g* and *w* for gray and white), we have

*p*, one has

*S*

<span id="page-71-1"></span>
$$\mathrm{S_g}(292\,\mathrm{K}) = \int_0^{292\,\mathrm{K}} \frac{\mathrm{C_g}(T)}{T} \,\mathrm{d}T = 10.53\,\mathrm{cal/mol\,K} \tag{4.5}$$

and *S*g(292 *K*) = 292*K* 0 *C*g(*T*) *T* d*T* = 10.53 cal/mol K. (4.5)

The heat of transformation from gray to white tin is *H*g→w = 535 cal/mol so the entropy of transformation is *S*g→w = *H*g→w/*T*0 = 535/292 = 1.83 cal/mol K. Adding this to the result of Eq. (4.5) gives 12.36 cal/mol K, in reasonable agreement with Eq. (4.4). The third law can also shed light on the behavior of the coefficient of thermal expan-

$$
\left(\frac{\partial S}{\partial V}\right)_{T=0} = 0; \quad \left(\frac{\partial S}{\partial p}\right)_{T=0} = 0. \tag{4.6}
$$

$$
\dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots
$$

 ∂*S* ∂*V T*=0 = 0; ∂*S* ∂*p T*=0 = 0. (4.6)

∂*S*

$$
\left(\frac{\partial S}{\partial p}\right)_T = -\left(\frac{\partial V}{\partial T}\right)_p = -V\alpha,\tag{4.7}
$$

∂*p T* ∂*T p* where α is the coefficient of isobaric thermal expansion. Indeed, it has been verified experimentally that α → 0 as *T* → 0. By means of another Maxwell relation (see Eq. (5.86))

$$
\left(\frac{\partial S}{\partial V}\right)_T = \left(\frac{\partial p}{\partial T}\right)_V = \alpha / \kappa_T,\tag{4.8}
$$

where κ*T* is the coefficient of isothermal compressibility. Thus, κ*T* must either remain nonzero as *T* → 0 or go to zero more slowly than α.

See Lupis [5, pp. 21-23] for further discussion of experimental verification of the third law as well as a discussion of some of its other consequences, particularly consequences concerning chemical reactions. See Fermi [1, p. 150] for an excellent discussion of the entropy of mercury vapor.

5 Open Systems Until now we have dealt with chemically closed thermodynamic systems in which there is no exchange of chemical components with the environment. Such chemically closed systems can receive heat *Q* from the environment and do work *W* on their environment.

$$\mathbf{d}U = T\,\mathbf{dS} - p\,\mathbf{d}V.\tag{5.1}$$

work is δ*W* = *p* d*V*, where *p* is the pressure and *V* is the volume. The heat received in a reversible change is δ*Q* = *T* d*S*, where *T* is the absolute temperature and *S* is the entropy. If the mole numbers of each chemical component are constant (no chemical reactions), the combined first and second laws (see Chapter 3) lead to

$$
\Delta U = Q - \mathcal{W} + E_{\text{ch}},\tag{5.2}
$$

Open systems can exchange chemical components with their environment. Consequently the number of moles of each chemical component, *Ni*, for *i* = 1, 2, ... , κ, are variables. This requires several modifications. The first law must be amended to read -*U* = *Q* − *W* + *E*ch, (5.2) where *E*ch is the energy (sometimes called chemical heat) that is added to the system when chemical components are exchanged with its environment. Moreover, *U* now b[ec](#page-73-0)omes a function of *S*, *T* and all of the *Ni*, so additional terms are needed in Eq. (5.1). This also sets

### the stage for changes of *Ni* due to chemical reactions within the system, which can even occur for a chemically closed system for which *E*ch = 0. We shall first treat an open system having a single component and then go on to treat multicomponent systems.

5.1 Single Component Open System If the simple chemically closed isotropic system discussed above has only one chemical component and is now opened to allow exchange of that component with the environ-

<span id="page-73-0"></span>
$$\mathbf{d}U = T\mathbf{dS} - p\mathbf{d}V + \mu \,\mathrm{dN},\tag{5.3}$$

where now

$$T = \left(\frac{\partial U}{\partial S}\right)_{V,N}; \quad -p = \left(\frac{\partial U}{\partial V}\right)_{S,N}; \quad \mu = \left(\frac{\partial U}{\partial N}\right)_{S,V}.\tag{5.4}$$

*S*,*V*

<span id="page-73-1"></span>d*U* = *T* d*S* − *p* d*V* + μd*N*, (5.3)

∂*N*

1Instead of *N*, we could use the mass, *M* or the number of atoms *N* . Then the resulting chemical potentials

*S*,*N*

∂*V*

∂*S*

*V*,*N*

*T* =

54 THERMAL PHYSICS

<span id="page-74-0"></span>The quantity μ, introduced originally by Gibbs [3], is called the **chemical potential**, by analogy to the thermal potential *T*. We shall see later that μ can be expressed as a function

$$
\mu(T, p) = \mu^*(T) + RT \ln p = RT \ln \frac{p}{p^*(T)},\tag{5.5}
$$

<span id="page-74-1"></span>and always holds for infinitesimal changes within the field of equilibrium states. 5.1.1 Ideal G[as](#page-74-0) The chemical potential of a monocomponent ideal gas can be written in the form μ(*T*, *p*) = μ∗(*T*) + *RT* ln *p* = *RT* ln *p p*∗(*T*) , (5.5) where *p*∗(*T*) is a function of temperature with dimensions of pressure. In this standard

$$
\mu(T, p) = \mu^0(T, p_0) + RT \ln p / p_0. \tag{5.6}
$$

dimensions of an energy. This can be fixed [by w](#page-74-1)riting μ∗(*T*)+ *RT* ln *p* = μ∗(*T*)+ *RT* ln *p*0 + *RT* ln *p*/*p*0, where *p*0 is a reference pressure, usually taken to be one atmosphere. Then the quantity μ0(*T*, *p*0) = μ∗(*T*) + *RT* ln *p*0 is the chemical potential of this ideal gas at *p*0 and we can write Eq. (5.5) in the form μ(*T*, *p*) = μ0(*T*, *p*0) + *RT* ln *p*/*p*0. (5.6) Moreover, if *p*0 is equal to one atmosphere, it is often omitted from formulas with the understanding that all pressures are expressed in atmospheres. In this case, the term *RT* ln *p*0 = 0, so numerically μ∗(*T*) = μ0(*T*, *p*0), even though the dimensions do not agree.

We avoid this shortcut in the interest of clarity, so pressures can be measured in any units. Even though each term on the right of Eq. (5.6) depends on *p*0, their sum is independent

of *p*0. Even for a real gas, liquid, or solid, μ(*T*, *p*) must be independent of any reference pressure such as *p*0.

**Example Problem 5.1.** For *N* moles of an ideal gas, the equation of state Eq. (2.12) takes the form *pV* = *NRT*. Show that its chemical potential can be expressed as a function of only its concentration *c* = *N*/*V* and the temperature. At the standard temperature *T*0 = 25 ◦C and a pressure of one standard atmosphere (1.01325×105 Pa), the volume of one mole of an ideal gas is 22.4 l. If one mole of gas remains at temperature *T*0 but is compressed so that it occupies only

2 l, how much does its chemical potential change compared to that at standard temperature and pressure?

$$
\mu = \mu^*(T) + RT\ln c\\RT = \mu^*(T) + RT\ln RT + RT\ln c.\tag{5.7}
$$

2Since *U* is only defined up to an additive constant, μ is similarly only defined up to a compatible additive constant. In practice, one usually adopts so-called standard states and deals with the quantities μ − μ0, where μ0 refers to the standard state.

μ = μ∗(*T*) + *RT* ln *cRT* = μ∗(*T*) + *RT* ln *RT* + *RT* ln *c*. (5.7)

The change in chemical potential at temperature *T*0 is μ = *RT*0 ln *c*/*c*0 = *RT*0 ln(22.4/2) = 2.416*RT*0. We have *T*0 = 25 + 273.15 = 298.15 K, so *RT*0 = 2479 J and μ = 5868 J. Alternat[ively](#page-74-0), we could evaluate the new pressure, which would be *p* = 11.2 atmospheres, and use Eq. (5.6) to get the same answer. At a given temperature, we see that the chemical potential of an ideal gas is just a measure of concentration, or pressure, on a logarithmic scale.

<span id="page-75-0"></span>**Example Problem 5.2.** According to statisticalmechanics, the chemical potential per atom of a monatomic gas having atoms of mass *m* is given by *k*B*T* ln[*n*/*nQ*(*T*)], where *k*B is Boltzmann's constant, *n* is the number of atoms per unit volume, and *nQ*(*T*) is the quantum concentration

$$\mu = RT \ln \frac{p}{n_Q(T)k_\mathcal{B}T} \tag{5.8}$$

3/2*k*B*T*. (5.9)

*Chapter 5* • Open Systems 55

**Solution 5.2.** To obtain the chemical potential per mole, [we](#page-75-0) simply multiply the given

$$p^*(T) = n_Q(T) \mathbf{k}_\mathbf{B} T = (m \mathbf{k}_\mathbf{B} T / 2\pi \hbar^2)^{3/2} \mathbf{k}_\mathbf{B} T. \tag{5.9}$$

μ = *RT* ln *p nQ*(*T*)*k*B*T* (5.8) from which we identify

### expressed will cancel when μ is evaluated, as illustrated by Eq. (5.8).

<span id="page-75-1"></span>*p*[∗](#page-73-1)(*T*) = *nQ*(*T*)*k*B*T* = (*mk*B*T*/2π*h*¯ 2)

d*U* = *T* d*S* − *p* d*V* +κ

Of course μ∗(*T*) = −*RT* ln *p*∗(*T*). Formally, numerical evaluation of μ∗(*T*) involves taking the logarithm of a quantity with dimensions of pressure, but the units in which pressures are

5.2 Multicomponent Open Systems

$$\mathbf{d}U = T\,\mathbf{dS} - p\,\mathbf{d}V + \sum_{l=1}^{k} \mu_{l}\,\mathbf{dN}_{l} \tag{5.10}$$

μ*i* d*Ni*, (5.10)

Then

where

$$T = \left(\frac{\partial U}{\partial S}\right)_{V, \{N_l\}}; \quad -p = \left(\frac{\partial U}{\partial V}\right)_{S, \{N_l\}}; \quad \mu_l = \left(\frac{\partial U}{\partial N_l}\right)_{S, V, \{N_l'\}}.\tag{5.11}$$

*T* = ∂*S V*,{*Ni*} ; −*p* = ∂*V S*,{*Ni*} ; μ*i* = ∂*Ni S*,*V*,{*N i*} . (5.11) Here, {*Ni*} stands for the entire set *N*1, *N*2, ... , *N*κ , and {*N i* } stands for that same set but with *Ni* missing. Since this notation is cumbersome, we will often omit these subscripts, but they should always be borne in mind to avoid confusion. Equation (5.11) defines κ + 2 intensive variables (*p*, *T*, and κ chemical potentials, one for each chemical component), although we shall see that only κ + 1 of them are independent (see Eq. (5.45)). One says 56 THERMAL PHYSICS

∂2*f* ∂*x*∂*y* = ∂2*f*

∂*y*∂*x* ;

- ∂*T* ∂*Ni*

− -∂*p* <span id="page-76-1"></span>that such a thermodynamic system has κ + 1 **degrees of freedom**. These thermodynamic degrees of freedom should not be confused with the number of degrees of freedom (typically of order 1023) of the underlying microscopic system. Equation (5.11) is valid for all infinitesimal changes of *S*, *V*,{*Ni*} within the field of equilibrium states and these

<span id="page-76-2"></span>
$$\mathbf{df} = \left(\frac{\partial f}{\partial \mathbf{x}}\right)_{\mathbf{y}, \mathbf{z}} \mathbf{dx} + \left(\frac{\partial f}{\partial \mathbf{y}}\right)_{\mathbf{z}, \mathbf{x}} \mathbf{dy} + \left(\frac{\partial f}{\partial \mathbf{z}}\right)_{\mathbf{x}, \mathbf{y}} \mathbf{dz} \tag{5.12}$$

In general, [Maxw](#page-76-1)ell r[elatio](#page-76-2)ns are obtained by equating the mixed second derivatives of a

*x*, *y*, and *z*. Then

cha[ng](#page-76-0)es are reversible.

$$
\frac{\partial^2 f}{\partial \mathbf{x} \partial \mathbf{y}} = \frac{\partial^2 f}{\partial \mathbf{y} \partial \mathbf{x}}; \quad \frac{\partial^2 f}{\partial \mathbf{y} \partial \mathbf{z}} = \frac{\partial^2 f}{\partial \mathbf{z} \partial \mathbf{y}}; \quad \frac{\partial^2 f}{\partial \mathbf{z} \partial \mathbf{x}} = \frac{\partial^2 f}{\partial \mathbf{x} \partial \mathbf{z}}.\tag{5.13}
$$

d*f* = -∂*f* ∂*x y*,*[z](#page-76-3)* d*x* + -∂*f* ∂*y z*,*x* d*y* + -∂*f* ∂*z x*,*y* d*z* (5.12) and3

<span id="page-76-3"></span>
$$
\left(\frac{\partial T}{\partial V}\right)_{\mathcal{S},\{N_l\}} = -\left(\frac{\partial p}{\partial \mathcal{S}}\right)_{V,\{N_l\}}.\tag{5.14}
$$

Equations (5.12) and (5.13) can be extended to any number of dependent variables. If we apply Eq. (5.13) to the first two members of Eq. (5.10), we obtain -∂*T* ∂*V* = −-∂*p* . (5.14)

$$
\left(\frac{\partial T}{\partial N_l}\right)_{\text{S,V,\{N_l^V\}}} = \left(\frac{\partial \mu_l}{\partial \mathbf{S}}\right)_{V,\{N_l\}},\tag{5.15}
$$

$$-\left(\frac{\partial p}{\partial N_l}\right)_{S,V,\{N_l'\}} = \left(\frac{\partial \mu_l}{\partial V}\right)_{S,\{N_l\}},\tag{5.16}$$

of another variable, for example,

thermodynamic functions.

<span id="page-76-0"></span>and for *i* = *j*

relations such as

$$\left(\frac{\partial \mu_l}{\partial N_l}\right)_{\text{S,V,\{N_j'\}}} = \left(\frac{\partial \mu_f}{\partial N_l}\right)_{\text{S,V,\{N_l'\}}}.\tag{5.17}$$

- ∂μ*i* ∂*Nj S*,*V*,{*N j*} = - ∂μ*j* ∂*Ni S*,*V*,{*N i*} . (5.17)

-∂μ*i*

For a system having κ chemical components, the number of these Maxwell relations is (κ + 2)(κ + 1)/2. Additional Maxwell relations may be obtained by solving Eq. (5.10) for the differential

3These relations are true if the derivatives exist and are continuous, which we will assume to be the case for

$$\mathbf{dS} = \frac{1}{T}\mathbf{d}U + \frac{p}{T}\mathbf{d}V - \sum_{l=1}^{k} \frac{\mu_l}{T} \mathbf{d}N_l. \tag{5.18}$$

Then

$$\left(\frac{\partial(1/T)}{\partial V}\right)_{U,\{N_l\}} = \left(\frac{\partial(p/T)}{\partial U}\right)_{V,\{N_l\}},\tag{5.19}$$

$$\left(\frac{\partial(1/T)}{\partial N_l}\right)_{U,V\{N_l'\}} = -\left(\frac{\partial(\mu_l/T)}{\partial U}\right)_{V,\{N_l\}},\tag{5.20}$$

$$\left(\frac{\partial(p/T)}{\partial N_l}\right)_{U,V\{N_l'\}} = -\left(\frac{\partial(\mu_l/T)}{\partial V}\right)_{U,\{N_l\}},\tag{5.21}$$

and for *i* = *j*

$$\left(\frac{\partial(\mu_l/T)}{\partial N_l}\right)_{U,V,\{N_j^r\}} = \left(\frac{\partial(\mu_f/T)}{\partial N_l}\right)_{U,V,\{N_l^r\}}.\tag{5.22}$$

Maxwell relations may be used to simplify thermodynamic expressions and also to derive formulae for desired quantities in terms of experimentally measurable quantities.

**Example: relationship of** *Cp* **to** *CV***:** A useful result of Maxwell relations is the general formula (previously quoted in Eq. (2.16) without proof ) that connects the heat capacity at constant pressure *Cp* to that at constant volume, *CV* . Here, we deal with a chemically closed system in the absence of chemical reactions, so we drop the subscripts {*Ni*} for the sake of simplicity. From the definitions *CV* := (δ*Q*/d*T*)*V* and *Cp* := (δ*Q*/d*T*)*p* and δ*Q* = d*U* + *p* d*V* for quasistatic work, we have

$$\mathbf{C}_{V} = \left(\frac{\partial U}{\partial T}\right)_{V} \quad \text{and} \tag{5.23}$$

$$\mathbf{C}_{P} = \left(\frac{\partial U}{\partial T}\right)_{p} + p\left(\frac{\partial V}{\partial T}\right)_{p} = \left(\frac{\partial U}{\partial T}\right)_{V} + \left(\frac{\partial U}{\partial V}\right)_{T}\left(\frac{\partial V}{\partial T}\right)_{p} + p\left(\frac{\partial V}{\partial T}\right)_{p}.\tag{5.24}$$

Therefore,

$$\mathbf{C}_{p} = \mathbf{C}_{V} + \left[ \left( \frac{\partial U}{\partial V} \right)_{T} + p \right] \left( \frac{\partial V}{\partial T} \right)_{p} \,. \tag{5.25}$$

To get the derivative (∂*U*/∂*V*)*T* , we make use of the fact that the entropy is a function of state with differential

$$\mathbf{dS} = \frac{1}{T}\mathbf{d}U + \frac{p}{T}\mathbf{d}V = \frac{1}{T}\left(\frac{\partial U}{\partial T}\right)_V \mathbf{d}T + \left[\frac{1}{T}\left(\frac{\partial U}{\partial V}\right)_T + \frac{p}{T}\right] \mathbf{d}V,\tag{5.26}$$

where we now regard *S* to be a function of *T* and *V*. Therefore

$$\left\{ \frac{\partial}{\partial V} \left[ \frac{1}{T} \left( \frac{\partial U}{\partial T} \right)_V \right] \right\}_T = \left\{ \frac{\partial}{\partial T} \left[ \frac{1}{T} \left( \frac{\partial U}{\partial V} \right)_T + \frac{p}{T} \right] \right\}_V,\tag{5.27}$$

which becomes

$$\frac{1}{T}\frac{\partial^2 U}{\partial V \partial T} = \frac{1}{T}\frac{\partial^2 U}{\partial T \partial V} - \frac{1}{T^2} \left[ \left( \frac{\partial U}{\partial V} \right)_T + p \right] + \frac{1}{T} \left( \frac{\partial p}{\partial T} \right)_V. \tag{5.28}$$

-∂*p* 58 THERMAL PHYSICS

<span id="page-78-2"></span>
$$
\left[ \left( \frac{\partial U}{\partial V} \right)_T + p \right] = T \left( \frac{\partial p}{\partial T} \right)_V,\tag{5.29}
$$

1 ∂2*U* ∂*V*∂*[T](#page-78-0)* = 1 ∂2*U* ∂*T*∂*V* − 1 -∂*U* 

*T*

<span id="page-78-1"></span>- ∂*p* ∂*T V* - ∂*T* ∂*V*

∂*U* ∂*V T* + *p* = *T* - ∂*p* ∂*T V*

$$\mathbf{C}_{p} = \mathbf{C}_{V} + T \left( \frac{\partial p}{\partial T} \right)_{V} \left( \frac{\partial V}{\partial T} \right)_{p} \,. \tag{5.30}$$

. (5.28)

-

*T*

$$
\left(\frac{\partial p}{\partial T}\right)_V \left(\frac{\partial T}{\partial V}\right)_p \left(\frac{\partial V}{\partial p}\right)_T = -1\tag{5.31}
$$

, (5.29)

∂*T V* ∂*T p* Finally, we use the relation5

+ *p* + 1

$$\mathbf{C}_{p} = \mathbf{C}V + \frac{TV\alpha^2}{\kappa_T},\tag{5.32}$$

to eliminate ∂*p*/∂*T V* . Then the definitions of the coefficient of expansion α := (1/*V*) (∂*V*/∂*T*)*p* and the compressibility κ*T* := −(1/*V*) ∂*V*/∂*p T* lead to *Cp* = *CV* + *TV*α2 κ*T* , (5.32) which is the same as Eq. (2.16). The isothermal compressibility κ*T* is always positive whereas the coefficient of thermal expansion α is usually positive but can be negative

or even zero, as it is for water near 4 ◦C. Since Eq. (5.32) depends on α2, we see that *Cp* − *CV* ≥ 0. For gases, *Cp* can be considerably larger than *CV* but for condensed phases the difference between them is relatively small.

$$\mathbf{C}_{V} = T \left( \frac{\partial \mathbf{S}}{\partial T} \right)_{V} \quad \text{and} \tag{5.33}$$

$$C_p = T \left(\frac{\partial S}{\partial T}\right)_p = T \left(\frac{\partial S}{\partial T}\right)_V + T \left(\frac{\partial S}{\partial V}\right)_T \left(\frac{\partial V}{\partial T}\right)_p. \tag{5.34}$$

∂*T*

Thus

<span id="page-78-0"></span>δ*Q* = *T* d*S*, so we can write

*Cp* = *T*

and solving for the remaining partial derivative.

∂*T*

*p* = *T*

$$C_p = C_V + T \left(\frac{\partial S}{\partial V}\right)_T \left(\frac{\partial V}{\partial T}\right)_p. \tag{5.35}$$

. (5.34)

∂*V*

+ *T*

*T*

∂*V*

∂*T*

4This is called the Helmholtz equation and sometimes written (∂*U*/∂*V*)*T* = *T*2 ∂(*p*/*T*)/∂*T V* . 5This relation follows immediately from the differential d*V* = (∂*V*/∂*T*)*p* d*T* + ∂*V*/∂*p T* d*p* by setting d*V* = 0

∂*T*

*p*

$$\mathbf{d}F = \mathbf{d}U - T\,\mathbf{dS} - \mathbf{S}\,\mathbf{d}T = -\mathbf{S}\,\mathbf{d}T - p\,\mathbf{d}V.\tag{5.36}$$

$$
\left(\frac{\partial S}{\partial V}\right)_T = \left(\frac{\partial p}{\partial T}\right)_V,\tag{5.37}
$$

To find an expression for (∂*S*/∂*V*)*T* , we invent a new state function6 *F* := *U* − *TS* so that

### d*F* = d*U* − *T* d*S* − *S* d*T* = −*S* d*T* − *p* d*V*. (5.36)

Regarding *F* [to be a functio](#page-88-0)n of *T* and *V*, we see that - ∂*S* ∂*V T* = - ∂*p* ∂*T V* , (5.37) so Eq. (5.35) becomes Eq. (5.30) and Eq. (5.32) follows as above. 5.2.2 Other Maxwell Relations

### <span id="page-79-0"></span>any state function. This is usually done by defining other functions that are related to *U* and *S* by means of Legendre transformations. A number of specific examples are presented in Section 5.5.1. Tables of so[me M](#page-79-0)axwell relations and a mnemonic diagram

Maxwell relations can be obtained by equating the mixed second partial derivatives of

for remembering them are given by Callen [2, chapter 7] but many others exist and can be derived as needed.

<span id="page-79-2"></span>
$$f(\lambda x, \lambda y, \lambda z) = \lambda^n f(x, y, z),\tag{5.38}$$

A function *f* (*x*, *y*, *z*) is said to be a homogeneous function of degree *n* with respect to the variables *x*, *y*, and *z* if *f* [(λ](#page-79-0)*x*, λ*y*, λ*z*) = λ*nf* (*x*, *y*, *z*), (5.38)

$$\mathbf{x}\left(\frac{\partial f}{\partial \mathbf{x}}\right)_{\mathbf{y},\mathbf{z}} + \mathbf{y}\left(\frac{\partial f}{\partial \mathbf{y}}\right)_{\mathbf{z},\mathbf{x}} + \mathbf{z}\left(\frac{\partial f}{\partial \mathbf{z}}\right)_{\mathbf{x},\mathbf{y}} = \boldsymbol{\eta}f(\mathbf{x},\mathbf{y},\mathbf{z}).\tag{5.39}$$

<span id="page-79-1"></span>Euler theorem states that *[x](#page-79-1)* -∂*f* ∂*x* [+](#page-79-2) *y* -∂*f* ∂*y* + *z* -∂*f* ∂*z* = *nf* (*x*, *y*, *z*). (5.39)

*x*,*y*

This theorem, illustrated for three dependent variables, holds for any number of dependent variables.

*z*,*x*

define later. For now, it is just a convenient state function that will allow us to get the desired result.

*y*,*z*

$$\frac{\partial f(\lambda \mathbf{x}, \lambda \mathbf{y}, \lambda \mathbf{z})}{\partial (\lambda \mathbf{x})} \frac{\partial (\lambda \mathbf{x})}{\partial \lambda} + \frac{\partial f(\lambda \mathbf{x}, \lambda \mathbf{y}, \lambda \mathbf{z})}{\partial (\lambda \mathbf{y})} \frac{\partial (\lambda \mathbf{y})}{\partial \lambda} + \frac{\partial f(\lambda \mathbf{x}, \lambda \mathbf{y}, \lambda \mathbf{z})}{\partial (\lambda \mathbf{z})} \frac{\partial (\lambda \mathbf{z})}{\partial \lambda} = n \lambda^{n-1} f(\mathbf{x}, \mathbf{y}, \mathbf{z})\tag{5.40}$$

∂*f* (λ*x*, λ*y*, λ*z*) ∂(λ*x*) ∂(λ*x*) ∂λ + ∂*f* (λ*x*, λ*y*, λ*z*) ∂(λ*y*) ∂(λ*y*) ∂λ + ∂*f* (λ*x*, λ*y*, λ*z*) ∂(λ*z*) ∂(λ*z*) ∂λ = *n*λ*n*−1*f* (*x*, *y*, *z*) (5.40) and note that ∂(λ*x*)/∂λ =*x*, ∂(λ*y*)/∂λ = *y* and ∂(λ*z*)/∂λ = *z*. After the differentiation is done, we set λ = 1 in Eqs. (5.40) and (5.39) results. Note especially that if the function *f* depends

$$f(\lambda \mathbf{x}, \lambda \mathbf{y}, \lambda \mathbf{z}, \mathbf{u}, v) = \lambda^n f(\mathbf{x}, \mathbf{y}, \mathbf{z}, \mathbf{u}, v), \tag{5.41}$$

*f* (λ*x*, λ*y*, λ*z*, *u*, *v*) = λ*nf* (*x*, *y*, *z*, *u*, *v*), (5.41) 6This state function is actually the Helmholtz free energy, a useful thermodynamic potential that we shall

<span id="page-80-0"></span>*n* = 1, we obtain

60 THERMAL PHYSICS Eq. (5.39) still holds, with no corresponding terms for *u* and *v*. In other words, Eq. (5.41)

$$x\frac{\partial\phi}{\partial x} + y\frac{\partial\phi}{\partial y} + z\frac{\partial\phi}{\partial z} = 2x^2 - \frac{2x^2z^4}{(x^2+y^2)^2} + 2y^2 - \frac{2y^2z^4}{(x^2+y^2)^2} + \frac{4z^3}{x^2+y^2} = 2\phi.$$

**Examples:** The function φ(*x*, *y*, *z*) := *x*2 + *y*2 + *z*4/(*x*2 + *y*2) is a homogeneous function of degree 2 in *x*, *y*, and *z*. We have ∂φ/∂*x* = 2*x* −2*xz*4/(*x*2 +*y*2)2, ∂φ/∂*y* = 2*y* −2*yz*4/(*x*2 +*y*2)2, and ∂φ/∂*z* = 4*z*3/(*x*2 + *y*2). Thus

*x* ∂φ ∂*x* + *y* ∂φ ∂*y* + *z* ∂φ ∂*z* = 2*x*2 − 2*x*2*z*4 (*x*2 + *y*2)2 + 2*y*2 − 2*y*2*z*4 (*x*2 + *y*2)2 + 4*z*3 *x*2 + *y*2 = 2φ. The function ψ(*x*, *y*, *z*) := sin(*x*/*y*) + *z*2/*x*2 is a homogeneous function of degree zero in *x*, *y*, and *z*. We have ∂ψ/∂*x* = (1/*y*) cos(*x*/*y*) − 2*z*2/*x*3, ∂ψ/∂*y* = −(*x*/*y*2) cos(*x*/*y*) and

∂ψ/∂*z* = 2*z*/*x*2, which yields *x*∂ψ/∂*x* + *y*∂ψ/∂*y* + *z*∂ψ/∂*z* = 0. The function η(*x*, *y*, *z*) := *x*3 +*y*3 +*z*2 is not a homogeneous function with respect to the variables *x*, *y*, and *z*. The function ζ (*x*, *y*, *z*) := *x*3*z* + *y*3*z*2 is not a homogeneous function with respect to the variables *x*, *y*, and *z*, but it is a homogeneous function of degree 3 in *x*

### and *y* with *z* held constant. Then *x*(∂ζ /∂*x*)*y*,*z* + *y* ∂ζ /∂*y x*,*z* = 3ζ . Note that it is not necessary for *n* to be an integer, and that *n* can even [be](#page-80-0) negative.

Thus, the function φ(*x*, *y*, *z*) := (*x*/*yz*)1/3 + (1/*x*)1/3 is a homogeneous function of degree *n* = −1/3 in *x*, *y*, and *z* and Eq. (5.39) holds, as the reader may verify.

<span id="page-80-1"></span>
$$U(\lambda S, \lambda V, \lambda N_1, \lambda N_2, \dots, \lambda N_k) = \lambda U(S, V, N_1, N_2, \dots, N_k). \tag{5.42}$$

We note that *U*, which is extensive, is a homogeneous function of degree one in the extensive variables *S*, *V*, *N*1, *N*2, ... , *N*κ . Thus, *U*(λ*S*, λ*V*, λ*N*1, λ*N*2, ... , λ*N*κ ) = λ*U*(*S*, *V*, *N*1, *N*2, ... , *N*κ ). (5.42) For example, if we double all of the extensive variables on which *U* depends, we will obtain

$$U = T\mathbf{S} - pV + \sum_{l=1}^{k} \mu_l N_l. \tag{5.43}$$

*U* = *TS* − *pV* +κ μ*iNi*. (5.43)

to the extensive variables on which *U* depends, so any constant multiple such as 2 will cancel.

$$\mathbf{d}U = T\,\mathbf{dS} + \mathbf{S}\,\mathbf{d}T - p\,\mathbf{d}V - V\,\mathbf{d}p + \sum_{l=1}^{\kappa} \mu_{l}\,\mathbf{d}N_{l} + \sum_{l=1}^{\kappa} N_{l}\,\mathbf{d}\mu_{l}.\tag{5.44}$$

*i*=1

*i*=1

<sup>7</sup>This follows because the intensive variables are partial derivatives of the extensive variable *U* with respect

<span id="page-81-1"></span><span id="page-81-0"></span>
$$\mathbf{0} = \mathbf{S} \, \mathbf{d}T - V \, \mathbf{d}p + \sum_{l=1}^{\kappa} N_l \, \mathbf{d}\mu_l. \tag{5.45}$$

*Chapter 5* • Open Systems 61 By comparing with Eq. (5.10), we deduce that

0 = *S* d*T* − *V* d*p* +κ *i*=1 *Ni* dμ*i*. (5.45) Eq. (5.45) is the **Gibbs-Duhem equation** for a multicomponent system. It shows that

$$\mathbf{d}\mu = -\mathbf{s}\,\mathrm{d}T + v\,\mathrm{d}p,\tag{5.46}$$

related. Thus for a κ component system, there are only κ + 1 independent intensive variables. For a monocomponent system, there are two independent intensive variables, say *p* and *T*, and μ(*p*, *T*) can be regarded to be a function of them.8 In that case, Eq. (5.45) can be divided by *N* and written in the form dμ = −*s* d*T* + *v* d*p*, (5.46) w[here](#page-81-0) *s* := *S*/*N* is the entropy per mole and *v* := *V*/*N* is volume per mole (molar volume).

![](_page_81_Picture_7.jpeg)

and *cv* depend on *T*.

*p*(*T*,μ).

three independent intensive variables, say *p*, *T*, and μ1, and then μ2(*p*, *T*,μ1). For a three component system, there would be four independent intensive variables, etc. **Example Problem 5.3.** By using the chemical potential of an ideal gas given by Eqs. (5.5) and

(5.46), determine its equations of state. From these results, calculate the enthalpy per mole *h* and the internal energy per mole *u* and comment on their dependence on pressure. Deduce the relationship between the molar heat capacities *cV* and *cp* at constant volume and constant pressure and compare with Eq. (2.13). **Solution 5.3.** We have *v* = ∂μ/∂*p T* = *RT*/*p*, which just reproduces the ideal gas law, which is

$$h = \mathbf{u} + pv = \mu + T\mathbf{s} = \mu^*(T) - T\frac{\mathbf{d}\mu^*(T)}{\mathbf{d}T},\tag{5.47}$$

dμ∗(*T*)

If the functions *s*(*T*, *p*) and *v*(*T*, *p*) are known (these are the two equations of state of

$$
\mu = h - pv = \mu^*(T) - T\frac{\mathbf{d}\mu^*(T)}{\mathbf{d}T} - RT,\tag{5.48}
$$

*u* = *h* − *pv* = μ∗(*T*) − *T* dμ∗(*T*) d*T* − *RT*, (5.48) which is also a function of only the temperature, independent of *v*. We readily compute *cp* = d*h*/d*T* = −*T*d2μ∗(*T*)/d*T*2 and *cv* = d*u*/d*T* = *cp* − *R* in agreement with Eq. (2.13), even if *cp*

<sup>8</sup>We could make other choices, such as regarding *T* and μ as the independent variables, and then writing

independent **mole fractions**

<span id="page-82-0"></span>
$$X_l := N_l / N,\tag{5.49}$$

62 THERMAL PHYSICS

**Composition:** For multicomponent systems, one often regards the independent intensive

κ *i*=1

*i*=1

$$\sum_{l=1}^{k} X_l = 1\tag{5.50}$$

*Xi* := *Ni*/*N*, (5.49) where *N* = κ *i*=1 *Ni* is the total number of moles. Note that the *Xi* are intensive variables, because they are ratios of extensive variables. Moreover, we have

$$\sum_{l=1}^{k} \mathbf{dX}_l = \mathbf{0} \tag{5.51}$$

so only κ−1 of them are independent, as already stated. Taking the differential of Eq. (5.50) gives κ d*Xi* = 0 (5.51)

$$
\mu_l \neq \left(\frac{\partial U}{\partial X_l}\right)_{\text{S,V,\{X_l^\times\}}} \tag{5.52}
$$

μ*i* d*Ni*, (5.53)

by taking a single partial derivative with respect to an *Xi*, that is,

and depends on the molecular masses, *mi*. Specifically, ω*i* = *miXi*/

μ*i* = -∂*U* ∂*Xi S*,*V*,{*X i*} (5.52) because the right-hand side is meaningless. For a system with two components, we could take a set of the independent intensive variables to be *p*, *T*, and *X*1, in which case μ1(*p*, *T*, *X*1) and μ2(*p*, *T*, *X*1). For three

components, independent intensive variables could be *p*, *T*, *X*1, and *X*2, in which case μ1(*p*, *T*, *X*1, *X*2), μ2(*p*, *T*, *X*1, *X*2), and μ3(*p*, *T*, *X*1, *X*2). To recover an extensive description, we could add to these variable sets *N* or any one of the *Ni*.

$$\mathbf{d}H = \mathbf{d}U + p\,\mathbf{d}V + V\,\mathbf{d}p = T\,\mathbf{d}S + V\,\mathbf{d}p + \sum_{l=1}^{\kappa} \mu_l \,\mathbf{d}N_l,\tag{5.53}$$

*i*=1

 *j mjXj*.

<sup>9</sup>For a mass based description, we can describe composition by the mass fractions ω*i* := *Mi*/*M*, where *Mi* is the mass of the *i*th component and *M* = κ *i*=1 *Mi* is the total mass. The relationship of the ω*i* to the *Xi* is nonlinear

$$T = \left(\frac{\partial H}{\partial S}\right)_{p, \{N_l\}}; \quad V = \left(\frac{\partial H}{\partial p}\right)_{S, \{N_l\}}; \quad \mu_l = \left(\frac{\partial H}{\partial N_l}\right)_{S, p, \{N_l'\}}.\tag{5.54}$$

*Chapter 5* • Open Systems 63

$$H(\lambda S, p, \lambda N_1, \lambda N_2, \dots, \lambda N_k) = \lambda H(S, p, N_1, N_2, \dots, N_k) \tag{5.55}$$

where Eq. (5.10) has been used. Thus, *H* is a **natural function**10 of *S*, *p*, and the *Ni* and we have -∂*H* -∂*H* - ∂*H* 

$$H = \text{TS} + \sum_{l=1}^{n} \mu_l N_l \tag{5.56}$$

*H*(λ*S*, *p*, λ*N*1, λ*N*2, ... , λ*N*κ ) = λ*H*(*S*, *p*, *N*1, *N*2, ... , *N*κ ) (5.55) because *p*, being intensive, does not participate. Thus, application of the Euler theorem

### *H* = *TS* +κ μ*iNi* (5.56)

d*u* = *T* d*s* − *p* d*v* +

*i*=1 which is in agreement with Eq. (5.43) once the definition of *H* is used. So we actually get nothing new (except self-consistency) and Eq. (5.45) follows as well. 5.3.2 Euler Theorem Applied to Intensive Functions Intensive functions are homogeneous functions of degree zero with respect to extensive

$$\mathfrak{u} = \frac{U(S, V, N_1, N_2, \dots, N_k)}{N} = \frac{U(\lambda S, \lambda V, \lambda N_1, \lambda N_2, \dots, \lambda N_k)}{\lambda N} \tag{5.57}$$

variables *S*, *V*, *N*1, *N*2, ... , *N*κ , which means that they can depend only on *ratios* of these variables, which ratios are themselves intensive. To see this formally, note that

*T* =

gives

∂*S*

*p*,{*Ni*}

; *[V](#page-80-1)* =

<span id="page-83-0"></span>
$$\mathfrak{u} = U(\mathfrak{s}, v, X_1, X_2, \dots, X_{\mathfrak{k}}),\tag{5.58}$$

*N* = *U*(λ*S*, λ*V*, λ*N*1, λ*N*2, ... , λ*N*κ ) λ*N* (5.57) and then choose λ = 1/*N* to deduce *u* = *U*(*s*, *v*, *X*1, *X*2, ... , *X*κ ), (5.58)

$$\mathfrak{u} = \mathfrak{u}(\mathfrak{s}, v, X_1, X_2, \dots, X_{\mathfrak{c}-1}) \tag{5.59}$$

independent variables,

of *U* or *S* with respect to their extensive variables).

whose differential turns out to be

$$\mathbf{d}u = T\,\mathbf{ds} - p\,\mathbf{d}v + \sum_{l=1}^{\kappa - 1} (\mu_l - \mu_{\kappa})\,\mathbf{dX}_l. \tag{5.60}$$

(μ*i* − μκ ) d*Xi*. (5.60)

10A natural function is a thermodynamic potential that contains information equivalent to a fundamental equation (for *U* or *S*) and whose independent variables are either members of the original complete set of extensive variables (on which *U* or *S* depends) or their conjugate variables (which are the partial derivatives

*i*=1

<span id="page-84-0"></span>
$$\mathbf{d}\mu = \frac{\mathbf{d}U}{N} - \frac{U}{N^2}\mathbf{d}N = \frac{1}{N} \left[ T\,\mathbf{dS} - p\,\mathrm{d}V + \sum_{l=1}^{\kappa} \mu_l \,\mathrm{d}N_l \right] - \frac{1}{N^2} \left[ T\mathbf{S} - pV + \sum_{l=1}^{\kappa} \mu_l N_l \right] \mathrm{d}N. \tag{5.61}$$

64 [THE](#page-84-0)RMAL PHYSICS

$$\mathbf{d}u = T\,\mathbf{ds} - p\,\mathbf{d}v + \sum_{l=1}^{\kappa} \mu_l \,\mathbf{dX}_l,\tag{5.62}$$
 
$$\text{which demonstrates that } \mathbf{F} = (\mathbf{f}, \mathbf{C} \mathbf{0}) \text{ after } \mathbf{d}V \text{ is a division and } \mathbf{N} \text{ to the decision theorem.}$$

d*u* = d*U N* − *U N*2 d*N* = 1 *N T* d*S* − *p* d*V* +κ *i*=1 μ*i* d*Ni N*2 *i*=1 μ*iNi* d*N*. (5.61) But d*s* = d*S*/*N* − (*S*/*N*2) d*N*, d*v* = d*V*/*N* − (*V*/*N*2) d*N* and d*Xi* = d*Ni*/*N* − (*Ni*/*N*2) d*N*, so Eq. (5.61) becomes

d*u* = *T* d*s* − *p* d*v* +κ

In a similar way, we can deduce that

numerically.

 

$$
\mu_V = \mathfrak{u}(\mathfrak{s}_V, \mathfrak{c}_1, \mathfrak{c}_2, \dots, \mathfrak{c}_k), \tag{5.63}
$$

which reduces to Eq. (5.60) after d*X*κ is eliminated. Note in this derivation that the total number of moles *N* was treated as a variable, even though the result appears as if we just treated it as a constant and divided by it.

$$\mathbf{d}\mu_V = T\,\mathbf{ds}_V + \sum_{l=1}^{\kappa} \mu_l \,\mathbf{dc}_l. \tag{5.64}$$

where *sV* := *S*/*V* is the entropy per unit volume and the *ci* := *Ni*/*V* are the **concentrations** of each component (in moles per unit volume). The corresponding differential is

$$\mathbf{d}h = T\mathbf{ds} + v\,\mathbf{d}p + \sum_{l=1}^{k-1} (\mu_l - \mu_k)\,\mathrm{d}\mathbf{X}_l.\tag{5.65}$$

$$\mathbf{d}h = T\,\mathbf{ds} + v\,\mathbf{d}p + \sum_{l=1}^{k-1} (\mu_l - \mu_k)\,\mathrm{d}\mathbf{X}_l.\tag{5.65}$$

### d*h* = *T* d*s* + *v* d*p* [+](#page-84-1) κ −1 (μ*i* − μκ ) d*Xi*. (5.65)

per mole, which is a function of *s*, *p*, *X*1, *X*2, ... , *X*κ−1 and whose differential is

*i*=1 5.4 Chemical Potential of Real Gases, Fugacity

<span id="page-84-1"></span>
$$\stackrel{\frown}{\mu}(T,\mathfrak{p}) = \stackrel{\frown}{\mu^*(T)} + RT\ln f; \quad f \to p \text{ as } p \to 0. \tag{5.66}$$

fugacity (see, for example, Denbigh [18, p. 125]). To do this, we replace Eq. (5.5) by μ(*T*, *p*) = μ∗(*T*) + *RT* ln*f* ; *f* → *p* as *p* → 0. (5.66) The **fugacity** *f* (*T*, *p*) is an effective pressure11 that replaces the pressure *p* of an ideal gas. Equation (5.66) is based on the idea that all gases will tend toward ideal gas behavior if sufficiently dilute, which will be the case for fixed temperature at sufficiently low pressure. Therefore, the function μ∗(*T*) is precisely the same function of *T* as for the corresponding

ideal gas. 11One can also employ a dimensionless fugacity *f D* = *f* /*p*0, where *p*0 is a reference pressure, by adding a term *RT* ln *p*0 to μ∗(*T*). Then if *p*0 = 1 atmosphere and pressures are measured in atmospheres, the term *RT* ln *p*0 = 0

<span id="page-85-0"></span>![](_page_85_Figure_1.jpeg)

200 400

200 400 600 800 1000 *p*

$$v(T, p) = \left(\frac{\partial \mu(T, p)}{\partial p}\right)_T = RT \left(\frac{\partial \ln f}{\partial p}\right)_T; \quad f \to p \text{ as } p \to 0. \tag{5.67}$$

The general dependence of the fugacity on pressure may be deduced by integrating the equation

$$\left(\frac{\partial \ln(f/p)}{\partial p}\right)_T = \frac{v(T,p)}{RT} - \frac{1}{p}.\tag{5.68}$$

In order to avoid a singularity and to incorporate the condition on *f* [at low](#page-85-0) pressures, we rewrite Eq. (5.67) in the form

$$\ln(f/p) = \int_0^p \left[ \frac{v(T, p')}{RT} - \frac{1}{p'} \right] \,\mathrm{d}p'.\tag{5.69}$$

ln(*f* /*p*) = *p* 0 *v*(*T*, *p* ) *RT* − 1 *p* d*p* . (5.69) If the gas is ideal, the integrand vanishes and one obtains simply *f* = *p*. Depending on the temperature, many gases behave like ideal gases at atmospheric pressure *p*0, but at high pressures the deviations from ideality can be quite significant. Figure 5–1 shows a plot of fugacity versus pressure for the gases O2 and CO2 at a temperature of 200 ◦C, as well as for

an ideal gas, for which *f* = *p* at all temperatures. Note the opposite deviations from ideality.

*f*

*v*(*T*, *p*) =

-

<span id="page-85-1"></span>∂μ(*T*, *p*) ∂*p*

-

**Example Problem 5.4.** Suppose that a non-ideal gas has an expansion (called a virial

$$\frac{v(T,p)}{RT} = \frac{1}{p} \left[ 1 + \tilde{B}p + \tilde{C}p^2 + \cdots \right] = \frac{1}{p} + \tilde{B} + \tilde{C}p + \cdots,\tag{5.70}$$

66 THERMAL PHYSICS

<span id="page-86-0"></span>
$$\vec{B}(T) = \frac{2\pi}{3} \left[ \frac{\sigma_1^3 - (\mathbf{e}^{x/k_B T} - 1)(\sigma_2^3 - \sigma_1^3)}{k_B T} \right]. \tag{5.71}$$

fugacity of this gas. For [a](#page-85-1) [sim](#page-85-1)ple model based on a potential consisting of a hard repulsive core of diameter σ1, an attractive potential well of constant depth ε in the annular region

between a sphere of diameter σ2 and the repulsive core, and zero potential beyond, the first virial coefficient is given by

$$\ln[f(T, p)/p] = \int_0^p [\vec{B} + \tilde{\mathcal{C}}p' + \dotsb] dp' = \tilde{B}(T)p + (\tilde{\mathcal{C}}(T)/2)p^2 + \dotsb \,. \tag{5.72}$$

If this is the only important virial coef[ficien](#page-86-0)t, discuss briefly the effect of temperature on the fugacity.

yields

$$f(T, p) = p \exp[\tilde{B}(T)p + (\bar{C}(T)/2)p^2 + \dotsb]. \tag{5.73}$$

1 /*k*B*T*) at high temperatures. It therefore changes

ln[*f* (*T*, *p*)/*p*] = *p* 0 [*B*˜ + *Cp*˜ +···]*dp* = *B*˜(*T*)*p* + (*C*˜ (*T*)/2)*p*2 +··· . (5.72) Thus, *f* (*T*, *p*) = *p* exp[*B*˜(*T*)*p* + (*C*˜ (*T*)/2)*p*2 +···]. (5.73) The first virial coefficient given by Eq. (5.71) becomes *B*˜(*T*) = −(2π/3)(σ 3 2 − σ 3 1 )(eε/*k*B*T* /*k*B*T*)

sign from negative to positive as the temperature increases. If this is the only important virial coefficient, *f* < *p* and varies strongly with temperature for low temperatures and *f* > *p* and varies weakly with temperature for high temperatures. **Example Problem 5.5.** For the previous example, compare the chemical potential difference

μ(*T*, *p*) − μ(*T*, *p*0) for a real gas with that for a condensed phase (solid or liquid) for which the

condensed phases it is practically independent of pressure.

at low temperatures and *B*˜(*T*) = (2π/3)(σ 3

$$
\mu(T, p) - \mu(T, p_0) = RT \left[ \ln(p/p_0) + \tilde{B}(T)(p - p_0) + (\tilde{C}(T)/2)(p^2 - p_0^2) + \dotsb \right].\tag{5.74}
$$

μ(*T*, *p*) − μ(*T*, *p*0) = *RT* ln(*p*/*p*0) + *B*˜(*T*)(*p* − *p*0) + (*C*˜ (*T*)/2)(*p*2 − *p*2 0) +··· . (5.74)

The term *RT* ln(*p*/*p*0) is very important and the other terms represent a small correction unless the pressure is very large. 

$$
\mu(T, p) - \mu(T, p_0) = v(T, p_0)[(p - p_0) - (\kappa_T/2)(p - p_0)^2], \quad \text{solid or liquid}.\tag{5.75}
$$

μ(*T*, *p*) − μ(*T*, *p*0) = *v*(*T*, *p*0)[(*p* − *p*0) − (κ*T* /2)(*p* − *p*0) 2], solid or liquid. (5.75)

Except for very large pressure differences, this difference is small compared to *RT*. Therefore, for gases the chemical potential has a significant dependence on pressure but for

*Chapter 5* • Open Systems 67

5.5 Legendre Transformations Legendre transformations are frequently used in thermodynamics to define new functions

$$\mathbf{d}U = \sum_{l=1}^{\kappa+2} p_l \,\mathrm{d}E_l.\tag{5.76}$$

transformations.

<span id="page-87-1"></span>κ

$$p_l = \left(\frac{\partial U}{\partial E_l}\right)_{\{E_l'\}},\tag{5.77}$$

d*U* = *i*=1 *pi* d*Ei*. (5.76) The extensive variables *E*1 = *S*, *E*2 = *V*, and *Ei*+2 = *Ni* for *i* = 1, 2, ... , κ. Evidently -∂*U* 

<span id="page-87-0"></span>
$$L_{\!\!\!} := U - p_{\!\!\!} \! E_{\!\!\!} = U - E_{\!\!\!} \left( \frac{\partial U}{\partial E_{\!\!\!\!}} \right)_{\!\!\!\!\!\!/},\tag{5.78}$$

*i* = 1, 2, ... , κ. The variables *pi* and *Ei* are called **conjugate variables**. We now define a **Legendre transform** by means of the function -∂*U* 

$$\mathbf{d}L_{l} = \mathbf{d}U - p_{l}\mathbf{d}E_{l} - E_{l}\mathbf{d}p_{l} = -E_{l}\,\mathbf{d}p_{l} + \sum_{l \neq j}^{\kappa + 2} p_{l}\,\mathbf{d}E_{l}.\tag{5.79}$$

obt[ain](#page-87-0) d*Lj* = d*U* − *pj* d*Ej* − *Ej* d*pj* = −*Ej* d*pj* + κ +2 *i*=*j pi* d*Ei*. (5.79) We can regard *Lj* to be a function of *pj* [and t](#page-87-1)he remaining *Ei* for *i* = *j*. In other words, *Lj* depends on the slope of the function *U* with respect to *Ej*. Moreover, *Lj* itself is the *Ej* = 0 intercept of a graph of *U* versus *Ej*. Since a curve may be defined by the envelope of its tangent lines, a knowledge of intercept *Lj* as a function of slope *pj* is equivalent to a knowledge of *U* as a function of *Ej*, regarding all of the remaining *Ei*, for *i* = *j* to be fixed.

$$E_{\!\!\!} = -\left(\frac{\partial L_{\!\!\!}}{\partial p_{\!\!\!\!}}\right)_{\{E_{\!\!\!\!}^{\!\!\!}}\right. \tag{5.80}$$

*Ej* = −-∂*pj* {*E j* } . (5.80)

Eq. (5.79) yields

$$U = L_l + p_l E_l = L_l - p_l \left(\frac{\partial L_l}{\partial p_l}\right)_{\{E_j\}}.\tag{5.81}$$

*j* } We note the reciprocity (with appropriate sign changes) of the relationship between *U* and *Lj*, so they can be regarded as Legendre transforms of one another.

We next obtain a useful relation between second derivatives of Legendre transforms. We have

$$\frac{\partial^2 U}{\partial E_f^2} = \frac{\partial p_f}{\partial E_f} = -\frac{\partial p_f}{\partial (\partial L_f / \partial p_f)} = -1/\frac{\partial^2 L_f}{\partial p_f^2}.\tag{5.82}$$

Thus if *U* is a convex function (positive second derivative) of *Ej*, then *Lj* will be a concave function (negative second derivative) of *pj*.

**Simple example:** For a single variable *E*, suppose that *U* = *A* + *BE*2, where *A* and *B* are constants. Then *p* = ∂*U*/∂*E* = 2*BE* and *L* = *U* −*pE* = *A*−*BE*2 = *A*−*p*2/4*B*. For the inverse transformation, we start with *L*(*p*) and obtain *E* = −∂*L*/∂*p* = *p*/2*B*. Then *U* = *L* + *pE* = *A* + *p*2/4*B* = *A* + *BE*2. We also have ∂2*U*/∂*E*2 = 2*B* and ∂2*L*/∂*p*2 = −1/(2*B*).

We could make an additional Legendre transformation by selecting a second pair of conjugate variables, say *pkEk*, and subtracting from *Lj*. This produces a function

$$L_{jk} := L_j - p_k E_k = U - p_j E_j - p_k E_k = L_k - p_j E_j := L_{kj},\tag{5.83}$$

which can be thought of as a double Legendre transform of the original *U*. We will then have

$$\mathbf{d}L_{jk} = -E_{l}\mathbf{d}p_{l} - E_{k}\mathbf{d}p_{k} + \sum_{l \neq j,k}^{\kappa+2} p_{l}\mathbf{d}E_{l} \tag{5.84}$$

and we can regard *Ljk* to be a function of *pj*, *pk* and the remaining *Ei*, where *i* = *j*, *k*. This process can be continued up to κ + 1 successive Legendre transforms. Since the Euler equation is *U* = κ+2 *i*=1 *piEi*, we see that κ + 2 Legendre transforms of *U* would lead identically to zero. The total number of possible transforms is therefore 2κ+2 − 2.

### <span id="page-88-0"></span>5.5.1 Specific Legendre Transforms

We end this section by identifying several specific Legendre transforms that play an important role in thermodynamics and statistical mechanics.

**Helmholtz free energy** *F***:** We define the Helmholtz free energy by the Legendre transformation

$$F \coloneqq U - T\mathbf{S} \tag{5.85}$$

with differential

$$\mathbf{d}\,\mathbf{d}F = -\mathbf{S}\,\mathbf{d}T - p\,\mathbf{d}V + \sum_{l=1}^{\kappa} \mu_l \,\mathbf{d}N_l.\tag{5.86}$$

Effectively, the dependence of *U* on *S* is replaced by the dependence of *F* on *T*, whereas both *U* and *F* depend on *V* and {*Ni*}. Thus, *F* is useful in situations where *T* is a control

$$H \coloneqq U + pV\tag{5.87}$$

$$\mathbf{d}H = T\,\mathbf{dS} + V\,\mathbf{d}p + \sum_{l=1}^{k} \mu_l \,\mathrm{d}N_l.\tag{5.88}$$

**Enthalpy** *H***:** We have previously mentioned the enthalpy defined by *H* := *U* + *pV* (5.87) with differential

d*H* = *T* d*S* + *V* d*p* +κ *i*=1 μ*i* d*Ni*. (5.88)

$$\mathbf{G} := \mathbf{U} - \mathbf{T}\mathbf{S} + p\mathbf{V} = \mathbf{F} + p\mathbf{V} = \mathbf{H} - \mathbf{T}\mathbf{S}.\tag{5.89}$$

∂*H*/∂*p* (∂*V*/∂*S*)*p*,{*Ni*}.

*S*,*Ni*

that *V* = 

$$\mathbf{d}G = -\mathbf{S}\,\mathrm{d}T + V\,\mathrm{d}p + \sum_{l=1}^{k} \mu_{l}\,\mathrm{d}N_{l}.\tag{5.90}$$

It has a differential d*G* = −*S* d*T* + *V* d*p* +κ *i*=1 μ*i* d*Ni*. (5.90) The control variables for *G* are *T* and *p* as opposed to *S* and *V* for *U*. *G* is especially important for the study of chemical reactions that take place at various temperatures and atmospheric pressure. We note that *S* = −(∂*G*/∂*T*)*p*,*Ni* and *V* = ∂*G*/∂*p T*,*Ni* as well as ∂2*H*/∂*S*2 = −1/(∂2*G*/∂*T*2) and ∂2*F*/∂*V*2 = −1/(∂2*G*/∂*p*2). One Maxwell relation is ∂*S*/∂*p T*,{*Ni*} = −(∂*V*/∂*T*)*p*,{*Ni*}. Other useful Maxwell relations involving the chemical potentials are ∂μ*i*/∂*p T*,{*Ni*} = (∂*V*/∂*Ni*)*T*,*p*,{*N i*} =: *V*¯*i* and (∂μ*i*/∂*T*)*p*,{*Ni*} = −(∂*S*/∂*Ni*)*T*,*p*,{*N i*} =: *S*¯ *i*. The quantities *V*¯*i* and *S*¯ *i* are known respectively as the partial

molar volume and the partial molar entropy and are examples of partial molar quantities discussed in Section 5.6.

*i*=1

*i*=1

$$K := U - TS - \sum_{l=1}^{k} \mu_l N_l \tag{5.91}$$
 
$$\text{.........class - different, }$$

and has a differential

$$\mathbf{d}K = -S\,\mathrm{d}T - p\,\mathrm{d}V - \sum_{l=1}^{k} N_{l}\,\mathrm{d}\mu_{l}.\tag{5.92}$$

and *Ni* = −(∂*K*/∂μ*i*)*T*,*V*,{μ

70 THERMAL PHYSICS *K* depends on *T*, *V*, and all of the chemical potentials μ*i*. We note that *S* = −(∂*K*/∂*T*)*V*,{μ*i*}

$$\mathbf{dS} = (1/T)\,\mathrm{d}U + (p/T)\,\mathrm{d}V - \sum_{l=1}^{k} (\mu_l/T)\,\mathrm{d}N_l.\tag{5.93}$$

**Massieu functions:** The functions *F*, *H*, *G*, and *K*, which are known as thermodynamic

$$M_1(1/T, V, \langle \mathcal{N}_l \rangle) := \mathbb{S} - (1/T)U \equiv \mathbb{S}[1/T],\tag{5.94}$$

d*S* = (1/*T*) d*U* + (*p*/*T*) d*V* −κ

$$\mathbf{d}M_{l} = -U\,\mathbf{d}(1/T) + (\mathbf{p}/T)\,\mathbf{d}V - \sum_{l=1}^{k} (\mu_{l}/T)\,\mathrm{d}N_{l}.\tag{5.95}$$

*M*1([1](#page-78-2)/*T*, *V*,{*Ni*}) := *S* − (1/*T*)*U* ≡ *S*[1/*T*], (5.94)

*i*

$$\left(\frac{\partial U}{\partial V}\right)_{1/T, \{N_l\}} = -\left(\frac{\partial (p/T)}{\partial (1/T)}\right)_{V, \{N_l\}} = -p + T\left(\frac{\partial p}{\partial T}\right)_{V, \{N_l\}},\tag{5.96}$$

*i*=1 This differential leads to the Maxwell relation -∂*U* ∂*V* 1/*T*,{*Ni*} = −-∂(*p*/*T*) ∂(1/*T*) *V*,{*Ni*} = −*p* + *T* - ∂*p* ∂*T V*,{*Ni*} , (5.96)

$$M_2(U, p/T, \langle N_l \rangle) := S - (p/T)V \equiv \operatorname{Slp}(T);\tag{5.97}$$

$$\operatorname{dM}_2 = (1/T)\operatorname{d}U - V\operatorname{d}(p/T) - \sum_{l=1}^{\kappa} (\mu_l/T)\operatorname{dN}_l$$

<span id="page-90-0"></span>and13

$$\begin{aligned} \mathbf{M}3(1/T,\mathbf{p}/T,\{\mathbf{N}_l\}):=\mathbf{S}-(\mathbf{1}/T)U-(\mathbf{p}/T)V \equiv \mathbf{S}[\mathbf{1}(1/T,\mathbf{p}/T);\tag{5.98} \\ \mathbf{d}M_3 = -U\,\mathbf{d}(\mathbf{1}/T) - V\,\mathbf{d}(\mathbf{p}/T) - \sum_{l=1}^{\kappa} (\mu_l/T)\,\mathbf{d}N_l. \end{aligned} \tag{5.99}$$

d*M*3 = −*U* d(1/*T*) − *V* d(*p*/*T*) −κ *i*=1 (μ*i*/*T*) d*Ni*. One could also add quantities such as μ1/*T* to *S* to obtain a function *S*[μ1/*T*] that depends on μ1/*T* instead of *N*1. The total number of possible transforms of the entropy is 2κ+2 − 2,

just as for the transforms of the thermodynamic potentials.

<sup>12</sup>*M*1 is sometimes denoted by and called the Helmholtz free entropy. 13*M*3 is sometimes denoted by (or by Planck) and is called the Gibbs free entropy.

*Chapter 5* • Open Systems 71 **Natural variables:** The natural variables of a thermodynamic potential are the set of independent variables that give complete information about the system under consideration. For isotropic multicomponent fluids, the natural variables of the entropy are the set of extensive variables *U*, *V*, {*Ni*}, where {*Ni*} = *N*1, *N*2, ... , *N*κ . For the internal energy, the natural variables are *S*, *V*, and {*Ni*}. Since *S* is a monotonically increasing function of *U* with other extensive variables held constant, one can always transform uniquely

from *S*(*U*, *V*,{*Ni*}) to *U*(*S*, *V*,{*Ni*}) and vice versa for these fundamental equations. For the thermodynamic potentials, the natural variables are those independent variables that

### result from Legendre transformation. For example, any of the functions *F*(*T*, *V*,{*Ni*}), *H*(*U*, *p*,{*Ni*}), *G*(*T*, *p*,{*Ni*}), *K*(*T*, *V*,{μ*i*}), *M*3(1/*T*, *p*/*T*,{*Ni*}) contain complete information

about a system. It is possible and sometimes useful to express these functions in terms of other variable sets, as discussed in the next section. 5.6 Partial Molar Quantities This section applies to any extensive state function that can be expressed in terms of the complete variable [set](#page-91-0) *T*, *p*,{*Ni*} for a homogeneous system having κ chemical components. For example, we could consider the internal energy *U*(*T*, *p*,{*Ni*}), even though the natural variables for *U* are the set *S*, *V*,{*Ni*}. We could also consider the entropy *S*(*T*, *p*,{*Ni*}) or the enthalpy *H*(*T*, *p*,{*Ni*}), etc. Of course a transformation of variables is necessary to convert from the set of natural variables of a function to the

set *T*, *p*,{*Ni*}, except for *G*(*T*, *p*,{*Ni*}) where these are also its natural variables. As we shall see in Chapter 6, the temperature *T* and the pressure *p* are uniform for phases in mutual equilibrium, so functions expressed in terms of these intensive variables are particularly

$$\bar{Y}_l := \left(\frac{\partial Y}{\partial N_l}\right)_{T, \mathfrak{p}, l \mid N_l^\dagger}. \tag{5.99}$$

*i* are defined as derivatives14 *Y*¯*i* := - ∂*Y* 

<span id="page-91-2"></span><span id="page-91-1"></span>
$$Y(T, p, \lambda N1, \lambda N2, \dots, \lambda N_k) = \lambda Y(T, p, N1, N2, \dots, N_k) \tag{5.100}$$

<span id="page-91-0"></span>Since *Y* is an extensive function in the variables *N*1, *N*2, ... , *N*κ , we have

so the Euler theorem gives

important.

*Y*˜

$$Y = \sum_{l=1}^{k} \tilde{Y}_l N_l. \tag{5.101}$$

*i*}.

*Y* = κ *i*=1 *Y*¯ *iNi*. (5.101) Since *T* and *p* are held constant in the definition Eq. (5.99), we can differentiate

the equations that define *H*, *F*, and *G* to obtain *H*¯ *i* = *U*¯ *i* + *pV*¯*i*, *F*¯*i* = *U*¯ *i* − *TS*¯ *i*, and 14Instead of the mole numbers *Ni*, we could use the masses *Mi* of each chemical component. Then one could develop a parallel treatment in terms of partial specific quantities defined by *Y*˜ *i* := (∂*Y*/∂*Mi*)*T*,*p*,{*M*

72 THERMAL PHYSICS

*G*¯ *i* = *U*¯ *i* − *TS*¯ *i* + *pV*¯*i*. Therefore, these partial molar quantities obey the same algebra as their definitions. Since the natural variables for *G* are *T*, *p*,{*Ni*}, we observe that *G*¯ *i* ≡ μ*i*, which is just a sp[ecial s](#page-91-1)ymbol for this very important partial molar quantity. By the same reasoning as for *Y* , the corresponding Euler e[quatio](#page-91-2)ns in terms of partial molar quantities are *H* = *i H*¯ *iNi*, *F* = *i F*¯*iNi*, and *G* = *i G*¯ *iNi* = *i* μ*iNi*. Given the algebra of the partial molar quantities just mentioned, the first two of these are in agreement with the Euler equations *H* = *TS* + *i* μ*iNi* and *F* = −*pV* + *i* μ*iNi*. For our further development, we take the volume *V*(*T*, *p*, *N*1, *N*2, ... , *N*κ ) as a specific example, but the procedure is quite general and applies to any extensive function *Y* (*T*, *p*, *N*1, *N*2, ... , *N*κ ). If the partial molar volumes *V*¯*i* were constants, Eq. (5.101) for *V* would have the obvious interpretation that *V*¯*i* was the volume per mole actually occupied by species *i*, in which case the total volume would be a linear function of

<span id="page-92-2"></span>
$$V(T, p, N_1, N_2, \dots, N_k) = \sum_{l=1}^{k} \bar{V}_l(T, p, X_1, X_2, \dots, X_{k-1}) N_l. \tag{5.102}$$

as functions of the independent variable set *T*, *p*, *X*1, *X*2, ... , *X*κ−1. Written out in full, we

equation for the molar volume

have

but from *V* =

$$\mathbf{d}V = V\boldsymbol{\alpha}\,\mathbf{d}T - V\kappa_T\,\mathbf{d}p + \sum_{l=1}^{\kappa} \bar{V}_l \,\mathbf{dN}_l,\tag{5.103}$$

The differential of *V* is

<span id="page-92-3"></span><span id="page-92-0"></span>
$$\mathbf{d}V = \sum_{l=1}^{\kappa} \bar{V}_l \,\mathbf{d}N_l + \sum_{l=1}^{\kappa} N_l \,\mathbf{d}\bar{V}_l. \tag{5.104}$$

d*V* = κ *V*¯*i* d*Ni* +κ

$$\sum_{l=1}^{\kappa} N_l \,\mathrm{d}\bar{V}_l = V\alpha \,\mathrm{d}T - V\kappa \tau \,\mathrm{d}p,\tag{5.105}$$

κ *i*=1 *Ni* d*V*¯*i* = *V*α d*T* − *V*κ*T* d*p*, (5.105)

$$v \coloneqq \frac{V}{N} = \sum_{l=1}^{\kappa} \tilde{V}_l \mathbf{X}_l. \tag{5.106}$$
 
$$\text{For a single common material then is unknown nontrivial molecular volume } \tilde{V} \quad \triangle VU \text{ (M}\Omega\text{)}$$

*i*=1 For a single component material there is only one partial molar volume, *V*¯1=(∂*V*/∂*N*)*T*,*p*

<span id="page-92-1"></span>*v* := *V*

$$v = \frac{V}{N} = \left(\frac{\partial V}{\partial N}\right)_{T, p}, \quad \text{single component.} \tag{5.107}$$

$$
\mathbf{d} \operatorname{d} \ln v = \boldsymbol{\alpha} \,\mathrm{d}T - \kappa_T \,\mathrm{d}p,\quad \text{single component.}\tag{5.108}
$$

Thu[s](#page-92-2)

<span id="page-93-0"></span>
$$\alpha = \left(\frac{\partial \ln v}{\partial T}\right)_p; \quad \kappa_T = -\left(\frac{\partial \ln v}{\partial p}\right)_T, \quad \text{single component.}\tag{5.109}$$

In this simple case, the derivative with respect to *N* becomes just the ratio *V*/*N*. Equation (5.105) becomes d*v* = *v*α d*T* − *v*κ*T* d*p* which can be rewritten

$$v = \frac{V}{N} = \left(\frac{\partial V}{\partial N}\right)_{T, p, \{X_l\}}, \quad \text{multi component.} \tag{5.110}$$

α = -∂ ln *v* ∂*T p* ; κ*T* = −-∂*p T* , single component. (5.109) For a multicomponent material, we see from Eq. (5.106) that Eq. (5.107) must be replaced by

$$\mathbf{d}v = \frac{\mathbf{d}V}{N} - \frac{V}{N^2} \,\mathrm{d}N = vu \,\mathrm{d}T - v\kappa_T \,\mathrm{d}p + \sum_{l=1}^{\kappa} \bar{V}_l \,\mathrm{d}X_l$$

$$= vu \,\mathrm{d}T - v\kappa_T \,\mathrm{d}p + \sum_{l=1}^{\kappa - 1} (\bar{V}_l - \bar{V}_k) \,\mathrm{d}X_l,\tag{5.111}$$

d*v* = d*V N* − *V N*2 d*N* = *v*α d*T* − *v*κ*T* d*p* +κ *i*=1 *V*¯*i* d*Xi* κ

$$\alpha = \left(\frac{\partial \ln v}{\partial T}\right)_{p, \{X_l\}}; \quad \kappa_T = -\left(\frac{\partial \ln v}{\partial p}\right)_{T, \{X_l\}}.\tag{5.112}$$

<span id="page-93-1"></span>. (5.112)

### α = -∂ ln *v* ∂*T*

variables. Instead of Eq. (5.109), we now have

*p*,{*Xi*} *T*,{*Xi*} 5.6.1 Method of Intercepts The method of intercepts provides a useful graphical representation of partial molar quantities. W[e illust](#page-93-1)rate it for partial molar volumes, but it applies to any partial molar

∂ ln *v* ∂*p* 

<span id="page-93-2"></span>; κ*T* = −-

quantities. We first illustrate it for a binary system and then derive the general formulae for a multicomponent system. **Binary system:** For a binary system, there are only two chemical components, so we choose an independent variable set *p*, *T*, *X*2. Since *X*1 is not a member of this set, *X*2 is allowed to vary freely, so we can take partial derivatives with respect to *T*, *p*, or *X*2 while

$$v = \mathbb{V}_1 X_1 + \mathbb{V}_2 X_2 = \mathbb{V}_1 (1 - X_2) + \mathbb{V}_2 X_2 \tag{5.113}$$

*v* = *V*¯1*X*1 + *V*¯ 2*X*2 = *V*¯1(1 − *X*2) + *V*¯2*X*2 (5.113)

> - ∂*v* ∂*X*2

$$
\left(\frac{\partial v}{\partial X_2}\right)_{T,p} = \bar{V}_2 - \bar{V}_1. \tag{5.114}
$$

<span id="page-94-0"></span>74 THERMAL PHYSICS

pure component 1. *V*¯ 2(*T*, *p*, *X*∗

*X*∗

obtain

- ∂*v* ∂*Xi*

*T*,*p*,{*X i*}

*v*

![](_page_94_Figure_1.jpeg)

*V*¯ 1 *[T,p](#page-93-2)*

**FIGURE 5–2** Illustration of the method of intercepts to calculate partial molar volumes for a system of two components. We plot a graph of *v* versus *X*2 at fixed *p* and *T*. Then the partial molar volumes for some composition

*X*2 *X*2 ∗

$$
\bar{V}_1 = v - X_2 \left(\frac{\partial v}{\partial X_2}\right)_{T, p}; \tag{5.115}
$$

$$
\bar{V}_2 = v + (1 - X_2) \left( \frac{\partial v}{\partial X_2} \right)_{T, p} \,. \tag{5.116}
$$

∂*X*2 *T*,*p V*[¯](#page-94-0)2 = *v* + (1 − *X*2) - ∂*v* ∂*X*2 *T*,*p* . (5.116)

Equations (5.115) and (5.116) are illustrated in Figure 5–2. On a graph of *v* versus *X*2 (at fixed *T* and *p*) we see that the partial molar volumes for some composition *X*∗ 2 are given by the intercepts, at *X*2 = 0 and *X*2 = 1, of the tangent to *v* at *X*∗ 2 . This graphic construction allo[ws one](#page-93-1) to see immediately how *V*¯1 and *V*¯2 vary with composition *X*∗ 2 . For example, if *V* is a linear function of *X*2, its tangent is coincident with *V* itself and *V*¯1 and *V*¯2 are independent of *X*2. In that case, one can imagine that each component of the solution has a fixed physical volume. Moreover, if the curve *V* versus *X*2 is convex, instead of concave as in Figure 5–2, a partial molar volume could be negative! In that case, it makes no sense to think of a partial molar volume as a physical volume; instead, it is

only a manifestation of the slope of the *V* versus *X*2 curve, even though Eq. (5.113) still holds. **Multicomponent system:** For multicomponent systems, we use the second form of Eq. (5.111) which depends on the set of independent variables *p*, *T*, *X*1, *X*2, ... , *X*κ−1. Within this reduced variable set, we can take the partial derivative with respect to *Xi* to

$$\left(\frac{\partial v}{\partial X_l}\right)_{T, p, \langle X_l'\rangle} = (\bar{V}_l - \bar{V}_k); \quad i = 1, 2, \dots, \kappa - 1. \tag{5.117}$$

$$\sum_{l=1}^{\kappa-1} \mathbf{X}_l \left( \frac{\partial \upsilon}{\partial \mathbf{X}_l} \right)_{T, p, \{X_l'\}} = \sum_{l=1}^{\kappa-1} \mathbf{X}_l \bar{V}_l - \bar{V}_\kappa \sum_{l=1}^{\kappa-1} \mathbf{X}_l \\ \tag{5.118}$$
 
$$= \sum_{l=1}^{\kappa-1} \mathbf{X}_l \bar{V}_l + \mathbf{X}_\kappa \bar{V}_\kappa - \bar{V}_\kappa.$$

We multiply Eq. (5.117) by *Xi* and sum to get

κ −1 *i*=1 *Xi* - ∂*v* ∂*Xi* 

$$\bar{V}_{\kappa} = v - \sum_{l=1}^{\kappa - 1} X_l \left( \frac{\partial v}{\partial X_l} \right)_{T, p, \{X_l'\}}.\tag{5.119}$$

*B*, where *XA* = 1 − *XB* is the mole

*A*/∂*XB* +

= κ −1 *i*=1 *XiV*¯*i* + *X*κ*V*¯κ − *V*¯κ . Then by using Eq. (5.106), Eq. (5.118) becomes *V*¯κ = *v* − κ −1 *i*=1 *Xi* - ∂*v* ∂*Xi T*,*p*,{*X* } . (5.119)

*i*

Equation (5.119) can be interpreted geometrically by imagining *v* to be plotted as a

hypersurface in the coordinates *X*1, *X*2, ... , *X*κ−1. The quantity on its right-hand side is then seen to be the intercept on the *v* axis, at the origin of the *Xi*, of a hyperplane that is tangent to *v* at composition *X*1, *X*2, ... , *X*κ−1. Unlike the case of two components, this is

- not particularly easy to visualize.
	- **Example Problem 5.6.** A solution of *A* and *B* atoms at constant temperature and pressure has
	- a molar volume *v* = 3 + 2*XB* − *X*2 *B* cm3/mol, where *XB* is the mole fraction of *B* atoms. (a) Use [the](#page-92-0) [me](#page-92-0)thod of intercepts to calculate the partial molar volumes *V*¯*A* and *V*¯ *B*.

### (b) Show *explicitly* from your results that *v* = *[XAV](#page-92-3)*¯*A* + *XBV*¯

(c) We readily compute ∂*V*¯

*XB*∂*V*¯

- fraction of *A* atoms. Why is such a relation true? (c) Show *explicitly* from your results that 0 = *XA*(d*V*¯ *A*/d*XB*) + *XB*(d*V*¯ *B*/d*XB*). Why is such a relation true?
- **Solution 5.6.** (a) We calculate *V*¯ *A* = *v*(*XB*) − *XB*d*v*/d*XB* = *X*3 *B* − 3 and *V*¯*B* = *v*(*XB*) + (1 − *XB*)d*v*/d*XB* =
- *X*2 *B* − 2*XB* + 5. (b) We can easily check that *v* = *XAV*¯*A* + *XBV*¯ *B*, where *XA* = 1 − *XB*. This is just a special case of Eq. (5.106).

*A*/∂*XB* = 2*XB* and ∂*V*¯*B*/∂*XB* = 2*XB* − 2 = −2*XA* so *XA*∂*V*¯

*B*/∂*XB* = 0. This result follows from Eq. (5.105) for constant *T* and *p* after division by *N*.

5.7 Entropy of Chemical Reaction Before leaving this chapter, we show how the formalism developed for open systems can be used to treat chemically closed systems in which the mole numbers can vary by means of chemical reactions. Then we proceed to calculate the entropy due to a chemical reaction. See Chapter 12 for a more complete treatment of chemical reactions that includes heats of reaction and detailed conditions for equilibrium.

We begin with Eq. (5.10) and write

monoxide, namely

of Eq. (3.4), we obtain

δ*Q*

$$\mathbf{d}N_l = \mathbf{d}^{\text{int}}N_l + \mathbf{d}^{\text{ext}}N_l,\tag{5.120}$$

76 THERMAL PHYSICS

<span id="page-96-0"></span>
$$\sum_{l} v_{l} A_{l} = \mathbf{0},\tag{5.121}$$

d*Ni* = dint*Ni* + dext*Ni*, (5.120) where dext*Ni* denotes changes in *Ni* due to exchanges of chemical species with the external environment and dint*Ni* denotes changes due to chemical reactions internal to the system. For simplicity, we treat only one che[mical](#page-96-0) reaction, which we write in the symbolic form

$$\rm{C} + (1/2)\rm{O}_2 \rightarrow \rm{CO} \tag{5.122}$$

where *Ai* is the symbol (such as C, CO, CO2, H, H2, etc.) of the chemical species *i* and ν*i* is its stoichiome[tric c](#page-75-1)oefficient in the reaction. We regard ν*i* to be negative for reactants

<span id="page-96-2"></span><span id="page-96-1"></span>*i*

$$\mathbf{d}^{\text{int}} N_l = \nu_l \,\mathbf{d} \tilde{N},\tag{5.123}$$

C + (1/2)O2 → CO (5.122) could be written in the [form](#page-96-1) [o](#page-96-1)f Eq. (5.121) with *A*1 = C, *A*2 = O2, *A*3 = CO and ν1 = −1,

$$\mathbf{d}U = T\,\mathbf{dS} - p\,\mathbf{d}V + \sum_{l=1}^{\kappa} \mu_l v_l \,\mathbf{d}\tilde{N} + \sum_{l=1}^{\kappa} \mu_l \,\mathbf{d}^{\text{ext}} N_l. \tag{5.124}$$

pla[ce. Equation](#page-96-2) [(](#page-96-2)5.10) therefore becomes d*U* = *T* d*S* − *p* d*V* +κ μ*i*ν*i* d*N*˜ +κ μ*i* dext*Ni*. (5.124)

<span id="page-96-3"></span>
$$\mathbf{d}U = T\,\mathbf{dS} - p\,\mathbf{d}V + \sum_{l=1}^{k} \mu_l v_l \,\mathbf{d}\tilde{N}.\tag{5.125}$$

case it becomes d*U* = *T* d*S* − *p* d*V* +κ μ*i*ν*i* d*N*˜ . (5.125)

*i*=1

<span id="page-96-4"></span>
$$\frac{\delta Q}{T} + \frac{p \, \mathrm{d}V - \delta \mathcal{W}}{T} - \sum_{l=1}^{\kappa} \frac{\mu_l \nu_l}{T} \, \mathrm{d}\tilde{N} = \mathrm{d}S. \tag{5.126}$$

δ*Q T* + *p* d*V* − δ*W T* −κ *i*=1 μ*i*ν*i T* d*N*˜ = d*S*. (5.126)

$$
\delta Q \left( \frac{1}{T} - \frac{1}{T_s} \right) + \frac{p \, \mathrm{d}V - \delta \mathcal{W}}{T} - \sum_{l=1}^{\kappa} \frac{\mu_l \eta_l}{T} \, \mathrm{d}\tilde{N} = \mathrm{d}S - \frac{\delta Q}{T_s} \ge \mathbf{0},\tag{5.127}
$$
 
$$
\text{where the } \mathrm{i}\text{-norm called } \mathrm{d}\Lambda \text{ for natural irversumable } \mathrm{i}\text{-norm modulo } \mathrm{d}\Lambda.\text{ The } \mathrm{i}\text{-norm should be defined as}
$$

*Ts i*=1 *T Ts* where the inequality holds for natural irreversible processes and the equal sign holds for an idealized reversible process. Comparison with Eq. (3.52) reveals an additional term that

can represent irreversible entropy production due to chemical reaction.

<span id="page-97-0"></span>
$$\mathbf{dS} = \frac{\delta Q}{T} - \sum_{l=1}^{\kappa} \frac{\mu_l \nu_l}{T} \,\mathbf{d}\tilde{N} \ge \mathbf{0}.\tag{5.128}$$

*Chapter 5* • Open Syste[ms](#page-97-0) [77](#page-97-0) If only quasistatic work is done so that δ*W* = *p* d*V*, and *T* = *Ts* so there is no entropy production due to irreversible heat transfer, Eq. (5.127) becomes d*S* = δ*Q T* −κ μ*i*ν*i* d*N*˜ ≥ 0. (5.128)

$$\mathrm{d}S - \frac{\delta Q}{T} = -\sum_{l=1}^{\kappa} \frac{\mu_l v_l}{T} \,\mathrm{d}\tilde{N} > 0,\tag{5.129}$$

to vanish. For d*N*˜ = 0, this would require κ *i* μ*i*ν*i* = 0, which turns out to be the condition that the reaction is in equilibrium. For an irrever[sib](#page-97-1)le process, the inequality sign in Eq. (5.128) holds, so d*S* − δ*Q T* = −κ μ*i*ν*i* d*N*˜ > 0, (5.129)

*i*=1 *T* which results in entropy production due to an irreversible chemical reaction. In that case, Eq. (3.6) would no longer hold. Such a reaction will continue u[ntil equ](#page-96-4)ilibri[um is r](#page-97-0)eached or until at least one of the reactants in the system is used up, which will occur when d*N*˜ = 0.

$$\mathbf{d}^{\text{Int}}\mathbf{S} = -\sum_{l=1}^{\kappa} \frac{\mu_l \nu_l}{T} \mathbf{d}\tilde{N} \ge 0. \tag{5.130}$$

the equality applies to an idealized reversible process. This leads to dint*S* = −κ μ*i*ν*i* d*N*˜ ≥ 0. (5.130)

<span id="page-97-2"></span>*i*=1

0 =

*T*

When Eq. (5.130) holds, we also have

$$\mathbf{0} = \oint \mathbf{dS} = \oint \mathbf{d}^{\text{ext}} \mathbf{S} + \oint \mathbf{d}^{\text{int}} \mathbf{S},\tag{5.131}$$

For a cyclic process,

not necessarily equal to zero.

which requires

$$-\oint \mathbf{d}^{\text{ext}} \mathbf{S} = -\oint \frac{\delta Q}{T} = \oint \mathbf{d}^{\text{int}} \mathbf{S} \ge \mathbf{0}.\tag{5.132}$$

<span id="page-97-1"></span>− dext*S* = − δ*Q T* = dint*S* ≥ 0. (5.132)

$$\oint \mathbf{d}^{\text{Int}} \mathbf{S} = -\oint \sum_{l=1}^{\kappa} \frac{\mu_l \nu_l}{T} \, \text{d}\tilde{\mathbf{N}} \ge \mathbf{0}.\tag{5.133}$$

*i*=1

*T*

<sup>15</sup>As shown below, dext*S* and dint*S* are not exact differentials because their integrals around a closed path are

78 THERMAL PHYSICS

Since *S* depends on *U*, *V*, and *N*˜ for this system, these quantities must return to their original values for a cyclic process. This means that any chemical reaction that takes place during part of a cycle must be reversed during another part of the cycle. If the inequality holds in Eq. (5.133), the chemical reaction is irreversible and entropy is produced; this requires heat to be exchanged with the system in such a way that Eq. (5.132) holds, so an

equal amount of entropy is extracted from the system.

# 6

Equilibrium and Thermodynamic Potentials In Chapter 3 we introduced the criterion for thermodynamic equilibrium for an isolated system in terms of the entropy. We now develop alternative criteria for equilibrium in terms of the internal energy and other thermodynamic potentials, the latter being related to the internal energy by Legendre transformations. Each of these potentials depends on a specific set of natural variables. The various resulting equilibrium criteria are useful for a situation in which a particular variable set is subject to control in an experiment. For example, many experiments on gases are conducted in a fixed volume *V* at constant

### <span id="page-99-0"></span>temperature constant. Experiments on liquids or solids are often conducted at fixed *T* and fixed pressure *p*, in which case both heat and work must be exchanged with the

environment to i[nsur](#page-99-0)e that these quantities remain constant. Therefore, our alternative equilibrium criteria will generally pertain to systems that are not isolated.

temperature *T*. In this case, heat must be exchanged with the environment to keep the

<span id="page-99-1"></span>
$$
\Delta S \ge 0, \quad \text{isolated system, allowed changes.} \tag{6.1}
$$

We first review the criterion for equilibrium in terms of the entropy, *S*. This criterion is based on the second law for an isolated system, according to which -*S* ≥ 0, isolated system, allowed changes. (6.1) For an isolated system, we have chemical closure, δ*Q* = 0 and δ*W* = 0, so d*U* = 0. The

$$
\Delta S > 0, \quad \text{isolated system, natural irreversible changes.} \tag{6.2}
$$

processes, we have -*S* > 0, isolated system, natural irreversible changes. (6.2)

Equilibriu[m pertains to a situation in wh](http://dx.doi.org/10.1016/B978-0-12-803304-3.00006-5)ich all natural irreversible processes are forbidden. Suppose that a composite system, which consists of a number of parts, is initially in equilibrium by virtue of some internal constraints, such as rigid, insulating, and impenetrable walls that separate its parts. When some of these constraints are removed, transformations to which Eq. (6.2) applies can occur, and the entropy can continue to increase as much as allowed by any remaining constraints until *S* achieves a maximum value. When this maximum value is reached, the system will no longer be able to undergo irreversible changes, and it will be in a new equilibrium state. We need not worry about

*S*

<span id="page-100-0"></span>![](_page_100_Figure_1.jpeg)

*U*

**FIGURE 6–1** Curve of entropy *S* versus internal energy *U* for a system in internal equilibrium. The state *U*∗, *S*∗ is an

equilibrium state of the same system but with constraints on some internal extensive variables. *U*∗ = *U*2 and *S*∗ < *S*2 since, according to the entropy criterion, the equilibrium state of the unconstrained system is higher. But this implies the existence of an equilibrium state *U*1, *S*1 with the same entropy *S*1 = *S*∗ as the constrained state but lower internal energy, *U*1 < *U*∗, in agreement with the energy criterion. the equality in Eq. (6.1) which corresponds to idealized reversible changes, because there are no driving forces for such changes to occur. This approach to equilibrium can be understood with reference to Figure 6–1 in which the curved line represents entropy *S* as a function of internal energy *U* for the equilibrium state of the system, with other extensive variables fixed. We recall that *S* is a monotonically increasing function of *U*, in agreement with the way that the curve is drawn. We focus on the equilibrium state *U*2, *S*2. The state *U*∗, *S*∗ is also an equilibrium state for the same system except that some of its internal extensive variables are constrained to have different values from those of the state *U*2, *S*2. It has the same energy *U*∗ = *U*2 but a lower entropy *S*∗ < *S*2 as compared to the equilibrium state. As constraints are removed, natural irreversible processes occur, the internal extensive variables change, and the entropy increases toward *S*2. After all internal constraints are removed, except for those present for the state *U*2, *S*2,

the entropy rises to its final value *S*2 and the internal extensive variables reach their final values. The foregoing considerations suggest the following test to find the equilibrium state. We select a state having fixed energy and other constraints on its extensive variables that are necessary for an isolated system. The selected state corresponds to some fixed values of the internal extensive variables of the system. We then imagine the internal extensive variables of the selected state to vary, resulting in a varied state. If any varied state has higher entropy than the original selected state, the selected state is not the correct equilibrium state. But if all such varied states have lower entropy, the selected state has the maximum possible entropy and is the equilibrium state. When a varied state has lower

entropy than the selected state, that varied state cannot be reached from the selected

*Chapter 6* • Equilibrium and Thermodynamic Potentials 81 state by means of a natural irreversible process. We can therefore think of the variations that lower the entropy as virtual variations, since they are allowed by the constraints but forbidden by the second law of thermodynamics. This approach leads to the following criterion, already stated in Section 3.1:

<span id="page-101-0"></span>**Entropy criterion:** The criterion for an isolated thermodynamic system to be in internal equilibrium is that its total entropy be a maximum with respect to variation of its *internal extensive* parameters, subject to external constraints and any remaining internal constraints. Isolation constitutes the external constraints of chemical closure, perfect thermal insulation and zero external work, which require the internal energy to be constant. In this

$$(\Delta S)_{U, V, [N_l]} \ge 0, \quad \text{isulated system, allowed changes.} \tag{6.3}$$

<span id="page-101-1"></span>For a system sufficiently simple that constant total volume *V* guarantees that there is no external work, and in which there are no chemical reactions such that constant values of {*Ni*} guarantee that the system is chemically closed, the entropy criterion can be based on the relation

*S*)*U*,*V*,{*Ni*} ≥ 0, isolated system, allowed changes. (6.3)

### Such a thermodynamic system will be in internal equilibrium if its entropy is a maximum subject to the constraints of constant internal energy, constant volume, and constant mole

numbers. 6.1.1 C[ond](#page-101-0)itions for Equilibrium, Multicomponent Subsystems

$$\mathbf{dS}^{\mathrm{l}} = (1/T^{\mathrm{l}})\,\mathrm{d}U^{\mathrm{l}} + (p^{\mathrm{l}}/T^{\mathrm{l}})\,\mathrm{d}V^{\mathrm{l}} - \sum_{l=1}^{k} (\mu_{l}^{\mathrm{l}}/T^{\mathrm{l}})\,\mathrm{d}N_{l}^{\mathrm{l}};\tag{6.4}$$

$$\mathbf{dS^{II}} = (1/T^{\Pi})\,\mathbf{d}U^{\Pi} + (p^{\Pi}/T^{\Pi})\,\mathbf{d}V^{\Pi} - \sum_{l=1}^{\kappa} (\mu_l^{\Pi}/T^{\Pi})\,\mathbf{d}N_l^{\Pi}.\tag{6.5}$$

d*S*II = (1/*T*II) d*U*II + (*p*II/*T*II) d*V*II −κ *i*=1 (μII *i* /*T*II) d*N*II *i* . (6.5) Equation (6.3) applies to finite entropy changes that we designate by -*S*. Of course it also

$$\mathbf{0} \le \mathbf{dS} = \mathbf{dS}^{\mathrm{I}} + \mathbf{dS}^{\mathrm{II}}, \text{ constraints } U, V, \langle N_{\mathrm{I}} \rangle \text{ held constant.} \tag{6.6}$$

(-

with differentials1

conditions we shall examine in Chapter 7.

0 ≤ d*S* = d*S*I + d*S*II, constraints *U*, *V*,{*Ni*} held constant. (6.6)

<sup>1</sup>These apply to bulk systems in the absence of chemical reactions. 2Examination of infinitesimal entropy changes will lead to an extremum of the entropy, but not necessarily a maximum. We must examine finite entropy changes, sometimes possible by examining higher derivatives, to *guarantee* that we have a maximum of entropy and hence that the equilibrium is stable. This leads to stability

$$\mathbf{d}\mathbf{J}^{\mathrm{I}} = -\mathbf{d}U^{\mathrm{II}}; \quad \mathbf{d}V^{\mathrm{I}} = -\mathbf{d}V^{\mathrm{II}}; \quad \mathbf{d}N_{l}^{\mathrm{I}} = -\mathbf{d}N_{l}^{\mathrm{II}}, \quad \text{for } i = 1, 2, \dots, \kappa. \tag{6.7}$$

<span id="page-102-0"></span>

$$0 \le (1/T^{\mathbf{I}} - 1/T^{\mathbf{II}}) \operatorname{d}U^{\mathbf{I}} + (p^{\mathbf{I}}/T^{\mathbf{I}} - p^{\mathbf{II}}/T^{\mathbf{II}}) \operatorname{d}V^{\mathbf{I}} - \sum_{l=1}^{\kappa} (\mu_{l}^{\mathbf{I}}/T^{\mathbf{I}} - \mu_{l}^{\mathbf{II}}/T^{\mathbf{II}}) \operatorname{d}N_{l}^{\mathbf{I}}.\tag{6.8}$$

These constraints require d*U*I = −d*U*II; d*V*I = −d*V*II; d*N*I *i* = −d*N*II *i* , for *i* = 1, 2, ... , κ. (6.7) Thus Eq. (6.6) becomes κ

$$\mathbf{d}U^{\mathrm{I}} = \text{arbitrary} \pm; \quad \mathbf{d}V^{\mathrm{I}} = 0; \quad \mathbf{d}N_{\mathrm{I}}^{\mathrm{I}} = \mathbf{0} \text{ for } i = 1, 2, \ldots, \kappa,\tag{6.9}$$

The key to extracting detailed **conditions for equilibrium** from Eq. (6.8) is to recognize

$$0 \le (1/T^l - 1/T^{\text{ill}}) \,\text{d}U^{\text{I}}, \quad \text{allowed changes.} \tag{6.10}$$

a number of *special* variations such as d*U*I = arbitrary ±; d*V*I = 0; d*N*I *i* = 0 for *i* = 1, 2, ... , κ, (6.9) which leads to

<span id="page-102-2"></span>
$$T^{\mathrm{I}} = T^{\mathrm{II}}.\tag{6.11}$$

In view of Eq. (6.10), the only way to achieve equilibrium is to prevent an actual irreversible process (which obeys the inequality) in which a change d*U*I of either sign can occur, and this requires *T*I = *T*II. (6.11)

<span id="page-102-3"></span>κ

If *T*I > *T*II, then a natural irreversible process d*U*I < 0 can occur; whereas for *T*I < *T*II,

<span id="page-102-1"></span>0 ≤ (1/*T*I − 1/*[T](#page-102-0)*II) d*U*I

$$\mathbf{0} \le (1/T^{\mathbf{l}})(\mathbf{p}^{\mathbf{l}} - \mathbf{p}^{\mathbf{II}})\,\mathrm{d}V^{\mathbf{l}} - (1/T^{\mathbf{l}})\sum_{l=1}^{k}(\mu_{l}^{\mathbf{l}} - \mu_{l}^{\mathbf{II}})\,\mathrm{d}N_{l}^{\mathbf{l}}.\tag{6.12}$$

$$\mathbf{d}V^{\mathrm{I}} = \text{arbitrary} \pm; \quad \mathbf{d}N_{\mathrm{I}}^{\mathrm{I}} = \mathbf{0} \text{ for } \mathrm{i} = 1, 2, \ldots, \kappa,\tag{6.13}$$

*p*I = *p*II. (6.15)

We then apply the special variation

$$\mathbf{0} \le (1/T^{\mathrm{l}})(\mathbf{p}^{\mathrm{l}} - \mathbf{p}^{\mathrm{ll}}) \, \mathrm{d}V^{\mathrm{l}},\tag{6.14}$$

*i* correspond to semipermeable membranes.

to Eq. (6.12) to obtain 0 ≤ (1/*T*I )(*p*I − *p*II) d*V*I

d*V*I could have either sign. Similarly, one-way constraints on the d*N*I

$$\mathbf{p}^{\mathrm{I}} = \mathbf{p}^{\mathrm{II}}.\tag{6.15}$$

<sup>3</sup>One can consider more general constraints that allow one-way changes only, for example d*V*I ≥ 0. These lead to equilibrium conditions that are inequalities, for example, *p*II ≥ *p*I instead of *p*II = *p*I which would result if

<span id="page-103-0"></span>
$$\mathbf{0} \le -(1/T^{\mathbf{I}})(\mu_{\parallel}^{\mathbf{I}} - \mu_{\parallel}^{\mathbf{II}})\,\mathrm{d}N_{\parallel}^{\mathbf{I}},\tag{6.16}$$

If *p*I > *p*II, an irreversible process in which d*V*I > 0 can occur, and if *p*I < *p*II, an

$$
\mu_j^{\rm I} = \mu_j^{\rm II} \text{ for each } j = 1, 2, \dots, \kappa. \tag{6.17}
$$

Proceeding in this manner, we consider a variation in which only d*N*I *j* = 0, which leads to 0 ≤ −(1/*T*I )(μI *j* − μII *j* ) d*N*I *j* , (6.16) from which we deduce the equilibrium conditions

μI *j* = μII *j* for each *j* = 1, 2, ... , κ. (6.17)

If μI *j* > μII *j* , a natural irreversible process in which d*N*I *j* < [0 ca](#page-102-2)n [occur](#page-102-3), and if [μ](#page-103-0)I *j* < μII *j* , a natural irreversible process in which d*N*I *j* > 0 can occur, in agreement with the notion that there will be diffusion from high chemical potential to low chemical potential for the *j*th chemical component. This leads to the following conditions for equilibrium: **Conditions for equilibrium:** The conditions for thermodynamic equilibrium for two systems capable of freely exchanging energy, volume, and chemical components with one another are: equality of temperature, equality of pressure, and equality of chemical potential of each chemical component. For a system of κ components, these conditions are expressed by κ + 2 equations, namely Eqs. (6.11), (6.15), and (6.17). Note

that these conditions imply uniformity of temperature, pressure, and chemical potential of each chemical component *within* any system. This follows because any two por-

### tions of a system can be regarded as subsystems that must be in equilibrium with one another.

6.1.2 Phase Rule If there are more than two subsystems in a given system, we can consider their equilibria in pairs and eventually arrive at the same conclusions for all of them. If each subsystem having κ chemical components corresponds to a different phase (e.g., solid with crystal structure α, solid with crystal structure β, liquid, vapor) we can count the number of independent intensive variables, subtract from it the number of equations needed to specify equilibrium, and get the number of free variables (if any) that remain. Requiring the number of free variables *f* to be positive or zero puts a limitation on the number of

<span id="page-103-1"></span>number of free variables = *f* = *n*(κ + 1) − (*n* − 1)(κ + 2) = κ + 2 − *n*. (6.18)

phases, *n*, that can exist in equilibrium. The result is the **Gibbs phase rule** which can be derived as follows: number of independent intensive variables = *n*(κ + 1), number of equilibrium equations = (*n* − 1)(κ + 2),

84 THERMAL PHYSICS Thus, for a monocomponent system, κ = 1 and the only possibilities are *n* = 1, 2, and 3. *n* = 1 corresponds to a single phase region for which the number of free variables is *f* = 2,

so the pressure *p* and temperature *T* can be chosen independently. *n* = 2 corresponds to a coexistence curve (say between solid and liquid) and on such a curve, *f* = 1 so *p* is a function of *T*. *n* = 3 corresponds to a triple point where, for example, solid, liquid, and

### vapor are at equilibrium; since *f* = 0, both *p* and *T* are fixed. See Chapter 8 and especially Fig[ure 8–1 for](#page-100-0) more detail. There could be more than one triple point, for example, one where two solid phases having different crystal structures and a liquid phase are at

equilibrium. For a binary system, κ = 2 and the only possibilities are *n* = 1, 2, 3, and 4 corresponding to *f* = 3, 2, 1, and 0, respectively. The possibilities become more numerous as κ increases. 6.2 Energy Criterion From the entropy criterion for equilibrium, one can derive an equilibrium criterion in terms of the internal energy with the entropy held constant. Such a criterion is suggested by Figure 6–1 by consideration of the state *U*1, *S*1 which is also an equilibrium state of the system. This state has the same entropy *S*1 = *S*∗ as the internally constrained state *U*∗, *S*∗ but a lower energy, *U*1 < *U*∗. According to the entropy criterion, *all* constrained states having the same entropy *S*∗ lie *below* the equilibrium curve. Therefore, as internal constraints are removed at constant entropy *S*∗, the system can lower its energy to *U*1 but no lower, and we see that the equilibrium state *U*1, *S*1 has the minimum possible energy at fixed entropy. The state *U*1, *S*1 is a different equilibrium state from *U*2, *S*2 which was found by applying the entropy criterion beginning with the state *U*∗, *S*∗, but this is only because *U*∗ = *U*2. Had we begun with a state *U*∗∗, *S*∗∗ with *S*∗∗ = *S*2 and *U*∗∗ > *U*2, then as internal

constraints are removed at constant entropy *S*2, the system can lower its energy to *U*2 but

no lower. The equilibrium state *U*2, *S*2 found in this manner is the same as that found by applying the entropy criterion starting from *U*∗, *S*∗. This leads to the following criterion for equilibrium: **Energy criterion:** The criterion for a chemically closed thermodynamic system to be in internal equilibrium is that its total internal energy be a minimum with respect to variation

of its *internal extensive* parameters, subject to any remaining internal constraints and the constraint of constant total entropy and no external work. **Paradox:** The entropy criterion applies to an isolated system, for which the internal energy cannot change. The equilibrium state *U*1, *S*1 can therefore be found by applying the entropy criterion at fixed energy *U*1, so it is an equilibrium state for an isolated system. On the other hand, application of the energy criterion to find the state *U*1, *S*1 requires the energy to change, which is impossible for an isolated system! So how do we apply the energy criterion? We have no choice but to deal with a system that is not isolated. In

principle, we must put our system in contact with a hypothetical external system that has

*Chapter 6* • Equilibrium and Thermodynamic Potentials 85 the unusual capability of exchanging heat in such a way as to mai[ntain a](#page-105-0) constant entropy

<span id="page-105-0"></span>
$$
\delta \mathcal{W} + \mathbf{d}U = \delta Q \le T_I \,\mathrm{d}S = 0, \quad \text{constant } \mathcal{S}, \tag{6.19}
$$

<span id="page-105-2"></span>To see this in more detail, we develop a general inequality that applies to a chemically closed system that can exchange both heat and work at constant entropy. If *S* is constant during a process, then d*S* = 0 at every infinitesimal stage of the process. We can then

<span id="page-105-1"></span>
$$\mathcal{W} + \Delta U = Q \le \mathbf{0},\tag{6.20}$$

obtain

the system and *W* = − -

must only satisfy Eq. (3.11) for -

*Q*1

algebra shows that

-

$$\mathcal{W} \le -\Delta U,\quad\text{constant S.}\tag{6.21}$$

over the path of the process to obtai[n](#page-105-1) *W* + -*U* = *Q* ≤ 0, (6.20) from which it follows that *W* ≤ −-*U*, constant *S*. (6.21) The maximum amount of work that can be done in such a process is equal to the decrease in internal energy and occurs for the reversible process for which the equality holds in Eqs. (6.19) and (6.21). In that case, δ*Q* = 0 and *Q* = 0, so no heat is exchanged with

$$
\Delta U \le \mathbf{0}, \quad \mathcal{W} = \mathbf{0} \text{ and constant } \mathbf{S}, \tag{6.22}
$$

*W* < −-*U*; in such a case, *Q* < 0 so heat was extracted from the system to keep its entropy

<span id="page-105-3"></span>constant. If *W* = 0 in Eq. (6.21), we have -*U* ≤ 0, *W* = 0 and constant *S*, (6.22) and equilibrium corresponds to a minimum of *[U](#page-105-2)*, compatible with constraints. We pause here to emphasize a subtle point. Constant *S* certainly guarantees -*S* = 0 but *S* = 0 does not guarantee constant *S*, because *S* can still vary throughout the process. If we only know that -*S* = 0 for a process, it is possible to have δ*Q* > 0 for some parts of the process which can lead to *Q* > 0 and violation of Eq. (6.20). This fact is easy to illustrate

$$\frac{Q_1}{T_1} + \frac{Q_2}{T_2} \le \mathbf{0}.\tag{6.23}$$

*Q*1 *T*1 + *Q*2 *T*2 ≤ 0. (6.23) If *Q*1 ≤ 0 and *Q*2 ≤ 0, then *Q* ≤ 0 and Eq. (6.20) is not violated. But suppose *T*2 > *T*1, *Q*2 = |*Q*2| > 0, and *Q*1 = −|*Q*1| < 0. If then we choose |*Q*2| = (*T*1 + *T*2)/(2*T*1)|*Q*1|, a little

$$\frac{Q_1}{T_1} + \frac{Q_2}{T_2} = \frac{T_1 - T_2}{2T_1 T_2} |Q_1| < 0; \quad Q = Q_1 + Q_2 = \frac{T_2 - T_1}{2T_1} |Q_1| > 0. \tag{6.24}$$

$$\text{and} \quad \dots \text{ to } \dots \text{ and } \dots \text{ to } \dots \text{ to } \dots$$

*T*1 *T*2 2*T*1*T*2 2*T*1

Thus Eq. (6.23) will be satisfied but Eq. (6.20) will be violated.

6.2.1 Local Energy Criterion

86 THERMAL PHYSICS In the next two sections, we proceed to give further motivation and finally an indirect proof, due to Gibbs, that the energy criterion and the entropy criterion are equivalent.

$$\left(\frac{\partial S}{\partial \Xi}\right)_U = 0; \quad \Xi = \Xi_0 \tag{6.25}$$

the entropy *S* at constant internal energy *U* implies a local minimum of *U* at constant *S*. To

resulting in

$$\left(\frac{\partial^2 S}{\partial \Xi^2}\right)_U < 0; \quad \Xi = \Xi_0. \tag{6.26}$$

 ∂*S* ∂ *U* = 0; = 0 (6.25) and

<span id="page-106-0"></span>
$$
\left(\frac{\partial U}{\partial \Xi}\right)_S \left(\frac{\partial \Xi}{\partial S}\right)_U \left(\frac{\partial S}{\partial U}\right)_\Xi = -1,\tag{6.27}
$$

of the suppressed parameters as well), it has a unique inverse function *U*(*S*, ). Such a

$$\left(\frac{\partial U}{\partial \Xi}\right)_{\mathcal{S}} = -\left(\frac{\partial S}{\partial \Xi}\right)_U / \left(\frac{\partial S}{\partial U}\right)_{\Xi} =: P(\Xi, U). \tag{6.28}$$

*S U* which can be rewritten ∂*U* ∂ = − ∂*S* ∂*S* 

$$\begin{aligned} \text{a. } \text{minimize } \text{ar}_{\Delta}(\text{a. } \square) &= \square \square \square \\ \text{b. } \square \square \square \square &= 0; \quad \square = \square_{0}. \end{aligned} \tag{6.29}$$

evaluation of Eq. (6.28) at = 0 shows that

<span id="page-106-1"></span>*S*

$$
\left(\frac{\partial^2 U}{\partial \Xi^2}\right)_S = \left(\frac{\partial P}{\partial \Xi}\right)_U + \left(\frac{\partial P}{\partial U}\right)_\Xi \left(\frac{\partial U}{\partial \Xi}\right)_S. \tag{6.30}
$$

∂2*U* ∂2 *S* = ∂*P* ∂ *U* + ∂*P* ∂*U* ∂*U* ∂ *S* . (6.30)

$$
\left(\frac{\partial P}{\partial \Xi}\right)_U = -\left(\frac{\partial^2 S}{\partial \Xi^2}\right)_U / \left(\frac{\partial S}{\partial U}\right)_\Xi + \left(\frac{\partial S}{\partial \Xi}\right)_U \frac{\partial^2 S}{\partial U \partial \Xi} / \left(\frac{\partial S}{\partial U}\right)_\Xi^2. \tag{6.31}
$$

$$
\text{By using Eq. (6.25), we see that the second term in Eq. (6.31) also vanishes at } \Xi - \Xi_U.
$$

 ∂*P* ∂ *U* ∂2 *U* / ∂*U* + ∂ *U* ∂*U*∂/ ∂*U* . (6.31) By using Eq. (6.25), we see that the second term in Eq. (6.31) also vanishes at = 0,

$$\left(\frac{\partial^2 U}{\partial \Xi^2}\right)_S = -\left(\frac{\partial^2 S}{\partial \Xi^2}\right)_U / \left(\frac{\partial S}{\partial U}\right)_\Xi ; \quad \Xi = \Xi_0. \tag{6.32}$$

$$\left(\frac{\partial^2 U}{\partial \Xi^2}\right)_S > 0; \quad \Xi = \Xi_0. \tag{6.33}$$

*Chapter 6* • Equilibrium and Thermodynamic Potentials 87 Since (∂*S*/∂*U*) > 0 as discussed above, the use of Eq. (6.26) in Eq. (6.32) shows that

### ∂2*U* ∂2 *S* > 0; = 0. (6.33)

From Eqs. (6.29) and (6.33), we conclude that *U* has a local minimum at = 0. This local analysis suggests that the energy criterion is true. A general proof requires one to prove that a global maximum of *S* at constant *U* corresponds to a global minimum of *U* at constant *S*. 6.2.2 Equivalence of Entropy and Energy Criteria We shall prove that the entropy criterion and the energy criterion are equivalent. Both

*S*(*U*,{ }) and *U*(*S*,{ }) (where { } stands for all other extensive variables of a complete set) are fundamental equations; if one is known, the other can be found because *S*

is a monotonically increasing function of *U* and vice versa. The procedure to obtain detailed conditions for equilibrium of systems by minimizing *U* is analogous to that for maximizing *S*, and the resulting conditions (uniformity of temperature, pressure, and chemical potential of each chemical component) are the same. This equivalence was recognized and emphasized by Gibbs [3, p. 56] who stated *"That these two theorems [of entropy maximization at constant energy and energy*

*that it is always possible to increase both the energy and entropy of the system, or to decrease both together, viz., by imparting heat to any part of the system or by taking it away."*

*minimization at constant entropy] are equivalent will appear from the consideration*

A key word in this statement is "both" and this relates to the fact that *S* is a monotonically increasing function of *U* and vice versa, as already stated. As had been stated previously by Gibbs [3, p. 55]: *"For by mechanical and thermodynamic contrivances, supposed theoretically perfect, any supply of work and heat may be transformed into any other which does not differ*

*from it either in the amount of work and heat taken together [which is equal to* -*U] or in the value of the integral* δ*Q*/*T."*

- Based on these statements of Gibbs, one can prove the equivalence of the entropy criterion and the energy criterion as follows: • First, suppose that for the equilibrium state, the entropy criterion is true but that the energy criterion is not true, that is, the entropy is a maximum at constant energy but the internal energy is not a minimum at constant entropy. Then there exists a state of the system with lower energy and the same entropy. We can therefore use a combination of
heat and work to *raise both* the internal energy and the entropy of this state, and thus

- 88 THERMAL PHYSICS achieve a state having the original internal energy but higher entropy. This contradicts the fact that the entropy is a maximum at constant internal energy.
• Second, suppose that for the equilibrium state, the energy criterion is true but that the entropy criterion is not true, that is, the internal energy is a minimum at constant

### entropy but the entropy is not a maximum at constant internal energy. Then there exists a state of the system with higher entropy and the same internal energy. We can therefore

use a combination of heat and work to *lower both* the internal energy and the entropy of this state, and thus achieve a state having the original entropy but lower internal energy. This contradicts the fact that the internal energy is a minimum at constant entropy. 6.3 Other Equilibrium Criteria

### We have shown that the entropy criterion and the internal energy criterion are equivalent. By means of Legendre transformations, one can use other so-called "thermodynamic

<span id="page-108-1"></span>-

potentials" (such as Helmholtz free energy, Gibbs free energy, enthalpy) for which an equilibrium criterion of minimization exists, but with other variables (some intensive) held constant. This is taken up in the following sections. 6.3.1 H[elmh](#page-108-0)oltz Free Energy Criterion

$$
\Delta U + \mathcal{W} = Q_I \le T_I \Delta \mathcal{S}, \tag{6.34}
$$

constant temperature *Tr* , then Eq. (3.10) becomes *Qr* ≤ *Tr*first law, we obtain

[7, p. 59].

<span id="page-108-2"></span><span id="page-108-0"></span>
$$\mathcal{W} \le -(\Delta U - T_I \Delta \mathcal{S}).\tag{6.35}$$

*S*. Combining this with the

which may be rewritten *W* ≤ −(-*U* − *Tr*-*S*). (6.35)

$$F \coloneqq U - T\text{S}.\tag{6.36}$$

transformation

$$\mathcal{W} \le -\Delta F; \quad T = T_I \text{ in initial and final states.} \tag{6.37}$$

*F*; *T* = *Tr* in initial and final states. (6.37)

*W* ≤ −-

<sup>4</sup>Many books denote the Helmholtz free energy by the symbol *A* and use *F* for the Gibbs free energy. We denote the Gibbs free energy by *G* := *U* − *TS* + *pV* = *H* + *pV*. 5Note that Eqs. (6.37) and (6.38) hold even if the temperature of the system is undefined *during* the process. Of course they also hold if *T* = *Tr* throughout the process, which is the case treated in most books. Fermi [1, p. 78] gives a careful discussion of this more general treatment, which is also mentioned by Landau and Lifshitz

<span id="page-109-0"></span>
$$
\Delta F \le 0; \quad \mathcal{W} = 0 \text{ and } T = T_I \text{ in initial and final states.} \tag{6.38}
$$

*Chapter 6* • Equilibrium and Thermodynamic Potentials 89 Hence the name "free" energy because the decrease in *F* is the energy that is free to do work for a system that exchanges heat with a heat reservoir at constant temperature *Tr* . If

*W* = 0, Eq. (6.37) becomes -*F* ≤ 0; *W* = 0 and *T* = *Tr* in initial and final states. (6.38) For a chemically closed system that does no external work and is held at constant temperature *T* = *Tr* in its initial and final states, the Helmholtz free energy can only decrease, and equilibriu[m is a](#page-109-0)chieved when *F* reaches its minimum, compatible with

constraints. This leads to the following equilibrium criterion: **Helmholtz free energy criterion:** The criterion for a chemically closed thermodynamic system held at constant temperature *T* = *Tr* in its initial and final states and which does no external work to be in internal equilibrium is that its Helmholtz free energy be a minimum

$$(\Delta F)_{T,V,[N_l]} \le 0, \quad \text{allowed changes.} \tag{6.39}$$

system is chemically closed, the system is sufficiently simple that constant total volume *V* guarantees that there is no external work, and the system temperature *T* is held constant by an external source, Eq. (6.38) reduces to [(-](#page-108-2)*F*)*T*,*V*,{*Ni*} ≤ 0, allowed changes. (6.39)

### Such a thermodynamic system will be in internal equilibrium if its Helmholtz free energy

enthalpy, rather than the Gibbs free energy.

is a minimum subject to the constraints of constant temperature, constant volume, and constant mo[le](#page-109-1) numbers. 6.3.2 Gibbs Free Energy Criterion

$$
\Delta U + \mathcal{W}^{\text{ins}} + p_I \,\Delta V = Q_I \le T_I \Delta S,\tag{6.40}
$$

<span id="page-109-1"></span>does work *pr* -*V*, then Eq. (6.34) becomes -*U* + *W*xs + *pr* -*V* = *Qr* ≤ *Tr*-*S*, (6.40)

<span id="page-109-2"></span>
$$\mathcal{W}^{\rm sus} \le -\text{[}\Delta U - T_{\rm l}\,\Delta S + p_{\rm l}\,\Delta V\text{]}.\tag{6.41}$$

*W*xs ≤ −[-*U* − *Tr* -*S* + *pr* -*V*]. (6.41)

$$G \coloneqq U - TS + pV = H - TS,\tag{6.42}$$

*G* := *U* − *TS* + *pV* = *H* − *TS*, (6.42)

6In order to have *W*xs = 0, the system must be sufficiently complex to do work by means other than just expanding against an external pressure. 7Note that *G* has the same relationship to *H* as *F* does to *U*. Consequently, *G* is sometimes called the free

$$
\Delta \mathcal{W}^{\text{us}} \le -\Delta G, \quad T = T_I \text{ and } p = p_I \text{ in initial and final states.} \tag{6.43}
$$

90 THERMAL PHYSICS

<span id="page-110-0"></span>
$$
\Delta G \le 0, \quad \mathcal{W}^{\text{xs}} = 0,\\
T = T_I \text{ and } p = p_I \text{ in initial and final states.} \tag{6.44}
$$

where *T* and *p* are temperature and pressure of the *system*. If *T* = *Tr* and *p* = *pr* in the initial and final states of a process,8 then Eq. (6.41) can be written *W*xs ≤ −-*G*, *T* = *Tr* and *p* = *pr* in initial and final states. (6.43) Equation (6.43) gives the maximum excess work (useful work) that a system in contact with a pressure reservoir can do at constant temperature. If *W*xs = 0, Eq. (6.43) becomes

*G* ≤ 0, *W*xs = 0, *T* = *Tr* and *p* = *pr* in initial and final states. (6.44)

For a chemically closed system held in its initial and final states at constant temperature *T* = *Tr* and constant pre[ssure](#page-110-0) *p* = *pr* that does external work only on a pressure reservoir at pressure *pr* , the Gibbs free energy can only decrease, and equilibrium is achieved whenever *G* reaches its minimum, compatible with constraints. This leads to the following equilibrium criterion: **Gibbs free energy criterion:** The criterion for a chemically closed thermodynamic system

$$(\Delta G)_{T, p, |N_l|} \le 0, \quad \text{allowed changes.} \tag{6.45}$$

free energy be a minimum with respect to variations of its internal extensive parameters. If there are no ch[emica](#page-105-1)l reactions such that constant values of{*Ni*} guarantee that the system is chemically closed, Eq. (6.44) becomes (-*G*)*T*,*p*,{*Ni*} ≤ 0, allowed changes. (6.45)

### a minimum subject to [the c](#page-110-1)onstraints of constant temperature, constant pressure, and constant mole numbers.

most books.

-

<span id="page-110-2"></span>6.3.3 Enthalpy Criterion

<span id="page-110-1"></span>Such a thermodynamic system will be in internal equilibrium if its Gibbs free energy is

$$
\mathcal{W}^{\rm ss} + p_\ell \Delta V \le -\Delta U,\quad \text{constant S},\tag{6.46}
$$

pressure *pr* and against which it does work *pr*-*V*, we obtain *W*xs + *pr*-*V* ≤ −-*U*, constant *S*, (6.46)

$$\mathcal{W}^{\rm ss} \le = -\Delta (U + p_l \Delta V), \quad \text{constant S.} \tag{6.47}$$

*H* := *U* + *pV*, (6.48)

the reservoir. Equation (6.46) can be rewritten *W*xs ≤= −-(*U* + *pr*-*V*), constant *S*. (6.47)

$$H := U + pV,\tag{6.48}$$

<sup>8</sup>Note that Eqs. (6.43) and (6.44) hold even if the temperature and pressure of the system are undefined *during* the process. Of course they also hold if *T* = *Tr* and *p* = *pr* throughout the process, which is the case treated in

where *p* is the pressure of the *system*. If *p* = *pr* in the initial and final state of the system, Eq. [(6.47)](#page-110-2) becomes

$$
\mathcal{W}^{\text{xs}} \le -\Delta H,\quad \text{constant S and } p = p_r \text{ in initial and final states.}\tag{6.49}
$$

Thus the maximum excess work that can be done under these conditions is given by the decrease in the enthalpy. If *W*xs = 0, we obtain

<span id="page-111-0"></span>
$$
\Delta H \le 0, \quad \mathcal{W}^{\text{us}} = 0, \text{ constant S and } p = p_{\mathcal{V}} \text{ in initial and final states.} \tag{6.50}
$$

Under these conditions, the enthalpy can only decrease, and equilibrium is achieved when *H* reaches its minimum, compatible with constraints. We are therefore led to the following equilibrium criterion:

**Enthalpy criterion:** The criterion for a chemically closed thermodynamic system held at constant pressure *p* = *pr* in its initial and final states which only does external work *pr* -*V* to be in internal equilibrium is that its enthalpy be a minimum with respect to variations of its internal extensive parameters, subject to the constraint of constant entropy.

If there are no chemical reactions such that constant values of {*Ni*} guarantee that the system is chemically closed, Eq. [(6.50)](#page-111-0) becomes

$$(\Delta H)_{S, p, \{N\}} \le 0, \quad \text{allowed changes.} \tag{6.51}$$

Such a thermodynamic system will be in internal equilibrium if its enthalpy is a minimum subject to the constraints of constant entropy, constant pressure, and constant mole numbers.

### 6.3.4 Kramers Potential Criterion

A somewhat different criterion for equilibrium can be obtained in terms of the Kramers potential (also known as the grand potential, and often denoted by ),

$$K = F - \sum_{l=1}^{k} \mu_l N_l,\tag{6.52}$$

introduced by Eq. (5.91). We consider a se[t9](#page-111-1) of chemical reservoirs, each having fixed temperature and volume and respective chemical potential μ*ri* for chemical component *i*. We apply Eq. [(6.38)](#page-109-0) to a composite system having total Helmholtz free energy *F*tot and consisting of the system of interest and all of the reservoirs. The total system is chemically closed and we forbid chemical reactions, so that -*Ni* + -*Nri* = constant, where *Nri* is the number of moles of component *i* in its reservoir. Then

$$
\Delta F_{\text{tot}} = \Delta F + \sum_{l=1}^{\kappa} \mu_{ll} \Delta N_{ll} = \Delta F - \sum_{l=1}^{\kappa} \mu_{ll} \Delta N_{l}, \tag{6.53}
$$

<span id="page-111-1"></span><sup>9</sup>The reservoirs need not be separate systems. In fact, this criterion is often used where the system of interest is a surface and the bulk of the system is the reservoir.

where for each reservoir, d*Fri* = μ*ri* d*Nri*, has been integrated. If μ*i* = μ*ir* , at least in the initial and final states, we have -*F*tot = -*K*, so minimization of *F*tot at constant *T* and no external work is the same as minimization of *K* at constant *T*, no external work and constant chemical potentials equal to those of the reservoirs. This leads to the following criterion:

**Kramers potential criterion:** The criterion for a thermodynamic system to be in equilibrium at constant temperature and a constant value of each of its chemical potentials is that its Kramers potential be a minimum with respect to variations of its internal extensive parameters under the constraints of no external work and no chemical reactions.

If there are no chemical reactions, the system is sufficiently simple that constant total volume guarantees no external work, and if the system temperature *T* and its chemical potentials {μ*i*} are held constant by external reservoirs, the equilibrium criterion for the Kramers potential reduces to a minimization of the Kramers potential at constant temperature, constant volume, and constant chemical potentials.

### 6.4 Summary of Criteria

For cases in which -*V* = 0 guarantees *W* = 0, or for *p* constant in which the only external work is *p* -*V* (so *W*xs = 0), and no chemical reactions such that constant values of {*Ni*} guarantee that the system is chemically closed, or for constant {μ*i*} imposed by external chemical reservoirs, the criteria for equilibrium can be summarized by first noting the natural variable set[10](#page-112-0) on which the various thermodynamic functions depend. For the entropy and the thermodynamic potentials discussed above, these variable sets are summarized in Table 6–1.

Then for internal equilibrium, *S* is a maximum, and each thermodynamic potential is a minimum, with respect to variations of its *internal extensive variables*, with all designated

| Function                  | Variable → | S | U | V | {Ni} | T | p | {µi} |
|---------------------------|------------|---|---|---|------|---|---|------|
| Entropy                   | S          |   | × | × | ×    |   |   |      |
| Internal Energy           | U          | × |   | × | ×    |   |   |      |
| Helmholtz Free Energy     | F          |   |   | × | ×    | × |   |      |
| Gibbs Free Energy         | G          |   |   |   | ×    | × | × |      |
| Enthalpy                  | H          | × |   |   | ×    |   | × |      |
| Kramers (Grand) Potential | K          |   |   | × |      | × |   | ×    |

**Table 6–1** Natural Variable Sets of Thermodynamic Functions

<span id="page-112-0"></span>10This is the variable set that gives complete information about the system, namely extensive variables for *U* and *S* and variables obtained by Legendre transformations in the case of *F*, *G* and *H*. For further discussion of this point in the context of Legendre transformations, see Callen [2, pp. 137-145].

variables held constant for the overall system. We emphasize that these are *alternative* criteria for equilibrium, each applicable for different constraints.

### 6.4.1 Equilibrium Conditions

No matter which of these criteria are applied, the conditions for mutual equilibrium of subsystems of a composite system will be the same as those derived from the entropy condition in [Section 6.1.1.](#page-101-1) For a composite system containing more than two subsystems, the systems may be considered in pairs. These conditions are uniformity, throughout the entire system, of the temperature *T*, the pressure *p*, and each chemical potential μ*i*. For the potentials, this can be seen by carrying out the same kind of variations as in Section 6.1.1 [for only the subset of variables that are unconstrained. For the Gibbs free energy,](#page-101-1) for example, *T* and *p* are already uniform and assumed to be held constant by external reservoirs, so only exchanges of the {*N*sub *i* } among the subsystems need to be considered. This leads to uniformity of the μ*i*.

### 6.4.2 Extension to Chemical Reactions

In event that chemical reactions are allowed, one must revert to an equilibrium criterion that allows variations of the {*Ni*} due to those reactions. Thus, to apply the entropy criterion for a single chemical reaction, one would have to vary the progress variable *N*˜ that appears in Eq. (5.125). Then according to the discussion of Eq. (5.128), there would be an additional condition *i* μ*i*ν*i* = 0 that the chemical potentials must satisfy for that chemical reaction to be in equilibrium. That same condition would apply to all subsystems because the chemical potentials must be uniform at equilibrium. This additional condition would lower the number of degrees of freedom in the phase rule, Eq. [(6.18)](#page-103-1), by one. If there were *c* independent chemical reactions, the phase rule would take the modified form

$$f = (\kappa - \mathfrak{c}) + 2 - n,\tag{6.54}$$

where κ−*c* ≥ 1 is the number of*independent* chemical components. See Darken and Gurry [19, p. 287] for a discussion of the phase rule for a variety of conditions, including "frozen reactions," in the context of the thermochemistry of metals.

This page intentionally left blank

![](_page_115_Picture_0.jpeg)

# Requirements for Stability

In Chapter 6 we discussed the criterion for thermodynamic equilibrium of an isolated system, namely that its entropy, *S*, be a maximum with respect to variations of its internal extensive variables. If is such an internal extensive variable, then d*S*/d- = 0 at equilibrium. But this condition could correspond to a maximum, a minimum or a horizontal point of inflection in a graph of *S* versus -. We must therefore examine higher derivatives in order to insure that *S* is a local maximum, and finite changes to ascertain if *S* is a global maximum. In this chapter, we examine the requirements for stable equilibrium, particularly with respect to the stability of homogeneous systems. We pose the question of whether a homogeneous system is stable with respect to breakup into a composite system consisting of two (or more) subsystems, each of which is homogeneous. This will lead to requirements concerning the functional dependence of *S* on its complete set of extensive variables.

In Chapter 6 we also discussed equilibrium criteria in terms of minimization of the internal energy, *U*, and its Legendre transforms, subject to suitable overall constraints on the system. Here again, criteria such as d*U* = 0 can lead to an extremum, but not necessarily a minimum, and we must examine higher derivatives or finite changes in order to ascertain requirements for stability. Similar considerations apply to stability criteria based on minimization of other thermodynamic potentials such as *F*, *G*, and *H*, but some of the natural variables on which these potentials depend are intensive, so their behavior with respect to stability must be ascertained by relating to extensive variables by means of Legendre transforms.

Examination of these requirements will also result in useful information about the signs of various physical quantities, such as heat capacities, and compressibilities, as well as inequalities that restrict the relative magnitudes or ratios of these quantities.

### 7.1 Stability Requirements for Entropy

For simplicity, we consider a homogeneous system having entropy *S*(*U*, *V*, *N*) and assume that constant values of *U*, *V*, and *N* will guarantee isolation. We first follow Callen [2, p. 203] based on an analysis by Griffiths [20] and pose the question of whether this system is stable with respect to breakup into two homogeneous subsystems, each having a volume *V*/2 and number of moles *N*/2, one having energy (*U* − *U*)/2 and the other having energy (*U* + *U*)/2. The energy of the combined subsystems is (1/2)(*U* − *U*) + (1/2)(*U* + *U*) = *U*. Since *S* is a homogeneous function of degree one in these extensive variables, the corresponding entropies of the subsystems are (1/2)*S*(*U* − *U*, *V*, *N*) and (1/2)*S*(*U* + *U*, *V*, *N*). Therefore, the homogeneous system will be stable with respect to this breakup by an irreversible process if

<span id="page-116-1"></span>
$$\mathbf{S}(1/2)\mathbf{S}(U-\Delta U, V, N) + (1/2)\mathbf{S}(U+\Delta U, V, N) \le \mathbf{S}(U, V, N). \tag{7.1}$$

This requirement is represented graphically in [Figure 7–1.](#page-116-0) By rewriting the left-hand side of Eq. [(7.1)](#page-116-1) in the form

<span id="page-116-2"></span>
$$\mathcal{S}(U - \Delta U, V, N) + (1/2)[\mathcal{S}(U + \Delta U, V, N) - \mathcal{S}(U - \Delta U, V, N)] \le \mathcal{S}(U, V, N),\tag{7.2}$$

we verify that the entropy of the composite system lies on the straight line (chord) joining (1/2)*S*(*U* − *U*, *V*, *N*) and (1/2)*S*(*U* + *U*, *V*, *N*) at the value *U*, midway between *U* − *U* and *U* + *U*. Thus, stability for all values of *U* requires *S* to be a **concave function** of *U* (as viewed from below). Thus, the situation in [Figure 7–1a](#page-116-0) is stable, and that in [Figure 7–1b](#page-116-0) is unstable. The equal sign in Eq. [(7.2)](#page-116-2) would correspond to a situation of neutral stability that would involve a hypothetical reversible process. We will discuss this possibility in Chapters 9 and 10 in connection with phase transformations.

For infinitesimal changes *U* → δ*U*, we can expand the entropies in Eq. [(7.1)](#page-116-1) to obtain

$$S(U \pm \delta U, V, N) = S(U, V, N) \pm S\upsilon(U, V, N)\delta U + (1/2)S\upsilon\upsilon(\delta U)^2 + \cdots,\tag{7.3}$$

where the subscripts *U* represent partial differentiation.[1](#page-116-3) Then neglecting terms of the third order and higher, Eq. [(7.1)](#page-116-1) becomes, after division by (δ*U*)2/2,

$$S_{UU} \equiv \left(\frac{\partial^2 S}{\partial U^2}\right)_{V,N} \le \mathbf{0}.\tag{7.4}$$

<span id="page-116-0"></span>![](_page_116_Figure_10.jpeg)

**FIGURE 7–1** Conditions for *S*(*U*, *V*, *N*), represented by the solid curves, for stability (a) or instability (b). To be stable, *S*(*U*, *V*, *N*) must be a concave function of *U* at fixed *V* and *N*. A composite system having the same values of *U*, *V*, and *N* would have an entropy represented by the intersection of the chord with the vertical line at *U*. (a) Stable (concave) and (b) Unstable (convex).

<span id="page-116-3"></span>1In this chapter, subscripts that indicate partial derivatives imply the natural variable sets for each function, explicitly *S*(*U*, *V*, *N*), *U*(*S*, *V*, *N*), *H*(*S*, *p*, *N*), *F*(*T*, *V*, *N*), and *G*(*T*, *p*, *N*).

*Chapter 7* • Requirements for Stability 97 Equation (7.4) is a requirement for *local* stability because it corresponds to infinitesimal changes. If *SUU* = 0, we could examine higher derivatives. For example, we would need *SUUU* = 0 and *SUUUU* < 0, but such a requirement would still be local.

The situation depicted in Figure 7–2 is more complicated because the second derivative *SUU* changes sign at the so-called spinodal points *US*1 and *US*2. The region between points *US*1 and *US*2 is clearly unstable with respect to infinitesimal variations δ*U*. The remainder of the curve is stable with respect to infinitesimal variations. The states between *U*1 and *US*1 and between *US*2, and *U*2, where *U*1 and *U*2 are points of common tangency, are more difficult to analyze because the above analysis requires values of *U* −*U* and *U* +*U* that are symmetrically situated and can span distant portions of the curve.

$$1 - f = \frac{u_2 - u}{u_2 - u_1}; \quad f = \frac{u - u_1}{u_2 - u_1}.\tag{7.5}$$

ume *Nv*. We consider breakup onto a composite system consisting of two homogeneous systems, one having (1 − *f* )*N* moles and intensive parameters *u*1, *v*,*s*(*u*1, *v*), and the other having *fN* moles and intensive parameters *u*2, *v*,*s*(*u*2, *v*), where

$$N(1 - f)u_1 + Nfu_2 = \frac{N}{\mu_2 - \mu_1} [(u_2 - u)u_1 + (u - u_1)u_2] = Nu = U. \tag{7.6}$$

<span id="page-117-0"></span>Without loss of generality we take *u*2 > *u*1. The volume of the composite system is *N*(1 − *f* )*v* + *Nf v* = *Nv* = *V* and its number of moles is *N*(1 − *f* ) + *Nf* = *N*. It has energy

The entropies of the subsystems are (1−*f* )*Ns*(*u*1, *v*) and *fNs*(*u*2, *v*). After division by *N*, the

requirement for stability becomes

*S*

$$(1 - f)\mathbf{s}(\mu_1, v) + f\mathbf{\hat{s}}(\mu_2, v) \le \mathbf{s}(\mu, v),\tag{7.7}$$

![](_page_117_Figure_9.jpeg)

*U*1 *US*1 *US*2 *U*2 **FIGURE 7–2** *S*(*U*, *V*, *N*) versus *U* under conditions for which some states are locally stable and others are locally unstable. The states between the spinodal points *US*1 and *US*2 are locally unstable and states outside these points are

locally stable. But states between *U*1 and *US*1 and between *US*2 and *U*2 are globally unstable, so they are metastable.

<span id="page-118-0"></span>
$$\mathbf{s}(\mathfrak{u}_1, v) + \frac{\mathfrak{u} - \mathfrak{u}_1}{\mathfrak{u}_2 - \mathfrak{u}_1} [\mathbf{s}(\mathfrak{u}_2, v) - \mathbf{s}(\mathfrak{u}_1, v)] \le \mathbf{s}(\mathfrak{u}, v). \tag{7.8}$$

98 THERMAL PHYSICS w[hich](#page-117-0) [can](#page-117-0) [be](#page-117-0) rewritten *s*(*u*1, *v*) + *u* − *u*1 *u*2 − *u*1 [*s*(*u*2, *v*) − *s*(*u*1, *v*)] ≤ *s*(*u*, *v*). (7.8) The requirement represented by Eq. (7.8) is shown in Figure 7–3, from which we see that the entropy per mole of the composite system is represented by the intersection of a vertical line at *u* with a chord joining *any* points *s*(*u*1, *v*) and *s*(*u*2, *v*), as long as *u*2 > *u* > *u*1 is satisfied. This criterion shows that the general requirement for stability is concavity of

*s*(*u*, *v*) as a function of *u* at fixed *v*. Since *S*(*U*, *V*, *N*) = *Ns*(*u*, *v*) = *Ns*(*U*/*N*, *V*/*N*), we see for stability that *S*(*U*, *V*, *N*) is a concave function of *U* at fixed *V* and *N*. Thus the states in Figure 7–2 between *U*1 and *US*1 and between *US*2 and *U*2, although locally stable, are globally unstable and are termed metastable. By letting *u*1 = *u* − δ*u*, *u*2 = *u* + δ*u* and expanding Eq. (7.8) for small δ*u*, one obtains ∂2*s*/∂*u*2 ≤ 0 as a local stability condition,

$$(1/2)\mathbf{S}(U, V - \Delta V, \mathbf{N}) + (1/2)\mathbf{S}(U, V + \Delta U, \mathbf{N}) \le \mathbf{S}(U, V, \mathbf{N}).\tag{7.9}$$

Returning to the general analysis of *S*(*U*, *V*, *N*), we can inquire about stability against breakup into two homogeneous subsystems, each having the same energy *U*/2 and mole

as above, stability requires

*S* could depend.

even though it is locally stable.

$$\mathbf{S}_{\mathcal{W}} \equiv \left( \frac{\partial^2 \mathbf{S}}{\partial V^2} \right)_{U, \mathcal{N}} \le \mathbf{0}. \tag{7.10}$$

≤ 0. (7.10)

For infinitesimal changes δ*V* ∂2*S*

*SVV* ≡ -

*s*

∂*V*2 *U*,*N*

![](_page_118_Figure_9.jpeg)

*u*1 *u u*2 **FIGURE 7–3** *s*(*u*, *v*) versus *u* under conditions for which some states are locally stable and others are locally unstable. At constant *v*, we test the state at *u* against breakup into a composite system consisting of states having molar energies *u*1 and *u*2 that are not equidistant from *u*. The entropy per mole of the composite system lies on the straight line at position *u* and exceeds *s*(*u*, *v*) which lies on the curve. Therefore, the state at *u* is globally unstable,

$$\mathbf{S}(1/2)\mathbf{S}(U-\Delta U, V-\Delta V, N) + (1/2)\mathbf{S}(U+\Delta U, V+\Delta U, N) \le \mathbf{S}(U, V, N). \tag{7.11}$$

<span id="page-119-2"></span><span id="page-119-0"></span>
$$\mathcal{S}_{UU}(\delta U)^2 + 2\mathcal{S}_{UV}\delta U \delta V + \mathcal{S}_{VV}(\delta V)^2 \le \mathbf{0},\tag{7.12}$$

If both *U* and *V* are different for the subsystems, we obtain

$$
\begin{pmatrix} \delta U & \delta V \end{pmatrix} \begin{pmatrix} \mathbf{S}_{UU} & \mathbf{S}_{UV} \\ \mathbf{S}_{UV} & \mathbf{S}_{VV} \end{pmatrix} \begin{pmatrix} \delta U \\ \delta V \end{pmatrix} \le \mathbf{0},\tag{7.13}
$$

*SUU* (δ*U*) 2 + 2*SUV* δ*U*δ*V* + *SVV* (δ*V*) 2 ≤ 0, (7.12)

$$\det\begin{pmatrix} S_{UU} - \lambda & S_{UV} \\ S_{UV} & S_{VV} - \lambda \end{pmatrix} = \mathbf{0},\tag{7.14}$$

≤ 0, (7.13)

 δ*U* δ*V* - *SUU SUV SUV SVV* - δ*U*

$$\lambda_{\pm} = \frac{\mathbf{S}_{UU} + \mathbf{S}_{VV}}{2} \pm \sqrt{\left(\frac{\mathbf{S}_{UU} + \mathbf{S}_{VV}}{2}\right)^2 + \mathbf{S}_{UV}^2 - \mathbf{S}_{UU}\mathbf{S}_{VV}}\tag{7.15}$$
 
$$= \frac{\mathbf{S}_{UU} + \mathbf{S}_{VV}}{2} \pm \sqrt{\left(\frac{\mathbf{S}_{UU} - \mathbf{S}_{VV}}{2}\right)^2 + \mathbf{S}_{UV}^2}.$$

λ± = *[SUU](#page-119-0)* + *SVV* 2 ± -*SUU* + *SVV* 2 2 + *S*2 *UV* − *SUUSVV* (7.15) = *SUU* + *SVV* ± -*SUU* − *SVV* 2 + *S*2 *UV* .

$$\mathbf{S}_{UU}\mathbf{S}_{VV} - \mathbf{S}_{UV}^2 \ge \mathbf{0}.\tag{7.16}$$

eigenvalues of any real symmetric matrix. From the first form, and rec[alling](#page-119-1) that *SUU* ≤ 0

<span id="page-119-1"></span>2

$$
\lambda_+ (\delta X_1)^2 + \lambda_- (\delta X_2)^2 \le \mathbf{0},\tag{7.17}
$$

After diagonalization, Eq. (7.13) can be rewritten in the form λ+(δ*X*1) 2 + λ−(δ*X*2) 2 ≤ 0, (7.17) where λ± ≤ 0 and δ*X*1 and δ*X*2 are linear combinations of δ*U* and δ*V* that can be found by calculating the eigenvectors of the matrix. Thus, *SUU* ≤ 0 and *SVV* ≤ 0 together with Eq. (7.16) guarantee that Eq. (7.12) is satisfied.2 They insure *locally* that the surface *S* will

<span id="page-119-4"></span><span id="page-119-3"></span>not lie above its *local* tangent plane. Calle[n](#page-119-1) [\[2,](#page-119-1) p. [206\]](#page-120-0) [refers](#page-120-0) to Eq. (7.16) as a "fluting condition." By a procedure similar to that used to derive Eq. (7.8), we can test a system with entropy *Ns*(*u*, *v*) with respect to breakup into a composite of three systems having entropies *Nf*1*s*(*u*1, *v*1), *Nf*2*s*(*u*2, *v*2), and *Nf*3*s*(*u*3, *v*3), where *f*1, *f*2, and *f*3 are positive fractions that sum to unity, chosen such that total energy and total volume are conserved. This leads to

*f*1(*u*, *v*)*s*(*u*1, *v*1) + *f*2(*u*, *v*)*s*(*u*2, *v*2) + *f*3(*u*, *v*)*s*(*u*3, *v*3) ≤ *s*(*u*, *v*), (7.18)

$$f_1(\mathfrak{u}, v)\mathfrak{s}(\mathfrak{u}_1, v_1) + f_2(\mathfrak{u}, v)\mathfrak{s}(\mathfrak{u}_2, v_2) + f_3(\mathfrak{u}, v)\mathfrak{s}(\mathfrak{u}_3, v_3) \le \mathfrak{s}(\mathfrak{u}, v),\tag{7.18}$$

<sup>2</sup>For an alternative procedure that would lead to Eq. (7.16), see Section 7.2.

$$\begin{array}{ll} f_1 + f_2 + f_3 &= 1, \\ f_1 u_1 + f_2 u_2 + f_3 u_3 &= u, \\ f_1 v_1 + f_2 v_2 + f_3 v_3 &= v. \end{array} \tag{7.19}$$

100 THERMAL PHYSICS where the *fi* satisfy the following linear equations: *f*1 + *f*2 + *f*3 = 1, *f*1*u*1 + *f*2*u*2 + *f*3*u*3 = *u*, *f*1*v*1 + *f*2*v*2 + *f*3*v*3 = *v*. (7.19) We could use Cramer's rule to solve Eq. (7.19) by means of determinants, but the actual expressions are cumbersome and not needed as long as we note the following properties. A solution is only possible if the determinant of the coefficients of the *fi* is not zero, which will be true if the points (*u*1, *v*1), (*u*2, *v*2), and (*u*3, *v*3) lie at the vertices [of a no](#page-120-1)n-degenerate

<span id="page-120-1"></span>
$$f_l(\mathbf{u}_f, \mathbf{v}_l) = \delta_{l\bar{l}}; \quad f_l(\mathbf{u}_0, \mathbf{v}_0) = A_{0\bar{l}k}/A_{123},\tag{7.20}$$

below, the point(*u*, *v*) where *s*(*u*, *v*) is to be tested for stability must be chosen within or on that triangle. With (*u*1, *v*1), (*u*2, *v*2), and (*u*3, *v*3) fixed, the *fi* will be linear functions of *u* and *v* that can be written in the form *fi*(*u*, *v*), as already indicated in Eq. (7.19); furthermore, they will satisfy *fi*(*uj*, *vj*) = δ*ij*; *fi*(*u*0, *v*0) = *A*0*jk*/*A*123, (7.20) where δ*ij* is the Kronecker delta, *i*, *j*, *k*, are cyclic permutations of [123,](#page-119-4) and the quantities *A*0*jk* are areas of triangles defined below. The first member of Eq. (7.20) follows from Cramer's rule because the determinant [of a m](#page-119-4)atrix having two identical columns is zero. If the point (*u*0, *v*0) is referred to as point zer[o, Cra](#page-119-2)mer's rule can also be used to show that

<span id="page-120-0"></span>*A*0*jk* is the area of triangle 0*jk*. Consistent with *A*123 > 0, the areas *A*0*jk* ≥ 0 are positive as long as (*u*0, *v*0) lies inside or on triangle 123. If (*u*0, *v*0) were to lie outside triangle 123, at least one of the *fi* will be negative, which is unacceptable. See Figure 8–11 that pertains to an isomorphous problem. From these properties of the *fi*(*u*, *v*), it follows that the left-hand side of Eq. (7.18) represents a plane that passes through the points *s*(*u*1, *v*1), *s*(*u*2, *v*2), and *s*(*u*3, *v*3). Therefore, geometrically, the global stability criterion represented by Eq. (7.18) states that *s*(*u*, *v*)

### **function** of *u* and *v*. If*s*(*u*, *v*) violates Eq. (7.18) for any such plane, that state will be globally unstable, but would be locally stable if Eq. (7.12) were satisfied.

lies above or on *any* such plane. In other words, for stability *s*(*u*, *v*) must be a **concave**

7.2 Stability Requirements for Internal Energy We can establish similar requirements for stability in terms of the internal energy *U* since

$$(1/2)U(\mathbb{S}-\Delta \mathbb{S}, V, N) + (1/2)U(\mathbb{S}+\Delta \mathbb{S}, V, N) \ge U(\mathbb{S}, V, N),\tag{7.21}$$

(1/2)*U*(*S* − *S*, *V*, *N*) + (1/2)*U*(*S* + *S*, *V*, *N*) ≥ *U*(*S*, *V*, *N*), (7.21)

-∂2*U* ∂*S*2

*V*,*N*

$$
\left(\frac{\partial^2 U}{\partial S^2}\right)_{V,N} \ge 0. \tag{7.22}
$$

![](_page_121_Figure_1.jpeg)

**FIGURE 7–4** Conditions for *U*(*S*, *V*, *N*), represented by the solid curves, for stability (a) or instability (b). To be stable, *U*(*S*, *V*, *N*) must be a convex function of *S* at fixed *V* and *N*. A composite system having the same values of *S*, *V*, and *N* would have an energy represented by the intersection of the chord with the vertical line at *S*. (a) Stable (convex) and (b) Unstable (concave).

(b)

Similar equations would apply for the ot[her ex](#page-119-2)tensive variables *V* and *N* on which *U* de-

$$(1/2)U(\mathbb{S}-\Delta \mathbb{S}, V-\Delta V, \mathbb{N}) + (1/2)U(\mathbb{S}+\Delta \mathbb{S}, V+\Delta V, \mathbb{N}) \ge U(\mathbb{S}, V, \mathbb{N}).\tag{7.23}$$

*S −* Δ*S S S* + Δ*S*

variables for more complicated systems). This requirement is represented graphically in Figure 7–4.

<span id="page-121-1"></span>*S −* Δ*S S S* + Δ*S*

*SUU* which reverses the sense of the inequality. Thus,

*U*

(a)

deduce

<span id="page-121-2"></span><span id="page-121-0"></span>
$$U_{\rm SS} (\delta \mathbf{S})^2 + U_{\rm IV} (\delta V)^2 + 2U_{\rm SV} \delta \mathbf{S} \delta V \succeq \mathbf{0}.\tag{7.24}$$

(1/2)*U*(*S* − *S*, *V* − *V*, *N*) + (1/2)*U*(*S* + *S*, *V* [+](#page-119-1) *V*, *N*) ≥ *U*(*S*, *V*, *N*). [(7.23)](#page-121-0) For infinitesimal changes, Eq. (7.23) yields the stability requirement *USS*(δ*S*) 2 + *UVV* (δ*V*) 2 + 2*USV* δ*S*δ*V* ≥ 0. (7.24)

$$\mathcal{D} \equiv U_{\rm SS} U \nu \mathcal{V} - U_{\rm SV}^2 \ge 0,\tag{7.25}$$

to the fluting condition *D* ≡ *USSUVV* − *U*2 *SV* ≥ 0, (7.25) which has the *same* sense of the inequality as Eq. (7.16). We can also deduce Eq. (7.25)

$$(U_{\rm SS} \& \mathbf{S} + U_{\rm SV} \& V)^2 + \mathcal{D}(\delta V)^2 \geq \mathbf{0}.\tag{7.26}$$

(*USS*δ*S* + *USV* δ*V*) 2 + *D*(δ*V*) 2 ≥ 0. (7.26) For given δ*V*, the first term can be made equal to zero by choice of δ*S*, so the second term must be non-negative, thus resulting in Eq. (7.25). Moreover, if Eq. (7.25) holds, Eq. (7.26) is always satisfied, so Eq. (7.25) is both necessary and sufficient. A similar technique can be applied to analyze Eq. (7.12); in that case, one multiplies first by the non-positive quantity

$$(\text{S}\,\text{U}\,\text{U}\,\Delta U + \text{S}\,\text{U}\,\Delta V)^2 + (\text{S}\,\text{U}\,\text{S}\,\text{V} - \text{S}_{UV}^2)(\Delta V)^2 \ge \mathbf{0},\tag{7.27}$$

<span id="page-122-0"></span>
$$
\mathbf{g}_1(\mathbf{s}, v)\boldsymbol{\mu}(\mathbf{s}_1, v_1) + \mathbf{g}_2(\mathbf{s}, v)\boldsymbol{\mu}(\mathbf{s}_2, v_2) + \mathbf{g}_3(\mathbf{s}, v)\mathbf{s}(\boldsymbol{\mu}_3, v_3) \ge \boldsymbol{\mu}(\mathbf{s}, v). \tag{7.28}
$$

102 THE[RMA](#page-122-0)L PHYSICS (*SUUU* + *SUV V*) 2 + (*SUUSVV* − *S*2 *UV* )(*V*) 2 ≥ 0, (7.27)

### procedure that led to Eq. (7.18), resulting in the stability requirement *g*1(*s*, *v*)*u*(*s*1, *v*1) + *g*2(*s*, *v*)*u*(*s*2, *v*2) + *g*3(*s*, *v*)*s*(*u*3, *v*3) ≥ *u*(*s*, *v*). (7.28)

which results in Eq. (7.16). For the internal energy we could also carry out the same

Here, the fractions *gi*(*s*, *v*) are linear functions of *s* and *v* that satisfy *gi*(*sj*, *vj*) = δ*ij*. Equation (7.28) shows that *u*(*s*, *v*) must lie below any plane represented by its left-hand side, so *u*(*s*, *v*) must be a **convex function** for global stability.

### <span id="page-122-1"></span>7.3 Stability Requirements for Other Potentials

We can also obtain stability requirements for other potentials, such as *H*, *F*, and *G*, which

-

*V*

-∂*p* ∂*S V*

∂*S*

∂*S*

*p*

*V*

*S*

$$(1/2)H(\mathbb{S}-\Delta\mathbb{S},p,N)+(1/2)H(\mathbb{S}+\Delta\mathbb{S},p,N)\geq H(\mathbb{S},p,N).\tag{7.29}$$

7.3.1 Enthalpy

$$H_{\rm SS} := \left(\frac{\partial^2 H}{\partial S^2}\right)_{p, \mathcal{N}} \ge 0. \tag{7.30}$$

For infinitesimal changes δ*S*, the local stability requirement is *HSS* := -∂2*H* ∂*S*2 *p*,*N* ≥ 0. (7.30) But there is no equation analogous to Eq. (7.29) involving changes *p* because *p* is

$$H_{\rm pp} := \left(\frac{\partial^2 H}{\partial p^2}\right)_{S,N} = -\frac{1}{U \rm UV} \le 0. \tag{7.31}$$

*Hpp* := -∂2*H* ∂*p*2 *S*,*N* = − 1 *UVV* ≤ 0. (7.31) Thus for local stability, *H* is a locally convex function of the extensive variable *S* but a locally concave function of the intensive variable *p*. As a result of this, the fluting condition *HSSHpp* −*H*2 *Sp* ≤ 0 is true by default because both terms are non-positive. The fact that this

$$
\left(\frac{\partial^2 U}{\partial S^2}\right)_V = \left[\frac{\partial}{\partial S} \left(\frac{\partial H}{\partial S}\right)_p\right]_V = H_{\rm SS} + H_{\rm Sp} \left(\frac{\partial p}{\partial S}\right)_V. \tag{7.32}
$$

But

*V*

∂*S*

But

$$\left(\frac{\partial p}{\partial \mathcal{S}}\right)_V = -\frac{(\partial V/\partial \mathcal{S})_p}{\left(\partial V/\partial p\right)_{\mathcal{S}}} = -\frac{H_{\mathcal{S}p}}{H_{pp}}.\tag{7.33}$$

Therefore

$$U_{\rm SS} = \frac{H_{\rm SS}H_{pp} - H_{\rm Sp}^2}{H_{pp}}.\tag{7.34}$$

*Chapter 7* • Requirements for Stability 103

$$H_{\rm SS} = \frac{U_{\rm SS}U_{VV} - U_{\rm SV}^2}{U_{VV}} = \frac{\mathcal{D}}{U_{VV}},\tag{7.35}$$

*USS* = *HSSHpp* − *H*2 *Sp Hpp* . (7.34) Since *USS* ≥ 0, *HSS* ≥ 0, and *Hpp* ≤ 0, we see consistently that *HSSHpp* − *H*2 *Sp* ≤ 0.

### In a similar manner, we can show that *HSS* = *USSUVV* − *U*2

*UVV UVV* so the fact that *D* ≥ 0 could have been deduced from *HSS* ≥ 0 and *UVV* ≥ 0. It is generally the case that all fluting conditions can be deduced from conditions on non-mixed second derivatives provided that appropriate Legendre transforms are considered. 7.3.2 Helmholtz Free Energy

= *D*

*SV*

$$U_{VV} = \frac{F_{VV}F_{TT} - F_{VT}^2}{F_{TT}} \tag{7.36}$$

, (7.35)

variable *V* and a locally concave function of the intensive variable *T*. By methods similar to those discussed for the enthalpy, we have the local stability requirement

$$F_{VV} = \frac{\mathcal{D}}{U_{\rm SS}} \ge \mathbf{0},\tag{7.37}$$

≥ 0, (7.37)

so *FVV FTT* − *F*2 *VT* ≤ 0, which is no contest because *FTT* ≤ 0 so both terms are non-positive. We also have

another redundancy. 7.3.3 Gibbs Free Energy For the Gibbs free energy *G*(*T*, *p*, *N*), both *T* and *p* are intensive, so local stability requirements involving their derivatives must be obtained indirectly from their Legendre transforms. We have *GTT* = −1/*HSS* ≤ 0 and *Gpp* = −1/*FVV* ≤ 0 as anticipated for both principal second partial derivatives with respect to intensive variables. In this case, the

*Tp*

*Gpp*

*GTT*

*FVV* = *D USS*

$$F_{TT} = \frac{G_{TT}G_{pp} - G_{Tp}^2}{G_{pp}} \tag{7.38}$$

(7.38)

or

$$H_{pp} = \frac{G_{TT}G_{pp} - G_{Tp}^2}{G_{TT}},\tag{7.39}$$

104 THERMAL PHYSICS

$$-G_{TT}G_{pp} - G_{Tp}^2 \geq \mathbf{0}.\tag{7.40}$$

$$\rm G_{TT}G_{pp} - G_{Tp}^2 = \frac{1}{U_{SS}U_{VV} - U_{SV}^2} \ge 0,\tag{7.41}$$

*Tp* ≥ 0. (7.40)

either of which shows that *GTTGpp* − *G*2

### A somewhat more involved calculation3 shows that *Gpp* = −*USS*/*D*, *GTT* = −*UVV* /*D*, and

*GTp* = −*USV* /*D* which results in *GTTGpp* − *G*2 *Tp* = 1 *USSUVV* − *U*2 ≥ 0, (7.41)

*SV*

- so the two non-trivial fluting conditions are just reciprocals of one another.
	-
- 7.3.4 Summary of Stability Requirements By means similar to those discussed above, we can extend the stability requirements to

any number of variables. For stability of a homogeneous system: • The entropy, *S*, must be a concave function of its natural extensive variables. • The internal energy, *U*, must be a convex function of its natural extensive variables. • Legendre transforms of *U*, such as *H*, *F*, and *G*, must be convex functions of their

natural extensive variables and concave functions of their natural intensive variables. We did not discuss the Massieu functions, which are Legendre transforms of the entropy, but they must be concave functions of their extensive variables and convex functions of

their intensive variables. Fluting conditions involve mixed partial derivatives, but are always redundant with requirements on non-mixed second partial derivatives of *S*, *U*, or some Legendre transform of *U*. It is possible to consider thermodynamic functions, perhaps derived from some model, for which the requirements for local stability are true for some range of variables but for

which the requirements for global stability are violated. Such situations can occur when different phases of a composite system are in equilibrium but in which phase transitions can occur. We shall illustrate this in Chapter 9 by means of the van der Waals model. In applying the above requirements, it is extremely important to note that they only apply to the extensive thermodynamic functions and the natural variables, extensive and intensive, on which they depend. Moreover, if one uses a "density" of some extensive variable, such as the Helmholtz free energy per mole, *f* = *F*/*N*, one finds that d*f* = −*s* d*T* − *p* d*v* where *v* = *V*/*N* is also a "density," namely the volume per mole. Although *f* and *v* are certainly intensive, they still behave from the point of view of stability like the extensive variables *F* and *V* from which they originate. In other words, ∂2*f* /∂*v* 2 *T* ≥ 0 for local stability, corresponding to *f* being a convex function of *v*, just as *F* is a convex function of *V*. But *T* is not a "density" so ∂2*f* /∂*T*2 *v* ≤ 0 for local stability, meaning that

*f* is a concave function of *T*. This peculiarity arises because the local stability condition

<sup>3</sup>For instance, *GTT* = −1/(∂*US*/∂*S*)*p*, (∂*US*/∂*S*)*p* = *USS* + *USV* (∂*V*/∂*S*)*p*, and (∂*V*/∂*S*)*p* = −*UVS*/*UVV* .

*Chapter 7* • Requirements for Stability 105 for an intensive variable such as *T* is derived from a Legendre transformation, rather than

$$U_{\rm SS} = \left(\frac{\partial T}{\partial S}\right)_{V,N} = T/C_V \ge 0 \tag{7.42}$$

7.4 Consequences of Stability Requirements

of stable homogeneous phases. Thus

$$H_{\rm SS} = \left(\frac{\partial T}{\partial S}\right)_{p,N} = T/C_p \ge 0 \tag{7.43}$$

*USS* = -∂*T* ∂*S* = *T*/*CV* ≥ 0 (7.42)

$$F_{VV} = -\left(\frac{\partial p}{\partial V}\right)_{T,V} = 1/(V\kappa_T) \ge 0\tag{7.44}$$

= 1/(*V*κ*T* ) ≥ 0 (7.44)

*Cp* − *CV* = *TV*α2/κ*T* (7.45)

*HSS* = ∂*S p*,*N* = *T*/*Cp* ≥ 0 (7.43)

> ∂*p* ∂*V T*,*N*

*FVV* = −-

$$\mathbf{C}_{p} - \mathbf{C}_{V} = T\mathbf{V}a^{2}/\kappa_{T} \tag{7.45}$$

so

$$\mathbf{C}_{\mathcal{V}} \ge \mathbf{C}_{V} \ge \mathbf{0}.\tag{7.46}$$

$$\kappa_S := -\frac{1}{V} \left( \frac{\partial V}{\partial p} \right)_{S,V} \,. \tag{7.47}$$

We can define a compressibility at constant entropy4 by the relation κ*S* := − 1 *V* -∂*V* ∂*p S*,*N* . (7.47)

-∂*T* 
$$-V\kappa_S = \left(\frac{\partial V}{\partial p}\right)_T + \left(\frac{\partial V}{\partial T}\right)_p \left(\frac{\partial T}{\partial p}\right)_S \tag{7.48}$$

<span id="page-125-0"></span>

Then from

so

Since *UVV* = −

∂*p*/∂*V* 

∂*T*/∂*p S* ∂*p*/∂*S* 

$$
\kappa_S = \kappa_T - \alpha \left(\frac{\partial T}{\partial p}\right)_S. \tag{7.49}
$$

κ*S* = κ*T* − α -∂*T* ∂*p S* . (7.49)

> -∂*T* ∂*p S*

− *V*κ*S* =

-∂*V* ∂*p* 

$$\left(\frac{\partial T}{\partial p}\right)_S = -\frac{\left(\partial S/\partial p\right)_T}{\left(\partial S/\partial T\right)_p} = \frac{V\alpha}{C_p/T},\tag{7.50}$$

-∂*V*

<sup>(∂</sup>*S*/∂*T*)*p* 4This is sometimes called the adiabatic compressibility, but strictly speaking it is isentropic.

$$
\kappa_T - \kappa_S = TV\alpha^2/\mathcal{C}p.\tag{7.51}
$$

106 THERMAL PHYSICS

Combining these relations gives

We therefore see that

where {*E*

Eq. (7.24) is

*i*

Eq. (7.56) would become

$$
\kappa_T \ge \kappa_S \ge \mathbf{0}.\tag{7.52}
$$

where the Maxwell relation − ∂*S*/∂*p* 

<span id="page-126-0"></span>
$$
\kappa_{\rm S}/\kappa_{\rm T} = \mathbf{C} \cdot \mathbf{C} \qquad \text{(7.5.2)}
$$

$$
\kappa_{\rm S}/\kappa_{\rm T} = \mathbf{C} \mathbf{y}/\mathbf{C}_{\rm p}.\tag{7.53}
$$

<span id="page-126-1"></span>κ*T* ≥ κ*S* ≥ 0. (7.52)

κ*T* − κ*S* = *TV*α2/*CP*. (7.51)

### In fact, combination of Eqs. (7.45) and (7.51) gives the interesting relation

κ*S*/κ*T* = *CV* /*Cp*. (7.53) For an alternative derivation of Eq. (7.53) that involves Jacobians, see Appendix B.

$$\mathbf{d}U = \sum_{j=1}^{n} p_j \,\mathrm{d}E_j,\tag{7.54}$$

We illustrate these beginning with the internal energy as a function of many extensive variables. If we write d*U* in the form

$$\begin{aligned} \left(\partial_t^2 U_i\right)_{\{E_i^2\}} &= \left(\partial_t^2 U_i\right)_{\{E_i^2\}} = \left(\frac{\partial p_l}{\partial E_l}\right)_{\{E_i^l\}} \ge 0, \\\ \left(\frac{\partial^2 U_i}{\partial E_l}\right)_{\{E_i^l\}} &\ge 0, \end{aligned} \tag{7.55}$$

stability with respect to a single variable will require ∂2*U* ∂*E*2 *i* {*E i* } = -∂*pi* ∂*Ei* {*E i* } ≥ 0, (7.55)

$$\sum_{l,l} \delta U_l \, U_l \, \delta U_l \ge 0; \quad U_{\parallel l} = \frac{\partial^2 U}{\partial E_l \partial E_l} = U_{\parallel l}. \tag{7.56}$$

 *i*,*j* δ*Ui Uij* δ*Uj* ≥ 0; *Uij* = ∂2*U* ∂*Ei*∂*Ej* = *Uji*. (7.56)

$$\sum_{l} \lambda_{l} \, (\delta X_{l})^{2} \ge \mathbf{0},\tag{7.57}$$

 *i* λ*i* (δ*Xi*) 2 ≥ 0, (7.57) where λ*i* are its eigenvalues and δ*Xi* are linear combinations of the δ*Uj* that depend on the eigenvectors of *U*. The condition for all eigenvalues of *U* to be positive definite is that the determinants of all of its principal minors be positive definite. Its principal minor of order *r* is the square symmetric matrix obtained from {*Uij*} by eliminating all of its rows for *i* > *r* and all of its columns for *j* > *r*. If *U* is an *n* × *n* matrix, there are *n* of these principal minors, the largest being the entire matrix *U*. For the simple case in which only δ*U*1 and δ*U*2 are non-zero, the minor of order *r* = 1 gives *U*11 > 0 and the minor of order *r* = 2 gives *U*11*U*22 − *U*2 12 > 0, in agreement with Eq. [(7.25)](#page-121-0).

For the entropy as a function of many extensive variables, the corresponding local stability criterion is a little trickier. In that case, one wants the eigenvalues of the matrix {*Sij*} to be non-positive. In order for such eigenvalues to be negative definite, one needs the determinants of the principal minors of odd order to be negative and those of even order to be positive. Thus, if only δ*S*1 and δ*S*2 are non-zero, one needs *S*11 < 0 but *S*11*S*22 − *S*2 12 > 0, in agreement with Eq. [(7.16)](#page-119-1).

If we consider the Legendre transform

$$\mathcal{L} = U - \sum_{k=r+1}^{n} p_k E_k \tag{7.58}$$

with differential

$$\mathbf{d}\mathcal{L} = \sum_{j=1}^{r} p_j \mathbf{d}E_j - \sum_{k=r+1}^{n} E_k \mathbf{d}p_k,\tag{7.59}$$

we get either a stability requirement of the type

<span id="page-127-0"></span>
$$\frac{\partial \mathcal{L}}{\partial E_j} = \left(\frac{\partial p_j}{\partial E_j}\right)_{\{E_j'\}, \{p_k\}} \ge 0; \quad j = 1, \dots, r; \quad k = r + 1, \dots, n,\tag{7.60}$$

or

$$\frac{\partial \mathcal{L}}{\partial p_k} = -\left(\frac{\partial E_k}{\partial p_k}\right)_{\{E_j\}, \{p'_k\}} \le 0; \quad j = 1, \dots, r; \quad k = r+1, \dots, n. \tag{7.61}$$

Comparison of Eq. [(7.60)](#page-127-0) with Eq. [(7.55)](#page-126-1) shows that a partial derivative of an intensive variable with respect to its conjugate extensive variable is non-negative, but different variables can be held constant in the partial differentiations. For instance, ∂μ*j*/∂*Nj S*,*V*,{*N j*} ≥ 0 but also ∂μ*j*/∂*Nj S*,*p*,{*N j*} ≥ 0, ∂μ*j*/∂*Nj T*,*V*,{*N j*} ≥ 0, and ∂μ*j*/∂*Nj T*,*p*,{*N j*} ≥ 0 follow from consideration of *U*, *H*, *F*, and *G*, respectively.

### 7.6 Principles of Le Chatlier and Le Chatlier-Braun

Before leaving the subject of stability, we mention some general principles that govern the approach of systems to equilibrium. The first, due to Le Chatlier, states that if some extensive variable fluctuates from its equilibrium value, its conjugate intensive variable will change in such a way as to restore that extensive variable to its equilibrium value. The second, due to Le Chatlier-Braun, states that if some extensive variable fluctuates and also produces changes in non-conjugate intensive variables, secondary induced processes occur in such a way as to oppose the change in the conjugate intensive variable associated with the original extensive variable. Thus, any fluctuations of a stable state will tend to decay in such a way as to restore equilibrium values. For formal treatments, see Landau and Lifshitz [7, p. 63] or Callen [2, p. 212].

This page intentionally left blank

8

# Monocomponent Phase Equilibrium

In this Chapter, we examine equilibrium for a monocomponent system for the simple case in which the solid phase has only a single crystal structure. The situation can be described by means of a **phase diagram** in the *T*, *p* plane, such as sketched in [Figure 8–1.](#page-130-0) This diagram divides the plane into regions where the phases solid (S), liquid (L), and vapo[r1](#page-129-0) (V) are stable. Therefore, the only lines that appear on the diagram are curves where pairs of these phases are in equilibrium. These are called coexistence curves and we shall proceed to develop equations that describe them.

According to the thermodynamics of open monocomponent systems, the conditions for phases to be in equilibrium (see Chapter 6) are for them to have the same temperature *T*, the same pressure *p*, and the same chemical potential μ. But according to Eq. (5.45), the Gibbs-Duhem equation, these variables are not independent and one can regard the chemical potential μ(*T*, *p*) to be a function of temperature and pressure. This function is not the same for different phases, so the **coexistence curves** are given by the following equations:

$$
\mu_{\mathbb{S}}(T, p) = \mu_{\mathbb{L}}(T, p), \quad \text{solid-liquid coexistentce curve}, \tag{8.1}
$$

$$
\mu_{\mathcal{S}}(T, p) = \mu \mathbf{v}(T, p), \quad \text{solid-vapor cocexistence curve}, \tag{8.2}
$$

<span id="page-129-2"></span>
$$
\mu_{\mathcal{L}}(T, p) = \mu_{\mathcal{V}}(T, p), \quad \text{liquid-vapor coexistence curve.} \tag{8.3}
$$

According to the Gibbs phase rule for a monocomponent system, the number of thermodynamic degrees of freedom is 3 − *n* where *n* is the number of phases. A single phase region, such as the solid, is represented by an area; accordingly, *n* = 1 and there are two degrees of freedom, *p* and *T*, that may be chosen independently throughout this area. Along each of the coexistence curves, *p* = 2 so there is one degree of freedom along these curves. Thus, if *T* is specified, *p* is known from the curve. For either solid-vapor or solidliquid equilibrium, the corresponding pressure of the vapor for a given value of *T* is known as the vapor pressure. If *n* = 3, there are no degrees of freedom; this happens at a point known as the **triple point** where solid, liquid, and vapor are in mutual equilibrium with each other. Thus we have

<span id="page-129-1"></span>
$$
\mu_S(T, p) = \mu \sqcup (T, p) = \mu \vee (T, p), \quad \text{triple point.} \tag{8.4}
$$

Equation [(8.4)](#page-129-1) represents two equations in two unknowns; their solution determines *Tt* and *pt*, the unique coordinates of the triple point. It turns out that the liquid-vapor coexistence curve actually ends at a point *Tc* and *pc* known as the **critical point**. Thus,

<span id="page-129-0"></span><sup>1</sup>A vapor is a gaseous phase that can be condensed to form a liquid or solid. Sometimes the word "gas" is used interchangeably with "vapor," but an ideal gas cannot undergo a phase transformation.

<span id="page-130-0"></span>![](_page_130_Figure_1.jpeg)

**FIGURE 8–1** Sketch (not to scale) of a phase diagram for a monocomponent system. The curves are coexistence curves for pairs of the phases solid (S), liquid (L), and vapor (V). All three phases coexist in mutual equilibrium at the triple point *Tt*, *pt*. The liquid-vapor coexistence curve ends at the critical point *Tc*, *pc*. This diagram pertains to the usual case in which the molar volume of the solid is less than that of the liquid from which it freezes. See [Figure 8–3](#page-133-0) for the unusual case.

for *T* > *Tc* or *p* > *pc*, liquid and vapor become indistinguishable. In Chapter 9 we will see how such a behavior follows from the van der Waals model of a fluid.

Phase diagrams for monocomponent systems can have great variety because the crystalline solids can have different crystal structures, each considered to be a phase. For example, if the solid can have two crystal structures, say α and β, there can be more than one triple point, for example, for equilibrium among (α, *L*, *V*) and (α, β, *L*). See deHoff [21, chapter 7] for some specific examples as well as geometrical details of chemical potential surfaces.

### 8.1 Clausius-Clapeyron Equation

We proceed to find a differential equation for one of the coexistence curves; we choose the liquid-vapor coexistence curve as a specific example. We take the differential of Eq. [(8.3)](#page-129-2) to obtain

<span id="page-130-1"></span>
$$
\left(\frac{\partial\mu_{\rm L}}{\partial T}\right)_{p}\mathrm{d}T + \left(\frac{\partial\mu_{\rm L}}{\partial p}\right)_{T}\mathrm{d}p = \left(\frac{\partial\mu_{\rm V}}{\partial T}\right)_{p}\mathrm{d}T + \left(\frac{\partial\mu_{\rm V}}{\partial p}\right)_{T}\mathrm{d}p.\tag{8.5}
$$

The derivatives in Eq. [(8.5)](#page-130-1) can be identified by noting for a monocomponent system that the chemical potential μ is equal to *g* := *G*/*N*, the Gibbs free energy per mole. This follows because the Euler equation is just *G* = μ*N* for a monocomponent system. Since d*G* = − *S* d*T* + *V* d*p* + μd*N*, we readily verify that

dμ= d*g* = −*s* d*T* + *v* d*p*, monocomponent system, (8.6)

where *s* is the entropy per mole and *v* is the volume per mole. Thus,

<span id="page-130-2"></span>
$$\left(\frac{\partial\mu}{\partial T}\right)_p = -\text{ s}; \quad \left(\frac{\partial\mu}{\partial p}\right)_T = v. \tag{8.7}$$

Therefore, Eq. [(8.5)](#page-130-1) becomes

<span id="page-131-0"></span>
$$\frac{\mathbf{d}p}{\mathbf{d}T} = \frac{\mathbf{sv} - \mathbf{su}}{v\mathbf{v} - v\mathbf{L}}.\tag{8.8}$$

We can further transform Eq. [(8.8)](#page-131-0) by recalling that *G* = *H* − *TS* so that *g* = *h* − *Ts* where *h* is the enthalpy per mole. Thus

$$
\mu = h - \text{Ts}, \quad \text{monocomponent system}, \tag{8.9}
$$

and Eq. [(8.3)](#page-129-2) leads to

<span id="page-131-1"></span>
$$\mathbf{s}_{\rm V} - \mathbf{s}_{\rm L} = \frac{h\mathbf{v} - h\mathbf{L}}{T} \tag{8.10}$$

along the coexistence curve. The quantity *h*V − *h*L is the latent heat of vaporization per mole from liquid to vapor. Similarly, the quantity *s*V −*s*L is the entropy of vaporization per mole from liquid to vapor. According to Eq. [(8.3)](#page-129-2), μ is continuous at a coexistence curve. But its first partial derivatives −*s* and *v* are not continuous. They have jumps from liquid to vapor that are related by Eq. [(8.10)](#page-131-1). Thus, it turn out that both *s*V − *s*L and *h*V − *h*L are positive quantities.[2](#page-131-2) Substitution of Eq. [(8.10)](#page-131-1) into Eq. [(8.8)](#page-131-0) leads to

<span id="page-131-4"></span>
$$\frac{\mathbf{d}p}{\mathbf{d}T} = \frac{h_{\rm V} - h_{\rm L}}{T(v_{\rm V} - v_{\rm L})},\tag{8.11}$$

which is known as the **Clausius-Clapeyron equation**. [3](#page-131-3) It is a differential equation for the liquid-vapor coexistence curve. It is generally more useful than Eq. [(8.3)](#page-129-2) because the quantities on the right-hand side of Eq. [(8.11)](#page-131-4) are better understood than μ itself and can be measured experimentally. Since *v*V − *v*L > 0, the vapor pressure curve of *p* versus *T* has a positive slope, so vapor pressure clearly increases with increasing *T*. To get the actual shape of the vapor pressure curve, we must know how *h*V − *h*L and *v*V − *v*L depend on *T* and *v*. Equations of the same form apply to the other coexistence curves.

### 8.1.1 Approximate Vapor Pressure Curve

We can integrate Eq. [(8.11)](#page-131-4) by making the following approximations:

- The latent heat *h* := *h*V − *h*L is a positive constant.
- The molar volume of the vapor is much greater than that of the liquid, so *v*V − *v*L ≈ *v*V.
- We can approximate the volume of the vapor by using the ideal gas law, *v*V ≈ *RT*/*p*.

These approximations are terrible near the critical point, but otherwise they are not too bad over a limited range of *T*. Of course, an ideal vapor will not condense to form a liquid, but the ideal gas law can still give a reasonable estimate of the molar volume of a real vapor. With these approximations, Eq. [(8.11)](#page-131-4) becomes

<span id="page-131-2"></span><sup>2</sup>Experiment as well as elementary considerations of statistical mechanics lead to the fact that a mole of vapor has a higher entropy (more disorder) than a mole of liquid. For similar reasons, *s*V−*s*S, *h*V −*h*S,*s*L−*s*S, and *h*L−*h*S are all positive quantities.

<span id="page-131-3"></span><sup>3</sup>According to Planck [15, p. 149] this equation was deduced by Clapeyron from Carnot's incorrect theory, but first rigorously proved by Clausius.

<span id="page-132-4"></span>
$$\frac{\mathrm{d}p}{\mathrm{d}T} = \frac{p\Delta h}{RT^2}.\tag{8.12}$$

The variables separate to give

$$\frac{\Delta p}{p} = \frac{\Delta h}{R} \frac{\mathbf{d}T}{T^2},\tag{8.13}$$

which integrates to yield

<span id="page-132-0"></span>
$$
\ln p = -\frac{\Delta h}{RT} + \ln C,\tag{8.14}
$$

where *C* is a constant. We can exponentiate Eq. [(8.14)](#page-132-0) to obtain

<span id="page-132-1"></span>
$$p = C \exp\left(-\frac{\Delta h}{RT}\right). \tag{8.15}$$

The constant *C* can be determined by relating to one point, *T*0, *p*0, on the coexistence curve, resulting in

<span id="page-132-3"></span>
$$p = p_0 \exp\left[-\frac{\Delta h}{R}\left(\frac{1}{T} - \frac{1}{T_0}\right)\right].\tag{8.16}$$

The exponential form of Eq. [(8.15)](#page-132-1) indicates that the vapor pressure *p* increases very rapidly as *T* increases. Consequently, it is often represented graphically by reverting to Eq. [(8.14)](#page-132-0) and plotting ln *p* as a function of 1/*T*, which yields a straight line of slope −*h*/*R*, as illustrated in [Figure 8–2.](#page-132-2) Such a plot of vapor pressure data could be used to determine experimentally a value of *h*. Any process that obeys an equation of the general form of Eq. [(8.14)](#page-132-0) is known as an **activated process** and is said to have **Arrhenius form**. The quantity *h* is often referred to as an **activation energy**, although it is really an enthalpy difference. The reason that many processes are activated will become apparent from statistical mechanics.

<span id="page-132-2"></span>The same approximations can be made for the vapor pressure along the solid-vapor coexistence curve, resulting in Eq. [(8.16)](#page-132-3) with *h* =*h*V − *h*S. The process of formation

![](_page_132_Figure_12.jpeg)

**FIGURE 8–2** Plot of the logarithm of the vapor pressure *p* versus 1/*T* according to Eq. [(8.14)](#page-132-0). The slope of the line is −*h*/*R*. Quantities that depend on temperature in this way are said to have Arrhenius form with an activation energy of *h*.

<span id="page-133-2"></span>*Chapter 8* • Monocomponent Phase Equilibrium 113

$$\frac{\mathrm{d}p}{\mathrm{d}T} = \frac{h_{\mathrm{L}} - h_{\mathrm{S}}}{T(v_{\mathrm{L}} - v_{\mathrm{S}})} \tag{8.17}$$

- 8.1.2 Approximate Solid-Liquid Coexistence Curve
- For the solid-liquid coexistence curve, the Clausius-Clapeyron equation becomes d*p* d*T* = *h*L − *h*S *T*(*v*L − *v*S) (8.17) and a different set of approximations applies as follows:
- The entropy of fusion *s* = *h*/*T* := (*h*L −*h*S)/*T* is a positive constant.

• The molar volume of the liquid is comparable to that of the solid, typically only a few

<span id="page-133-1"></span>
$$\frac{\mathbf{d}p}{\mathbf{d}T} \approx \frac{\Delta s}{\Delta v},\tag{8.18}$$

• *v* := *v*L − *v*S is constant.

*p*

<span id="page-133-0"></span>
$$p - p_0 = \frac{\Delta \mathbf{s}}{\Delta v} (T - T_0). \tag{8.19}$$
 
$$\text{Thus the solid-liquid cosistance curve is noarch by a straight line with staea slope. In the case}$$

*v* , (8.18) which integrates to give *p* − *p*0 = *s v* (*T* − *T*0). (8.19)

Thus the solid-liquid coexistence curve is nearly a straight line with steep slope. In the case for which *v* is positive, the phase diagram looks like Figure 8–1, but when it is negative,

![](_page_133_Figure_14.jpeg)

*T* **FIGURE 8–3** Sketch (not to scale) of a phase diagram for a monocomponent system for the unusual case for which the molar volume of the solid exceeds that of the liquid from which it freezes. The curves are coexistence curves for

pairs of the phases solid (S), liquid (L), and vapor (V). See Figure 8–1 for the usual case and other notation.

![](_page_134_Picture_1.jpeg)

114 THERMAL PHYSICS

$$\frac{\mathrm{d}p}{\mathrm{d}T} = \frac{11,950}{1235 \times 0.4 \times 10^{-6}} = 2.38 \times 10^7 \,\mathrm{Pa/K} = 2.38 \times 10^2 \,\mathrm{atm/K}.\tag{8.20}$$

**Example Problem 8.1.** At atmospheric pressure, silver melts at *T* = 1235 K and its volume expands about 4%, the actual volume change being about 0.4 cm3/mol. Its latent heat of fusion is 11,950 J/mol. How much must the pressure increase to raise its melting point by 1 K? **Solution 8.1.** Inserting this data into Eq. (8.17), we obtain d*p* d*T* = 11,950

Thus, an enormous pressure of about 240 [atmos](#page-132-3)phere[s wou](#page-133-1)ld be required to raise the melting point of by 1 K. We conclude that the melting point of silver is practically insensitive to pressure, which is typical of other substances as well. On the other hand, as will be shown below, boiling

1235 × 0.4 × 10−6 = 2.38 × 107 Pa/K = 2.38 × 102 atm/K. (8.20)

### points are quite sensitive to pressure because the molar volumes of gaseous phases depend strongly on pressure and are many times larger than the molar volumes of condensed phases.

<span id="page-134-0"></span>8.1.3 Approximate Relative Magnitudes The app[roxim](#page-133-2)ations used to obtain Eqs. (8.16) and (8.19) are rather crude and only meant to be illustrative. Although they lead to results that resemble the phase diagrams for real systems, they are no substitute for accurate experimental data. We can, however, gain

$$\frac{\mathrm{d}p}{\mathrm{d}T} \approx \frac{10.5R}{\mathrm{v}}, \quad \text{vaporization at atmospheric pressure,} \tag{8.21}$$

estimates *h*/(*RT*) = 1.0 for melting. By using these rules, Eq. (8.11) becomes

liquid coexistence.

<span id="page-134-1"></span>d*p*

$$\frac{\mathrm{d}p}{\mathrm{d}T} \approx \frac{1.0R}{\Delta v}, \quad \text{melting at atmospheric pressure.} \tag{8.22}$$

and Eq. (8.17) becomes d*p*

$$
\left(\frac{\mathrm{d}p}{\mathrm{d}T}\right)_{\mathrm{vaporization}} \left| \left(\frac{\mathrm{d}p}{\mathrm{d}T}\right)_{\mathrm{melting}} \right|^{-1} \approx 10.5 \frac{|\Delta v|}{v_{\mathrm{V}}} \ll 1,\tag{8.23}
$$

<span id="page-134-2"></span> d*p* d*T* vaporization d*p* d*T* melting ≈ 10.5 |*v*| *v*V 1, (8.23) where the inequality applies because *v*V is typically many orders of magnitude larger than |*v*| for melting. Therefore, the slope of the solid-liquid coexistence curve is much steeper for melting than for vaporization. For vaporization of water at 373.1 K = 100 ◦C, Fermi [1, p. 67] estimates d*p*/d*T* = 2.7 cm Hg/K = 0.036 atm/K, whereas for melting of ice at

273.1 K = 0 ◦C he estimates4 d*p*/d*T* = −134 atm/K. The ratio of these slopes is −2.7×10−4. 4This temperature is 100 K lower than for vaporization, but d*p*/d*T* is nearly constant along the line of solid*Chapter 8* • Monocomponent Phase Equilibrium 115

### If we compute this ratio using Eq. (8.23), we get −5.5 × 10−4. But the latent heats of H2O deviate significantly from those given by Trouton's rule and Richard's rule as [given above](#page-130-0) because of the complexity of the water molecule and the structure o[f ice. For H2](#page-135-0)O, 10.5 for

the line *p*1 in Figure 8–4.

Maxwell relation

curve.

*p*

*p*2

*p*3

*p*1

Trouton's rule should be replaced by 13.0 and for 1.0 for Richard's rule should be replaced by 2.64. This has the net effect of replacing 10.5 in Eq. (8.23) by 13.0/2.64 = 4.92[, so](#page-130-2) the corrected value of the slope ratio for H2O is −2.6 × 10−4, in reasonable agreement.

8.2 Sketches of the Thermodynamic Functions We can gain more insight into monocomponent systems by sketching the thermodynamic functions μ, *h*, and *s* as functions of *p* and *T*. For a phase diagram of the form of Figure 8–1, we choose three constant pressures, *p*1, *p*2, and *p*3 as indicated in Figure 8–4, and then

discuss μ, *h*, and *s* as a function *T* at each of these pressures. Along a line of constant *p*, μ is a continuous function of *T*. According to Eq. (8.7), its

$$\mathbf{ds} = \left(\frac{\partial \mathbf{s}}{\partial T}\right)_p \mathbf{d}T + \left(\frac{\partial \mathbf{s}}{\partial p}\right)_T \mathbf{d}p = \frac{\mathbf{c}_p}{T} \mathbf{d}T + \left(\frac{\partial \mathbf{s}}{\partial p}\right)_T \mathbf{d}p,\tag{8.24}$$

<span id="page-135-0"></span>To quantify the behavior of *s* and *h*, we must view them as functions of *T* and *p*. Within a bulk phase,

where *cp* is the heat capacity per mole at constant pressure. From Eq. (8.7) we have the

![](_page_135_Figure_8.jpeg)

d*s* = - ∂*s* ∂*T p* d*T* + - ∂*s* ∂*p T* d*p* = *cp T* d*T* + - ∂*s* ∂*p T* d*p*, (8.24)

*T* **FIGURE 8–4** Constant pressure paths *p*1, *p*2, and *p*3 on a phase diagram for the monocomponent system of Figure 8–1. The chemical potential μ is continuous along these paths, but its slope, −*s*, changes as *T* crosses a coexistence

116 THERMAL PHYSICS

![](_page_136_Figure_1.jpeg)

*µ*

<span id="page-136-0"></span>V

*TSV T*

S

$$\mathbf{ds} = \frac{c_p}{T} \,\mathrm{d}T - vu \,\mathrm{d}p.\tag{8.26}$$

phase transition. The stable phase is solid (S) for *T* ≤ *T*SV and vapor (V) for *T* ≥ *T*SV.

$$\mathbf{d}h = T\,\mathbf{ds} + v\,\mathbf{d}p = T\left(\frac{\partial\mathbf{s}}{\partial T}\right)_p \,\mathrm{d}T + \left[T\left(\frac{\partial\mathbf{s}}{\partial p}\right)_T + v\right]\,\mathrm{d}p.\tag{8.27}$$
 
$$\mathbf{r}_1, \dots$$

For the enthalpy per mole, we have

$$\mathbf{d}h = c_p \mathbf{d}T + v(1 - Ta)\,\mathrm{d}p.\tag{8.28}$$

∂*T p* ∂*p T* Thus

$$h(T_2) - h(T_1) = \int_{T_1}^{T_2} c_p \, \mathrm{d}T \approx c_p (T_2 - T_1);\tag{8.29}$$

$$\mathbf{s}(T_2) - \mathbf{s}(T_1) = \int_{T_1}^{T_2} \frac{\mathbf{c}_p}{T} \, \mathrm{d}T \approx \mathbf{c}_p \ln(T_2/T_1),\tag{8.30}$$

*s*(*T*2) [−](#page-137-1) *s*(*T*1) = *T*2 *T*1 *cp T* d*T* ≈ *cp* ln(*T*2/*T*1), (8.30)

where the approximate expressions hold if *cp* is a constant. Figure 8–6 shows sketches of *h* and *s* as a function of *T* along the line *p* = *p*1 in Figure 8–4. Along the line *p* = *p*2, there are two phase transitions, from S to L and from L to V, so μ has a discontinuity of slope at each transition, and *h* and *s* have jumps at each transition. Along the line *p* = *p*3, there is only one phase transition, because *p*3 > *pc* and there is no

distinction between liquid and vapor above the critical pressure. Next, we choose three constant temperatures *T*1, *T*2, and *T*3, as indicated in Figure 8–7. Along a line of constant *T*, μ is continuous and within a single phase, according to Eq. (8.7), it has a slope of *v*. Figure 8–8 is a sketch of μ versus *p* at *T* = *T*1. We observe the discontinuity of slope as the vapor-solid coexistence curve is crossed.

![](_page_137_Figure_0.jpeg)

<span id="page-137-0"></span>*h* Δ*h* S *s* S

![](_page_137_Figure_2.jpeg)

Figure 8–5.

coexistence curve.

*p*

*µ*

phase transition. The stable phase is vapor (V) for *p* ≤ *p*SV and solid (S) for *p* ≥ *p*SV.

<span id="page-137-1"></span>V

*T*1 *T*2 *T*3

*T*

![](_page_137_Figure_4.jpeg)

*pSV p* **FIGURE 8–8** Sketch of the chemical potential μ as a function of *p* along the line *T* = *T*1 in Figure 8–7. The full line corresponds to the stable solid and vapor phases. The dashed lines are extrapolations into unstable regions of superheated solid and supercooled vapor, intended to emphasize the discontinuity of slope of the full line at the

![](_page_138_Figure_1.jpeg)

*h* Δ*h* S *s* Δ*s* S

*pSV p pSV p* **FIGURE 8–9** Sketches of the enthalpy *h* per mole and the entropy *s* per mole as a function of *p* along the line *T* = *T*1 in Figure 8–7. The full line corresponds to the stable solid and vapor phases. The stable phase is vapor (V) for

$$h(p_2) - h(p_1) = \int_{p_1}^{p_2} v(1 - Ta) \, \mathrm{d}p;\tag{8.31}$$

$$\mathbf{s}(p_2) - \mathbf{s}(p_1) = \int_{p_1}^{p_2} -vu \, \mathbf{d}p. \tag{8.32}$$

*v*(1 − *T*α) d*p*; (8.31)

*h*(*p*2) − *h*(*p*1) = *p*2

$$h(p_2) - h(p_1) = 0; \quad s(p_2) - s(p_1) = \int_{p_1}^{p_2} -\frac{v}{T} \, \mathrm{d}p = -R \ln(p_2/p_1). \tag{8.33}$$

For an ideal vapor, *T*α = 1 which gives

$$h(p_2) - h(p_1) \approx v(p_2 - p_1); \quad \mathbf{s}(p_2) - \mathbf{s}(p_1) \approx \mathbf{0}.\tag{8.34}$$

For the solid phase, *T*α 1, so for constant *v* we have5

*h*(*p*2) − *h*(*p*1) ≈ *v*(*p*2 − *p*1); *s*(*p*2) − *s*(*p*1) ≈ 0. (8.34) [Figure](#page-139-0) [8–9](#page-139-0) shows sketches of *h* and *s* as functions of *p* along a line *T* = *T*1 in Figure 8–7. Along the line *T* = *T*2 in Figure 8–7, there are two phase transitions, from V to L and from L to S, so μ has a discontinuity of slope at each transition and *h* and *s* have jumps at each

<span id="page-138-0"></span>transition. Along the line *T* = *T*3, the liquid-vapor phase transition is absent because *T*3 >

### *Tc* and there is no distinction between liquid and vapor above the critical temperature.

8.3 Phase Diagram in the *v*, *p* Plane In the *v*, *p* plane, the phase diagram of a monocomponent system is sketched in

5The same approximation would be true for a liquid.

Figure 8–10. The regions where single phases are stable are separated by miscibility gaps.

<span id="page-139-0"></span>![](_page_139_Figure_1.jpeg)

*p*

*pc pt L vc vS vV vt v* S V **FIGURE 8–10** Sketch of the phase diagram for a monocomponent system in the *v*, *p* plane. The solid S is stable to the left of all lines. The liquid L is stable in the region of distorted triangular shape, the bottom vertex of which is at the triple point *vt*, *pt*. The triple point of the *p*, *T* phase diagram actually becomes a triple line on the *v*, *p* diagram and extends from *v*S to *v*V. Thus *vt* also represents the molar volume *v*L of the liquid phase that is in equilibrium with

solid of molar volume *v*S and vapor of molar volume *v*V. The vapor V is stable to the right of all lines. The critical point *vc*, *pc* is at the top of the miscibility gap that separates L from V. For *p* > *pc*, there is no distinction between liquid and vapor. The regions of stable phases are separated by miscibility gaps. A point within a miscibility gap can

represent a composite made up of stable phases at its boundaries having the same pressure. This diagram is not to scale. Typically, the difference in molar volume of L and S is a few percent, whereas the molar volume of a vapor in equilibrium with S or L can be thousands of times larger. These gaps occur because of the jumps in molar volumes between phases that are in equilibrium with one another. A point within a miscibility gap could correspond to an unstable single phase, for example, a supersaturated vapor that, for kinetic reasons, has not yet transformed to precipitate some liquid. At equilibrium, a point within a miscibility gap can represent a composite made up of stable phases at its boundaries having the same pressure. Most points within a miscibility gap correspond to only two stable phases that lie along a [coexi](#page-132-4)stence curve of a *T*, *p* pha[se](#page-139-1) [dia](#page-139-1)gram. But along the line *p* = *pt*, three phases can coexist in equilibrium. The amounts of these three phases cannot be determined by specifying the overall molar volume *v* alone, except for the special cases *v* = *v*S and *v* = *v*V which correspond to the ends of the triple line. However, the three phases h[ave different](#page-140-0)

<span id="page-139-1"></span>
$$\begin{array}{c} f_1 + f_2 + f_3 = 1, \\ f_1 v_1 + f_2 v_2 + f_3 v_3 = v, \\ f_1 h_1 + f_2 h_2 + f_3 h_3 = h. \end{array} \tag{8.35}$$

*f*1*v*1 + *f*2*v*2 + *f*3*v*3 = *v*, *f*1*h*1 + *f*2*h*2 + *f*3*h*3 = *h*. (8.35) But Eq. (8.12) is isomorphous with Eq. (8.35), so the *fi*(*v*, *h*) will have analogous properties to the *fi*(*s*, *v*) discussed in Chapter 7. In particular, to get positive values of *fi*(*v*, *h*), the point *v*, *h* must be chosen within or on the non-degenerate triangle with vertices (*v*S, *h*S),(*v*L, *h*L),

and (*v*V, *h*V). The values of the *fi*(*v*, *h*) are given by the triangle construction in Figure 8–11.

of triangle 123, only two phases will be present.

<span id="page-140-0"></span>![](_page_140_Figure_1.jpeg)

*h A*3 2 *A*2 *A*1 1

*v*

**FIGURE 8–11** Triangle construction for solution of the *fi*(*v*, *h*) in Eq. (8.35). The vertices (1,2,3) are located at the states (*v*S, *h*S), (*v*L, *h*L), and (*v*V, *h*V), respectively. The point within triangle 123 where the dashed lines meet has coordinates (*h*, *v*) where the total molar volume and total molar enthalpy are specified. If we designate the area of triangle 123 by *A*123, then *fi*(*u*, *v*) = *Ai*/*A*123, where *Ai* denotes the area of the inner triangle opposite to the vertex *i*. The diagram is not to scale because typically *v*V − *v*S *v*L − *v*S and *h*V − *h*S *h*L − *h*S. If *u*, *v* lies on one of the sides

![](_page_141_Picture_0.jpeg)

# 9

Two-Phase Equilibrium for a van der Waals Fluid In this chapter, we use the van der Waals model of a fluid to develop the methods that enable one to analyze the thermodynamics of two-phase equilibrium for a monocomponent system. This model will also serve to illustrate why the Helmholtz and Gibbs free energies are useful thermodynamic functions. We will focus particular attention on two graphical constructions, the common tangent and the c[hor](#page-141-0)d, that will enable us to see easily the

### <span id="page-141-1"></span>stability and metastability. We will also derive Maxwell's construction that allows one to determine the miscibility gap in the *v*, *p* plane. Although we have used the simple model

of a van der Waals fluid, the methods developed in this ch[apte](#page-141-1)r are general and apply to more realistic models or data. 9.1 van der Waals Equation of State

conditions under which two phases can exist in equilibrium as well as identify regions of

<span id="page-141-2"></span>
$$(p + \frac{a}{v^2})(v - b) = RT,\tag{9.1}$$

tion and a critical point is based on a generalized1 equation of state, due to van der Waals, of the form (*p* + *a v* 2 )(*v* − *b*) = *RT*, (9.1)

$$p = \frac{RT}{v - b} - \frac{a}{v^2},\tag{9.2}$$

<span id="page-141-0"></span>constants. Equation (9.1) can be rewritten in the form *p* = *RT v* − *b* − *a v* 2 , (9.2) which becomes the equation of state for one mole of an ideal gas for *a* = 0 and *b* = 0. The constant *b* [accounts for the finite size of vapo](http://dx.doi.org/10.1016/B978-0-12-803304-3.00009-0)r molecules, so *v* − *b* is the volume per mole that is free for occupancy. The constant *a* accounts for an attractive force between vapor molecules, which for sufficiently low temperatures will lead to condensation to a liquid. The explicit form of the term −*a*/*v* 2 in the pressure can be justified on the basis of mean

field theory, but we postpone this connection until Section 9.2.

<sup>1</sup>Strictly speaking, an equation of state expresses a partial derivative of a fundamental equation (for S or U) with respect to one of its dependent extensive variables as a function of its complete set of extensive variables. In this generalized equation of state, we have a relation among intensive variables which gives the partial derivative,

122 THERMAL PHYSICS

The van der Walls fluid is a useful model because it is tractab[le an](#page-141-2)d gives rise to an

### approximate phase diagram that exhi[bits many o](#page-142-0)f the features of real phase diagrams. Nevertheless, it is wrong in detail, especially near the critical point where correlations

associated with an unstable phase.

p

become important and mean field models fail. We shall examine this model with these shortcomings in mind, but with the aim of illustrating important constructions that allow one to analyz[e graphs of](#page-142-0) the Helmholtz and Gibbs free energies. 9.1.1 Isotherms Insight about the van der Waals fluid can be gained by using Eq. (9.2) to plot isotherms in the *v*, *p* plane, as sketched below in Figure 9–1. In doing this, we make the restriction

<span id="page-142-1"></span>
$$pv^3 - (pb + RT)v^2 + av - ab = 0,\tag{9.3}$$

isotherms resemble those for an ideal gas, except shifted to the right by *b*. For sufficiently low *T*, *p* is not a monotonically decreasing function of *v* and there are three values of *v* for a given *p* (see Figure 9–1b which shows such an isotherm on an exaggerated scale). These values are roots of the cubic equation *pv* 3 − (*pb* + *RT*)*v* 2 + *av* − *ab* = 0, (9.3)

<span id="page-142-0"></span>which is equivalent to Eq. (9.2). For *T* sufficiently low, one root of Eq. (9.3) can be small (of the order of *b*) and will be associated with a liquid; another can be large (of the order of

*RT*/*p*) and can be associated with a vapor, and a middle sized root is spurious and can be

![](_page_142_Figure_7.jpeg)

v v **FIGURE 9–1** (a) Sketch of isotherms in the *v*, *p* plane according to Eq. (9.2), for *T*4 > *T*3 > *Tc* > *T*2 > *T*1. For sufficiently high temperatures, the isotherms are monotonically decreasing functions of *v*, as they would be for an ideal gas. *Tc* is the critical temperature and its isotherm has a horizontal point of inflection. For sufficiently low temperatures, the isotherms display multiple values of *v* for the same value of *p*. (b) A low temperature isotherm on an exaggerated scale, illustrating a maximum and a minimum value of *p*. The curve between the maximum and

minimum values, *p*max and *p*min, corresponds to unstable states having negative compressibility, κ*T* < 0.

<span id="page-143-0"></span>![](_page_143_Figure_1.jpeg)

(*v*−*b*)2 *v*3 *RT*1 2*a*

$$\left(\frac{\partial p}{\partial v}\right)_T = -\frac{RT}{(v-b)^2} + \frac{2a}{v^3} = 0.\tag{9.4}$$

*RT*/(2*a*) above the maximum of the curve, there are no r[eal roots. For](#page-143-0) *RTc*/(2*a*) corresponding to the maximum of the curve, there is one real root, and this defines the critical temperature *Tc*. Below the critical temperature, there

> <span id="page-143-2"></span>-∂*p*

<span id="page-143-3"></span>

$$\frac{(v-b)^2}{v^3} = \frac{RT}{2a},\tag{9.5}$$

∂*v T* = − *RT* (*v* − *b*)2 + *v* 3 = 0. (9.4) Eq. (9.4) may be rewritten in the form (*v* [−](#page-143-1) *b*) 2 *v* 3 = *RT* 2*a* , (9.5) which admits a graphic solution depicted in Figure 9–2. For *T* > *Tc* where *Tc* is a critical value of temperature, there are no real roots, so *p* versus *v* is monotonic; for *T* = *Tc*, there

$$T_c = \frac{8a}{27bR},\tag{9.6}$$

value (*vc* − *b*)2/*v* 3 *c* = 4/(27*b*). Therefore

coefficients of powers of *v* gives three simultaneous equations.

$$p_c = \frac{RT_c}{v_c - b} - \frac{a}{v_c^2} = \frac{a}{27b^2}.\tag{9.7}$$

<span id="page-143-1"></span>*pc* = *RTc vc* − *b* − *a v* [2](#page-142-1) *c* = *a* 27*b*2 . (9.7) Returning to Eq. (9.4), we note that the partial derivative (∂*p*/∂*v*)*T* = −1/(*v*κ*T* ) where κ*T* := −(1/*v*)(∂*v*/∂*p*)*T* is the isothermal compressibility. Therefore, the maximum and minimum of *p* as a function of *v* correspond to points of infinite compressibility, and the values of *v* in between to a region of negative compressibility. As discussed in Chapter 7, this region of negative compressibility corresponds to an unstable phase, which is an

artifact of the van der Waals model. 2These results are the same as those obtained by Fermi [1, p. 73] by using the clever method of finding a triple root of *v* for Eq. (9.3) when *p* = *pc* and *T* = *Tc* . Thus Eq. (9.3) can be written *pc* (*v* − *vc*)3 = 0 and comparison of

124 THERMAL PHYSICS

$$v = \frac{a \pm \sqrt{a^2 - 4abRT}}{2RT},\tag{9.8}$$

Another consideration of the van der Walls model is the need to restrict *T* to prevent negative pressures. Setting *p* = 0 in Eq. (9.2) and solving the resulting quadratic equation for *v* yields *v* = *a* ± √ *a*2 − 4*abRT* 2*RT* , (9.8)

which has a double root, corresponding to the minimum of a *p* versus *v* curve just touching zero, whenever *a*2−4*abRT* = 0. This gives *T* = 27*Tc*/32. The restriction *T* > 27*Tc*/32 would

### seem to allow only a narrow range of temperature, but we must recall that we are dealing here with absolute temperatures. For H20, for example, *Tc* = 647 K, so 27*Tc*/32 = 5[46 K,](#page-143-3)

<span id="page-144-1"></span>allowing [a ra](#page-141-2)nge of 100 K. If one restricts the model to temperatures above which *stable* phases have positive pressure, even lower temperatures are possible. 9.1.2 Spinodal Curve

$$p = \frac{a(v - 2b)}{v^3}, \quad \text{spinodal curve}, \tag{9.9}$$

later). A simple equation for this spinodal curve can be obtained by substituting Eq. (9.5) into Eq. (9.2) to eliminate *T* and thus obtain[ing](#page-145-0) *p* = *a*(*v* − 2*b*) *v* 3 , spinodal curve, (9.9)

$$y = \frac{3v - 2}{v^3}, \quad \text{spinodal curve},\tag{9.10}$$

<span id="page-144-0"></span>written *y* = 3ν − 2 ν3 , spinodal curve, ([9.10)](#page-141-2) which is depicted by the dashed curve in Figure 9–3. Note the asymmetry of the plot relative to its maximum. This asymmetry is due to the fact that the liquid always has a

molar volume of the order of *vc*, whereas the vapor has a large volume as well as a large

range of volume, depending on its pressure *p*.

9.2 Thermodynamic Functions We now calculate thermodynamic functions for the van der Waals fluid. Since Eq. (9.2) gives *p* as a function of *v* and *T*, the most natural function to deal with is the Helmholtz

$$\mathbf{df} = -\mathbf{s}\,\mathrm{d}T - p\mathrm{d}v,\tag{9.11}$$

d*f* = −*s* d*T* − *p* d*v*, (9.11)

<span id="page-145-0"></span>![](_page_145_Figure_1.jpeg)

y

ν

Spinodal curve

so

where *f*

at constant volume

$$-p = \left(\frac{\partial f}{\partial v}\right)_T = \frac{a}{v^2} - \frac{RT}{v - b}.\tag{9.12}$$

same as *v* = 2*b*.

<span id="page-145-2"></span><span id="page-145-1"></span>
$$f = -\frac{a}{v} - RT\ln(v/b - 1) + f_0(T),\tag{9.13}$$

− *p* = ∂*v T v* 2 − *RT v* [−](#page-145-1) *b* . (9.12) We can therefore integrate Eq. (9.12) at constant *T* to obtain *f* = −*a v* − *RT* ln(*v*/*b* − 1) + *f*0(*T*), (9.13)

$$\mathbf{s} = -\left(\frac{\partial f}{\partial T}\right)_v = R\ln(v/\mathbf{b} - 1) - f_0'(T),\tag{9.14}$$

logarithm dimensionless. Then by differentiation we can calculate the entropy *s* = −- ∂*f* = *R*ln(*v*/*b* − 1) − *f* 0(*T*), (9.14)

$$\mathbf{c}_{v} = T \left( \frac{\partial \mathbf{s}}{\partial T} \right)_{v} = -T f_{0}^{v\prime}(T) \tag{9.15}$$

*cv* = *T* - ∂*s* = −*Tf*

∂*T*

*f* or drop out entirely when values of *f* are compared at fixed *T* for different *v*.

$$\mathbf{u} = \mathbf{f} + \mathbf{T}\mathbf{s} = -\frac{\mathbf{a}}{v} + f_0(T) - Tf_0'(T). \tag{9.16}$$

*u* = *f* + *Ts* = −*a v* + *f*0(*T*) − *Tf* 0(*T*). (9.16)

Note from Eq. (9.16) that *u* depends on both *v* and *T*, whereas for an ideal gas, *a* = 0 and *u* is a function of only *T*, as we know. In the following, we shall be concerned with the behavior of *f* as a function of *v* at various fixed values of *T*, so the unknown function *f*0(*T*) will either just shift the origin of

*s* and *u*.

126 THERMAL PHYSICS **Example Problem 9.1.** In many treatments of the van der Waals fluid, *cv* is taken to be a constant. In that case, find an explicit form of *f*0(*t*) by integrating Eq. (9.15) and intro-

ducing any necessary constants of integration. Then calculate the corresponding values of

<span id="page-146-1"></span>0 (*T*) = −*cv* /*T* once to obtain *f*

### constant of integration. Then we integrate again to obtain *f*0(*T*) = −*cvT* ln *T* + *cvT* + *c*1*T* − *u*00 where *u*00 is another constant of integration. For convenience we choose the form of *c*1 so that

**Solution 9.1.** We integrate *f*

*f*0(*T*) = −*cvT* ln(*T*/*Tc*)−*s*00*T* +*u*00 where *s*00 is a new constant with the dimensions of entropy. Then *s* = *R* ln(*v*/*b* [−](#page-146-0) 1) + *cv* [ln(*T*/*Tc*) + 1] + *s*00 and *u* = −*a*/*v* + *cvT* + *u*00. 9.2.1 Origin of the Constant *a* As mentioned above, the constant *a* accounts for an attractive force b[etwee](#page-146-1)n vapor

$$
\Delta U_{\rm d} \approx \frac{N^2}{2V} \int_{r_0}^{\infty} \varphi(\mathbf{r}) \, 4\pi r^2 \, \mathbf{d} \mathbf{r}, \tag{9.17}
$$

0(*T*) = −*cv* ln *T* + *c*1 where *c*1 is a

<span id="page-146-0"></span>as sketched in Figure 9–4. For a system of *N* molecules, there are *N* (*N* − 1)/2 ≈ *N* 2/2 distinct pairs, so the attractive energy associated with these pairs is *Ua* ≈ *N* 2 2*V* ∞ *rb* ϕ(*r*) 4π*r*2 d*r*, (9.17) where *V* is the volume and we have taken the integral to infinity provided the potential

cuts off sufficiently rapidly. The mean field approximation is implicit in Eq. (9.17) because

ϕ

negative, resulting in mild attraction.

![](_page_146_Figure_8.jpeg)

**FIGURE 9–4** Sketch of the potential function ϕ(*r*) as a function of *r*. For small *r*, say *r* = *rb*, corresponding roughly to the excluded volume *b*, ϕ(*r*) is large and positive, resulting in strong repulsion, while for larger values of *r*, ϕ(*r*) is

$$
\Delta u_d = -\frac{a}{v} \quad \text{with} \quad a = -\frac{N_\Lambda^2}{2} \int_{r_b}^\infty \varphi(r) \, 4\pi r^2 \, \text{d}r > 0. \tag{9.18}
$$

*Chapter 9* • Two-Phase Equilibrium for a van der Waals Fluid 127

### and the molar energy change *ua* = *Ua*/*N*, Eq. (9.17) can be rewritten in the form ∞

number of moles *N* = *N* /*N*A, where *N*A is Avogadro's number, the molar volume *v* = *V*/*N*,

as the **miscibility gap**, in which the equilibrium state is a composite system consisting

except at the critical point where the two intersect. Outside the miscibility gap, the fluid

*ua* = −*a v* with *a* = −*N* 2 A 2 *rb* ϕ(*r*) 4π*r*2 d*r* > 0. (9.18) Equation (9.18) has the same form as the first term in Eq. (9.13). Some values of *a* and *b* for a variety of van der Walls fluids are given by Callen [2, p. 77]. 9.3 Phase Equilibrium and Miscibility Gap Armed with a knowledge of *f* , we shall now use several methods to examine the conditions for phase equilibrium, particularly the representation in the *v*, *p* plane of the coexistence curve (in the *T*, *p* plane) for these phases. Coexistence in the *v*, *p* plane is represented by two regions, one in which the equilibrium state is a single phase and the other, known

### of two phases. The spinodal curve derived above lies entirely within the miscibility gap

-

Eq. (9.20) becomes

is stable; between the miscibility gap and the spinodal, the fluid is metastable; and within the spinodal, it is unstable. We shall use several methods to illustrate these points.

<span id="page-147-1"></span>9.3.1 Common Tangent Construction The **common tangent construction** is a useful method that provides a graphical solution to phase equilibrium problems. We develop it in general, and then apply it specifically to the van der Waals fluid. We consider a composite system at uniform temperature *T* and consisting of two

$$F = N_1 f(T, v_1) + N_2 f(T, v_2). \tag{9.19}$$

Helmholtz free energy of the system is *F* = *N*1*f* (*T*, *v*1) + *N*2*f* (*T*, *v*2). (9.19) If these phases are in equilibrium, *F* must be a minimum with respect to changes of the

*internal extensive* variables *N*1, *V*1, *N*2, *V*2 *subject to the constraints N*1 + *N*2 = constant,

*T*

$$N_1 \left(\frac{\partial f(T, v1)}{\partial v1}\right)_T \left(\frac{\partial v1}{\partial V1}\right)_{N_1} \mathrm{d}V_1 + N_2 \left(\frac{\partial f(T, v2)}{\partial v2}\right)_T \left(\frac{\partial v2}{\partial V2}\right)_{N_2} \mathrm{d}V_2 = \mathbf{0}.\tag{9.20}$$

*N*1 -∂*v*1 *T* ∂*V*1 *N*1 d*V*1 + *N*2 ∂*v*2 *T* ∂*V*2 *N*2 d*V*2 = 0. (9.20) Since (∂*v*1/∂*V*1)*N*1 = 1/*N*1, (∂*v*2/∂*V*2)*N*2 = 1/*N*2, and d*V*1 = −d*V*2 from a constraint,

*T*

<span id="page-147-0"></span>
$$\left(\frac{\partial f(T, v_1)}{\partial v_1}\right)_T = \left(\frac{\partial f(T, v_2)}{\partial v_2}\right)_T.\tag{9.21}$$

<span id="page-148-3"></span><span id="page-148-0"></span>
$$p(T, v_1) = p(T, v_2). \tag{9.22}$$

128 THERMAL PHYSICS

*f* (*T*, *v*1) + *N*1

potentials, that is,

-

∂*v*1

$$\left[f(T, v1) + N_1 \left(\frac{\partial f(T, v1)}{\partial v_1}\right)_T \left(\frac{\partial v_1}{\partial N_1}\right)_{V_1}\right] \text{dN}_1 + \left[f(T, v2) + N_2 \left(\frac{\partial f(T, v_2)}{\partial v_2}\right)_T \left(\frac{\partial v_2}{\partial N_2}\right)_{V_2}\right] \text{dN}_2 = \mathbf{0}. \tag{9.23}$$

This result is not to be unexpected! Next, we hold *V*1 and *V*2 constant and set the differential *dF* = 0 to o[btain](#page-148-1)

<span id="page-148-1"></span>
$$f(T, v_1) - \left(\frac{\partial f(T, v_1)}{\partial v_1}\right)_T v_1 = f(T, v_2) - \left(\frac{\partial f(T, v_2)}{\partial v_2}\right)_T v_2. \tag{9.24}$$

(9.23) Since (∂*v*1/∂*N*1)*V*1 [=](#page-148-1) [−](#page-148-1)*V*1/*N*2 1 , (∂*v*2/∂*N*2)*V*2 = −*V*2/*N*2 2 , and d*N*1 = −d*N*2 from a constraint, Eq. (9.23) becomes

$$f(T, v) - \left(\frac{\partial f(T, v)}{\partial v}\right)_T v = f(T, v) + p(T, v)v =: \mu(T, v). \tag{9.25}$$

We identify the members on the left-hand and right-hand sides of Eq. (9.24) as chemical

-

∂*f* (*T*, *v*)

<span id="page-148-2"></span>
$$
\mu(T, v_1) = \mu(T, v_2). \tag{9.26}
$$

*f* (*T*, *v*) − ∂*v T v* = *f* (*T*, *v*) + *p*(*T*, *v*)*v* =: μ(*T*, *v*)[.](#page-147-0) (9.25)

This enables Eq. (9.24) to be rewritten μ(*T*, *v*1) = μ(*T*, *v*2). [(](#page-148-1)9.26) From general co[nside](#page-147-0)rations, Eq. (9.26) is also not to be [unexp](#page-148-1)ected! We seem to have labored to obtain what a[moun](#page-147-0)ts to [Eqs.](#page-148-1) (9.22) and (9.26), which we might have just written do[wn from ge](#page-149-0)neral considerations. Nevertheless, the chemical potential μ, which for a mono[component](#page-149-0) system is equal to the Gibbs free energy per mole, *g*, is ordinarily regarded as a function of *T* and *p*, not *T* and *v*. The variables *T* and *v* are the natural variables of *f* , not μ. We therefore return to Eqs. (9.21) and (9.24) and establish the following geometrical interpretation: According to Eq. (9.21), a graph of *f* versus *v* has the same slope at two values of *v*, namely at *v*1 and *v*2. There can be many pairs of *v*1 and *v*2 for which this is true. But either the left or the right member of Eq. (9.24) can be interpreted as the *intercept*, on the *f* axis (*v* = 0), of a tangent to a graph of *f* versus *v* at *v*1 and *v*2. So Eq. (9.21) requires parallel tangents and Eq. (9.24) requires equal intercepts. It

follows that the simultaneous solution to Eqs. (9.21) and (9.24) requires a *common tangent* at *v*1 and *v*2, as illustrated in Figure 9–5a. Another important feature of Figure 9–5a is noteworthy. A composite system consisting of the two phases having molar volumes *v*1 and *v*2 at its common tangent has a total molar free energy that lies along the tangent line joining the points of tangency. To see this, consider first a homogeneous system consisting of *N* moles and having molar volume *v* ∗.

For our composite system to have the same volume, we would need *N*1 + *N*2 = *N* and

<span id="page-149-0"></span>![](_page_149_Figure_1.jpeg)

f v∗ v2 v1 (a) f v*S*1 v*S*2 v2 v1 D (b) **FIGURE 9–5** (a) Common tangent construction and (b) chord construction. The curves represent the Helmholtz free energy per mole, *f* = *F*/*N*, versus the molar volume *v*. For the common tange[nt con](#page-147-1)struction, the dashed line is tangent to the curve at *v*1 and *v*2. Its slope is the negative of the common pressure and its intercept is μ, the common value of the chemical potential. The free energy per mole of a composite state having total molar volume *v* ∗ lies

global stability of a homogeneous phase. If the chord lies above the curve, as for the chord *AB*, the homogeneous phases along the curve *AB* are stable with respect to a composite, whereas if it lies below the curve, as for the chord *CD*, the homogeneous phases along the curve *CD* are unstable. *vS*1 and *vS*2 mark the spinodal points *S*1 and *S*2 at which ∂2*f*/∂*v* 2 = 0.

along the tangent line at *v* ∗ and is lower than the free energy of a single phase having *v* ∗. Hence, the composite system is more stable than a homogeneous system. The chord construction can be used to investigate the local or

$$F/N = \left[ (v_2 - v^*)/(v_2 - v_1) \right] f(T, v_1) + \left[ (v^* - v_1)/(v_2 - v_1) \right] f(T, v_2) \tag{9.27}$$

$$= f(T, v_1) + \left[ (v^* - v_1)/(v_2 - v_1) \right] \left[ f(T, v_2) - f(T, v_1) \right], \quad \text{composite system.}$$

which is known as the **lever rule**. Inserting these values in Eq. (9.19) gives *F*/*N* = [(*v*2 − *v* ∗)/(*v*2 − *v*1)]*f*(*T*, *v*1) + [(*v* ∗ [−](#page-149-1) *v*1)/(*v*2 − *v*1)]*f* (*T*, *v*2) (9.27) = *f* (*T*, *v*1) + [(*v* ∗ − *v*1)/(*v*2 − *v*1)][*f* (*T*, *v*2) − *f* (*T*, *v*1)], [com](#page-149-1)posite system. Comparing this value with that for the homogeneous system having molar volume *v* ∗, we see that the free energy of the composite system is *lower* for all *v* ∗ between *v*1 and *v*2. T[hus, for thes](#page-149-0)e values of *v* ∗, the *composite system is the equilibrium state.* Put another way,

### given the opportunity, the homogeneous system will decompose to form the equilibrium composite system consisting of two phases that are in equilibrium with each other.

<span id="page-149-1"></span>μ

9.3.2 Chord Construction We can also use the reasoning that led to Eq. (9.27) to establish another valuable construction which we shall call the **chord construction**. Indeed, Eq. (9.27) is still valid if *v*1 and *v*2 correspond to any two points along the curve, provided only that *v*1 < *v*2. We can therefore apply it to various points along the curve, such as the pair *AB* or the pair *CD*, as illustrated in Figure 9–5b. For chord *AB*, the free energy of a composite lies along the chord, which is above the curve *AB*, so a homogeneous phase along the curve *AB* is stable with respect to a composite consisting of its end points. But for *CD*, the free energy of a composite lies on

a chord of *f* that is below *f* , so the single phase is unstable with respect to that particular

130 THERMAL PHYSICS

composite. Any homogeneous state that lies above the chord corresponding to the common tangent is unstable, but some of those states are locally stable. Local stability or instability requires the chord construction to be applied to neighboring points. The spinodal points where −∂*p*/∂*v* = ∂2*f* /∂*v* 2 = 0 separate locally stable states from locally unstable states. States that are locally stable but globally unstable are said to be **metastable**.

- 9.3.3 Summary for *f*(*v*) Curves We can summarize this situation as follows: With respect to a curve of *f* versus *v* for a
- monocomponent system, portions of the curve that are convex (as viewed from below) correspond to locally stable states; portions of the curve that are concave (as viewed from below) correspond to locally unstable states. All states that lie above the common tangent
- between *v*1 and *v*2 are ultimately unstable. Thus there are three kinds of states: **unstable** locally unstable (locally concave) and also above the common tangent be-

tween *v*1 and *v*2; therefore, locally unstable and globally unstable; **metastable** locally stable (locally convex) but above the common tangent between *v*1 and *v*2; therefore, locally stable but globally unstable; **stable** locally stable (locally convex) but outside the common tangent region, i.e., *v* ≤ *v*1 or *v* ≥ *v*2; therefore, locally stable and globally stable. The concave and convex regions are separated by points, *S*1 and *S*2, at which the second partial derivative (∂2*f* /∂*v* 2)*T* = 0. But since (∂2*f* /∂*v* 2)*T* = −(∂*p*/∂*v*)*T* , these points also correspond to maxima and minima of *p*, which [mea](#page-147-0)ns th[at](#page-148-1) [the](#page-148-1)y correspond to the spinodal curve in the *v*, *p* plane. Thus the spinodal curve separates the metastable region from the unstable region. On the other hand, the locus of the points of common tangency in the *v*, *p* plane separate the stable region from the metastable region; the region inside

### this curve is called the **miscibility gap** because within it a composite *mixture* of phases located at the ends of the common tangent, rather than a homogeneous phase, is globally

<span id="page-150-0"></span>*RT*

<span id="page-150-1"></span>stable.

= *RT*

$$\frac{RT}{v_1 - b} - \frac{a}{v_1^2} = \frac{RT}{v_2 - b} - \frac{a}{v_2^2} \tag{9.28}$$

(9.28)

and

$$-\frac{2a}{v_1} - RT\ln(v_1/b - 1) + \frac{RTv_1}{v_1 - b} = -\frac{2a}{v_2} - RT\ln(v_2/b - 1) + \frac{RTv_2}{v_2 - b}.\tag{9.29}$$

− 2*a v*1 − *RT* ln(*v*1/*b* − 1) + *RTv*1 *v*1 − *b* = −2*a v*2 − *RT* ln(*v*2/*b* − 1) + *RTv*2 *v*2 − *b* . (9.29) For a given value of *T*, the simultaneous equations (9.28) and (9.29) can be solved for *v*1 and *v*2 and then *p* can be evaluated by using Eq. (9.2). In principle, such a solution determines the shape of the miscibility gap, but these equations would have to be solved numerically because they are not tractable analytically. A graphical representation of their

![](_page_151_Figure_1.jpeg)

-1.8 2 4 6 8 10 12 14 -1.8 -1.6

-2.2

(a) -2.4 (b) **FIGURE 9–6** Graphical representation of simultaneous solution of Eqs. (9.28) and (9.29). (a) *T*/*Tc* = 27/32, *v*/*vc* = 0.548 for the liquid and 3.241 for the vapor. The pressure is *p*/*pc* = 0.183. (b) *T*/*Tc* = 20/32, *v*/*vc* = 0.440 for the liquid and 13.585 for the vapor. The pressure is *p*/*pc* = 0.0411.

### solution is presented in Figure 9–6. Since the liquid and vapor have quite different molar volumes, the curve of *f* becomes quite flat at large values of *v* and such a solution is not

to construct plots of such functions with ease.

<span id="page-151-0"></span>v/v*c*

-2.2

1 2 3 4

very practi[cal.](#page-141-2) We t[herefo](#page-145-2)re turn to other methods [to de](#page-151-0)monstrate the nature of these solutions. 9.4 Gibbs Free Energy

$$\mathbf{g} = -\frac{2a}{v} - RT\ln(v/b - 1) + \frac{vRT}{v - b} + f\mathbf{\hat{n}}(T),\tag{9.30}$$

v/v*c*

equal to the chemical potential μ for this monocompo[nent](#page-151-0) syste[m. I](#page-141-2)t can be written in the form *g* = −2*a v* − *RT* ln(*v*/*b* − 1) + *vRT v* − *b* + *f*0(*T*), (9.30) where Eqs. (9.2) and (9.13) have been used. Equation (9.30) gives *g* [as a function](#page-152-0) of *T* and *v*, but this is not very useful information because the equilibrium criterion for *g* is that it be a minimum for given values of *T* and *p*. Equation (9.2) for *p* could be solved for *v*(*p*). But since *v* is a root of the cubic Eq. (9.3), one would have to write analytical expressions for its three roots by using the cubic formula and then substitute into Eq. (9.30). This would result in unwieldy expressions for *g* whose functional behavior would not be easy to analyze. A much more useful procedure is to regard Eqs. (9.30) and (9.2) to be a *parametric* representation3 of *g*(*T*, *p*), with *v* as a parameter. This can be done by assigning a fixed value to *T* and then allowing *v* to range through a set of numerical values. For each numerical value of *v*, one can calculate a pair of numerical values of *g* − *f*0(*T*) and *p*,

and ultimately construct a graph of *g* versus *p*, such as shown in Figure 9–7a. Note that 3A parametric representation is a very powerful way of representing a function, especially if it is multiple valued. A simple example would be the ellipse *x*2/*a*2 + *y*2/*b*2 = 1 which can be represented parametrically by *x* = *a* cos ψ and *y* = *b* sin ψ, where ψ is a parameter that ranges from 0 to 2π as the ellipse is traversed once in the counterclockwise direction. Powerful software packages, such as ParametricPlot of Mathematica R , can be used

g

Eq. (9.30).

<span id="page-152-0"></span>![](_page_152_Figure_1.jpeg)

p0 p A B E F (a) p0 v F E D C B (b)

**FIGURE 9–7** (a) Isotherms in the *p*, *g* plane for two temperatures below *Tc*, one at *Tc* and one above *Tc*. The labeled curve is for th[e](#page-152-1) [l](#page-152-1)owest temperature, *T*/*Tc* = 27/32. (b) Isotherms in the *v*, *p* plane for temperatures corresponding to those in (a). The isotherm with labeled points is for *T*/*Tc* = 27/32 . The dashed curve is the spinodal. Point *A* is

outside the figure to the right on the labeled isotherm in (b). The segment *AB* is stable vapor, *BC* is metastable vapor, *CDE* is unstable fluid, *EF* is metastable liquid, and *FG* is stable liquid. The pressure *p*0 intersects the *T*/*Tc* = 27/32 isotherm at points *F* and *B*, corresponding to the miscibility gap, and also at point *D* on the unstable branch. Points *C* and *E* lie along the spinodal curve. there are three values of *g* for a range of *p* [between the maximum and minimum values](#page-152-0) of *p* that correspond to an isotherm in the *p*, *v* plane. These triple roots end at cusps of *g* that correspond to points on the spinodal curve. Points along the curve *EDC* correspond

to unstable4 fluid states inside the spinodal. Points along *BC* or *EF* represent metastable states; they are outside the spinodal region but inside the miscibility gap (gap separating stable phases, to be defined more precisely in the following section). States along *AB* and *FG* [are sta](#page-151-0)ble and lie outside the boundary of the miscibility gap. At constant *T*, d*g* = *v* d*p*, and since *v* > 0, the isotherms of *g* are monotonically increasing functions of *p*. But for *T* < *Tc*, *v* is a multiple valued function of *p*, so the

<span id="page-152-1"></span>
$$\mathbf{g}(\mathbf{p},T) = RT\ln(\mathbf{p}/\mathbf{p}_0) + \mathbf{g}(\mathbf{p}_0,T), \quad \text{ideal gas},\tag{9.31}$$

resemble those for an ideal gas, *g*(*p*, *T*) = *RT* ln(*p*/*p*0) + *g*(*p*0, *T*), ideal gas, (9.31) where *p*0 is some reference pressure. For the van der Waals fluid at any fixed *T*, one

could integrate d*g* = *v* d*p* at constant *T* by parts, which would lead to the already-known

state but a concave function of *p* for an unstable state. Specifically, ∂2*f* /∂*v* 2 = −1/∂2*g*/∂*p*2.

<sup>4</sup>We can draw this conclusion based on the fact that *EDC* in Figure 9–7a corresponds to the convex region of a curve of *f* as a function of *v* for fixed *T*. Note, however, that the curves *ABC* and *EFG* are concave. This is because *p* is an intensive variable. By the methods of Chapter 7, we know that *g* is a convex function of *p* for an unstable

### 9.4.1 Maxwell Construction

A miscibility gap is a two-phase region that separates stable phases. For the van der Walls fluid, this gap separates stable liquid from stable vapor. A point within that miscibility gap does not represent a homogeneous phase but instead a mixture of liquid and vapor in proportions given by the lever rule discussed immediately above Eq. [(9.27)](#page-149-1). A simple way to determine the miscibility gap graphically is the equal area construction of Maxwell. According to this construction, the horizontal line *p* = *p*0 that makes equal areas with an isotherm in the *v*, *p* plane intersects that isotherm at the boundaries, *v*1 and *v*2, of the miscibility gap, as illustrated in [Figure 9–8.](#page-153-0) To prove this construction, we rewrite Eq. [(9.13)](#page-145-2) in the form

$$f(v, T) = -\int_{v0}^{v} p(T, v') \, \mathbf{d}v' + f(v_0, T), \tag{9.32}$$

<span id="page-153-0"></span>where *v*0 is some reference molar volume and the function *p*(*T*, *v*) is given by Eq. [(9.2)](#page-141-2). For a *fixed* pressure *p*0, equality of the molar Gibbs free energies at two different volumes, *v*1 and *v*2, that lie on the miscibility gap, gives

![](_page_153_Figure_5.jpeg)

**FIGURE 9–8** Maxwell's equal area construction for determining the miscibility gap. The isotherms from top to bottom are *T*/*Tc* = 32/30, 1, 30/32, 28/32. The dashed curve is the spinodal and the dotted curve is the miscibility gap, computed numerically as discussed in the example problem. The dashed horizontal line at *p*0/*pc* illustrates the equal-area construction for the lowest isotherm and the shorter horizontal line illustrates the equal area construction for the next lowest isotherm.

<span id="page-154-0"></span>
$$-\int_{v_0}^{v_1} p(T, v) \, \mathrm{d}v + f(v_0, T) + p_0 v_1 = -\int_{v_0}^{v_2} p(T, v) \, \mathrm{d}v + f(v_0, T) + p_0 v_2. \tag{9.33}$$

After canceling *f* (*v*0, *T*), Eq. [(9.33)](#page-154-0) can be rewritten in the form

<span id="page-154-1"></span>
$$\int_{v_1}^{v_2} p(T, v) \, \mathbf{d}v - p_0(v_2 - v_1) = \mathbf{0},\tag{9.34}$$

where we shall take *v*2 > *v*1 to correspond to [Figure 9–8.](#page-153-0) But *p*0(*v*1−*v*2) = *v*2 *v*1 *p*0 d*v* because *p*0 is a constant, so Eq. [(9.34)](#page-154-1) becomes

<span id="page-154-2"></span>
$$\int_{v_1}^{v_2} \left[ p(T, v) - p_0 \right] \mathbf{d}v = \mathbf{0}.\tag{9.35}$$

In Eq. [(9.35)](#page-154-2), regions of integration where *p*(*T*, *v*) > *p*0 give positive contributions whereas regions where *p*(*T*, *v*) < *p*0 give negative contributions. If *p*0 is chosen to satisfy Eq. [(9.35)](#page-154-2), the areas between the *p*(*T*, *v*) curve and *p*0 will be equal. This proves the Maxwell construction which holds for the van der Waals fluid.

However, the **Maxwell construction** holds generally for any fluid for which the isotherms in the *v*, *p* plane have the qualitative features of the van der Waals fluid. This can be seen in a simple way from Fermi's observation [1, p. 71] that the reversible work *W* done by the system in a cyclic reversible isothermal process is zero. That observation follows from the fact that Eq. (3.28) (which is the same as Eq. (3.33) for a reversible cycle) holds for such a process and *T* can be taken outside the integral to give δ*Q* = 0, which requires *Q* = 0. But for a cyclic process, *U* = 0, so by the first law, *W* = 0. Thus

$$
\oint \mathbf{p} \, \mathbf{d}v = \mathcal{W} = \mathbf{0}.\tag{9.36}
$$

One can therefore integrate from one side of the miscibility gap to the other side along the curve *p*(*v*, *T*) and then return to the first side along the line *p* = *p*0, thus proving the Maxwell construction generally.

**Example Problem 9.2.** Although the Maxwell construction allows one to visualize the miscibility gap, it does not provide an accurate quantitative determination. Solve simultaneously Eqs. [(9.28)](#page-150-0) and [(9.29)](#page-150-1) to determine the miscibility gap and discuss the relationship of pressure to temperature on the miscibility gap.

**Solution 9.2.** This can only be done numerically because of the transcendental form of Eq. [(9.29)](#page-150-1). Rather than choosing specific values of the constants *a* and *b*, we introduce the dimensionless variables *t* = *T*/*Tc*, ν1 = *v*1/*vc*, and ν2 = *v*2/*vc* and the corresponding dimensionless pressure *y* = *p*/*pc*. The equivalent dimensionless equations are

$$\frac{8t}{3\nu_1 - 1} - \frac{3}{\nu_1^2} = \frac{8t}{3\nu_2 - 1} - \frac{3}{\nu_2^2} = \text{y} \tag{9.37}$$

and

$$1 - \frac{6}{\nu_1} - \frac{8t}{3} \ln(3\nu_1 - 1) + \frac{8t\nu_1}{3\nu_1 - 1} = -\frac{6}{\nu_2} - \frac{8t}{3} \ln(3\nu_2 - 1) + \frac{8t\nu_2}{3\nu_2 - 1}.\tag{9.38}$$

Forgetting about *y* for the moment, we specify a value of *t* which leads to two simultaneous equations in ν1 and ν2 that can be solved numerically, for example by using a procedure such as FindRoot in Mathematica R . To do this, one must specify guesses for ν1 and ν2 which serve as a starting point for an iterative procedure; the Maxwell construction is useful in this respect. Then one can compute the value of *y* for that temperature and repeat the whole process for a number of temperatures. The result is the dotted curve in [Figure 9–8.](#page-153-0) Along the miscibility gap, *T* is an increasing function of *p* so there will also be a miscibility gap in the *v*, *T* plane where the corresponding spinodal curve will be given by Eq. [(9.5)](#page-143-3), as illustrated in [Figure 9–2.](#page-143-0)

This page intentionally left blank

# 10

# Binary Solutions

One commonly thinks of solutions as liquids, such as salt or sugar dissolved in water. In thermodynamics, we regard a solution more generally as being a homogeneous phase consisting of more than one chemical species, intermixed on an atomic scale, and thus mutually soluble. Solutions can be solids, liquids, or gases, and can contain any number of chemical components. Binary solutions consist of two chemical components, *A* and *B*, which for simplicity we will refer to as atoms, even though they may actually be molecules that do not dissociate. In a solution, chemical components can interact but cannot form new molecules. A solution should not be confused with a mixture of more than one phase.

In this chapter we consider binary solutions and their phase equilibria. A given amount of a solution of chemical components *A* and *B* can characterized by a set of state variables consisting of the temperature *T*, the pressure *p* and the composition that can be expressed by one of the mole fractions, say *XB*. Although vapor phases could be considered, we shall confine ourselves to the important case of condensed phases (solids and liquids) for which the thermodynamic functions, in particular the Gibbs free energy *g* per mole, are insensitive to the pressure except for very large applied pressures of many atmospheres. This is true because ∂*g*/∂*p* = *v*, the molar volume, which is quite small relative to that of a gaseous phase. Therefore, the problem reduces to one in which *g* effectively depends on only two important variables, *T* and *XB*, similar to the case of monocomponent systems for which the molar Helmholtz free energy *f* depends on only the two variables *T* and *v*. As a result, we will be able to analyze two-phase equilibria in terms of a common tangent construction and a chord construction, analogous to those for monocomponent systems. We will illustrate our treatment with simple models, namely ideal solutions and so-called regular solutions, recognizing that the subject of binary phase diagrams for real materials is huge and quite complex. The interested reader is referred to the materials science literature for a thorough analysis of real systems.

### 10.1 Thermodynamics of Binary Solutions

We consider a binary solution made up of chemical components *A* and *B*. The internal energy *U* of such a solution is a function of the entropy *S*, the volume *V*, and the mole numbers *NA* and *NB*. Its differential is

<span id="page-157-0"></span>
$$\mathbf{d}U = T\,\mathbf{dS} - p\,\mathbf{d}V + \mu_A\,\mathbf{dN}_A + \mu_B\,\mathbf{dN}_B,\tag{10.1}$$

where *T* is the temperature, *p* is the pressure, μ*A* is the chemical potential of component *A* and μ*B* is the chemical potential of component *B*. *U* = *U*˜ (*S*, *V*, *NA*, *NB*) is a fundamental equation[,1](#page-158-0) so it contains complete information about the system. The Euler equation for *U* is

$$\mathbf{U} = \mathbf{T}\mathbf{S} - \mathbf{p}V + \mu_A \mathbf{N}_A + \mu_B \mathbf{N}_B \tag{10.2}$$

and the Gibbs-Duhem equation is

<span id="page-158-1"></span>
$$\mathbf{0} = \mathbf{S} \, \mathbf{d}T - V \, \mathbf{d}p + N_{\text{A}} \, \mathbf{d}\mu_{\text{A}} + N_{\text{B}} \, \mathbf{d}\mu_{\text{B}}.\tag{10.3}$$

There are four equations of state, which give *T*, *p*, μ*A*, and μ*B* as functions of *S*, *V*, *NA*, and *NB*. Thus

$$T = \hat{T}(\mathcal{S}, V, N_A, N_B); \quad p = \tilde{p}(\mathcal{S}, V, N_A, N_B); \tag{10.4}$$

$$\mu_A = \tilde{\mu}_A(\mathcal{S}, V, N_A, N_B); \quad \mu_B = \tilde{\mu}_B(\mathcal{S}, V, N_A, N_B).$$

Note, however, that *T*, *p*, μ*A*, and μ*B* are intensive variables so they can only depend on the ratios of the extensive variables *S*, *V*, *NA*, and *NB*, of which only three are independent.

A convenient way to make the reduction to three independent intensive variables is to introduce the per mole quantities *u* := *U*/*N*, *s* := *S*/*N*, *v* := *V*/*N*, *XA* = *NA*/*N*, and *XB* = *NB*/*N*. Since the mole fractions satisfy *XA* + *XB* = 1, we only need to keep one of them, so we retain the three independent variables *s*, *v*, and *XB*. Then Eqs. [(10.1)](#page-157-0)–[(10.3)](#page-158-1) become

$$\mathbf{d}\mu = T\,\mathrm{ds} - p\,\mathrm{d}v + (\mu_B - \mu_A)\,\mathrm{d}X_B;\tag{10.5}$$

<span id="page-158-2"></span>
$$
\mu = \text{Ts} - \text{pv} + \mu_A (1 - X_B) + \mu_B X_B;\tag{10.6}
$$

$$\mathbf{0} = \mathbf{s} \, \mathbf{d}T - v \, \mathbf{d}p + (1 - X_B) \, \mathbf{d}\mu_A + X_B \, \mathbf{d}\mu_B. \tag{10.7}$$

The equations of state can be written

$$T = \hat{T}(\mathbf{s}, v, X_B); \quad p = \tilde{p}(\mathbf{s}, v, X_B); \tag{10.8}$$

$$\mu_A = \tilde{\mu}_A(\mathbf{s}, v, X_B); \quad \mu_B = \tilde{\mu}_B(\mathbf{s}, v, X_B).$$

Since *s*, *v*, and *XB* are independent, it is possible to take partial derivatives with respect to one of them while holding the other two constant. For example, from Eq. [(10.5)](#page-158-2) we obtain[2](#page-158-3)

<span id="page-158-6"></span><span id="page-158-5"></span><span id="page-158-4"></span>
$$
\left(\frac{\partial \mu}{\partial X_B}\right)_{\mathcal{S}, \upsilon} = (\mu_B - \mu_A). \tag{10.9}
$$

To obtain μ*A* and μ*B* separately, we would have to solve Eq. [(10.9)](#page-158-4) simultaneously with Eq. [(10.6)](#page-158-5). The result is

$$
\mu_A = \mathbf{u} - \mathbf{T}\mathbf{s} + pv - X_{\mathcal{B}} \left(\frac{\partial \mathbf{u}}{\partial X_{\mathcal{B}}}\right)_{\mathbf{s},v}; \quad \mu_B = \mathbf{u} - \mathbf{T}\mathbf{s} + pv + (1 - X_{\mathcal{B}}) \left(\frac{\partial \mathbf{u}}{\partial X_{\mathcal{B}}}\right)_{\mathbf{s},v}. \tag{10.10}
$$

<span id="page-158-0"></span><sup>1</sup>Here, we use the more elaborate functional notation *U* = *U*˜ (*S*, *V*, *NA*, *NB*) to distinguish the value *U* from its functional form *U*˜ . In cases where there is no confusion between these quantities, we use the abbreviated

<span id="page-158-3"></span>functional notation *U* = *U*(*S*, *V*, *NA*, *NB*). 2Note well that *XA* is *not* held constant in this differentiation.

<span id="page-159-2"></span><span id="page-159-1"></span>*Chapter 10* • Binary Solutions 139

<span id="page-159-0"></span>
$$\mathbf{dg} = -\mathbf{s}\,\mathrm{d}T + v\,\mathrm{d}p + (\mu_B - \mu_A)\,\mathrm{d}\mathbf{X}_B;\tag{10.11}$$

$$\mathbf{g} = \mu_A (1 - X_\mathbf{B}) + \mu_B X_\mathbf{B};\tag{10.12}$$

$$\mathbf{0} = \mathbf{s} \, \mathbf{d}T - v \, \mathbf{d}p + (1 - X\mathbf{s}) \, \mathbf{d}\mu_A + X\mathbf{s} \, \mathbf{d}\mu_B,\tag{10.13}$$

energy per mole *g* := *G*/*N* = *u* − *Ts* + *pv*. This is because complete information about the system is con[tained](#page-159-0) in the function *G* = *[G](#page-158-6)*˜ (*T*, *p*, *NA*, *NB*) [or, for](#page-159-1) one [mole, in](#page-159-0) the function

hyperplanes. See Section 5.6.1 for more detail.

$$\begin{aligned} \mathfrak{s} &= \tilde{\mathfrak{s}}(T, p, X_B); \quad v = \tilde{v}(T, p, X_B); \\ \mu_A &= \tilde{\mu}_A(T, p, X_B); \quad \mu_B = \tilde{\mu}_B(T, p, X_B). \end{aligned} \tag{10.14}$$

*g* = μ*A*(1 − *XB*) + μ*BXB*; (10.12) 0 = *s* d*T* − *v* d*p* + (1 − *XB*) dμ*A* + *XB* dμ*B*, (10.13)

and the equations of [state](#page-158-4) *s* = *s*˜(*T*, *p*, *XB*); *v* = ˜*v*(*T*, *p*, *XB*); (10.14)

$$\left(\frac{\partial \mathbf{g}}{\partial X_{\mathcal{B}}}\right)_{T,p} = (\mu_{\mathcal{B}} - \mu_{\mathcal{A}}),\tag{10.15}$$

3

dent variable set is *T*, *p*, and *XB* rather than *s*, *v*, and *XB* in Eqs. (10.5) and (10.6). By partial differentiation of Eq. (10.11) we obtain

$$
\mu_A = \mathbf{g} - X_B \left(\frac{\partial \mathbf{g}}{\partial X_B}\right)_{T, p}; \quad \mu_B = \mathbf{g} + (1 - X_B) \left(\frac{\partial \mathbf{g}}{\partial X_B}\right)_{T, p}. \tag{10.16}
$$

### μ*A* = *g* − *XB* - ∂*g* ; μ*B* = *g* + (1 − *XB*) - ∂*g* . (10.16)

constant in the differentiation. Simultaneous solution of Eqs. (10.15) and (10.12) gives

intercepts of the tangent an appreciation for μ*A* and μ*B* as a function of the value of *XB* at

the point of tangency. This procedure is known as **the method of intercepts**.

∂*XB T*,*p* ∂*XB T*,*p* 10.1.2 Intercept and Common Tangent Constructions Unlike Eq. (10.10), Eq. (10.16) contains the same function *g* and its partial derivative with respect to *XB*, so these equations can be interpreted geometrically. This is illustrated in Figure 10–1a from which it can be seen that μ*A* is just the intercept at *XB* = 0 of the tangent to a graph of *g* versus *XB* at constant *T* and *p*. Similarly, μ*B* is the intercept at *XB* = 1 of that same tangent. As the point of tangency slides along the curve, one obtains from the

<sup>3</sup>This famous construction, known as the method of intercepts, works for the molar value *y* := *Y*/*N* of any extensive function *Y* = *Y*˜ (*T*, *p*, *NA*, *NB*). The partial derivatives *Y*¯*A* := (∂*Y*/∂*NA*)*T*,*p*,*NB* and *Y*¯*B* := (∂*Y*/∂*NB*)*T*,*p*,*NA* , which are analogous to the chemical potentials, are known as partial molar values of *Y*. *Y*¯*A* and *Y*¯*B* are then given by the intercepts to the tangent of a graph of *y* as a function of *XB* for fixed *T* and *p*. In fact, the method can be generalized to multicomponent systems for which the relevant intercepts are those of tangent planes or

g

(a)

*B* . The region *X*α

*B* < *XB* < *X*β

is stable; it is a two-phase region where a mixture of α with composition *X*α

*XB* > *X*β

<span id="page-160-0"></span>![](_page_160_Figure_1.jpeg)

0.0 1 XB XB .0 ∗ [μ](#page-160-0)A μB 0.0 XB 1.0 β XB α μA α

**FIGURE 10–1** (a) Sketch of *g*(*T*, *p*, *XB*), in arbitrary units, as a function of *XB* for fixed *T* and *p* illustrating the method of intercepts. The *XB* = 0 and *XB* = 1 intercepts of the tangent give the values of μ*A* and μ*B*, respectively, at the point of tangency *X*∗ *B*. (b) Common tangent construction. The chemical potentials of *each* component are equal for α and β phases having compositions *X*α *B* and *X*β *B* at points of common tangency. The α phase is stable for *XB* < *X*α *B* and the β phase is stable for *XB* > *X*β *B* . The region *X*α *B* < *XB* < *X*β

(b)

$$
\mu_A(T, \mathfrak{p}, X_{\mathcal{B}}^{\mathfrak{a}}) = \mu_A(T, \mathfrak{p}, X_{\mathcal{B}}^{\mathcal{B}}); \quad \mu_B(T, \mathfrak{p}, X_{\mathcal{B}}^{\mathfrak{a}}) = \mu_B(T, \mathfrak{p}, X_{\mathcal{B}}^{\mathcal{B}}), \quad \text{common tangent}, \tag{10.17}
$$

XB

*B* is a miscibility gap where no homogeneous phase

*B* and β with

From Figure 10–1b, we note that the graph of *g* versus *XB* is not convex, as will be the case when an unstable phase and more than one stable phase are involved.4 In such a case, the common tangent intersects the curve at values of *XB* that satisfy μ*A*(*T*, *p*, *X*α *B* ) = μ*A*(*T*, *p*, *X*β *B* ); μ*B*(*T*, *p*, *X*α *B* ) = μ*B*(*T*, *p*, *X*β *B* ), common tangent, (10.17) where *X*α *B* and *X*β *B* are the values of *XB* at which common tangency occurs. This **common tangent** construction solves the equilibrium prob[lem for pha](#page-160-0)ses of a binary system. It is the analog of the common tangent construction for the molar Helmholtz free energy, *f* , treated in Chapter 9. The α phase is stable for *XB* < *X*α *B* and the β phase5 is stable for

composition *X*β *B* is globally stable. **Example Problem 10.1.** Show that the values of *XB* that correspond to a common tangent

construction of a non-convex *g*, such as depicted in Figure 10–1b, are unchanged if a linear function of *XB* is added to *g*.

**Solution 10.1.** For the function *g*(*x*), the values of *XB* subtended by a common tangent are

from α by composition. If there were a change in structure, there could be two separate curves that cross.

solutions to the simultaneous equations 4In Chapter 7 we showed for stability that the extensive Gibbs free energy *G* must be a convex function of

each of its extensive variables. For a binary solution we could regard *G* to depend on the variable set *T*, *p*, *NB*, *N*, so with *N* constant, *g* = *G*/*N* must be a convex function of *XB* = *NB*/*N* for stability. 5The fact that the present *g*-curve is continuous and has a continuous derivative implies that there is not a change of structure as *XB* increases from 0 to 1. Therefore, one could rename the β phase α since it only differs

$$\mathbf{g'(x) = g'(y); \quad g(x) - xg'(x) = g(y) - yg'(y),}\tag{10.18}$$

$$\tilde{\mathbf{g}}'(\mathbf{x}) = \mathbf{g}'(\mathbf{x}) + a; \quad \tilde{\mathbf{g}}(\mathbf{x}) - \mathbf{x}\tilde{\mathbf{g}}'(\mathbf{x}) = \mathbf{g}(\mathbf{x}) - \mathbf{x}\mathbf{g}'(\mathbf{x}) + b. \tag{10.19}$$

(*y*), (10.18)

*Chapter 10* • Binary Solutions 141

(*x*) = *g*(*y*) − *yg*

(*y*); *g*(*x*) − *xg*

where the prime denotes differentiation and fixed values of *p* and *T* have been suppressed. Let

### *g*˜(*x*) = *g*(*x*) + *ax* + *b* where *a* and *b* are constants. Then *g*˜ (*x*) = *g* (*x*) + *a*; *g*˜(*x*) − *xg*˜

and *f*1*XB*1 + *f*2*XB*2 = *X*∗

*g* (*x*) = *g*

(*x*) = *g*(*x*) − *xg* (*x*) + *b*. (10.19) Therefore, if *g*˜ is substituted for *g* in Eq. (10.18), the constants *a* and *b* cancel. This happens because a straight line is its own common tangent. 10.1.3 Chord Construction

$$f_1 = \frac{X_{B2} - X_B^*}{X_{B2} - X_{B1}}; \quad f_2 = \frac{X_B^* - X_{B1}}{X_{B2} - X_{B1}}; \quad \text{lever rule.} \tag{10.20}$$

<span id="page-161-0"></span>*B* ≤ *XB*2. This requires *f*1 + *f*2 = 1

*XB*1 and a mole fraction *f*2 of material having composition *XB*2. Suppose that the total composit[e](#page-161-0) [has](#page-161-0) *X*∗ *B* moles of component *B*, where *XB*1 ≤ *X*∗

$$\begin{aligned} \mathbf{g}_{\mathcal{C}} &= f_1 \mathbf{g}(T, p, X_{\mathcal{B}1}) + f_2 \mathbf{g}(T, p, X_{\mathcal{B}2}) \\ &= \mathbf{g}(T, p, X_{\mathcal{B}1}) + \frac{X_{\mathcal{B}2} - X_{\mathcal{B}}^*}{X_{\mathcal{B}2} - X_{\mathcal{B}1}} [\mathbf{g}(T, p, X_{\mathcal{B}1}) - \mathbf{g}(T, p, X_{\mathcal{B}2})]. \end{aligned} \tag{10.21}$$

The molar Gibbs free energy of the composite is *gc* = *f*1 *g*(*T*, *p*, *XB*1) + *f*2 *g*(*T*, *p*, *XB*2) = *g*(*T*, *p*, *[XB](#page-162-0)*1) + *XB*2 − *X*∗ *B XB*2 − *XB*1 [*g*(*T*, *p*, *XB*1) − *g*(*T*, *p*, *XB*2)]. (10.21) From Eq. (10.21), we see that *gc* lies on the chord connecting *g*(*T*, *p*, *XB*1) with *g*(*T*, *p*, *XB*2) on a graph of *g* versus *XB* at fixed *T* and *p*, as illustrated in Figure 10–2a. Since that chord is below the curve, the homogeneous state with *g*(*T*, *p*, *X*∗ *B*) is unstable with respect to the composite, which has lower energy *gc*. If a chord is above the curve, the homogeneous states below it are at least locally stable. They are only globally stable if they lie outside the common tangent chord *BE*. A state that is locally stable but globally unstable is said to be metastable and can exist for significant periods of time if kinetics of nucleation of a new phase are slow. Thus, the *g*-curve can be divided into stable, metastable, and unstable regions, as illustrated in Figure 10–2b. The situation is similar to the analysis of *f* (*T*, *v*) as a function of *v* for fixed *T*, but there are some differences. For one thing, the phase rule for a binary system allows up to four phases to coexist at equilibrium, not just three as for a monocomponent system. Second, we now have three independent variables, rather than two. As a consequence, one often confines analysis of condensed binary systems to atmospheric pressure and studies phase stability as *T* and *XB* are varied. Such a procedure is fairly general because condensed phases have sufficiently small molar volumes and are practically incompressible, resulting in a very weak dependence of *g* on pressure. For gaseous phases, which have relatively large molar volumes that are approximately inversely proportional to pressure at constant temperature, the dependence of *g* on pressure is large and cannot be ignored.

g

and is lower than *g*(*T*, *p*, *X*∗

<span id="page-162-0"></span>![](_page_162_Figure_1.jpeg)

XB1 XBXB2 ∗ gc μA B E (a) 1.0 A B C D E XB μA α (b) 0.0 1.0 0.0 **FIGURE 10–2** (a) Graph of *g* versus *XB* at fixed *T* and *p* illustrating the chord construction. The energy *gc* of a

*B*) of homogen[eo](#page-162-1)us material, which is unstable. The chord to the left of one point *B*

composite system having compositions *XB*1 and *XB*2 lies along the chord where it intersects the composition *X*∗

of common tangency lies above the curve, so the states below it are stable. The chord near the other point *E* of common tangency lies above the curve, so the states below it are locally stable, but those to the left of *E* are only

### metastable because a composite along *BE* would have lower energy. (b) *C* and *D* are points of inflection where ∂2*g*/∂*X*2 *B* = 0. Branch *AB* is stable phase α, *BC* is metastable α, *CD* is an unstable branch, *DE* is metastable β and *EF* is

stable phase β. 10.2 Ideal Solutions We shall first give a brief description of an ideal binary solution from the point of view of elementary statistical mechanics.6 Let *NA* be the number of moles of *A*, *NB* the number of moles of *B*, and *N* = *NA* + *NB* the total number of moles. We could equally well describe the system in terms of the numbers, *N*A and *NB*, of atoms of *A* and *B*, respectively, and *N* = *N*A + *NB* the total number of atoms. This latter description relates better to statistical

<span id="page-162-3"></span>
$$
\Omega = \frac{\mathcal{N}!}{\mathcal{N}_{\mathcal{A}}! \mathcal{N}_{\mathcal{B}}!}.\tag{10.22}
$$

*B*

<span id="page-162-1"></span> = *N* ! . (10.22)

<span id="page-162-2"></span>
$$
\Delta S^{\rm ideal} = k_{\rm B} \ln \frac{N!}{\mathcal{N} \Lambda! \mathcal{N}_{\rm B}!} \sim k_{\rm B}! \mathcal{N} \ln \mathcal{N} - \mathcal{N}_{\rm A} \ln \mathcal{N}_{\rm A} - \mathcal{N}_{\rm B} \ln \mathcal{N}_{\rm B}!,\tag{10.23}
$$

*S*ideal = *k*B ln *N* ! *N*A!*NB*! ∼ *k*B[*N* ln *N* − *N*A ln *N*A − *NB* ln *NB*], (10.23) where Stirling's approximation ln *N* ∼ *N* ln *N* − *N* , valid for large numbers, has been used.7 The symbol is used here to remind us that this entropy is in addition to the

entropy of the same number of *A* and *B* atoms in their undissolved states. By introducing

6For a detailed treatment of the ideal entropy of mixing, see Section 16.5.1.

7See Appendix A.

we can arrange these atoms is

$$
\Delta S^{\text{ideal}} = -\mathcal{N}k_{\text{B}}[X_{\text{A}}\ln X_{\text{A}} + X_{\text{B}}\ln X_{\text{B}}] = -NR[X_{\text{A}}\ln X_{\text{A}} + X_{\text{B}}\ln X_{\text{B}}],\tag{10.24}
$$

*Chapter 10* • Binary Solutions 143

<span id="page-163-1"></span>
$$
\Delta S^{\text{ideal}} = -R \left[ N_A \ln(N_A/N) + N_B \ln(N_B/N) \right], \tag{10.25}
$$

the mole (or atom) fractions *XA* = *NA*/*N* = *N*A/*N* and *XB* = *NB*/*N* = *NB*/*N* , Eq. (10.2) becomes *S*ideal = −*N k*B[*XA* ln *XA* + *XB* ln *XB*]=−*NR*[*XA* ln *XA* + *XB* ln *XB*], (10.24) which is known as the **ideal entropy of mixing**. In terms of extensive variables, Eq. (10.24) can be written in the form *S*ideal = −*R*

$$
\Delta H^{\text{ideal}} = \mathbf{0}.\tag{10.26}
$$

ics. An **ideal solution** is one in which *S*ideal is the only entropy in addition to that of the undissolved components, and for which the enthalpy of mixing *H*, also known as the

"heat of mixing," is zero. This requires that there be no chemical interaction between the components *A* and *B*. Thus

$$\mathcal{G} = N_{\rm A} \mu_{\rm A}^{\rm 0}(T, p) + N_{\rm B} \mu_{\rm B}^{\rm 0}(T, p) - T \Delta \mathcal{S}^{\rm ideal} \tag{10.27}$$

$$= N_{\rm A} \mu_{\rm A}^{\rm 0}(T, p) + N_{\rm B} \mu_{\rm B}^{\rm 0}(T, p) + RT \left[ N_{\rm A} \ln(N_{\rm A}/N) + N_{\rm B} \ln(N_{\rm B}/N) \right],$$

the solution is not ideal. We shall deal with a model of such a solution in Section 10.4. The entire Gibbs free energy of an ideal solution is therefore *G* = *NA*μ0 *A*(*T*, *p*) + *NB*μ0

$$
\mu_A = \left(\frac{\partial G}{\partial N_A}\right)_{T, p, N_B} = \mu_A^0(T, p) + RT\ln(N_A/N),
\tag{10.28}
$$

$$
\mu_{\rm B} = \left(\frac{\partial G}{\partial N_{\rm B}}\right)_{T, p, N_{\rm A}} = \mu_{\rm B}^{0}(T, \mathfrak{p}) + RT \ln(N_{\rm B}/N). \tag{10.29}
$$

$$
\text{For a } \omega\text{-Cille a for a } \omega\text{-Cille a for a } \omega\text{-Cille a for} \tag{10.20}
$$

μ*A* [=](#page-163-1) ∂*NA T*,*p*,*NB*

For any Gibbs free energy, we have

μ*B* = - ∂*G* ∂*NB* 

<span id="page-163-0"></span>= *NA*μ0

where μ0

<span id="page-163-3"></span><span id="page-163-2"></span>
$$\left(\frac{\partial(\mathbf{G}/T)}{\partial(1/T)}\right)_{p,N_{\mathbf{A}},N_{\mathbf{B}}} = H,\tag{10.30}$$

-∂(*G*/*T*) ∂(1/*T*) *p*,*NA*,*NB* = *H*, (10.30) which can be proven by noting that *G*/*T* = *H*/*T* − *S* and carrying out the required

$$H = N_A \left( \frac{\partial (\mu_A^0/T)}{\partial (1/T)} \right)_{p, N_{\text{th}}, N_B} + N_B \left( \frac{\partial (\mu_B^0/T)}{\partial (1/T)} \right)_{p, N_{\text{th}}, N_B} = N_A h_A + N_B h_B,\tag{10.31}$$

*H* = *NA* ∂(1/*T*) *p*,*NA*,*NB* + *NB* ∂(1/*T*) *p*,*NA*,*NB*

*AB*2, or even by combining other solutions. For a general discussion, see Lupis [5, pp. 179-184].

where *hA* and *hB* are the molar enthalpies of *A* and *B*, respectively.

*T*,*p*,*NA*

8The chemical potentials μ0 *A*(*T*, *p*) and μ0 *B*(*T*, *p*) refer to so-called "reference states" which we have chosen to be pure *A* and pure *B*, respectively. One can also make solutions whose constituents are molecules, such as *AB* or <span id="page-164-0"></span>*s*

g

μA

μA 0

$$
\Delta s^{\text{ideal}} = -R \left[ X_4 \ln X_4 + X_3 \ln X_3 \right] = -R \left[ (1 - X\mathbb{B}) \ln(1 - X\mathbb{B}) + X\mathbb{B} \ln X_3 \right] \tag{10.32}
$$

$$\mathbf{g} = (1 - X_{\mathcal{B}})\mu_A^{\mathcal{U}}(T, p) + X_{\mathcal{B}}\mu_B^{\mathcal{U}}(T, p) + RT \left[ (1 - X_{\mathcal{B}})\ln(1 - X_{\mathcal{B}}) + X_{\mathcal{B}}\ln X_{\mathcal{B}} \right]. \tag{10.33}$$

On a per mole basis, the ideal entropy of mixing is

$$
\mu_A = \mu_A^0(T, \mathfrak{p}) + RT \ln(1 - X_{\mathfrak{B}}); \quad \mu_B = \mu_B^0(T, \mathfrak{p}) + RT \ln X_{\mathfrak{B}}.\tag{10.34}
$$

*[g](#page-162-3)* = (1 − *XB*)μ0 *A*(*T*, *p*) + *XB*μ0 *B*(*T*, *p*) + *RT* (1 − *XB*)ln(1 − *XB*) + *XB* ln *XB* . (10.33) Figure 10–3a shows a plot of *g* as a function of *XB*. We could obtain the chemical potential[s graphically](#page-164-1) from the method of intercepts. We could also use the analytic formulae Eq. (10.16), which are the basis of the common tangent construction, to obtain μ*A* = μ0 *A*(*T*, *p*) + *RT* ln(1 − *XB*); μ*B* = μ0 *B*(*T*, *p*) + *RT* ln*XB*. (10.34)

The chemical potentials in Eq. (10.34) are the same as in Eqs. (10.28) and (10.29) except for notation. Note that μ*B* = −∞ for *XB* = 0. This can be traced back to the fact that *S*ideal has an infinite slope at *NB* = 0. More precisely, the first member on the right-hand side of Eq. (10.23) shows that *S*ideal = 0 for *NB* = 0 and *S*ideal = *k*B ln *N* for *NB* = 1. Its slope at *NB* = 0 is therefore *k*B ln *N* which is actually finite but diverges logarithmically as *N* → ∞ in the thermodynamic limit. Similarly, μ*A* = −∞ for *XB* = 1. From Figure 10–3a we see that *g* is a convex function of *XB*, so there is a stable homogeneous phase for every value of *XB*; in other words, there is a complete range of mutual solubility. In particular, such a homogeneous solution is stable with respect to phase separation to a composite state. At temperatures for which pure *A* and pure *B* are both crystalline solids, they can only form solid solutions for all *XB* if they have the same crystal structure. Examples are silicon and germanium (Si, Ge) which are both diamond cubic, or nickel and copper (Ni, Cu) which are both face centered cubic. The solid solutions

![](_page_164_Figure_9.jpeg)

<span id="page-164-1"></span>of these pairs of elements formed by substituting one atom for the other on the same

0.0 XB 0.6 1.0 (a) 0.0 XB 0.6 1.0 (b) **FIGURE 10–3** (a) Plot of *g* versus *XB* for an ideal solution according to Eq. (10.33). The chemical potentials of the pure components are μ0 *A* and μ0 *B*. At *XB* = 0.6, intercepts of the tangent give the chemical potentials μ*A* and μ*B*. (b) Plot of *g* versus *XB* for an ideal solution according to Eq. (10.35). At *XB* = 0.6, intercepts of the tangent give the chemical potential differences μ*A* = μ*A* − μ0 *A* and μ*B* = μ*B* − μ0

*B*.

$$\Delta \mathbf{g} := \mathbf{g} - (1 - X_{\mathcal{B}}) \mu_A^0 (T, \mathbf{p}) - X_{\mathcal{B}} \mu_B^0 (T, \mathbf{p}) = RT \left[ (1 - X_{\mathcal{B}}) \ln(1 - X_{\mathcal{B}}) + X_{\mathcal{B}} \ln X_{\mathcal{B}} \right]. \tag{10.35}$$

*Chapter 10* • Binary Solutions 145

### It is often convenient to eliminate consideration of unmixed constituents by defining

*g* := *g* − (1 − *XB*)μ0 *A*(*T*, *p*) − *XB*μ0 *B*(*T*, *p*) = *RT* (1 − *XB*)ln(1 − *XB*) + *XB* ln *XB* . (10.35) Figure 10–3b shows a plot of *g* as a function of *XB*. Its minimum value occurs for *XB* = 0.5 and has the value −*RT* ln 2 = −0.693*RT*. Applying the method of intercepts to *g* gives the chemical potential *differences* μ*A* = μ*A* − μ0 *A* and μ*B* = μ*B* − μ0 *B*.

<span id="page-165-1"></span>10.3 Phase Diagram for an Ideal Solid and an Ideal Liquid As we have seen above, *g* or *g* for an ideal binary solution is a convex function of *XB*, and this could happen either below or above the melting points of the pure components. The interesting question is: What happens for temperatures between the melting points of the pure elements? For example, Si melts at 1685 K and Ge melts at 1210.4 K. Moreover,

<span id="page-165-2"></span>
$$
\mu_A^{\rm L} = \mu_A^{\rm 0L}(T, p) + RT \ln(1 - X\mathfrak{g}); \quad \mu_B^{\rm L} = \mu_B^{\rm 0L}(T, p) + RT \ln X\mathfrak{g}, \tag{10.36}
$$

part solid and part liquid. We analyze this situation as an application of the ideal solution

μ0L

μ*S*

*X*S

*B* (*T*, *p*)<μ0S

$$
\mu_A^{\rm S} = \mu_A^{\rm OS}(T, p) + RT \ln(1 - X_{\rm B}); \quad \mu_B^{\rm S} = \mu_B^{\rm OS}(T, p) + RT \ln X_{\rm B} \tag{10.37}
$$

*A* (*T*, *p*)>μ0S

*A* (*T*, *p*) and

*A*(1 − *XB*) +

<span id="page-165-0"></span>μL *A* = μ0L *A* (*T*, *p*) + *RT* ln(1 − *XB*); μL *B* = μ0L *B* (*T*, *p*) + *RT* ln *XB*, (10.36) and for the ideal solid μS *A* = μ0S *A* (*T*, *p*) + *RT* ln(1 − *XB*); μS *B* = μ0S *B* (*T*, *p*) + *RT* ln*XB*, (10.37) where the superscripts L and S denoting liquid and solid have been added to Eq. (10.34).

For a temperature *T* that satisfies *TA* > *T* > *TB*, we know that μ0L

μS

![](_page_165_Figure_11.jpeg)

0.0 X 1.0 L X B S B **FIGURE 10–4** Curves of *g*L for an ideal liquid solution and *g*S for an ideal solid solution versus *XB* for a temperature *T* between the melting points of pure *A* and pure *B*. The common tangent construction applies, with tangency at *B* and *X*L

*B*. As the temperature changes, the curves shift, resulting in a change of the points of common tangency.

146 THERMAL PHYSICS

μL

*A*(*T*, *p*, *X*L

<span id="page-166-0"></span>tangent construction to Figure 10–4, we see that there is a miscibility gap for *X*S *B* < *XB* < *X*L *B*. Here, *X*S *B* and *X*L *B* are the compos[itions](#page-165-2) at which common tangency occurs for the value of *T* corresponding to [the](#page-165-1) [fig](#page-165-1)ure. As *T* varies, th[ese](#page-166-0) [cur](#page-166-0)ves shift and we can trace out the

$$
\mu_A^\mathcal{L}(T, p, X_\mathcal{B}^\mathcal{L}) = \mu_A^\mathcal{S}(T, p, X_\mathcal{B}^\mathcal{S}); \quad \mu_\mathcal{B}^\mathcal{L}(T, p, X_\mathcal{B}^\mathcal{L}) = \mu_\mathcal{B}^\mathcal{S}(T, p, X_\mathcal{B}^\mathcal{S}).\tag{10.38}
$$

plotted in Figure 10–5.

$$
\mu_A^{\text{0L}}(T, p) - \mu_A^{\text{0S}}(T, p) = RT \ln \left( \frac{1 - X_B^{\text{S}}}{1 - X_B^{\text{L}}} \right);
$$

$$
\mu_B^{\text{0L}}(T, p) - \mu_B^{\text{0S}}(T, p) = RT \ln \left( \frac{X_B^{\text{S}}}{X_B^{\text{L}}} \right). \tag{10.39}
$$

μ0L *A* (*T*, *p*) − μ0S *A* (*T*, *p*) = *RT* ln 1 − *X*S *B* 1 − *X*L *B* ;

<span id="page-166-3"></span><span id="page-166-2"></span><span id="page-166-1"></span>
$$
\Delta\mu_A:=\mu_A^{\rm 0L}(T,p)-\mu_A^{\rm 0S}(T,p)=\Delta h_A-T\Delta\mathfrak{s}_A;
$$

$$
\Delta\mu_B:=\mu_B^{\rm 0L}(T,p)-\mu_B^{\rm 0S}(T,p)=\Delta h_B-T\Delta\mathfrak{s}_B,\tag{10.40}
$$

In order to proceed further, we need a model to evaluate the chemical potential differences on the left of Eq. (10.39). We write these in the forms μ*A* : = μ0L *A* (*T*, *p*) − μ0S *A* (*T*, *p*) = *hA* − *TsA*; μ*B* : = μ0L *B* (*T*, *p*) − μ0S *[B](#page-166-2)* (*T*, *p*) = *hB* − *TsB*, (10.40) where *hA* and *hB* are enthalpy differences (liquid minus solid) and *sA* and *sB* are the corresponding entropy [differe](#page-166-2)nces. We [assum](#page-166-1)e as an approximation that these enthalpy

$$
\Delta\mu_A = \Delta h_A (1 - T/T_A); \quad \Delta\mu_B = \Delta h_B (1 - T/T_B). \tag{10.41}
$$

μ*B* = 0 at *T* = *TB*. This gives *hA* = *TAsA* and *hB* = *TBsB*, so Eqs. 10.40 become approximately μ*A* = *hA*(1 − *T*/*TA*); μ*B* = *hB*(1 − *T*/*TB*). (10.41) We recognize *hA* and *hB* as the respective latent heats of fusion per mole [and o](#page-166-3)bserve that Eqs. (10.41) have the expected algebraic signs, that is, μ*A* > 0 and μ*B* < 0 for

*TA* > *T* > *TB*. An alternative view of Eqs. (10.41) is to assume that they are the leading

$$\frac{1 - X_B^{\rm L}}{1 - X_B^{\rm S}} = \exp\left[-\frac{\Delta h_A}{R}\left(\frac{1}{T} - \frac{1}{T_A}\right)\right] \equiv E_A(T);$$

$$\frac{X_B^{\rm S}}{X_B^{\rm L}} = \exp\left[\frac{\Delta h_B}{R}\left(\frac{1}{T} - \frac{1}{T_B}\right)\right] \equiv E_B(T). \tag{10.42}$$

$$\text{For } T \ll T_c: T_c \text{ : un no state that } 0 \ll E_A(T) \text{ : 1 and 0 } \dots E_A(T) \text{ : 1. Sekring Eq. (10.42) for } \mathbf{X}^{\rm S} \text{ (see } \mathbf{X}^{\rm S} \text{)}$$

*X*L *B R TB* For *TA* > *T* > *TB*, we note that 0 < *EA*(*T*) < 1 and 0 < *EB*(*T*) < 1. Solving Eq. (10.42) for *X*S *B* and *X*L *B* gives

<span id="page-167-0"></span>![](_page_167_Figure_1.jpeg)

1200 K TB

0.0 0.2 0.4 0.6 0.8 1.0

$$X_B^\mathbb{S} = E\mathbf{e}(T)\frac{1 - E_\mathcal{A}(T)}{1 - E_\mathcal{A}(T)E_\mathcal{B}(T)}; \quad X_B^\mathbb{L} = \frac{1 - E_\mathcal{A}(T)}{1 - E_\mathcal{A}(T)E_\mathcal{B}(T)}.\tag{10.43}$$

and *TB* = 1210.4 K. 1 − *EA*(*T*)

*X*S *B* = *EB*(*T*) 1 − *EA*(*T*)*EB*(*T*) ; *X*L *B* = 1 − *EA*(*T*) 1 − *EA*(*T*)*EB*(*T*) . (10.43) We observe from Eq. (10.43) that *X*S *B* and *X*L *B* increase from 0 to 1 with *X*S *B* ≤ *X*L *B* as *T* decreases from *TA* to *TB*. In order to make a plot of Eq. (10.43) we need some numerical values of the physical constants. If *A* were Si and *B* were Ge, then *hA*/(*RTA*) = 3.59 and *hB*/(*RTB*) = 3.14. Figure 10–5 shows a plot of the resulting phase diagram. T[here is a](#page-167-0) **miscibility gap** with a "lens shape" connecting the melting points of pure *A* and *B*. Above the miscibility gap, the liquid solution is stable, and below it the solid solution is stable. The curve *X*S *B*(*T*) is called the **solidus** and *X*L *B*(*T*) is called the **liquidus**. For a point within the miscibility gap, a homogeneous solution is unstable, so the corresponding equilibrium state is a composite,

in this composite are governed by the lever rule.

**Example Problem 10.2.** For the phase diagram depicted in Figure 10–5, what is the mole fraction of solid in equilibrium with liquid at *T* = 1600 K if the overall composition is *XB* = 0.22 mole fraction? By how much does the chemical potential of *A* in this solid differ from that of pure solid *A* at *T* = 1600 K?

consisting of part liquid solution and part solid solution. The amounts of solid and liquid

148 THERMAL PHYSICS

**Solution 10.2.** At *T* = 1600 K, the compositions at the solidus and liquidus are estimated to be 0.13 and 0.28. By the lever rule, the mole fraction of solid is (0.28−0.22)/(0.28−0.13) = 0.4. From the first of Eqs. (10.37) we obtain μS *A* − μ0S *A* = *RT* ln(1 − *XB*) = 3200ln(1 − 0.13) = −456 cal/mol.

*B* and the slope d*X*L

*B*/*X*L

$$\frac{\mathbf{d}(X_B^L - X_B^S)}{\mathbf{d}T} = -\frac{\Delta h_A}{RT_A^2}.\tag{10.44}$$

*B*/d*T*.

formulae for the distribution coefficient *k* := *X*S **Solution 10.3.** From the second of Eqs. (10.42) we can approximate *T* = *TA* to obtain *k* =

*B* = *X*L

*B*

d*T* = − *hA*

This result is related to J. H. van't Hoff's law of freezing point lowering for a dilute solid solution

(1 − *k*)*RT*2 *A*

and evaluate the result at *X*S

$$\frac{d\mathbf{X}_B^L}{dT} = -\frac{\Delta h_A}{(1-k)RT_A^2}.\tag{10.45}$$

. (10.45)

*A*/d*T* = *hB*/[(*k* − 1)*RT*2

1.

*B*].

<span id="page-168-0"></span>d(*X*L *B* − *X*S *B*) d*T* = −*hA RT*2 *A* . (10.44) Then use of *k* to eliminate *X*S *B* gives d*X*L

### [22, p. 235]. Similar formulae can be obtained at the other end of the phase diagram for *XA* The results are *k* := *X*S *A*/*X*L *A* = 1/*EA*(*TB*) = constant > 1 and d*X*L

10.4 Regular Solution

$$
\Delta H^{\text{reg}} = \tilde{\Omega} X_A X_B = \tilde{\Omega} (1 - X_B) X_B,\tag{10.46}
$$

A so-called **regular solution** is a solution having an ideal e[ntr](#page-168-1)opy of mixing, but also a heat of mixing of the form *H*reg = ˜ *XAXB* = (˜ 1 − *XB*)*XB*, (10.46) where ˜ is a constant. In a quasichemical approximation [23], this heat of mixing arises

$$1 = (X_A + X_B)^2 = X_A^2 + 2X_A X_B + X_B^2. \tag{10.47}$$

<span id="page-168-1"></span>terms on the right-hand side of the expression 1 = (*XA* + *XB*) 2 = *X*2 *A* + 2*XAXB* + *X*2 *B*. (10.47)

$$E_{\rm 4A}X_A^2 + 2E_{\rm 4B}X_A X_B + E_{\rm 3B}X_B^2 - E_{\rm 4A}X_A - E_{\rm 3B}X_B = 2X_A X_B [E_{\rm 4B} - (1/2)(E_{\rm 4A} + E_{\rm 3B})].\tag{10.48}$$

*EAAX*2 *A* + 2*EABXAXB* + *EBBX*2 *B* − *EAAXA* − *EBBXB* = 2*XAXB*[*EAB* − (1/2)(*EAA* + *EBB*)]. (10.48) To get the actual energy for *N* moles, we need to multiply by (1/2)*Nz*, where *z* is the

coordination number (number of significant, probably nearest) of neighbors, which we

constant pressure, so the distinction between energy and enthalpy is not important.

<sup>9</sup>These energies are negative for attraction and positive for repulsion. We deal here with condensed phases at

<span id="page-169-1"></span>![](_page_169_Figure_1.jpeg)

0.0 1.0 *−*0.7 XB (a) 0.0 1.0 *−*0.2 XB (b)

<span id="page-169-0"></span>**FIGURE 10–6** Plots of *g* versus *XB* for a reg[ular](#page-169-0) [solu](#page-169-0)tion according to Eq. (10.51). (a) For *RT*/ω = −3/8, −1/2, −5/8 for top to bottom curves, there is relative attraction of *A* and *B*, and *g* is convex. (b) For *RT*/ω = 3/8, 1/2, 5/8 for top to bottom curves, there is relative repulsion of *A* and *B*. *g* is convex at high *T* but develops a concave portion

$$
\tilde{\Omega} \approx N \text{z} [E_{\text{AB}} - (1/2)(E_{\text{AA}} + E_{\text{BB}})].\tag{10.49}
$$

<span id="page-169-2"></span>assume to be the same for the pure components and the solution. The factor of (1/2) arises to avoid double counting. This results in ˜ ≈ *Nz*[*EAB* − (1/2)(*EAA* + *EBB*)]. (10.49)

The main thing we learn from Eq. (10.49) is that ˜ will be negative if *A* atoms are attracted to *B* atoms more than these atoms are attracted to their own kind. Otherwise, there will be ne[t repulsion of](#page-169-1) *A* and *B* atoms, and ˜ will be positive. If ˜ is positive, we anticipate that a

$$
\Delta G = \Delta H^{\text{reg}} - T\Delta S^{\text{ideal}} = \tilde{\Omega}\,X_{\text{A}}X_{\text{B}} + RT \left[ N_{\text{A}}\ln(N_{\text{A}}/N) + N_{\text{B}}\ln(N_{\text{B}}/N) \right]. \tag{10.50}
$$

proceed to analyze the thermodynamics. The total free energy of mixing is

solution repulsive.

$$
\Delta \mathbf{g} = \omega X_B (1 - X_B) + RT \left[ (1 - X_B) \ln(1 - X_B) + X_B \ln X_B \right], \tag{10.51}
$$

For one mole, this becomes

*g* = ω *XB*(1 − *XB*) + *RT* (1 − *XB*)ln(1 − *XB*) + *XB* ln *XB* , (10.51) where ω := /˜ *N* is the value of the interaction parameter per mole. Figure 10–6 shows some plots of *g* versus *XB* for a few temperatures and values of ω. For ω < 0 (relative attraction of *A* and *B*) *g* is convex. In this case, *A* and *B* are mutually soluble for all *XB*, just as for an ideal solution. For ω > 0 (relative repulsion of *A* and *B*) *g* is convex at high *T* but develops a concave portion at low *T*. Therefore a miscibility gap develops at sufficiently low *T* and its boundary is given by the common

tangent construction. Within the miscibility gap is a spinodal curve, which is the locus in the *XB*, *T* plane of the points where *g* changes from convex to concave. To compute the spinodal curve, we solve

T/Tc

∂2*g*

<span id="page-170-2"></span>![](_page_170_Figure_1.jpeg)

0.2 0.4 0.6 0.8 1.0 0.2 0.4 X

**FIGURE 10–7** Miscibility gap boundary (solid curve) and spinodal curve (dashed curve) for a regular solution. For *T* > *Tc* there is a stable solid phase α with a complete range of solid solubility. For *T* < *Tc*, the stable phases are α and α which have the same crystal structure as α but different compositions. A point between the miscibility gap

$$\frac{\partial^2 \Delta \mathbf{g}}{\partial X_B^2} = -2\omega + RT \left( \frac{1}{X_B} + \frac{1}{1 - X_B} \right) = \mathbf{0},\tag{10.52}$$

given by the lever rule.

form

<span id="page-170-1"></span><span id="page-170-0"></span>
$$X_B(1 - X_B) = RT/(2\omega); \quad \text{spinodal.}\tag{10.53}$$

∂*X*2 *B XB* 1 − *XB* which yields

$$T_c = \omega / (2R) \tag{10.54}$$

curve occurs at the critical temperature *Tc* = ω/(2*R*) (10.54) because for higher temperatures Eq. (10.53) has no allowable roots. From [the](#page-169-2) [for](#page-169-2)m of Eq. (10.53), we see that the spinodal curve is symmetric with respect to *XB* = 1/2. By

$$T/T_c = 1 - 4X^2,\tag{10.55}$$

*T*/*Tc* = 1 − 4*X*2, (10.55)

which is a parabola that ranges from *X* = −1/2 to *X* = 1/2 with its maximum at *T* = *Tc*. The spinodal is represented by the dashed curve in Figure 10–7. To compute the boundary of the miscibility gap, we need the chemical potentials.

10Note that one must write ˜ *XAXB* = ω*NANB*/(*NA* + *NB*) before performing the differentiation.

These can be obtained by differentiation of the extensive10 *G* given by Eq. (10.50) with

$$
\mu_A - \mu_A^0(T, p) = RT \ln(1 - X_B) + \omega X_B^2; \quad \mu_B - \mu_B^0(T, p) = RT \ln X_B + \omega (1 - X_B)^2. \tag{10.56}
$$

*Chapter 10* • Binary Solutions 151

$$RT\ln(1 - X_{B1}) + \alpha X_{B1}^2 = RT\ln(1 - X_{B2}) + \alpha X_{B2}^2;$$

$$RT\ln X_{B1} + \alpha(1 - X_{B1})^2 = RT\ln X_{B2} + \alpha(1 - X_{B2})^2. \tag{10.57}$$

μ*A* − μ0 *A*(*T*, *p*) = *RT* ln(1 − *XB*) [+](#page-171-1) ω*X*2 *B*; μ*B* − μ0 *B*(*T*, *p*) = *RT* ln*XB* + ω(1 − *XB*) 2. (10.56) Note that by working with *G* or *g* rather than *G* or *g*, we get μ*A* = μ*A* − μ0 *A*(*T*, *p*) and μ*B* = μ*B* − μ0 *B*(*T*, *p*). Equating chemical potentials for *A* and *B* at *XB*1 and *XB*2 gives *RT* ln(1 − *XB*1) + ω*X*2 *B*1 = *RT* ln(1 − *XB*2) + ω*X*2

$$RT\ln\left(\frac{1}{2} + X\right) + \omega\left(\frac{1}{2} - X\right)^2 = RT\ln\left(\frac{1}{2} - X\right) + \omega\left(\frac{1}{2} + X\right)^2. \tag{10.58}$$

reveals that [the b](#page-170-1)oundary of the miscibility gap is symmetric with respect to *XB* [=](#page-171-2) 1/2.

<span id="page-171-2"></span><span id="page-171-0"></span>-1

1

intercepts. The results are

in which case they both become11

$$\ln\left[\frac{\frac{1}{2} + X}{\frac{1}{2} - X}\right] = 4(T_{\mathcal{E}}/T)X,\tag{10.59}$$

*RT* ln-2 + *X* + ω 2 − *X* 2 − *X* 2 + *X* Equation (10.58) can be rearranged to yield ln 1 2 [+](#page-169-1) *X* 1 2 − *X* = 4(*Tc*/*T*) *[X](#page-171-3)*, (10.59) where Eq. (10.54) has been used. The function on [the left-han](#page-170-2)d side of Eq. (10.59) is sketched in Fi[gure 10–8](#page-170-2) along with three possibilities for the right-hand side. For *T* = *Tc*, the full line is tangent to [the cu](#page-171-2)rve at *X* = 0, which corresponds to the top of the miscibility gap at *XB* = 1/2. For *T* > *Tc* there is just one root at *X* = 0 which corresponds to the stable state *XB* = 1/2 on a convex *g* curve. For *T* < *Tc* there are two unequal roots, being of equal magnitude but opposite sign, and corresponding to distinct values of *XB*1 and *XB*2 on the miscibility gap. The root at *X* = 0 for *T* < *Tc* corresp[onds to an](#page-169-1) unstable state at *XB* = 1/2 on the upper curve of Figure 10–6b. Thus for *T* < *Tc* the eq[uilibri](#page-171-2)um state

<span id="page-171-3"></span><span id="page-171-1"></span>of the system is a composite consisting of one phase12 α having composition 1/2 − |*X*| and another phase α having composition 1/2 + |*X*|, where *X* is a root of Eq. (10.59). The boundary of the resulting miscibility gap is shown in Figure 10–7.

$$\frac{T}{T_{\mathcal{E}}} = 1 - (4/3)X^2 - (64/45)X^4 \cdots \, , \tag{10.60}$$

*T Tc* = 1 − (4/3)*X*2 − (64/45)*X*4 ··· , (10.60) 11A shorter determination of the miscibility gap can be made by noting from Figure 10–6b that the common tangent has a slope of zero. Thus we could solve ∂2*g*/∂*X*2 *B* = 0 which would also lead to Eq. (10.59). We follow

a more general procedure, however, because other models of solutions do not have such high symmetry and the slope of the common tangent is not zero. 12As mentioned above, the regular solution model only makes sense for solid phases if they have the same crystal structure. When a miscibility gap develops, the phases in the equilibrium composite still have the same crystal structure, but different composition. Hence we denote one by α and the other by α, reserving the notation α and β for models in which different crystal structures occur. For systems having liquid miscibility gaps, one usually uses *L* and *L*.

−2

2 + *X* / 1 2 − *X*

of inflection of *g* and is therefore given by

and (10.62) also hold if *g* is replaced by *g*.

**FIGURE 10–8** Plot of ln  1

solution model.

0

2

4

<span id="page-172-0"></span>![](_page_172_Figure_1.jpeg)

−0.4 −0.2 0.0 0.2 0.4 −4

versus *X* and comparison to 4(*Tc*/*T*)*X*. The full line is for *T* = *Tc* and is

tangent to the curve at *X* = 0, which corresponds to the top of the miscibility gap. For *T* > *Tc*, illustrated by the line with large dashes for *T* = 2*Tc*, there is only a root at *X* = 0, which corresponds to a stable state on a convex *g* curve. For *T* < *Tc*, illustrated by the line with small dashes for *T* = (2/3)*Tc*, Eq. (10.59) has two non-zero roots that lie on the miscibility gap; its root at *X* = 0 corresponds to an unstable state at *XB* = 1/2. which should be compared to Eq. (10.55). For the regular solution, the top of the miscibility gap occurs at temperature *Tc* and composition *XB* = 1/2 and the first three partial

derivatives of *g* with respect to *XB* are equal to zero there. This is not general, however, because the vanishing of the first derivative is only due to the symmetry of the regular

$$\frac{\partial^2 \Delta \mathbf{g}}{\partial X_B^2} = \mathbf{0}.\tag{10.61}$$

∂2*g* = 0. (10.61)

∂*X*2 *B*

X

$$\frac{\partial^3 \Delta \mathbf{g}}{\partial X_B^3} = \mathbf{0}.\tag{10.62}$$

∂3*g* ∂*X*3 *B* = 0. (10.62) Therefore, at the top of the miscibility gap, both the second and third partial derivatives of *g* with respect to *XB* vanish simultaneously. This determines *Tc* and the corresponding *Xc*. Since *g* differs from *g* only by a linear function of *XB*, Eqs. (10.61)

### 10.5 General Binary Solutions

We have barely scratched the surface of the subject of binary solutions and their phase diagrams. In general, binary phase diagrams are much more complicated and display intricate topologies including eutectics, peritectics, and the occurrence of several intermediate phases. The interested reader is referred to Lupis [5, chapter VIII] for a very thorough discussion of binary phase diagrams, with particular attention to their relationship to free energy curves. The book by DeHoff [21] devotes several detailed chapters to this subject and goes on to treat multicomponent solutions, which are of great practical importance to the understanding of commercial alloys. Nevertheless we have covered all of the essential physics and the most important constructions (method of intercepts, common tangent, lever rule, chord construction) that allow analysis of more general models. For a compendium of information about the phase diagrams of real materials, the reader is referred to three volumes edited by Massalski [24].

This page intentionally left blank

# 11

# External Forces and Rotating Coordinate Systems

In Chapter 6 we developed criteria for equilibrium of a thermodynamic system under various conditions. In the absence of external forces, those criteria included the minimization of the internal energy *U* for a system that does no work at constant entropy *S* and the minimization of the Helmholtz free energy *F* for a system that does no work at constant temperature, *T*. In this chapter, we generalize these equilibrium conditions to include external forces, such as gravity and electromagnetic forces, that can exert body forces and do work on a system.

At equilibrium, such systems will usually be inhomogeneous. For example, in the case of gravity, the pressure, and the chemical potentials will be functions of position within a sample[.1](#page-175-0) We shall restrict our development to conservative external forces that can be derived from a potential function. Then the equilibrium conditions can be expressed conveniently in terms of new potentials, such as gravitational chemical potentials and electrochemical potentials that are uniform at equilibrium.

We examine in detail the equilibrium conditions for multicomponent ideal gases and binary liquids in a uniform gravitational field. Then we treat rotating systems by means of a potential that relates to centrifugal force. Finally, we give a brief treatment of applied electric fields.

### 11.1 Conditions for Equilibrium

We begin with the inequality Eq. (6.19) which we rewrite in the form

<span id="page-175-1"></span>
$$
\delta \mathbf{U} + \delta \mathcal{W} < \mathbf{0}, \quad \text{constant } \mathbf{S}, \text{ natural process, technically closed,} \tag{11.1}
$$

where we have written a strict inequality to confine our attention to actual processes that are always natural and irreversible. This eliminates hypothetical reversible processes for which there is really no driving force. To have equilibrium, all such natural irreversible processes must be prevented. A state will therefore be in equilibrium if all *virtual* variations of the system, which we indicate by δ applied to *U*, violate Eq. [(11.1)](#page-175-1), that is,

<span id="page-175-2"></span>
$$
\delta U + \delta \mathcal{W} \ge 0,\quad \text{constant S, clearly closed, all virtual variations.}\tag{11.2}
$$

<span id="page-175-0"></span>1In this chapter, we make use of methods of the calculus of variations to treat inhomogeneous systems. This subject is treated in many standard references, for example [25, p. 198] and [26, p. 164]. The main results, however, can be appreciated and in many cases applied without a complete understanding of their derivation.

By a **virtual variation**, we mean any imagined variation that is compatible with the constraints of the system but does not necessarily satisfy the laws of thermodynamics. If all virtual variations satisfy Eq. [(11.2)](#page-175-2), they all violate the laws of thermodynamics, so no natural irreversible processes are possible and the system is in equilibrium.

We next confine ourselves to the case in which the *only* work is done against conservative external forces. Thus, there exists a potential function such that δ*W* = δ and in which the δ applied to denotes a *change* in due to a virtual variation, unlike the general meaning of the symbol δ*W* which means a small amount of work, not a change of work. We shall assume that the overall volume of the system is constant. Our equilibrium criterion Eq. [(11.2)](#page-175-2) therefore becomes

<span id="page-176-0"></span>
$$\delta(U+\Phi) \ge 0,\quad \text{constant S and } V, \text{ chemicalally closed, all virtual variations.}\tag{11.3}$$

Although Eq. [(11.3)](#page-176-0) is a valid criterion for equilibrium, it would be difficult if not impossible to realize it experimentally because one would have to devise a way to hold the entropy constant. Theoretically, however, one can satisfy the constraint of constant entropy by means of a Lagrange multiplier λ and consider virtual variations of the form δ(*U* +−λ*S*), but we must also insure that the system is chemically closed. For simplicity we first forbid chemical reactions. Therefore, we also introduce additional Lagrange multipliers λ*i* for each chemical component and obtain

<span id="page-176-2"></span>
$$\delta(U + \Phi - \lambda S - \sum_{l} \lambda_l N_l) \ge 0, \quad \text{constant } V, \text{ all virtual variations.} \tag{11.4}$$

As is usual with Lagrange multipliers, we could choose λ and the λ*i* later to satisfy the constraints of constant entropy and constant mole numbers[.2](#page-176-1) By following this methodology, one finds, not surprisingly, that λ =*T* at equilibrium, so the absolute temperature of the system is a constant.

An alternative approach is to assume at the outset that the system in question is in contact with a heat reservoir having constant temperature *T* and that the system is maintained at temperature *T* throughout any process under consideration. Then returning to Eq. (6.19) with *Ts* = *T* but allowing *S* to vary gives

$$
\mathbf{d}F + \delta \mathcal{W} < \mathbf{0}, \quad \text{constant } T, \text{ natural process, technically closed,} \tag{11.5}
$$

where *F* = *U* − *TS* is the Helmholtz free energy. Then if there exists a potential function such that the only work done is δ*W* = δ, as discussed above, one can use Lagrange multipliers λ*i* to insure the chemical closure. This results in the equilibrium criterion

<span id="page-176-3"></span>
$$\delta \left( F + \Phi - \sum_{l} \lambda_{l} N_{l} \right) \ge 0, \quad \text{constant } T \text{ and } V, \text{ all virtual variations.} \tag{11.6}$$

<span id="page-176-1"></span><sup>2</sup>We could equally well constrain the masses *Mi* of each chemical component since *Mi* = *miNi*, where *mi* are molecular weights. This would change the values of the λ*i* but not the fact that they are just constants. This is often done when the force under consideration is due to gravity, which acts on the masses, and was preferred by Gibbs [3, p. 144].

We proceed to illustrate the use of the equilibrium criteria, Eq. [(11.4)](#page-176-2) or Eq. [(11.6)](#page-176-3), extensively for the case of gravitational forces and then discuss several other forces.

### 11.2 Uniform Gravitational Field

We first consider the case of a uniform gravitational field that exerts a constant downward acceleration *g* per unit mass on any chemical species. We take the *z* axis of a cartesian coordinate system to be vertically upward, "up" defined as antiparallel to the acceleration due to gravity. In that case,

<span id="page-177-4"></span>
$$\Phi = \int_{V} \rho \mathbf{g} \mathbf{z} \, d^3 \mathbf{x} + \text{constant}, \tag{11.7}$$

where ρ = *i* ρ*i* is the local mass density and the integral is over the constant volume *V* of the system. We use masses rather than moles to simplify the form of the potential for gravity.[3](#page-177-0) The total internal energy, entropy, and masses of each species are given by

$$\mathcal{U} = \int_{V} \boldsymbol{\mu}_{V} \, \mathbf{d}^{3} \mathbf{x}; \quad \mathbf{S} = \int_{V} \mathbf{s}_{V} \, \mathbf{d}^{3} \mathbf{x}; \quad M_{l} = \int_{V} \rho_{l} \, \mathbf{d}^{3} \mathbf{x}, \tag{11.8}$$

where the internal energy density, entropy density, and mass densities are denoted by *uV* , *sV* , and ρ*i*, respectively.

We treat a multicomponent fluid for which d*uV* is given by Eq. (5.64) except we use partial densities ρ*i* instead of the mole concentrations *ci*, resulting in

<span id="page-177-3"></span>
$$\mathbf{d}\mu_V = T\,\mathbf{ds}_V + \sum_{l=1}^{\kappa} \mu_l^m \,\mathbf{d}\rho_l. \tag{11.9}$$

Then the general equilibrium criterion Eq. [(11.4)](#page-176-2) becomes

<span id="page-177-1"></span>
$$\int \left[ \frac{\partial \mathbf{u}_V}{\partial \mathbf{s}_v} \delta \mathbf{s}_V + \sum_{l=1}^{\kappa} \frac{\partial \mathbf{u}_V}{\partial \rho_l} \delta \rho_l + \mathbf{g} \mathbf{z} \delta \rho - \lambda \delta \mathbf{s}_V - \sum_{l=1}^{\kappa} \lambda_l^m \delta \rho_l \right] \mathbf{d}^3 \mathbf{x} \ge \mathbf{0}. \tag{11.10}$$

By identifying the partial derivatives, using δρ = κ *i*=1 δρ*i* and grouping terms, Eq. [(11.10)](#page-177-1) becomes

<span id="page-177-2"></span>
$$\int \left[ (T - \lambda) \delta \mathbf{s}_V + \sum_{l=1}^{\kappa} (\mu_l^m + \mathbf{g}z - \lambda_l^m) \delta \rho_l \right] \mathbf{d}^3 \mathbf{x} \ge \mathbf{0}. \tag{11.11}$$

Then by requiring Eq. [(11.11)](#page-177-2) to be true for all independent and arbitrary virtual variations δ*sV* and δρ*i*, both positive and negative, the only possibility is for their coefficients to be zero. Thus we obtain the κ + 1 conditions

$$T = \lambda \tag{11.12}$$

<span id="page-177-0"></span>3The corresponding chemical potentials μ*m i* are per unit mass and are related to those per mole by μ*m i* = μ*i*/*mi*, where the *mi* are molecular weights. Consistent with this change, we use total masses *Mi* = ρ*id*3*x* instead of total mole numbers *Ni*, so the Lagrange multipliers λ*m i* will have corresponding units.

and[4](#page-178-0)

<span id="page-178-1"></span>
$$
\mu_l^m + \mathbf{g}\mathbf{z} = \lambda_l^m; \quad i = 1, 2, \dots, \kappa. \tag{11.13}
$$

Therefore, at equilibrium, the temperature is constant and uniform, as anticipated in the discussion of Eq. [(11.4)](#page-176-2), but the chemical potentials μ*m i* of each chemical component are no longer uniform. Instead, the quantities μ*m i* + *gz*, which are often referred to as **gravitational chemical potentials**, are uniform. For this reason, the μ*m i* are often referred to as **intrinsic chemical potentials** because they are the same as those in the absence of external forces. Of course one could also incorporate the potential with *U* to form a new potential *U*˜ = *U* + whose density would have a differential

$$\mathbf{d}\tilde{\boldsymbol{\mu}}_{V} = T\,\mathbf{ds}_{V} + \sum_{l=1}^{k} (\mu_{l}^{m} + \mathbf{g}\mathbf{z})\,\mathbf{d}\rho_{l} \tag{11.14}$$

in which the gravitational chemical potentials appear directly.

According to Eq. [(11.13)](#page-178-1), values of the intrinsic chemical potentials will depend linearly on *z* at equilibrium. Through the Gibbs-Duhem equation, we can relate this to a dependence of the pressure on *z*. The Euler equation (see Eq. (5.43)) per unit volume can be written

<span id="page-178-2"></span>
$$\mathbf{u}_V = \mathbf{T}\mathbf{s}_V - \mathbf{p} + \sum_{l=1}^{k} \mu_l^m \rho_l. \tag{11.15}$$

By taking the differential of Eq. [(11.15)](#page-178-2) and subtracting Eq. [(11.9)](#page-177-3), the required Gibbs-Duhem equation is found to be

$$\operatorname{svd} T - \operatorname{d} p + \sum_{l=1}^{k} \rho_l \operatorname{d} \mu_l^m = 0. \tag{11.16}$$

However, we already know that the temperature is constant, so

<span id="page-178-3"></span>
$$\mathbf{d}p = \sum_{l=1}^{k} \rho_l \, \mathbf{d}\mu_l^m. \tag{11.17}$$

From Eq. [(11.13)](#page-178-1), dμ*m i* = − *g* d*z*, so Eq. [(11.17)](#page-178-3) yields

<span id="page-178-4"></span>
$$\mathbf{p}\,\mathrm{d}p = -\sum_{l=1}^{\kappa} \rho_l \mathbf{g}\,\mathrm{d}z = -\rho \mathbf{g}\,\mathrm{d}z,\tag{11.18}$$

where the total density ρ depends on pressure and the *local* composition. Of course Eq. [(11.17)](#page-178-3) can be invoked on the basis of mechanical equilibrium by using the mechanical interpretation of pressure, but here it arises naturally as a consequence of applying the laws of thermodynamics. For a single component liquid with negligible compressibility, ρ can often be treated as a constant and Eq. [(11.18)](#page-178-4) can be integrated to give *p* = ρ*gz* + *p*0,

<span id="page-178-0"></span><sup>4</sup>In terms of chemical potentials per mole, Eq. [(11.13)](#page-178-1) would be μ*i* + *migz* = λ*i*.

where *p*0 is the pressure at *z* = 0. In the case of a single component ideal gas of molecular weight *m*, ρ = *mp*/*RT* and Eq. [(11.18)](#page-178-4) can be integrated to give

<span id="page-179-0"></span>
$$p = p_0 \exp\left(-m\text{gz}/RT\right),\tag{11.19}$$

which is often called the **law of atmospheres**. Of course the atmosphere of the Earth is not a single component ideal gas and its temperature is not uniform, so Eq. [(11.19)](#page-179-0) would only provide a crude approximation to the decrease of its pressure with height.

Had we used Eq. [(11.6)](#page-176-3) at the outset, with *T* presumed to be imposed and uniform from the start, we could use the differential

$$\mathbf{d}\mathbf{f}_V = \sum_{l=1}^{\kappa} \mu_l^m \mathbf{d}\rho_l \tag{11.20}$$

and obtain

$$\int \left[ \sum_{l=1}^{k} (\mu_l^m + \mathbf{g}\mathbf{z} - \lambda_l^m) \delta \rho_l \right] \mathbf{d}^3 \mathbf{x} \ge \mathbf{0},\tag{11.21}$$

which for arbitrary δρ*i* of either sign leads immediately to Eq. [(11.13)](#page-178-1).

**Example Problem 11.1.** If a single chemical reaction is allowed, show that the conditions for equilibrium in a uniform gravitational field are the same as in the absence of such a reaction but there is an additional condition for the reaction to be in equilibrium.

**Solution 11.1.** When a chemical reaction is allowed in a homogeneous system, the differential of the number of moles of component *i* is given by combining Eqs. (5.120) and (5.123) to obtain d*Ni* = ν*i* d*N*˜ +d*N*ext *i* , where ν*i* is the stoichiometric coefficient for the reaction, d*N*˜ is the change in the progress variable of the reaction, and d*N*ext *i* is the number of moles of component *i* that enter the system from its exterior. For an inhomogeneous system having constant volume, we have

$$\delta N_l^{\text{ext}} = \int_V \left[ \delta \mathbf{c}_l - \nu_l \delta \tilde{\mathbf{c}} \right] \mathbf{d}^3 \mathbf{x}, \tag{11.22}$$

where *ci* is the concentration of component *i* in moles per unit volume and *c*˜ is the progress variable per unit volume. In order to assure chemical closure of our system, Eq. [(11.4)](#page-176-2) must be replaced by

<span id="page-179-1"></span>
$$
\delta (U + \Phi - \lambda S - \sum_{l} \lambda_l N_l^{\text{ext}}) \ge 0,\quad \text{constant } V, \text{ all virtual variations.}\tag{11.23}
$$

Given that the chemical reaction is expressed in terms of moles, it is expedient to express all other quantities in terms of the *ci* instead of the ρ*i*. For example, the density in Eq. [(11.7)](#page-177-4) for should be replaced by ρ = κ *i mici*. Thus Eq. [(11.23)](#page-179-1) becomes

$$\int \left[ (T - \lambda) \delta \mathbf{s} \boldsymbol{\nu} + \sum_{l=1}^{\kappa} (\mu_l + m_l \mathbf{g} \mathbf{z} - \lambda_l) \delta \mathbf{c}_l + \sum_{l=1}^{\kappa} \lambda_l \nu_l \delta \tilde{\mathbf{c}} \right] \mathbf{d}^3 \mathbf{x} \ge \mathbf{0}. \tag{11.24}$$

160 THERMAL PHYSICS

has the form μ*i* = μ0

$$\mathbf{0} = \sum_{l=1}^{\kappa} \lambda_l \boldsymbol{\nu}_l = \sum_{l=1}^{\kappa} [\mu_l + m_l \mathbf{g} \mathbf{z}] \boldsymbol{\nu}_l,\tag{11.25}$$

Arbitrary variation of *sV* gives Eq. (11.12) whereas arbitrary variation of *ci* gives μ*i* + *migz* = λ*i*, which is the same as Eq. (11.13) divided by *mi*. Arbitrary variation of *c*˜ gives an additional condition 0 = κ λ*i*ν*i* = κ [μ*i* + *migz*]ν*i*, (11.25)

### served in a chemical reaction, we have κ *i*=1 *mi*ν*i* = 0, so Eq. (11.25) reduces to κ which is the same as obtained in Section 5.7 (and also later in Chapter 12, Eq. (12.29)) in

<span id="page-180-0"></span>*i*=1

*i*=1

which is the condition for the chemical reaction to be in equilibrium. But since mass is con-

the absence of gravity. Nevertheless, the quantities μ*i* + *migz* in Eq. (11.25) are uniform in equilibrium, which shows clearly that the chemical reaction is in equilibrium at every height *z*, even though each μ*i* varies linearly with *z*. 11.2.1 Multicomponent Ideal Gas in Gravity

$$
\left(\frac{\partial \mu_l}{\partial p}\right)_{T, \{N_l\}} = (\partial V / \partial N)_{T, p, \{N'_l\}} = \frac{RT}{p},\tag{11.26}
$$

*i*=1 μ*i*ν*i* = 0,

of gas *i* and *ni* is its concentration in moles per unit volume. Its total pressure is *p* = κ *i*=1 *pi* = *NRT*/*V*. By a Maxwell relation readily obtained from d*G*, one has ∂μ*i* ∂*p T*,{*Ni*} = (∂*V*/∂*Ni*)*T*,*p*,{*N i* } = *RT p* , (11.26)

<span id="page-180-1"></span>
$$
\mu_l = RT \ln p + \mathcal{w}(T, \langle X_l \rangle),
\tag{11.27}
$$

*Ni* missing. If the *Ni* are constant, the compositions *Xi* are constant so we can integrate Eq. [(11.26)](#page-180-1) at constan[t comp](#page-180-1)osition and temperature to obtain μ*i* = *RT* ln *p* + *w*(*T*,{*Xi*}), (11.27)

$$
\mu_l = RT \ln p + RT \ln X_l + q_l(T), \tag{11.28}
$$

*i*. Therefore, this chemical potential has the form μ*i* = *RT* ln *p* + *RT* ln *Xi* + *qi*(*T*), (11.28)

where *qi*(*T*) is a function of only the temperature. In fact, Denbigh [18, p. 115] takes

*RT mi*

$$
\mu_l^m = \frac{RT}{m_l} \ln p_l + q_l^m(T) \tag{11.29}
$$

μ*m i* = *RT mi* ln*pi* + *qm i* (*T*) (11.29) for the chemical potential per unit mass of an ideal gas. Here, *qm i* (*T*) = *qi*(*T*)/*mi*. We take

$$\frac{RT}{m_l} \ln \frac{\mathbf{d}p_l}{p_l} = -\mathbf{g} \,\mathrm{d}z.\tag{11.30}$$

<span id="page-181-2"></span>
$$p_l = p_{l0} \exp(-m_l \text{gz}/RT),\tag{11.31}$$

$$p = \sum_{l=1}^{k} p_{l0} \exp(-m_l \text{gz}/RT). \tag{11.32}$$

Equation (11.30) can then be integrated to give

The composition at *z* is given by

$$X_l = \frac{p_l}{p} = \frac{p_{l0} \exp(-m_l \text{gz}/RT)}{\sum_{j=1}^{\kappa} p_{j0} \exp(-m_l \text{gz}/RT)}.\tag{11.33}$$

*p* = κ *i*=1 *pi*0 exp(−*migz*/*RT*). (11.32)

<span id="page-181-1"></span>
$$X_l = \frac{X_{l0} \exp(-m_l \text{gz}/RT)}{\sum_{j=1}^{\kappa} X_{j0} \exp(-m_l \text{gz}/RT)}\tag{11.34}$$
 
$$\text{howforno ho zwitteno}$$

κ *j*=1 *pj*0 exp(−*mjgz*/*RT*)

*Xi* = *pi*

$$p = p_0 \sum_{l=1}^{\kappa} X_{l0} \exp(-m_l \text{gz}/RT). \tag{11.35}$$

κ *j*=1 *Xj*0 exp(−*mjgz*/*RT*) (11.34) and the total pressure can therefore b[e writte](#page-178-4)n *p* = *p*0 κ *Xi*0 exp(−*migz*/*RT*). (11.35)

$$\rho = \sum_{l=1}^{\kappa} m_l n_l = n \sum_{l=1}^{\kappa} m_l X_l = \frac{p_0}{RT} \sum_{l=1}^{\kappa} m_l X_{l0} \exp(-m_l \text{gz}/RT). \tag{11.36}$$

little more complicated because

*mig* 

analogous to a canonical partition function for degenerate states.

ρ = κ *i*=1 *mini* = *n* κ *i*=1 *miXi* = *p*0 *RT* κ *i*=1 *miXi*0 exp(−*migz*/*RT*). (11.36) The reader is invited to verify that Eq. (11.18) is satisfied. Although Eq. (11.34) correctly describes the gravitational segregation of the chemical components of an ideal gas that have different molecular weights, it has been expressed in terms of composition in the plane *z* = 0. If the overall mole numbers *Ni*00 of a sample were known, one would have to integrate *ni* = *pi*/(*RT*) over *z* with due respect to the

<span id="page-181-0"></span>
$$N_{00} = \frac{p_0}{RT} \int_0^H A(\mathbf{z}) X_{00} \exp(-m_l \mathbf{g} \mathbf{z}/RT) \,\mathrm{d}z. \tag{11.37}$$

*Ni*00 = *p*0 *RT H A*(*z*)*Xi*0 exp(−*migz*/*RT*) d*z*. (11.37)

1 − exp(−*migH*/*RT*)

$$N_{000} = \frac{Ap_0 X_{l0}}{m_l \text{g}} \left[ 1 - \exp(-m_l \text{g}H/RT) \right]. \tag{11.38}$$

. (11.38)

<sup>5</sup>For future reference, we remark that the structure of Eq. (11.34) is exactly what one would expect from the canonical ensemble of statistical mechanics (see Chapters 18 and 19) in which case the denominator is

Then by using κ

yields

which

<span id="page-182-0"></span>
$$p_0 = \frac{1}{A} \sum_{l=1}^{\kappa} \frac{m_l N_{l00} \,\mathrm{g}}{\left[1 - \exp(-m_l \mathrm{g}H/RT)\right]}.\tag{11.39}$$

162 THERMAL PHYSICS

$$X_{l0} = \frac{m_l N_{l00}}{\left[1 - \exp(-m_l \text{g}H/RT)\right]} \left\{ \sum_{j=1}^{k} \frac{m_j N_{l00}}{\left[1 - \exp(-m_j \text{g}H/RT)\right]} \right\}^{-1} \,. \tag{11.40}$$

*p*0 = 1 *A* κ *i*=1 *miNi*00 *g* 1 − exp(−*migH*/*RT*) . (11.39)

This expression for *p*0 can be substituted into Eq. (11.38) to obtain *Xi*0 = *miNi*00 1 − exp(−*migH*/*RT*) ⎧ ⎨ ⎩ κ *j*=1 *mjNj*00 1 − exp(−*mjgH*/*RT*) ⎫ ⎬ ⎭ −1 . (11.40) Then by substitution of Eqs. (11.39) and (11.40) into Eqs. (11.34) and (11.35), one can determine exactly the composition and the pressure as a function of *z*. For samples of laboratory size, however, it is important to recognize that the effect of gravitational segregation on gases is extremely small. For example, for *H* = 1 m and *T* = 300 K one has *gH*/*RT* = 3.93 × 10−3 mol/kg. Thus for N2 (*mi* = 28 g/mol) and O2 (*mi* = 32 g/mol) one would have *migH*/*RT* equal to 1.1×10−4 and 1.26×10−4, respectively. Even for a heavy gas such as uranium hexafluoride UF6 (*mi* = 352 g/mol) one would have *migH*/*RT* = 1.4 × 10−3. Therefore, for samples of laboratory size, one has *migH*/*RT* 1 and the above expressions for ideal gases can be expanded in these small quantities. If we keep o[nly lin](#page-182-0)ear terms in *migH*/*RT* and *migz*/*RT*, the pressure and the compositions

$$p \approx \frac{N \text{q} RT}{V} + \frac{M \text{q} \text{g}}{A} \left(\frac{1}{2} - \frac{z}{H}\right) = \frac{N \text{q} RT}{V} \left[1 + \frac{\bar{m} \text{g} H}{RT} \left(\frac{1}{2} - \frac{z}{H}\right)\right];\tag{11.41}$$

$$X_l \approx \frac{N_{l00}}{N_{l00}} \left[ 1 + (m_l - \bar{m}) \frac{\text{gH}}{\text{RT}} \left( \frac{1}{2} - \frac{z}{H} \right) \right]. \tag{11.42}$$
 
$$\dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \tag{11.42}$$

*p* ≈ *N*00*RT V* + *A* 2 − *z H* = *N*00*RT V* 1 + *mgH* ¯ *RT* 1 2 − *z H* ; (11.41) *Xi* ≈ *Ni*00 *N*00 1 + (*mi* − *m*¯ ) *gH RT* 1 2 − *z H* . (11.42) Equation (11.41) shows that the pressure, largest at the bottom and smallest at the top, is equal to its value in the absence of gravity plus a linear correction related to the mass of the gas. According to Eq. (11.42), the composition is given by the overall composition times a

### linear function that either decreases or increases with height depending on whether the molecular weight is smaller or larger than the average molecular weight.

μ*m*

μ*m*

11.2.2 Binary Liquid in Gravity A binary liquid in a uniform gravitational field will also undergo segregation of its *A* and *B* species but the situation is different from that of a gas because a liquid is much denser and comparatively incompressible. We carry out the calculation for an ideal solution for

<span id="page-182-1"></span>
$$
\mu_A^m = \mu_A^{m0}(p, T) + \frac{RT}{m_A} \ln X_{\text{A}};\tag{11.43}
$$

$$
\mu_B^m = \mu_B^{m0}(p, T) + \frac{\stackrel{\cdots \pi_n}{RT}}{m_B} \ln X_B,\tag{11.44}
$$

$$
\mu_A^{m0}(\mathbf{p}, T) - \mu_A^{m0}(\mathbf{p}_0, T) + \frac{RT}{m_A} \ln(\mathbf{X}_{\text{A}}/\mathbf{X}_{\text{A0}}) + \mathbf{g}z = \mathbf{0};\tag{11.45}
$$

<span id="page-183-1"></span><span id="page-183-0"></span>
$$
\mu_B^{m0}(p, T) - \mu_B^{m0}(p_0, T) + \frac{RT}{m_B} \ln(X_{\text{B}}/X_{\text{B0}}) + \text{gz} = 0. \tag{11.46}
$$

where μ*m*0 *A* (*p*, *T*) and μ*m*0 *B* (*p*, *T*) correspond to standard states of pure *A* and *B*, respectively. We substitute into Eq. (11.13) and identify the Lagrange multipliers by setting *z* = 0, where we denote the pressure by *p*0 and the compositions by *XA*0 and *XB*0, to obtain μ*m*0 *A* (*p*, *T*) − μ*m*0 *A* (*p*0, *T*) + *RT mA* ln(*XA*/*XA*0) + *gz* = 0; (11.45) μ*m*0 *B* (*p*, *T*) − μ*m*0 *B* (*p*0, *T*) + *RT* ln(*XB*/*XB*0) + *gz* = 0. (11.46)

$$\frac{1}{\rho_A}(p - p_0) + \frac{RT}{m_A} \ln(\mathcal{X}_A / \mathcal{X}_{A0}) + \text{gz} = \mathbf{0};\tag{11.47}$$

$$\overset{\cdots}{\frac{1}{\rho_{\text{B}}}}(\text{p}-\text{p}0) + \frac{RT}{m_{\text{B}}} \ln(\text{X}_{\text{B}}/\text{X}_{\text{B0}}) + \text{gz} = \text{0.} \tag{11.48}$$

constants in order to obtain a tractable problem. This results in 1 ρ*A* (*p* − *p*0) + *RT mA* ln(*XA*/*XA*0) + *gz* = 0; (11.47) 1 ρ*B* (*p* − *p*0) + *RT mB* ln(*XB*/*XB*0) + *gz* = 0. (11.48) Since *XB* = 1 − *XA* we could solve Eqs. (11.47) and (11.48) simultaneously for *XA* and

$$(p - p_0) + \frac{\rho_A RT}{m_A} \frac{(X_A - X_{t0})}{X_{A0}} + \rho_A \mathbf{gz} = \mathbf{0};\tag{11.49}$$

$$(p - p_0) - \frac{\rho_\text{BRT}}{m_\text{B}} \frac{(X_\text{A} - X_\text{A0})}{X_\text{B0}} + \rho_\text{Bgz} = \mathbf{0}.\tag{11.50}$$

(*p* − *p*0) + ρ*ART mA* (*XA* − *XA*0) *XA*0 + ρ*Agz* = 0; (11.49)

*f*

+ 1 − *f*

If ρ*A* > ρ*B*, we observe that *XA* decreases with increasing *z* as would be expected. Finally,

$$(X_A - X_{A0}) \left[ \frac{f}{X_{A0}} + \frac{1 - f}{X_{B0}} \right] = -\frac{m^* \text{gz}}{RT},\tag{11.51}$$

where

equations

given by ∂μ*m*

*A* /∂*p* = ∂μ*m*0

<span id="page-183-2"></span>
$$f = \frac{\rho_{\text{A}}/m_{\text{A}}}{\rho_{\text{A}}/m_{\text{A}} + \rho_{\text{B}}/m_{\text{B}}}; \quad m^* = \frac{\rho_{\text{A}} - \rho_{\text{B}}}{\rho_{\text{A}}/m_{\text{A}} + \rho_{\text{B}}/m_{\text{B}}}. \tag{11.52}$$

*p* − *p*0 = −ρ∗*gz*, (11.53)

*f* = ρ*A*/*mA* ρ*A*/*mA* + ρ*B*/*mB* ; *m*∗ = ρ*A* − ρ*B* ρ*A*/*mA* + ρ*B*/*mB* . (11.52)

= −*m*∗*gz*

$$
\mathbf{p} - \mathbf{p}_0 = -\rho^* \mathbf{g} \mathbf{z},\tag{11.53}
$$

where

$$\rho^* = \frac{\rho_A \rho_B (m_A X_{A0} + m_B X_{B0})}{\rho_A m_B X_{B0} + \rho_B m_A X_{A0}}.\tag{11.54}$$

164 THERMAL PHYSICS

### Thus the pressure always decreases linearly with height *z*, but the weighting of densities

 = *V*

μ*m*

is not obvious. Incidentally, if ρ*A* = ρ*B*, there is no segregation and the pressure increases with ρ∗ equal to their common density. As compared to a binary ideal gas, the magnitude

$$\Phi = \int_{V} \rho \,\varphi(\mathbf{r}) \,\mathrm{d}^3 \mathbf{x} + \text{constant},\tag{11.55}$$

11.3 Non-Uniform Gravitational Field For a non-uniform gravitational field, Eq. (11.7) can be written

<span id="page-184-0"></span>
$$
\varphi(\mathbf{r}) = -\frac{\mathcal{M}G}{r},\tag{11.56}
$$

where ϕ(**r**) is the gravitational potential (potential energy per unit mass) at position **r**. For example, the gravitational potential du[e](#page-184-0) [to](#page-184-0) [at](#page-184-0)tractio[n](#page-181-2) [by](#page-181-2) [th](#page-181-2)e Earth, whose center of mass is assumed to be located at the origin, would be

$$
\mu_l^m + \varphi(\mathbf{r}) = \lambda_l^m; \quad \mathbf{i} = 1, 2, \dots, \kappa. \tag{11.57}
$$

where *r* = |**r**|, *M* is the mass of the Earth and *G* = 6.67 × 10−11 m3 kg−1 s−2 is the universal gravitational constant. Since ϕ(**r**) is the same for all chemical species, Eq. (11.13) be[comes](#page-181-2) simply

$$p_l = p_{l0} \exp\left[-\frac{m_l MG}{RT} \left(\frac{1}{r_0} - \frac{1}{r}\right)\right],\tag{11.58}$$

0 .

multicomponent gas would be replaced by *pi* = *pi*0 exp −*miMG RT*  1 *r*0 − 1 *r* , (11.58) where *r* is the distance to the center of gravity of the Earth and *r*0 is a reference distance

where the partial pressure is *pi*0. This result is not significantly different from Eq. (11.31) for a constant gravitational acceleration unless *r* varies by large distances compared to *r*0.

## Indeed, for |(*r* − *r*0)/*r*0| 1, the effective gravitational acceleration would be *g* = *MG*/*r*2

11.4 Rotating Systems A system undergoing uniform rotation at an angular velocity ω about some axis behaves as if it were in a non-uniform gravitational field with potential (potential energy per unit mass) ϕ = − *r*2 ⊥ω2/2, where *r*⊥ is the distance from the axis of rotation. This result follows because the corresponding force per unit mass would be −dϕ/d*r*⊥ = *r*⊥ω2 and would be directed radially outward. This is just the centrifugal acceleration (centrifugal force per unit mass) that is experienced in a rotating coordinate system. The work done by this external force when a mass *m* moves from *r*⊥ =0 to *r*⊥ is just

$$\int_0^{r_\perp} m r'_\perp \omega^2 \,\mathrm{d}r'_\perp = m r_\perp^2 \omega^2 / 2 = -m\wp. \tag{11.59}$$

*r*⊥

*mr*

$$
\mu_l^m - r_\perp^2 \alpha^2 / 2 = \lambda_l^m; \quad \mathbf{i} = 1, 2, \dots, \kappa. \tag{11.60}
$$

*Chapter 11* • External Forces and Rotating Coordinate Systems 165

$$p_l = p_{l0} \exp(m_l r_\perp^2 \alpha^2 / 2RT),\tag{11.61}$$

0 Thus Eq. (11.57) becomes μ*m i* − *r*2 ⊥ω2/2 = λ*m i* ; *i* = 1, 2, ... , κ. (11.60) For the partial pressure of a multicomponent ideal gas, one therefore obtains *pi* = *pi*0 exp(*mir*2 ⊥ω2/2*RT*), (11.61) which differs from Eq. (11.31) in two important ways: the exponential depends on the

square of the distance *r*⊥ and ω2 can be quite large in the sense that *r*⊥ω2 *g*. Thus, in

a fast centrifuge, the components of such a gas with sufficiently different *mi* can undergo significant segregation of components. To achieve significant segregation of components

negligible.

with only slightly different *mi*, such as isotopes, one would have to make *r*2 ⊥ω2 as large as practical and employ a multi-stage process wherein the enriched portion of each stage is used as the starting sample for the next stage. **Example Problem 11.2.** A circular cylinder with axis of symmetry along the *z* axis contains a monocomponent liquid that is practically incompressible and therefore has constant density ρ. The cylinder is rotated at constant angular [veloc](#page-178-3)ity ω. The liquid is also in a constant

function of position in the cylinder. Determine the shape of the isobars and comment on the

*p* − *p*0 = ρ

atmosphere to the extent that capillary effects (see Chapter 13) are negligible.

<span id="page-185-0"></span>gravitational field *g* directed downward, a[ntipara](#page-185-0)llel to *z*. Find the pressure of the liquid as a

$$
\mu^m - (\mathbf{x}^2 + \mathbf{y}^2)\omega^2/2 + \mathbf{g}\mathbf{z} = \lambda^m. \tag{11.62}
$$

**Solution 11.2.** The governing equation for the chemical potential is μ*m* − (*x*2 + *y*2)ω2/2 + *gz* = λ*m*. (11.62)

$$p - p_0 = \rho \left[ (\mathbf{x}^2 + \mathbf{y}^2) \alpha^2 / 2 - \mathbf{g} \mathbf{z} \right]. \tag{11.63}$$

The isobars satisfy

$$z = \frac{\alpha^2}{2\mathbf{g}}(\mathbf{x}^2 + \mathbf{y}^2) + \frac{p_0 - p}{\rho} \tag{11.64}$$

. (11.63)

*z* = ω2 2*g* (*x*2 + *y*2) + *p*0 − *p* ρ (11.64) and each has the shape of a parabola of revolution whose lowest point is along the axis of rotation. The upper free surface of the liquid will also have this parabolic shape with *p* = 1

(*x*2 + *y*2)ω2/2 − *gz*

position **r** is

can be replaced by

166 THERMAL PHYSICS

$$\int_{\mathbf{r}_0}^{\mathbf{r}} z_l |e| \mathbf{E} \cdot d\mathbf{r} = z_l |e| [\phi(\mathbf{r}_0) - \phi(\mathbf{r})] = -\mathcal{W}.\tag{11.65}$$

11.5 Electric Fields We consider a single phase multicomponent fluid in the presence of an electric field **E** =−∇φ, where φ(**r**) is the electrical potential. If species *i* carries an electric charge *zi*|*e*|, the work done by the field in moving that charge from a reference position **r**0 to

$$\Phi = \int_{V} \sum_{l} z_{l} |e| \phi(\mathbf{r}) \mathcal{N}_{\mathbf{A}} \mathbf{c}_{l} \, \mathbf{d}^{3} \mathbf{x} = \int_{V} \sum_{l} z_{l} \phi(\mathbf{r}) \mathcal{F} \mathbf{c}_{l} \, \mathbf{d}^{3} \mathbf{x}, \tag{11.66}$$

In electrochemistry, *zi* is regarded to be the valence of each species. For convenience we take the reference potential φ(**r**0) = 0 in which case the total potential of Eq. (11.6) can be written in the form

$$\int_{V} \sum_{l} \left[ \mu_{l} + \mathbf{z}_{l} \phi(\mathbf{r}) \mathcal{F} - \lambda_{l} \right] \delta \mathbf{c}_{l} \, \mathbf{d}^{3} \mathbf{x} \ge \mathbf{0} \tag{11.67}$$
 
$$\mathbf{z}_{l}, \mathbf{z}_{l}, \dots, \mathbf{z}_{l}, \dots, \mathbf{z}_{l}, \dots, \mathbf{z}_{l}$$

number and *F* = |*e*|*N*A = 96,485 coulomb/mol is the Faraday constant. Then Eq. (11.21)

*i*

 = *V* -

$$
\lambda \mu_l + \mathbf{z}_l \phi(\mathbf{r}) \mathcal{F} = \lambda_l. \tag{11.68}
$$

*V i* [μ*i* + *zi*φ(**r**)*F* − λ*i*] δ*ci* d3*x* ≥ 0 (11.67) which leads to the equilibrium equations μ*i* + *zi*φ(**r**)*F* = λ*i*. (11.68)

$$
\mu_l^a + q_l \phi(\mathbf{r}) = \lambda_l^a,\tag{11.69}
$$

*i* , the equilibrium equations can be

instead of per mole. If we designate this quantity by μ*a* written in the form

μ*a i* + *qi*φ(**r**) = λ*a i* , (11.69) where *qi* is the charge carried by species *i*. When dealing with heterogeneous equilibrium among phases of various composition, a word of caution is in order because relative electrical potentials can become ill-defined due to surface potentials and different chemical environments that a test charge encoun-

ters when entering a material from infinity, where the potential is taken to be zero. For a

discussion of the equilibrium for transfer between phases, see Denbigh [18, p. 86].

12 Chemical Reactions We regard chemical reactions to be the formation or dissociation of chemical molecules or compounds in which no chemical elements are created or destroyed. In other words, *we exclude nuclear reactions* in which new nuclei can form and during which there is a change *m*0 in the rest mass *m*0, resulting in a change of energy given by the Einstein relation -*E* = *m*0*c*2 where *c* is the speed of light. By excluding nuclear reactions, both mass and energy are separately conserved during chemical reactions and the first law of thermodynamics, which embodies the conservation of energy, applies in the form presented in Chapter 2 for a chemically closed system. Therefore, if a chemical reaction occurs in an *isolated* system, the change in internal energy from initial to

final state if*U* := *U*f − *U*i = 0.1 Microscopically this makes sense because the internal energy consists of kinetic energy and potential energy associated with chemical bonds or intermolecular forces. The making or breaking of chemical bonds during chemical reactions in an isolated system involves a redistribution of kinetic an[d](#page-187-0) [p](#page-187-0)otential energy,

<span id="page-187-1"></span>
$$
\sum_{l} \nu_{l} A_{l} = \mathbf{0},
\tag{12.1}
$$

parts, d*Ni* = dint*Ni* + dext*Ni*, where dint*Ni* is due to chemical reactions and dext*Ni* is due to exchanges with the environment. We write a chemical reaction in the symbolic form - *i* ν*iAi* = 0, (12.1) where the *Ai* are chemical symbols and the ν*i* are stoichiometric coefficients that are

$$\mathbf{d}N_l^{\rm int} = \nu_l \,\mathbf{d}\tilde{\mathbf{N}}.\tag{12.2}$$

example. Then if *N*˜ is the progress variable for the reaction, we will have2 d*N*int *i* = ν*i* d*N*˜ . (12.2) Here, *N*˜ has the dimensions of moles; it is zero when the reaction begins and *N*˜ final

<span id="page-187-0"></span>when the [reaction ends. In this chapter, we c](http://dx.doi.org/10.1016/B978-0-12-803304-3.00012-0)onsider only chemically closed systems, so

.

*i* .

but no net change of energy.

dext*Ni* = 0 and d*Ni* = d*N*int

<sup>1</sup>In this section we add subscripts to quantities such as if*U* and if*H* to emphasize that these symbols denote the change from initial to final states. This is to avoid confusion with the standard notation for such

quantities as -*H* in Eq. (12.13), which is actually a derivative of *H* with respect to the progress variable *N*˜ . 2The generalization to multiple chemical reactions is straightforward. One needs only to add a superscript *s s* ν*s i* d*N*˜ *s*

is a volume change -

168 THERMAL PHYSICS

$$
\Delta_{\text{fl}}U = Q, \quad \text{constant volume, chemicalally closed}, \tag{12.3}
$$

12.1 Reactions at Constant Volume or Pressure Chemical reactions are typically carried out either at constant volume or at constant pressure. Those involving gases can usually be carried out easily at constant volume because the gases can be contained in a strong and nearly inert solid container. Then the work *W* = 0, so the change in internal energy of the gases is if*U* = *Q*, constant volume, chemically closed, (12.3) where the heat *Q* is positive if added to the gases and negative if extracted from the gases. If the reaction vessel is thermally insulated, the reaction will result in a change of temperature that can be measured. For example, a **bomb calorimeter** is a rigid vessel with a known heat capacity *C*cal that is large compared to the heat capacity of the gases undergoing reaction. Typically it is filled with oxygen at high pressure and some fuel that

<span id="page-188-0"></span>is burned to completion during the reaction. If the calorimeter is well insulated from its surroundings and its temperature changes by if*T*, then *Q* = −*C*if*T*, where *C* is the heat capacity of the calorimeter and the gases. To extent that the heat capacity of the gases can be neglected, *C*calif*T* represents the energy that is converted from chemical bond energy as a result of the reaction. Of great practical importance, howev[er,](#page-188-0) [are](#page-188-0) chemical reactions that are carried out such that the only work done is against a constant external pressure *p*ext. In such reactions, there

$$
\Delta \!\!\!\!\!\!\/} \!\!\!\!\!\!\/) + p_{\text{ext}} \Delta \!\!\!\!\/) V = Q. \tag{12.4}
$$

the atmosphere might provide the constant external pressure in industrial reactions. The work done by the system will then be *W* = *p*extif*V* and from the first law we will have if*U* + *p*extif*V* = *Q*. (12.4)

$$
\Delta_{\rm H}H = Q, \quad \text{constant pressure, chemicalally closed}, \tag{12.5}
$$

enthalpy *H* = *U* + *pV* in which case Eq. (12.4) takes the form if*H* = *Q*, constant pressure, chemically closed, (12.5) where *Q* is the heat added to the reacting system. Thus the enthalpy *H* plays the same role

$$\mathbf{d}H = T\,\mathbf{dS} + V\,\mathbf{dp} + \sum_{l} \mu_{l}\,\mathbf{dN}_{l}.\tag{12.6}$$

d*H* = *T* d*S* + *V* d*p* +*i* μ*i* d*Ni*. (12.6) However, for practical purposes it is more convenient to use the temperature instead of

$$\mathbf{d}H = \left(\frac{\partial H}{\partial T}\right)_{p,N_l} \mathbf{d}T + \left(\frac{\partial H}{\partial p}\right)_{T,N_l} \mathbf{d}p + \sum_l \ddot{H}_l \, \mathbf{dN}_l,\tag{12.7}$$

*i*

*Chapter 12* • Chemical Reactions 169

$$\mathrm{d}H = \mathrm{C}_{p}\mathrm{d}T + V(1 - \alpha T)\,\mathrm{d}p + \sum_{l} \hat{H}_{l}\,\mathrm{d}N_{l}.\tag{12.8}$$

to depend on *T*, *p*, *Ni*, we readily establish that *H*¯ *i* = μ*i* − *TS*¯ *i* and ∂*H*/∂*p T*,*Ni* = *V* +

*T* ∂*S*/∂*p T*,*Ni*

readily yields

<span id="page-189-1"></span><span id="page-189-0"></span>∂*S*/∂*p* 

$$\mathbf{d}H = \mathbf{C}_p \mathbf{d}T + V(\mathbf{1} - \alpha T)\,\mathbf{d}p + (\sum_l v_l \bar{H}_l)\,\mathbf{d}\tilde{N}.\tag{12.9}$$

d*H* = *Cp* d*T* + *V*(1 − α*T*) d*p* +- *i H*¯ *i* d*Ni*. (12.8)

$$H = \sum_{l} N_{l} \bar{H}_{l}.\tag{12.10}$$

*i* Since *T* and *p* are intensive variables, the Euler equation for the enthalpy (see Eq. (5.101)) is just *H* = - *NiH*¯ *i*. (12.10)

$$H(T, p, N_l) = \sum_l (N_l^0 + \nu_l \tilde{N}) H_l,\tag{12.11}$$

are evaluated at *p*, *T* and the corresponding composition. At any stage of the reaction, *Ni* = *N*0 *i* + ν*iN*˜ , where *N*0 *i* is the initial value of *Ni*. The Euler equation (12.10) becomes *H*(*T*, *p*, *Ni*) = - (*N*0 *i* + ν*iN*˜ )*H*¯ *i*, (12.11)

*i*

where it is understood that the *H*¯ *i* are to be evaluated at the corresponding composition,

temperature, and pressure. **Example Problem 12.1.** For the chemical reaction given by Eq. (5.122), namely C+(1/2)O2 → CO, assume initially that the mole numbers are *N*0 C = 3, *N*0 O2 = 1, and *N*0 CO = 2. If conditions are such that the reaction goes to the right until one of the reactants is completely used, what is the value of *N*˜ final and how many moles of each component will there be? Answer the same

question under different conditions for which the reaction goes to the left until all of the CO is used. **Solution 12.1.** The stoichiometric coefficients ν*i* for C, O2, and CO are −1, −1/2, and 1, respectively. For either the forward or backward reaction we have *N*C = 3−*N*˜ , *N*O2 = 1−(1/2)*N*˜ , and *N*CO = 2 + *N*˜ . The reaction can go to the right until *N*˜ final = 2 = *N*˜max in which case *N*C = 1, *N*O2 = 0, and *N*CO = 3. The reaction can go to the left until *N*˜ final = −1 = *N*˜ min in which case *N*C = 4, *N*O2 = 3/2, and *N*CO = 0. The actual direction of the reaction and the extent of reaction will depend on the conditions under which the reaction is carried out, particularly the temperature. For conditions to be discussed below, the reaction may reach equilibrium at some value *N*˜ min ≤ *N*˜ final ≤ *N*˜ max.

becomes simply

and Prigogine [14, p. 52] treat -

<span id="page-190-0"></span>
$$-Q_p = H(T_{\text{final}}, p, N_l^0 + \nu_l \tilde{N}_{\text{final}}) - H(T_{\text{initial}}, p, N_l^0). \tag{12.12}$$

170 THERMAL PHYSICS 12.1.1 Heat of Reaction

$$
\Delta H \equiv -Q_{\tilde{N}} := \sum_{l} v_{l} H_{l} = \left(\frac{\partial H}{\partial \tilde{N}}\right)_{T, p}. \tag{12.13}
$$

$$
\dots \quad . \qquad \dots \quad . \qquad . \qquad . \qquad . \qquad \dots \quad . \qquad \dots \quad . \qquad . \qquad . \qquad . \qquad . \qquad . \qquad . \qquad . \qquad . \qquad . \qquad .
$$

− *Qp* = *H*(*T*final, *p*, *N*0 *i* ). (12.12) But *Qp* is not a very useful way to characterize a reaction because it depends specifically on the initial conditions. A much more useful quantity is the derivative of *H* with respect to the progress variable *N*˜ at constant temperature and pressure, namely -*H* ≡ −*QN*˜ := - *i* ν*iH*¯ *i* = ∂*H* ∂*N*˜ *T*,*p* . (12.13) This quantity is commonly called "the -*H* of the reaction" but that is somewhat of a misnomer because it is a derivative. In particular, -*H* should not be confused with −*Qp* for a specific reaction, which is the difference in enthalpy between final and initial states given by Eq. (12.12). *QN*˜ = −-*H* is the heat *liberated* by the reaction per unit change of the progress variable at constant *p* and *T*. Callen [2, p. 170] refers to -*H* as the **heat of**

**reaction** and suggests that it be evaluated near the equilibrium state; however, depending on conditions, a specific reaction might go to completion before the equilibrium state is reached. For *QN*˜ = −-*H* > 0, the reaction is said to be *exothermic* whereas for *QN*˜ = −-*H* < 0, the reaction is said to be *endothermic*. 3 In Section 12.3 we will relate -*H* to the -*G* of the reaction.

$$
\mu_l(T, p, X_l) = \mu_l(T, p) + RT \ln X_l,\tag{12.14}
$$

is the enthalpy per mole of the respective pure component. This follows for a solu[tion](#page-190-0) [of](#page-190-0) ideal gases because the chemical potentials

$$H_l = \frac{\partial(\mu_l(T, p, X_l)/T)}{\partial(1/T)} = \frac{\partial(\mu_l(T, p)/T)}{\partial(1/T)} = H_l(T, p),\tag{12.15}$$

the total pressure is *p* and the partial pressure is *pi* = *pXi*. Thus, *H*¯ *i* = ∂(μ*i*(*T*, *p*, *Xi*)/*T*) ∂(1/*T*) = ∂(μ*i*(*T*, *p*)/*T*) ∂(1/*T*) = *Hi*(*T*, *p*), (12.15) so there is no heat of mixing for an ideal solution. Under these conditions, the initial

$$
\Delta H = \sum_{l} v_{l} H_{l}(T, p), \quad \text{heterogeneous components}, \tag{12.16}
$$

-*H* = *i* ν*iHi*(*T*, *p*), heterogeneous components, (12.16)

for which there is extensive tabulation of data as discussed in the next section. 3Unfortunately, various authors use different terminology. Kondepudi and Prigogine [14, p. 53] associate the quantity ∂*U*/∂*N*˜ *T*,*V* = *i* ν*iU*¯ *i* with endothermic and exothermic reactions. Lupis [5, p. 10] and Kondepudi

*H* for the case in which the constituents are not in solution.

<span id="page-191-0"></span>*Chapter 12* • Chemical Reactions 171 12.2 Standard States We shall define the **standard state** of an element or compound to be its *most stable*

*state* at a pressure *p*0 = 101,325 Pa = 1 standard atmosphere and at the temperature *T* of relevance.4 The enthalpy of *one mole* of an element or compound in its standard

$$
\Delta H^{\emptyset}(T, p_0) = \sum_l \nu_l H^{\emptyset}_l(T, p_0). \tag{12.17}
$$

*T*0 = 298.15 K = 25 ◦C. Here, the superscript 0 reminds us that the element or compound

-

-

∂*N*˜

*i*

*T*,*p*0

$$
\Delta H^0(T, p_0) = \left(\frac{\partial H}{\partial \tilde{N}}\right)_{T, p_0}, \quad \text{all constituents in their standard states.}\tag{12.18}
$$

-*H*0(*T*, *p*0) = *i* ν*iH*0 *i* (*T*, *p*0). (12.17) Note that *H*0(*T*, *p*0) = ∂*H* 

$$
\Delta H^{\emptyset}(T_0, p_0) = \sum_l \nu_l H^{\emptyset}_l(T_0, p_0),
\tag{12.19}
$$

function. This was discovered empirically and is known as Hess's law. A quantity that is tabulated extensively is

$$
\Delta H^{0}(T, p_{0}) = \Delta H^{0}(T_{0}, p_{0}) + \sum_{l} \upsilon_{l} [H^{0}_{l}(T, p_{0}) - H^{0}_{l}(T_{0}, p_{0})].\tag{12.20}
$$

which is the value of -*H*0 at *both* standard temperature *T*0 and pressure *p*0. It follows that -*H*0(*T*, *p*0) = -*H*0(*T*0, *p*0) +- *i* ν*i*[*H*0 *i* (*T*, *p*0) − *H*0 *i* (*T*0, *p*0)]. (12.20) The quantity -*H*0(*T*0, *p*0) is especially valuable because for many reactions, the gases in the reaction behave approximately as ideal gases in an ideal solution (even though they react occasionally due to collisions) so the partial molar quantities *H*¯ *i* are very nearly equal to the molar values *Hi*(*T*, *p*) for pure constituents (see Eq. (12.15)). Second, for ideal gases, α = 1/*T*, so the term *V*(1 − α*T*) in Eq. (12.8) vanishes, and would be expected to be small even for real gases. For heterogeneous solids and liquids that are not in solution,

$$
\Delta H^{\mathbb{0}}(T_0, \mathfrak{p}) = \sum_{l} \nu_l H_l(T_0, \mathfrak{p}) \approx \sum_{l} \nu_l H_l(T_0, \mathfrak{p}_0) = \Delta H^{\mathbb{0}}(T_0, \mathfrak{p}_0). \tag{12.21}
$$

*i*

standard state to be the most stable state of the pure constituent at temperature *T* and pressure *p*.

<sup>4</sup>For gases, the standard state is usually defined as the state in which the fugacity is equal to the pressure *p*, as *p* → 0, which would make a small difference if the gas did not behave like an ideal gas at *p*0. Other definitions of standard states, such as solutions of a specified concentration, are sometimes used. We could also define a

172 THERMAL PHYSICS

reactants and products is

$$
\Delta C_{p} = \sum_{l} \nu_{l} C_{pl},
\tag{12.22}
$$

$$
\Delta H^{0}(T, p) \approx \Delta H^{0}(T_{0}, p_{0}) + \int_{T_{0}}^{T} \Delta C_{p} \, \mathrm{d}T.\tag{12.23}
$$

ν*i Cpi*, (12.22)

### where the *Cpi* are heat capacities at constant pressure of the pure reactants and produ[ct](#page-192-0)s.

12.2.1 Heat of Formation

Then -*H*0(*T*, *p*) ≈ -*H*0(*T*0, *p*0) + *T T*0 -*Cp* d*T*. (12.23)

<span id="page-192-2"></span>
$$
\Delta H^{0}(T, p_{0}) = \sum_{l} v_{l} H_{f}^{0}(T, p_{0}).\tag{12.24}
$$

*f* (*T*, *p*0). (12.24)

ature *T*, everything in its standard state at pressure *p*0, is called the **heat of formation** and is designated by *H*0 *f* (*T*, *p*0). Since elements cannot be created by chemical reaction,5 it

<span id="page-192-1"></span>*H*0(*T*, *p*0) = -

follows that the heat of formation of an element is zero. Moreover, -

-

*Cp* = -

*i*

several hundred kJ/mol.

*i* Note in the sum that the only contribution comes from compounds.

ν*iH*0

$$\text{H}_2(\text{gas}) + \text{CO}_2(\text{gas}) \rightarrow \text{CO}(\text{gas}) + \text{H}_2\text{O}(\text{liquid}). \tag{12.25}$$

are −285.8 kJ/mol, −393.5 kJ/mol, and −110 kJ/mol, respectively. Discuss the relevant chemical reactions. Then compute -*H*0(*T*0, *p*0) for the reaction

- H2(gas) + CO2(gas) → CO(gas) + [H](#page-192-1)2[O](#page-192-1)(liquid). (12.25) **Solution 12.2.** The relevant reactions for compound formation are: H2(gas) + (1/2)O2(gas) → H2O(liquid),
<span id="page-192-0"></span>C(graphite) + O2(gas) → CO2(gas),

$$
\Delta H^{0}(T_{0}, p_{0}) = (-285.8 - 110 + 393.5)\,\text{kJ/mol} = -2\,\text{kJ/mol.}\tag{12.26}
$$

For the reaction given by Eq. (12.25), we have -*H*0(*T*0, *p*0) = (−285.8 − 110 + 393.5) kJ/mol = −2 kJ/mol. (12.26)

Note the sign change for CO2 because it is a reactant in Eq. (12.25).

<sup>5</sup>Recall that nuclear reactions are excluded. If 2 moles of deuterium react to form one mole of 3He and a neutron, about 3 × 108 kJ/mol are released. Heats of formation of most chemical compounds are typically only

<span id="page-193-2"></span><span id="page-193-1"></span>
$$\mathbf{d}G = -\mathbf{S}\,\mathrm{d}T + V\,\mathrm{d}p + \sum_{l} \mu_{l}\,\mathrm{d}N_{l}.\tag{12.27}$$

12.[3](#page-193-0) Equilibrium and Affinity We now examine the conditions under which a chemical reaction is in equilibrium and the direction that the reaction will proceed if it is not in equilibrium. For a multicomponent

$$\mathbf{d}G = -\mathbf{S}\,\mathrm{d}T + V\,\mathrm{d}p + (\sum_{l} \nu_{l}\mu_{l})\,\mathrm{d}\tilde{N}.\tag{12.28}$$

As before, we assume that d*Ni* = dint*Ni* + dext*Ni*, that the system is chemically closed so that dext*Ni* = 0, and that d*Ni* = dint*Ni* = ν*i*d*N*˜ due to chemical reaction, as in Eq. (12.2).

*i*

$$\left(\frac{\partial G}{\partial \tilde{N}}\right)_{p,T} = \sum_{l} \upsilon_{l} \mu_{l} = \mathbf{0}.\tag{12.29}$$

For a chemically closed system at constant *p* and *T*, we know that *G* is a minimum at

<span id="page-193-0"></span>depen[ds on](#page-193-1) the initial values *N*0

Belgian school of thermodynamics [14, p. 104].

left. For -

Then6

$$
\Delta G \equiv -\mathcal{A} := \sum_{l} \nu_{l} \mu_{l} = \left(\frac{\partial G}{\partial \tilde{N}}\right)_{p,T} \tag{12.30}
$$

*p*,*T i* The notations -*G* ≡ −*A* := - *i* ν*i*μ*i* = ∂*G* ∂*N*˜ *p*,*T* (12.30) are common. *A* is called the **affinity**7 of the reaction and is usually used in irreversible thermodynamics. The other notation, "the -*G* of the reaction" is somewhat of a misnomer because it is reall[y a derivative](#page-194-0) of *G* with respect to the progress variable *N*˜ and should not be confused with the actual change in *G* from beginning to end of the reaction, which

$$(\mathbf{d}\mathbf{G})_{T,p} = \Delta G \,\mathbf{d}\tilde{N} = -\mathcal{A} \,\mathbf{d}\tilde{N} \le \mathbf{0},\tag{12.31}$$

in *N*˜ at constant *[p](#page-193-2)* and *T* is therefore (d*G*)*T*,*p* = -*G* d*N*˜ = −*A* d*N*˜ ≤ 0, (12.31) where the inequality holds for a natural irreversible process. Thus if -*G* < 0 (*A* > 0) the reaction will proceed to the right and for -*G* > 0 (*A* < 0) the reaction will proceed to the

*G* = −*A* = 0, which corresponds to a minimum of *G*, the reaction will be in

equilibrium. See Figure 12–1 for a sketch of *G* and *A* near equilibrium. Equilibrium can 6Eq. (12.27) implies that *G* is a function of *T*, *p* and the *Ni* in the field of equilibrium states. If a chemical reaction can occur, the system will not be in an equilibrium state but we can imagine, for thermodynamic purposes, that the reaction proceeds slowly through a set of constrained equilibrium states. It is generally

assumed that Eq. (12.28) is valid for small deviations from equilibrium. The same assumption was implicit in Eq. (12.9). 7We use a calligraphic symbol *A* to avoid confusion with *A* which in some books is used to denote the Helmholtz free energy, which we denote by *F*. The name "affinity" is due to T. De Donder, who founded the

-

<span id="page-194-0"></span>![](_page_194_Figure_1.jpeg)

*G G*eq *A* 0

*N*˜

eq *N*˜

*N*˜eq *N*˜

**FIGURE 12–1** Sketches of the Gibbs free energy *G* and the affinity *A* as a function of the progress variable *N*˜ near its equilibrium value *N*˜ eq. At a given value of *N*˜ , the affinity is the negative of the slope of *G*. If *G* is nearly parabolic near its minimum value *G*eq, the affinity *A* will be nearly linear. Equilibrium will occur at *N*˜ eq provided that the [initial values](#page-192-2) *N*0 *i* of the constituents of the reaction are such that *N*˜ min ≤ *N*˜ eq ≤ *N*˜ max. Otherwise, the reaction will proceed in the direction of *N*˜ eq but will stop when *N*˜ min or *N*˜ max is reached. occur at the value of *N*˜ = *N*˜ eq that satisfies Eq. (12.29). In an actual situation, equilibrium at this minimum value of *G* will be achieved provided that the values of the initial mole

numbers *N*0 *i* are such that *N*˜ min ≤ *N*˜ eq ≤ *N*˜ max. Otherwise the reaction will come to equilibrium at the lowest value of *G* subject to the constraint that no mole numbers can be negative. Note that the positive quantity *N*˜ max occurs if one of the reactants goes to zero and the negative quantity *N*˜ min occurs if one of the products becomes zero. See Example

$$\mathbf{dS} = \frac{\delta Q}{T} - \sum_{l} \nu_{l} \mu_{l} \,\mathrm{d}\tilde{N} = \frac{\delta Q}{T} + \frac{\mathcal{A}}{T} \,\mathrm{d}\tilde{N} > \mathbf{0} \tag{12.32}$$

flow, *Tr* = *T*, Eq. (5.127) applies, so d*S* = δ*Q T* −- *i* ν*i*μ*i* d*N*˜ = δ*Q T* + *A T* d*N*˜ > 0 (12.32) for a natural irreversible process. Then according to irreversible thermodynamics, one

$$\mathbf{d}^{\text{int}} \mathbf{S} = \frac{\mathcal{A}}{T} \mathbf{d} \tilde{\mathbf{N}} > \mathbf{0}, \quad \text{natural irreversible process.} \tag{12.33}$$

dint*S* = *A T* d*N*˜ > 0, natural irreversible process. (12.33) Again, *A* > 0 leads to reaction to the right (d*N*˜ > 0) whereas *A* < 0 leads to reaction to the

left (d*N*˜ < 0). Equilibrium requires prevention of a natural irreversible process for both possible signs of d*N*˜ , which requires *A* = 0. We can relate -*G* = ∂*G*/∂*N*˜ *T*,*p* of a reaction to -*H* = ∂*H*/∂*N*˜ *T*,*p* that pertains to the heat of reaction by regarding *G*, *H*, and *S* to be functions of *T*, *p*, and *N*˜ . Then by taking ∂/∂*N*˜ *T*,*p* of *G* = *H* −*TS*, we verify that -*G* = -*H* −*T*-*S*, where -*S* = ∂*S*/∂*N*˜ *T*,*p* . Hence

$$
\Delta H = \left(\frac{\partial(\Delta G/T)}{\partial(1/T)}\right)_{p,\hat{N}} = \Delta G - T \left(\frac{\partial \Delta G}{\partial T}\right)_{p,\hat{N}}; \quad \Delta S = -\left(\frac{\partial \Delta G}{\partial T}\right)_{p,\hat{N}}.\tag{12.34}
$$

$$\mathbf{dS} = C_p \mathbf{d}T - V\alpha \,\mathrm{d}p + \Delta \mathbf{S} \,\mathrm{d}\tilde{N},\tag{12.35}$$

Note that -

$$\mathbf{dS} = \mathbf{d}U/T + (\mathbf{p}/T)\,\mathrm{d}V + (\mathcal{A}/T)\,\mathrm{d}\tilde{N},\tag{12.36}$$

*S*d*N*˜ = (∂*A*/∂*T*) d*N*˜ is not the same as dint*S* = *A*/*T* d*N*˜ . This arises because

### d*S* = *Cp* d*T* − *V*α d*p* + -*S* d*N*˜ , (12.35) w[hereas (see Eq](#page-191-0). (12.32))

d*S* = d*U*/*T* + (*p*/*T*) d*V* + (*A*/*T*) d*N*˜ , (12.36) so different variables are held constant when *N*˜ changes in these expressions.

<span id="page-195-2"></span>
$$
\mu_l = \mu_l^0(T, p) + RT \ln a_l = \mu_l^0(T, p_0) + [\mu_l^0(T, p) - \mu_l^0(T, p_0)] + RT \ln a_l,\tag{12.37}
$$

12.4 Explicit Equilibrium Conditio[ns](#page-195-0) Explicit conditions for equilibrium can be obtained by referring the chemical potentials to **standard states** for pure elements or compounds. For the standard state at *p*0, *T* discussed in Section 12.2, one may express a che[mi](#page-195-1)cal potential in the form μ*i* = μ0 *i* (*T*, *p*) + *RT* ln *ai* = μ0 *i* (*T*, *p*0) + [μ0 *i* (*T*, *p*) − μ0 *i* (*T*, *p*0)] + *RT* ln *ai*, (12.37) where *ai* [is a d](#page-195-2)imensionless quantity called the **activity**. In general, μ*i*(*T*, *p*, *X*) and

*ai*(*T*, *p*, *X*) depend on temperature, pressure, and composition which we symbolize by the vector *X*. The quantities μ0 *i* (*T*, *p*) and μ0 *i* (*T*, *p*0) are the chemical potentials of the pure component *i* for the most stable phase at the given temperature and pressures.8

$$\tilde{f}_l(T, p, p_0) := \exp( [\mu_l^0(T, p) - \mu_l^0(T, p_0)] / RT). \tag{12.38}$$

For the pure component *i*, whether solid, liquid, or gas, we define a dimensionless quantity that we call the **fugacity ratio**10

μ*i*(*T*, *p*, *X*) = μ0

 ∂μ0 *i* (*T*, *p*) ∂*p*

 

*T*

= *V*0

˜

$$
\mu_l(T, p, \mathbf{X}) = \mu_l^0(T, p_0) + RT \ln[\tilde{f}_l(T, p, p_0) a_l(T, p, \mathbf{X})].\tag{12.39}
$$

Thus Eq. (12.37) can be written in the form

<span id="page-195-1"></span><span id="page-195-0"></span>In general,

$$\left(\frac{\partial \mu_l^0(T, p)}{\partial p}\right)_T = V_l^0(T, p), \tag{12.40}$$

*i* (*T*, *p*), (12.40)

8There could possibly be a phase change between *p*0 and *p* in which case the chemical potential will be a

continuous function of pressure but its pressure derivative will be discontinuous at the pressure at which the phase change takes place. 9Some authors, such as Kondepudi and Prigogine [14, p. 235], refer the activity to the state μ0(*T*, *p*0). Here we

follow Lupis [5, p. 108] and refer the activity to the state μ0(*T*, *p*). One can also employ standard states in which some constituents are in solution. 10Note that Eq. (12.38) does not define a fugacity itself. We take this approach because the standard state for the fugacity of a gas is defined to be a state for which the pressure goes to zero; however, for a condensed phase (solid or liquid) it is a state at pressure *p*0. In terms of individual fugacities *fi*, defined in Section 5.4, one would have ˜ *fi*(*T*, *p*, *p*0) = *fi*(*T*, *p*)/*fi*(*T*, *p*0).

<span id="page-196-3"></span>
$$
\mu_l^0(T, p) - \mu_l^0(T, p_0) = \int_{p_0}^p V_l^0(T, p') \, \mathbf{d}p'.\tag{12.41}
$$

176 THERMAL PHYSICS

*p*

$$
\tilde{f}(T, \mathbf{p}, \mathbf{p}_0) = \mathbf{p} / \mathbf{p}_0 \tag{12.42}
$$

μ0 *i* (*T*, *p*) − μ0 *i* (*T*, *p*0) = *p*0 *V*0 *i* (*T*, *p* ) d*p* . (12.41) For condensed phases (solids and liquids), usually *pV*0 *i* /*RT* 1 in the range of integration so ˜ *fi*(*T*, *p*, *p*0) ≈ 1 and the dependence on pressure is unimportant. For an ideal gas, one has *V*0 *i* (*T*, *p*)/*RT* = 1/*p* so ˜ *fi*(*T*, *p*, *p*0) = *p*/*p*0 (12.42) and there is considerable dependence on pressure. See Section 5.4 for a more complete discussion of fugacities for real gases and condensed phases. Unless one is dealing with

<span id="page-196-1"></span>very large pressure differences |*p* − *p*0|, the quantity |μ0 *i* (*T*, *p*) − μ0 *i* (*T*, *p*0)|/*RT* is small and usually negligible for solids and liquids but is important and varies considerably

$$
\Delta G = \sum_{l} \nu_{l} \mu_{l}^{0}(T, p\mathbf{o}) + RT \sum_{l} \nu_{l} \ln[\tilde{f}_{l}(T, p, p\mathbf{o}) a_{l}(T, p, \mathbf{X})] = \mathbf{0}.\tag{12.43}
$$

where *pi* := *Xip* is the partial pressure of gas *i*.

<span id="page-196-4"></span><span id="page-196-2"></span>-*G* = -

*i*

is on the left-hand side and has a negative ν*i*.

where *V*0

$$
\Delta G^{0}(T, p_{0}) \equiv \sum_{l} \nu_{l} \mu_{l}^{0}(T, p_{0}) \equiv -RT \ln K(T, p_{0}) \tag{12.44}
$$

*[i](#page-196-1) i* The first term -*G*0(*T*, *p*0) ≡ - *i* ν*i*μ0 *i* (*T*, *p*0) ≡ −*RT* ln *K*(*T*, *p*0) (12.44)

$$RT\sum_{l} \nu_{l} \ln[\tilde{f}_{l}(T, p, p_{0}) a_{l}(T, p, \mathbf{X})] = RT \ln \prod_{l} [\tilde{f}_{l}(T, p, p_{0}) a_{l}(T, p, \mathbf{X})]^{\eta_{l}}.\tag{12.45}$$

the form *RT* ν*i* ln[˜

*fi*(*T*, *p*, *p*0)*ai*(*T*, *p*, *X*)]

<span id="page-196-0"></span>
$$\prod_{l} [\tilde{f}_l(T, p, p_0) a_l(T, p, X)]^{\mathbb{N}} = K(T, p_0). \tag{12.46}$$

 [˜ *fi*(*T*, *p*, *p*0)*ai*(*T*, *p*, *X*)] ν*i* = *K*(*T*, *p*0). (12.46)

$$\prod_{l} [\tilde{f}_l(T, p, p_0) a_l(T, p, \mathbf{X})]^{v_l} = \frac{\prod_{l}^{\text{products}} [\tilde{f}_l(T, p, p_0) a_l(T, p, \mathbf{X})]^{v_l}}{\prod_{l}^{\text{reactants}} [\tilde{f}_l(T, p, p_0) a_l(T, p, \mathbf{X})]^{v_l}} \tag{12.47}$$

*i* reactants *i* [˜ *fi*(*T*, *p*, *p*0)*ai*(*T*, *p*, *X*)]|ν*i*| (12.47) 11Most authors would write just *K*(*T*) instead of *K*(*T*, *p*0) because *p*0 is fixed at one atmosphere. We carry the extra symbol *p*0 to remind ourselves of the standard state that has been used. Our equilibrium constant *K*(*T*, *p*0)

is dimensionless. 12Here, a product is on the right-hand side of the chemical equation and has a positive ν*i* whereas a reactant

$$
\Delta G = \sum_{l} \upsilon_{l} \mu_{l}^{0}(T, p) + RT \sum_{l} \upsilon_{l} \ln a_{l} = 0. \tag{12.48}
$$

Then one can define

we have ˜

data are tabulated at that pressure.

$$
\Delta G^{\mathbf{0}}(T, p) \equiv \sum_{l} \nu_{l} \mu_{l}^{\mathbf{0}}(T, p) \equiv -RT \ln K(T, p) \tag{12.49}
$$

on *p* instead of *p*0. In that case, the equilibrium condition Eq. (12.43) is replaced by -

*G* = -

*i*

*G*0(*T*, *p*) ≡ -

<span id="page-197-0"></span>ν*i*μ0

ν*i*μ0

$$\prod_{l} a_{l}^{v_{l}} = K(T, p). \tag{12.50}$$

### *i i* (*T*, *p*) ≡ −*RT* ln *K*(*T*, *p*) (12.49)

-

<span id="page-197-2"></span><span id="page-197-1"></span> *i*

and [the](#page-196-2) [co](#page-196-2)ndition for equilibrium becomes13 *i a*ν*i i* = *K*(*T*, *p*). (12.50) 12.4.1 Reactions among Gases

$$\prod_{l} (p_l/p_0)^{v_l} = \frac{\prod_{l}^{\text{products}} (p_l/p_0)^{v_l}}{\prod_{l}^{\text{reactants}} (p_l/p_0)^{|v_l|}} = K(T, p_0). \tag{12.51}$$

Eq. [(12.46)](#page-197-0) becomes

$$\prod_{l} X_{l}^{v_{l}} = \frac{\prod_{l}^{\text{products}} X_{l}^{v_{l}}}{\prod_{l}^{\text{reactants}} X_{l}^{|v_{l}|}} = \left(\frac{p}{p_{0}}\right)^{-\sum_{l} v_{l}} K(T, p_{0}),\tag{12.52}$$

 *i X*ν*i i* = products *i X*ν*i i* reactants *i X*|ν*i*| = *p p*0 − *i* ν*i K*(*T*, *p*0), (12.52)

*i*

the reverse reaction. The reaction will be independent of pressure if

$$K(T, p) = \left(\frac{p}{p_0}\right)^{-\sum_{l \neq l}} K(T, p_0), \quad \text{ideal gases.} \tag{12.53}$$

*i* ν*i* = 0.

*K*(*T*, *p*) = *p p*0 − *i* ν*i K*(*T*, *p*0), ideal gases. (12.53) For a given reaction, it follows that an increase in the overall pressure *p* will favor the reaction if − *i* ν*i* > 0, meaning that the number of moles of reactant gases exceeds the number of moles of product gases. If − *i* ν*i* < 0, an increase of pressure will favor

<sup>13</sup>This equation illustrates clearly that the equilibrium condition does not depend on the value of *p*0. Other conditions that appear to contain *p*0 are also independent of *p*0 but their individual parts depend on *p*0 because

−

at 1130 K and 1500 K?

forward reaction would be

178 THERMAL PHYSICS **Example Problem 12.3.** Discuss the dependence on overall pressure of the reactions H2(gas) + CO2(gas) → CO(gas) + H2O(gas), CO(gas) + (1/2)O2(gas) → CO2(gas) and A2(gas) → 2A(gas). **Solution 12.3.** For the first reaction, νH2 = −1, νCO2 = −1, νCO = 1, and νH2O = 1, so

*i* ν*i* = 0 and that reaction is independent of pressure. For the second reaction, νCO = −1, νO2 = −1/2, and νCO2 = 1, so − *i* ν*i* = 1/2 and that reaction is favored by an increase in pressure because *K*(*T*, *p*) = *p*/*p*0 1/2 *K*(*T*, *p*0). For the third, ν*A*2 = −1 and ν*A* = 2 so *K*(*T*, *p*) = *p*/*p*[0](#page-197-1) −1 *K*(*T*, *p*0). In this last case, we see that the dissociation of argon is impeded by a high pressure, which can be thought of heuristically as a force tending to hold the argon molecule together.

<span id="page-198-0"></span>**Example Problem 12.4.** For the reaction H2(gas) + CO2(gas) → CO(gas) + *H*2O(gas), some values of the equilibrium constant are *K*(1130 K, 1 atm) = 1.0 and *K*(1500 K, 1 atm) = 2.16.

Suppose initially that there is one mole of each gas. What will be the composition at e[quilibr](#page-198-0)ium

<span id="page-198-1"></span>reaction was in equilibrium initially. For *K*(1500 K, 1 atm) = 2.16, the solutions to Eq. (12.54) are *N*˜ = 0.19 and *N*˜ = 5.26 but the latter is unacceptable because it would lead to a negative value

$$\frac{[(1+\bar{N})/4]^2}{[(1-\tilde{N})/4]^2} = K(T, p_0). \tag{12.54}$$

each component will be *N*H2 = 1 − *N*˜ , *N*CO2 = 1 − *N*˜ , *N*CO = 1 + *N*˜ , and *N*H2O = 1 + *N*˜ so Eq. (12.52) becomes [(1 + *N*˜ )/4] 2 [(1 − *N*˜ )/4]2 = *K*(*T*, *p*0). (12.54) For *K*(1130 K, 1 atm) = 1.0, the solution is *N*˜ = 0; the mole fraction of each gas is 0.25 and the

of 1 − *N*˜ , which would correspond to a negative value of *N*H2 . Therefore, the composition at equilibrium is *X*H2 = *X*CO2 = 0.20 and *X*CO = *X*H2O = 0.3[0.](#page-198-1)

$$\prod_{l} [\mathbf{i}]^{\nu_l} = \frac{\prod_{l}^{\text{products}} [\mathbf{i}]^{\nu_l}}{\prod_{l}^{\text{reactants}} [\mathbf{i}]^{|\nu_l|}} = \left(\frac{RT}{p_0}\right)^{-\sum_{l}^{\text{lor}}} K(T, p_0) \equiv K_\mathbf{c}(T, p_0), \tag{12.55}$$

 *i* [*i*] ν*i* = products *i* [*i*] ν*i* reactants *i* [*i*]|ν*i*| = *RT p*0 − *i* ν*i K*(*T*, *p*0) ≡ *Kc*(*T*, *p*0), (12.55)

where *Kc*(*T*, *p*0) is a new equilibrium constant that will not be dimensionless unless *i* ν*i* = 0. Any of these forms for ideal gases, especially Eq. (12.55), are referred to as the **law of mass action**. This follows because the rate of gaseous reactions depends on collisions and the collision rate would be expected to depend on a product of concentrations. The rate of

*i*

<span id="page-198-2"></span>
$$R_f = k_f(T, p_0) \prod_{l}^{\text{meas}} \left[ \text{i} \right]^{|v_I|}, \tag{12.56}$$

$$R_b = k_b(T, p_0) \prod_{l}^{\text{products}} [l]^{\nu_l}. \tag{12.57}$$

*Chapter 12* • Chemical Rea[ctions](#page-198-2) 179 where *kf* (*T*, *p*0) is a constant of proportionality. Similarly, the rate of backward reaction would be *Rb* = *kb*(*T*, *p*0) products *i* [*i*] ν*i* . (12.57) At equilibrium, *Rf* = *Rb* leads to Eq. (12.55) with *Kc*(*T*, *p*0) = *kf* (*T*, *p*0)/*kb*(*T*, *p*0). This relationship of thermodynamics to kinetics holds provided that the given reaction actually

### (12.57). On the other hand, if the reaction actually [takes](#page-196-3) [p](#page-196-3)lace by means of a combination

proceeds by an *elementary step* involving the collisions embodied in Eqs. (12.56) and

of elementary steps, *Kc*(*T*, *p*0) can be related to the rate constants of all of these elementary steps. Nevertheless, the value of *Kc*(*T*, *p*0), since it is a thermodynam[ic qua](#page-197-1)ntity, is independent of the details of the kinetics of the reaction. See Kondepudi and Prigogine [14, p. 241] for further discussion of this point in terms of the principle of detailed balance. 12.4.2 Heterogeneous Solids and Liquids with Gases Heterogeneous reactions constitute an important special case in which gases rea[ct](#page-197-1) [with](#page-197-1) immiscible solids and liquids. In this case, the activities of the liquids and solids are equal

$$\prod_{l}^{\text{gases}} X_l^{v_l} = \left(\frac{p}{p_0}\right)^{-\sum_l v_l} K(T, p_0). \tag{12.58}$$

the reaction product is only over the gases, that is, gases *X*ν*i i* = *p* − *i* ν*i K*(*T*, *p*0). (12.58)

$$\prod_{l}^{\text{gases}} (p_l / p_0)^{\eta_l} = K(T, p_0). \tag{12.59}$$

*i* **Example Problem 12.5.** For the reaction C(graphite) + O2(gas)→CO2(gas) one has *G*0 = −394.4 kJ/mol, practically independent of temperature. The gas constant *R* = 8.314 J/mol.

### What is the equilibrium constant *K*(*T*, *p*0) of this reaction? What is the composition of the gas at equilibrium? What is the fraction of O2 at 1000 K?

**Solution 12.5.** We have

namely

-

with -

$$\frac{X_{\text{CO}_2}}{X_{\text{O}_2}} = \frac{p_{\text{CO}_2}}{p_{\text{O}_2}} = K(T, p_0) = \exp(-\Delta G^0/RT) \tag{12.60}$$

ν*i* = *K*(*T*, *p*0). (12.59)

*X*O2 *p*O2 = *K*(*T*, *p*0) = exp(−-

*X*O2

*X*CO2

<span id="page-199-0"></span>*i*

gases 

(*pi*/*p*0)

$$\frac{X_{\text{O}_2}}{1 - X_{\text{O}_2}} = \exp(-47.44) = 2.5 \times 10^{-21},\tag{12.61}$$

so this is also practically the value of *X*O2 . If only graphite and O2 were present initially, practically all of the oxygen would react to form CO2 if enough graphite were present. Otherwise, the reaction would stop when all of the graphite is consumed.

$$\text{12.4.3 \textbf{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**} \text{**}$$

We begin with Eq. (10.30), generalized to a multicomponent system, namely

$$\left(\frac{\partial(\mathbf{G}/T)}{\partial(1/T)}\right)_{p,N_l} = H \tag{12.62}$$

in which the Gibbs free energy *G* and the enthalpy *H* are expressed in terms of the variable set *T*, *p*, *Ni*. This equation also holds for any chemical component in its standard state, and therefore holds if *G* is replaced by the sum

$$
\Delta G^0(T, p_0) \equiv \sum_l \upsilon_l \mu_l^0(T, p_0) \tag{12.63}
$$

and *H* is replaced by the sum

$$
\Delta H^0(T, p_0) \equiv \sum_l \upsilon_l H^0_l(T, p_0). \tag{12.64}
$$

We therefore obtain

<span id="page-200-0"></span>
$$\frac{\partial(\Delta G^0(T, p_0)/T)}{\partial(1/T)} = \Delta H^0(T, p_0). \tag{12.65}$$

Since ∂/∂(1/*T*) = −*T*2∂/∂*T*, Eq. [(12.65)](#page-200-0) can also be written

$$\frac{\partial(\Delta G^0(T, p_0)/T)}{\partial T} = -\frac{\Delta H^0(T, p_0)}{T^2}. \tag{12.66}$$

Recalling the definition of *K*(*T*, *p*0) from Eq. [(12.44)](#page-196-4), we obtain

<span id="page-200-1"></span>
$$\frac{\partial \ln K(T, p_0)}{\partial T} = \frac{\Delta H^0(T, p_0)}{RT^2},\tag{12.67}$$

which is known as the **van't Hoff equation**.

**Example Problem 12.6.** For many chemical reactions, the quantity -*H*0(*T*, *p*0) does not depend strongly on *T* over a significant temperature range and may be treated as a constant, say -*H*0 0 . Determine the dependence of *K*(*T*, *p*0) on *T* under these circumstances. Discuss the dependence on temperature for endothermic and exothermic reactions. What is the dependence on temperature of -*G*0(*T*, *p*0) in this case?

**Solution 12.6.** We integrate Eq. [(12.67)](#page-200-1) from *T*0 to *T* to obtain

$$\ln K(T, p_0) = \ln K(T_0, p_0) - \frac{\Delta H_0^0}{R} \left( \frac{1}{T} - \frac{1}{T_0} \right). \tag{12.68}$$

Exponentiation gives

$$K(T, p_0) = K(T_0, p_0) \mathbf{e}^{\Delta H_0^0 / RT_0} \mathbf{e}^{-\Delta H_0^0 / RT},\tag{12.69}$$

so *K* increases strongly with temperature for an endothermic reaction -*H*0 0 > 0 and decreases strongly with temperature for an exothermic reaction -*H*0 0 < 0. This type of exponential dependence is said to be of **Arrhenius form** and -*H*0 0 plays the role of an activation energy.

Integration of Eq. [(12.65)](#page-200-0) for constant -*H*0 gives

$$\frac{\Delta G^{0}(T, p_{0})}{T} = \frac{\Delta G^{0}(T_{0}, p_{0})}{T_{0}} + \Delta H_{0}^{0} \left(\frac{1}{T} - \frac{1}{T_{0}}\right). \tag{12.70}$$

Multiplication by *T* and rearrangement gives

<span id="page-201-0"></span>
$$
\Delta G^{0}(T, p_{0}) = \Delta H_{0}^{0} + \frac{T}{T_{0}} [\Delta G^{0}(T_{0}, p_{0}) - \Delta H_{0}^{0}(T_{0}, p_{0})] = \Delta H_{0}^{0} - T\Delta S^{0}(T_{0}, p_{0}).\tag{12.71}
$$

We see in this case that -*G*0(*T*, *p*0) is linear in *T*. In general, ∂-*G*0(*T*, *p*0)/∂*T* = -*S*0(*T*, *p*0) so we see from differentiation of Eq. [(12.71)](#page-201-0) with respect to *T* that *S*0(*T*, *p*0) = *S*0(*T*0, *p*0). In other words, the standard entropy difference is also independent of *T* in this case.

**Example Problem 12.7.** For the formation of Cu2O, -*H*0 *f* (*T*0, *p*0) = −168.6 kJ/mol and -*G*0 *f* (*T*0, *p*0) = −146.0 kJ/mol. For the formation of Al2O3, -*H*0 *f* (*T*0, *p*0) = −1675.7 kJ/mol and -*G*0 *f* (*T*0, *p*0) = −1582.3 kJ/mol. In both cases, the metal and its oxide are solids, not in solution, and the oxygen can be treated as an ideal gas. Write chemical equations for the two reactions. Assume that -*H*0(*T*, *p*0) can be treated as a constant equal to -*H*0 *f* (*T*0, *p*0). Determine the equilibrium constants *K*(*T*, *p*0) as a function of temperature and then determine the equilibrium pressures of oxygen for each reaction at 1000 K.

**Solution 12.7.** The relevant reactions are 2Cu(solid) + (1/2)O2(gas) → Cu2O(solid) and 2Al(solid) + (3/2)O2(gas) → Al2O3(solid). From Eq. [(12.71)](#page-201-0),

$$K(T, p_0) = \exp[(\Delta H_f^0(T_0, p_0) - \Delta G_f^0(T_0, p_0))/RT_0] \exp(-\Delta H_f^0/RT). \tag{12.72}$$

For the oxidation of copper,

$$K(T, p_0) = 1.098 \times 10^{-4} \exp(20.280 \,\text{K}/T),\tag{12.73}$$

so *K*(1000 K, *p*0) = 2.018 × 1010. From Eq. [(12.59)](#page-199-0), we see that (*p*O2 /*p*0) −1/2 = *K*, so we obtain *p*O2 = 2002 × 10−10 atm.

For the oxidation of aluminum,

$$K(T, p_0) = 4.326 \times 10^{-17} \exp(201, 550 \,\text{K}/T),\tag{12.74}$$

so *K*(1000 K, *p*0) = 1.475 × 1071. For this reaction, (*p*O2 /*p*0)−3/2 = *K*, so we obtain *p*O2 = 3.58 × 10−48 atm.

Both of these oxygen pressures are very small but their relative values indicate that aluminum oxide is much more stable than copper oxide; an extremely low oxygen pressure would be needed to reduce aluminum oxide to the metallic state.

### 12.4.4 Dependence of *K*(*T*, *p*) on Pressure

Since ∂*G*/∂*p* = *V* we have ∂μ0 *i* (*T*, *p*)/∂*p* = *V*0 *i* (*T*, *p*), which is the molar volume of each constituent in its standard state[.14](#page-202-0) Therefore,

$$\frac{\partial \Delta G^{0}(T, p)}{\partial p} = \sum_{l} \nu_{l} \frac{\partial \mu_{l}^{0}(T, p)}{\partial p} = \sum_{l} \nu_{l} V_{l}^{0}(T, p) \equiv \Delta V^{0}(T, p). \tag{12.75}$$

Thus,

<span id="page-202-1"></span>
$$\frac{\partial \ln K(T, p)}{\partial p} = -\frac{\Delta V^0(T, p)}{RT} = -\sum_{l} \nu_l \frac{V_l^0(T, p)}{RT}.\tag{12.76}$$

As remarked previously, *V*0 *i* (*T*, *p*)/*RT* = 1/*p* for ideal gases and *V*0 *i* (*T*, *p*)/*RT* 1/*p* for condensed phases, so the only really important correction is for gases. If all gases can be treated as ideal,

$$\frac{\partial \ln K(T, p)}{\partial p} = -\sum_{l}^{\text{gases}} \frac{\nu_l}{p},\tag{12.77}$$

which can be integrated to give

$$\ln \frac{K(T, p)}{K(T, p_0)} = -\sum_{l}^{\text{gases}} v_l \ln \frac{p}{p_0} = \ln \left[ \left( \frac{p}{p_0} \right)^{-\sum_{l}^{\text{gases}} v_l} \right]. \tag{12.78}$$

Exponentiation of this expression gives agreement with Eq. [(12.53)](#page-197-2). If better information is available for non-ideal gases, one could integrate Eq. [(12.76)](#page-202-1).

### 12.5 Simultaneous Reactions

As mentioned in connection with Eq. [(12.2)](#page-187-1), it is possible to have simultaneous reactions. In that case, there is a progress variable *N*˜ *s* for each reaction and we will have

$$\mathbf{d}^{\rm int} N_l = \sum_s \nu_l^s \,\mathbf{d} \tilde{N}^s. \tag{12.79}$$

Then for a chemically closed system,

$$\mathbf{d}\,\mathbf{d}G_{l,p} = \sum_{l} \mu_{l}\,\mathbf{d}^{\text{int}}N_{l} = \sum_{l} \mu_{l}\sum_{s} \nu_{l}^{s}\,\mathbf{d}\tilde{N}^{s} = -\sum_{s} \mathcal{A}^{s}\,\mathbf{d}\tilde{N}^{s} \le \mathbf{0},\tag{12.80}$$

where *As* = *i* ν*s i* μ*i* is the affinity of the reaction *s*. The corresponding entropy production is

$$\mathbf{d}^{\text{Int}}\mathbf{S} = \sum_{s} \frac{\mathcal{A}^s}{T} \,\mathbf{d}\tilde{N}^s \succeq \mathbf{0}.\tag{12.81}$$

<span id="page-202-0"></span>14Here as above, we extend the meaning of standard state to mean the most stable phase of the pure constituent at *T* and *p*. A stricter definition (see Lupis [5, p. 120]) that restricts the standard state to *T* and *p*0 for chemical reactions would lead to ∂-*G*0(*T*, *p*0)/∂*p* = 0, in which case ∂-*K*(*T*, *p*0)/∂*p* = 0.

Since these chemical reactions can take place at the same spatial position, they may be coupled and it is only necessary that the sum be positive during the reaction. See Lupis [5, p. 122] for examples of uncoupled simultaneous reactions and Kondepudi and Prigogine [14, p. 369] for a discussion of coupled simultaneous reactions in the context of entropy production.

This page intentionally left blank

# 13

# Thermodynamics of Fluid-Fluid Interfaces

Until now we have dealt primarily with homogeneous phases or with composite systems consisting of several homogeneous phases. In all of these cases, we have ignored the thermodynamics of the surfaces of these phases or the interfaces that separate them. This was done on the basis that we were interested in the bulk properties of sufficiently large phases that the contributions of surfaces and interfaces could be neglected. Nevertheless, there are many familiar instances where the properties of surfaces cannot be ignored. For example, a glass of water in a gravitational field can be filled somewhat beyond its capacity without spilling; the surface of the water bulges above the top of the glass but is held in place by a force due to "surface tension" that supports the water above the glass. Roughly speaking, the surface of the water has a free energy per unit area in excess of the free energy of the bulk. Thus, the creation of more area requires an increase in free energy and hence to a force per unit length around the perimeter of the area that tries to keep the area from increasing. Another example is the substantial rise (typically a few centimeters) of water in a capillary tube immersed vertically in a large vessel.

In this chapter, we explore in more detail the thermodynamic properties of the thin transition regions that exit in actual systems near these idealized surfaces of discontinuity. We do this under conditions for which the change from one homogeneous phase to another takes place over a region that is thin compared to the extent of the homogeneous phases.[1](#page-205-0) We begin by considering a model developed by Gibbs [3, p. 223] that is based on the concept of a dividing surface. Such a surface has zero thickness, so it is a mathematical abstraction. By means of a clever formalism, Gibbs was able to account for the thermodynamic properties of the actual transition region by associating it with the dividing surface. We first consider the Gibbs dividing surface model of planar interfaces in fluid systems, for which the surface tension can be defined unambiguously. Then for planar interfaces, we present Cahn's layer model which allows one to express physically meaningful surface quantities in terms of determinants whose properties illustrate clearly their invariance with respect to the thickness or location of the layer that contains the region of discontinuity. The Gibbs model is seen to be a special case of Cahn's model.

Next, we discuss curved interfaces for fluids, for which the location of the dividing surface must be fixed by some convention, in particular the Gibbs "surface of tension" that we define later. We illustrate surface tension phenomena by examples such as rise or

<span id="page-205-0"></span><sup>1</sup>For curved surfaces, the region of discontinuity must also be thin relative to its radii of curvature.

of the bulk phases.

according to δ*U*α = *T*αδ*S*α +

are per unit mass and differ from ours by factors of the molecular weights.

### <span id="page-206-2"></span>186 THERMAL PHYSICS

depression in a capillary tube, the meniscus that forms at the edge of a submerged plate, a

variety of interface shapes for two-dimensional problems, and the shapes of pendant and sessile drops in three dimensions. 13.1 Planar Interfaces in Fluids We begin by considering a planar interface, such as depicted in Figure 13–1, that separates two essentially homogeneous fluid phases that we denote by superscripts α and β. The transition region between the phases is assumed to be thin compared to the extent of the phases themselves. The entire system, which is chemically closed, has an internal energy *U*, entropy *S*, volume *V*, and mole numbers *Ni* of its chemical components. It is assumed to be in equilibrium and to have a temperature *T* and chemical potentials μ*i* that are uniform throughout. Gibbs discusses the need for this uniformity in great detail by imagining the system to be divided into three subsystems by means of imaginary parallel walls that are similarly situated with respect to the transition region. These [wa](#page-206-0)lls

<span id="page-206-1"></span>
$$
\delta U^L = T^L \delta \mathcal{S}^L + \sum_l \mu_l^L \delta N_l^L,\tag{13.1}
$$

<span id="page-206-3"></span>homogeneous phases, α*H* and β*H*. For*immobile walls*, Gibbs assumes that an infinitesimal variation of the energy of the layer *L* is given by δ*UL* = *TL*δ*SL* +- *i* μ*L i* δ*NL i* , (13.1)

where *SL* is the entropy of the layer and *NL i* is the number of moles of component *i* in the layer. Gibbs *defines TL* to be its temperature and the μ*L i* to be its chemical potentials.2 He then proceeds to show that they must be equal to the temperature and chemical potentials

![](_page_206_Figure_8.jpeg)

<span id="page-206-0"></span>**FIGURE 13–1** Schematic diagram showing a planar interface, which is a region of discontinuity (located near the innermost dotted lines) between bulk α and β phases. The dashed lines, which are located near the region of discontinuity but practically in homogeneous regions, are imaginary walls that define a layer that contains the region of discontinuity. This is the same layer *L* used by Gibbs to define *TL* and μ*L i* in Eq. (13.1) and used in Cahn's layer model in Section 13.1.3 to establish Eq. (13.11). The Gibbs dividing surface is any plane parallel to the walls of

the layer and can be inside or outside the layer. 2Gibbs deals with the masses of the components rather than the number of moles, so his chemical potentials

*Chapter 13* • Thermodynamics of Fluid-Fluid Interfaces 187 special variations of entropy and mole numbers of each component among the layer *L* and the homogeneous subsystems α*H* and β*H* and requiring the total energy *U* = *U*α+*UL*+*U*β to be a minimum at constant total entropy and total mole numbers, Gibbs reasons for variations that can have either sign that the temperature and chemical potentials must be uniform, just as they would be for three bulk systems in heterogeneous equilibrium. For example, for a special variation in which component *j* is exchanged between α

and *L* but there is no other change, one has δ*U* = μα *j* δ*N*α *j* + μ*L j* δ*NL j* = (μα *j* − μ*L j* )δ*N*α *j* . Then for variations δ*N*α *j* of either sign, one must have μα *j* − μ*L j* = 0 to prevent δ*U* from being negative, which would violate the fact that *U* must be a minimum at equilibrium. Gibbs also deals carefully with the manner in which extensive quantities can be defined during such variations, which involve infinitesimal discontin[uit](#page-207-0)ies at the walls [3, p. 224]. Ultimately, *T*α = *TL* = *T*β and μα *i* =μ*L i* = μβ *i* for each component *i*. The pressures in the bulk phases are also uniform and equal to one another. This must be true for mechanical equilibrium and can be established by means of a variation in which the *entire* layer *L* is *translated* by an infinitesimal distance in a direction perpendicular to its walls without any change in the layer *L* itself. This gives rise to a change in volume δ*V* of one homogeneous system and −δ*V* of the other, just as if the

### layer *L* were absent. Thus the variation of the internal energy of the whole system will be δ*U* = δ*V*(*p*α − *p*β), so (*p*α − *p*β) must vanish for arbitrary δ*V* of either sign. Therefore, the

*N*xs

includes the region of discontinuity. See [27, p. 44] for a derivation.

pressures of the bulk systems must be equal (we shall hereafter denote them both by *p*) as they would be for bulk systems in heterogeneous equilibrium.3 13.1.1 Gibbs Dividing Surface Model Following Gibbs, we replace the actual system by a model system consisting of two strictly homogeneous phases separated by a single mathematical plane, known as the **Gibbs dividing surface**. In this model system, the homogeneous phases extend uniformly *until they meet* at the dividing surface. This plane is similarly situated with respect to the transition region. For the moment, we assume that it is located *anywhere* in the system, not

<span id="page-207-0"></span>
$$U^{\infty} := U - U^{\alpha} - U^{\beta};\tag{13.2}$$

$$S^{\rm ss} := S - S^{\rm ar} - S^{\theta};\tag{13.3}$$

<span id="page-207-1"></span>
$$N_l^{\text{xs}} := N_l - N_l^{\text{cr}} - N_l^{\beta};\tag{13.4}$$

$$\dot{\mathbf{0}} := \dot{V} - \dot{V^a} - V^\beta. \tag{13.5}$$

0 := *V* − *V*α − *V*β . (13.5) 3Note that this treatment avoids discussion of the pressure of the subsystem *L*. In fact, that subsystem is inhomogeneous, so on a microscopic scale it could be characterized by a pressure tensor *pij*. If the *z* direction is perpendicular to the walls of the layer, then *pzz* must be uniform and equal to the common pressure *p* of the homogeneous phases. The components *pxx* = *pyy* will vary from *p* near the homogenous phases to negative values within the discontinuity itself, giving rise to a surface tension σ = (*p* − *pxx*)d*z* > 0, where the integration 188 THERMAL PHYSICS

of the dividing surface.

Therefore

<span id="page-208-0"></span>noting for a bulk phase that *F* −

$$F^{\infty} \coloneqq F - F^{\alpha} - F^{\beta} \,. \tag{13.6}$$

Equation (13.5) is different from the previous three equations because there is no excess

volume, due to the fact that the homogeneous phases of the model system meet at the dividing surface, which has no thickness. Since the temperature is uniform, one can also define excesses of the thermodynamic potentials, such as the Helmholtz free energy *F* = *U* − *TS*, for which *F*xs := *F* − *F*α − *F*β. (13.6) It follows that all excess quantities follow the same algebra as their bulk counterparts.

illustrated for the case of a single component material in which one bulk phase is a liquid

$$N^{\rm xs} = N - n^{\ell}V + (n^{\ell} - n^{g})V^{g}.\tag{13.7}$$

having molar density *n* and the other is a gas having molar density *ng* . Then if the dividing surface is located such that the gas has volume *Vg* and the liquid has volume *V* −*Vg* , where *V* is the total volume, it follows that *N*xs = *N* − *nV* + (*n* − *ng* )*Vg* . (13.7) For *n* − *ng* > 0, the sum of the first two terms on the ri[gh](#page-208-0)t is negative and independent of the location of the dividing surface whereas the last term on the right is positive and depends linearly on *Vg* and hence linearly on the position of the dividing surface. Thus, *N*xs varies with the position of the dividing surface and can be positive, negative, or zero. Therefore, *N*xs has no physical significance. One could fix the position of the dividing surface by convention by choosing its location so that *N*xs = 0; this is known as

the **equimolar surface**. Nevertheless, this choice is still artificial. Moreover, in a multicomponent system one could only choose the dividing surface to be equimolar relative to

$$K^{\infty} := K - K^{\alpha} - K^{\beta} = F^{\infty} - \sum_{l} \mu_{l} N_{l}^{\infty} \tag{13.8}$$

*K*xs := *K* − *K*α − *K*β = *F*xs −- *i* μ*iN*xs *i* (13.8) turns out to be independent of the location of the dividing surface. This can be seen by

<span id="page-208-1"></span>
$$K^{\infty} = K + p(V^{\alpha} + V^{\beta}) = K + pV,\tag{13.9}$$

*K*xs = *K* + *p*(*V*α + *V*β) = *K* + *pV*, (13.9) where Eq. (13.5) has been used. The right-hand side of Eq. (13.9) is *independent* of the

location of the dividing surface, so *K*xs is also independent of that location and has

4This is also called the grand potential and is often denoted by .

<span id="page-209-2"></span>
$$\gamma := \frac{K^{\rm xs}}{A} = \frac{F^{\rm xs} - \sum_{l} \mu_{l} N_{l}^{\rm xs}}{A} = \frac{K + pV}{A},\tag{13.10}$$

*Chapter 13* • Thermodynamics of Fluid-Fluid Interfaces 189

physical meaning. We can therefore divide by the area *A* of the dividing surface to define the surface free energy5 (per unit area of interface) γ := *K*xs *A* = *F*xs − *i* μ*iN*xs *i A* = *K* + *pV A* , (13.10) which will be independent of the choice of the location of the dividing surface for a planar region of discontinuity. We now approach the same problem from a different vantage point by considering small reversible changes of the same planar system in contact with a thermal reservoir at temperature *T*, a pressure reservoir at pressure *p*, and chemical reservoirs at potentials μ*i*. In particular, we allow the system to undergo an infinitesimal change in which its length is unchanged but its cross-sectional area changes by an amount d*A*. In order to account for

<span id="page-209-0"></span>
$$\mathbf{d}U = T\,\mathbf{d}S - p\,\mathbf{d}V + \sigma\,\mathbf{d}A + \sum_{l} \mu_{l}\,\mathrm{d}N_{l}.\tag{13.11}$$

is the extra work done *on* the system because of the surface of discontinuity. The quantity σ is the surface (interfacial) tension, which is [a force](#page-209-0) per unit length that must be applied

$$\mathbf{d}U^{\mathbf{u}} = T\,\mathbf{dS}^{\mathbf{u}} - p\,\mathbf{d}V^{\mathbf{u}} + \sum_{l} \mu_{l}\,\mathbf{d}N_{l}^{\mathbf{u}};\tag{13.12}$$

$$\mathbf{d}U^{\beta} = T\,\mathbf{d}S^{\beta} - p\,\mathbf{d}V^{\beta} + \sum_{l} \mu_{l}\,\mathbf{d}N_{l}^{\beta}.\tag{13.13}$$

d*U*α = *T* d*S*α − *p* d*V*α +- μ*i* d*N*α *i* ; (13.12)

elastically.

<span id="page-209-1"></span>
$$\mathbf{d}U^{\mathbf{x}\mathbf{s}} = T\,\mathbf{d}S^{\mathbf{x}\mathbf{s}} + \sum_{l} \mu_{l}\,\mathbf{d}N_{l}^{\mathbf{x}\mathbf{s}} + \sigma\,\mathbf{d}A.\tag{13.14}$$

We subtract both of these equations from Eq. (13.11) to obtain d*U*xs = *T* d*S*xs +- *i* μ*i* d*N*xs *i* + σ d*A*. (13.14)

$$U^{\rm ss}(\lambda S^{\rm ss}, \lambda N_l^{\rm ss}, \lambda A) = \lambda U^{\rm ss}(S^{\rm ss}, N_l^{\rm ss}, A) \tag{13.15}$$

different cross-sectional areas, we deduce that *U*xs(λ*S*xs, λ*N*xs *i* , λ*A*) = λ*U*xs(*S*xs, *N*xs *i* , *A*) (13.15) 5The name surface free energy is commonly used, but it is important to remember that the relevant free energy is the Kramers potential. For the case of planar interfaces that is treated here, the pressure is the same in both bulk phases so one can define a Gibbs free energy *G* = *U* −*TS*+*pV* and note that *K* +*pV* = *G*− *i* μ*iNi*. Then γ *A* can be thought of as an excess Gibbs free energy relative to a homogeneous system. For curved surfaces, the pressures in the bulk phases are not equal, so one must resort to the Kramers potential. For the very special case of a single component material with the dividing surface chosen to be the equimolar surface, one has γ = *F*xs/*A* which is the surface excess of the Helmholtz free energy. The name surface tension is perfectly applicable for γ for a surface of discontinuity between fluids because it can be shown to be the force per unit length needed to extend the surface. For solids, this would be a misnomer because surface can be created but also stretched

<span id="page-210-1"></span>
$$\mathbf{U}^{\mathbf{x}\mathbf{s}} = \mathbf{T}\mathbf{S}^{\mathbf{x}\mathbf{s}} + \sum_{l} \mu_{l} \mathbf{N}_{l}^{\mathbf{x}\mathbf{s}} + \sigma \mathbf{A}. \tag{13.16}$$

190 THERMAL PHYSICS

$$\sigma = \frac{U^{\rm ss} - TS^{\rm ss} - \sum_{l} \mu_{l} N_{l}^{\rm xs}}{A} = \chi. \tag{13.17}$$

(see Eq. (5.39)), we deduce that *U*xs = *TS*xs +- μ*iN*xs *i* + σ*A*. (13.16)

<span id="page-210-0"></span>*i*

### Equation (13.15) can be solved for σ to deduce

equations

σ = *U*xs − *TS*xs − *i* μ*iN*xs *i A* = γ . (13.17)

$$\mathbf{d}U^{\rm gs} = T\,\mathbf{d}S^{\rm gs} + S^{\rm ns}\,\mathrm{d}T + \sum_{l} \mu_{l}\,\mathrm{d}N_{l}^{\rm ns} + \sum_{l} N_{l}^{\rm ns}\,\mathrm{d}\mu_{l} + \chi\,\mathrm{d}A + A\,\mathrm{d}\chi.\tag{13.18}$$

13.1.2 Gibbs Adsorption Equation

$$A\,\mathbf{d}\chi = -\mathbf{S}^{\mathrm{us}}\,\mathrm{d}T - \sum_{l} N_{l}^{\mathrm{res}}\,\mathrm{d}\mu_{l}.\tag{13.19}$$

d*U*xs = *T* d*S*xs + *S*xs d*T* +*i i* +*i i* dμ*i* + γ d*A* + *A* dγ . (13.18) Comparison with Eq. (13.14), again with σ [=](#page-210-0) γ , gives *A* dγ = −*S*xs d*T* −- *N*xs *i* dμ*i*. (13.19)

$$\mathbf{d}\chi = -\mathbf{s}_{\mathbf{d}} \, \mathbf{d}T - \sum_{l} \Gamma_{l} \mathbf{d}\mu_{l}.\tag{13.20}$$

the excess mole numbers per unit area by *i* := *N*xs *i* /*A* to obtain the **Gibbs adsorption equation** dγ = −*sA* d*T* −- *i* dμ*i*. (13.20)

$$\mathbf{d}u_{\mathbf{A}} = T\,\mathbf{ds}_{\mathbf{A}} + \sum_{l} \mu_{l} \,\mathbf{d}\Gamma_{l},\tag{13.21}$$

we obtain d*uA* = *T* d*sA* +- μ*i* d *i*, (13.21)

*i* which resembles Eq. (13.1) because the special variation considered there was for fixed *A* and immobile walls. Equation (13.20) must be handled with great care because the quantities *sA* and *i* depend on the location of the dividing surface and are therefore not of physical significance. For example, one might be tempted to try to calculate *sA* as a derivative (∂γ /∂*T*)μ*i* but such a derivative does not exist in this case of planar surfaces. The reason is that the variable set *T*,{μ*i*} is not independent because the bulk phases are each governed by Gibbs-Duhem

<span id="page-210-3"></span><span id="page-210-2"></span>*i*

$$\mathbf{S}^{\alpha} \mathbf{d}T - V^{\alpha} \mathbf{d}p + \sum_{l} N_{l}^{\alpha} \, \mathbf{d}\mu_{l} = \mathbf{0};\tag{13.22}$$

$$S^{\beta} \operatorname{d} T - V^{\beta} \operatorname{d} p + \sum_{l}^{l} N_{l}^{\beta} \operatorname{d} \mu_{l} = 0. \tag{13.23}$$

<span id="page-211-0"></span>
$$\left(\mathbf{s}_V^{\mu} - \mathbf{s}_V^{\beta}\right)\mathbf{d}T + \sum_{l=1}^{\kappa} (\mathbf{c}_l^{\mu} - \mathbf{c}_l^{\beta})\,\mathbf{d}\mu_l = \mathbf{0}.\tag{13.24}$$

*Chapter 13* • Thermodynamics of Fluid-Fluid Interfaces 191 Introducing the entropy density *sV* and the concentrations *ci* = *Ni*/*V* for bulk α and β and

(*s* [α](#page-210-0) *V* − *s* β *V* ) d*T* +*i*=1 (*c*α *i* − *c* β *i* ) dμ*i* = 0. (13.24)

<span id="page-211-1"></span>κ

Therefore[, only](#page-211-0) κ of the κ + 1 variables *T*,{μ*i*} are independent. Elimination of one of these variables enables dγ to be expressed in terms of independent variables, and then

$$\mathbf{d}\chi = -\mathbf{s}\mathbf{t}\,\mathrm{d}T - \Gamma^{\mathrm{ax}}\mathbf{d}\mu \tag{13.25}$$

**Example Problem 13.1.** For the case of a single component, evaluate dγ /d*T* and interpret

the result physically.

and Eq. (13.24) yields

Eq. (13.25). In that case

to obtain

then eliminating d*p* gives

$$\mathbf{d}\mu = -\frac{(\mathbf{s}_V^a - \mathbf{s}_V^\beta)}{(\mathbf{c}^a - \mathbf{c}^\beta)}\,\mathrm{d}T.\tag{13.26}$$

dγ = −*sA* d*T* −

**Solution 13.1.** Equation (13.20) becomes

$$\mathbf{d}\chi = -\left[\mathbf{s}_A - \Gamma^{\text{xs}} \frac{s_V^{\alpha} - s_V^{\beta}}{c^{\alpha} - c^{\beta}}\right] \mathbf{d}T. \tag{13.27}$$

xs dμ (13.25)

Eli[minatio](#page-211-1)n of dμ from Eq. (13.25) gives dγ = − *sA* − xs *s*α *V* − *s* β *V c*α − *c*β d*T*. (13.27) The required derivative dγ /d*T* is the negative of the expression in square brackets. The bulk phases are only in equilibrium along a coexistence curve, say *p* = ˜ *f* (*T*), which is a solution of

μα(*T*, *p*) = μβ (*T*, *p*), so μ depends only on *T*. The quantity in brackets is an effective surface entropy that governs the dependence of γ on *T*. It is therefore independent of the choice of the dividing surface. If one adopts the convention of the equimolar surface, then xs = 0. In that

$$\mathbf{d}\boldsymbol{\gamma} = -\left[\boldsymbol{\Gamma}^{\mathrm{xs}} - \mathbf{s}_{\mathrm{A}} \frac{\boldsymbol{\sigma}^{\mathrm{a}} - \mathbf{c}^{\beta}}{\boldsymbol{s}_{\mathrm{V}}^{\mathrm{a}} - \boldsymbol{s}_{\mathrm{V}}^{\beta}}\right] \mathbf{d}\boldsymbol{\mu}.\tag{13.28}$$

dγ = − xs − *sA c*α − *c*β *s*α *V* − *s* β *V* dμ. (13.28)

Now μ is the only independent variable and the quantity in brackets is an effective surface adsorption, which has physical significance independent of the choice of dividing surface.

1

In the general case, we can solve Eq. (13.24) for dμ1 and then substitute into Eq. (13.20)

$$\mathbf{d}\boldsymbol{\gamma} = -\left[\mathbf{s}_A - \Gamma_1 \frac{\mathbf{s}_V^\alpha - \mathbf{s}_V^\beta}{c_1^\alpha - c_1^\beta}\right] \mathbf{d}T - \sum_{l=2}^\kappa \left[\Gamma_l - \Gamma_1 \frac{c_l^\alpha - c_l^\beta}{c_1^\alpha - c_1^\beta}\right] \mathbf{d}\mu_l. \tag{13.29}$$

1

<span id="page-212-1"></span>192 THERMAL PHYSICS

$$\mathbf{d}\boldsymbol{\gamma} = -\mathbf{s}_{\mathcal{A}(1)} \, \mathrm{d}T - \sum_{l=2}^{k} \Gamma_{l(1)} \, \mathrm{d}\mu_{l},\tag{13.30}$$

of γ with respect to them and obtain the quantities in square brackets, which must be independent of the location of the dividing surface.6

$$\mathbf{s}_{A(1)} = \left[ \mathbf{s}_A - \Gamma_1 \frac{\mathbf{s}_V^a - \mathbf{s}_V^\beta}{c_1^a - c_1^\beta} \right];\tag{13.31}$$

$$
\Gamma_{\ell(1)} = \begin{bmatrix}
\Gamma_{\ell} & \Gamma_{\ell} \\
\Gamma_{\ell} - \Gamma_{1} \frac{c_{\ell}^{\alpha} - c_{\ell}^{\beta}}{c_{1}^{\mu} - c_{1}^{\beta}}
\end{bmatrix}.
\tag{13.32}
$$

. (13.32)

<span id="page-212-0"></span>*sA*(1) = *sA* − 1 *s*α *V* − *s* β *V c*α 1 − *c* β 1 ; (13.31) *i*(1) = *i* − *c*α *i* − *c* β *i* 

*NL*

1

*c*α 1 − *c* β 1

It should be clear at this [stage](#page-206-2) [that](#page-206-2) [oth](#page-206-2)er choices of the set of κ ind[ependent vari](#page-206-3)ables are possible. This freedom of choice is obvious from the generalization developed in the next section. 13.1.3 Cahn's Layer Model For planar interfaces, Cahn [28] or [29, pp. 379-399] developed a layer model that treats an interfacial region of finite thickness and for which physically meaningful surface quantities can be represented by determinants which are manifestly invariant with respect to the thickness and location of the layer. The layer in Cahn's theory can be taken to be the layer we called *L* in Section 13.1 and employed by Gibbs (see Figure 13–1). It is only necessary that the planes that bound the layer be sufficiently far from the transition region that they lie in regions that are essentially homogeneous. Outside the layer, one has homogeneous phases α*H* and β*H* as in Section 13.1. These homogeneous phases are

$$U^L := U - \stackrel{\star}{U^{w_H}} - U^{\theta_H},\tag{13.33}$$

$$\mathcal{S}^{\mathcal{L}} := \mathcal{S} - \mathcal{S}^{\text{wH}} - \mathcal{S}^{\theta \mu},\tag{13.34}$$

$$\mathbf{N}_{l}^{L} := \mathbf{N}_{l} - \mathbf{N}_{l}^{\mathbf{a}H} - \mathbf{N}_{l}^{\boldsymbol{\beta}H},\tag{13.35}$$

$$V^L := V - V^{aH} - V^{\beta H}.\tag{13.36}$$

*VL* := *V* − *V*α*H* − *V*β*H* . (13.36) 6The fact that they are independent of the location of the dividing surface is not obvious from the given expressions, but they can be rewritten in terms of determinants, as shown in Section 13.1.3, in which case their

independence is obvious. 7This is consistent with the Cahn theory but not essential; one could equally well extend the uniform phases until they met each other at a dividing surface, just as in the Gibbs case, but then the quantity *VL* would be zero. In the Cahn theory, [*V*] := *VL*/*A* depends on the layer thickness, so it is not a fundamental physical quantity.

*Chapter 13* • Thermodynamics of Fluid-Fluid Interfaces 193

Note the similarity to Eqs. (13.2)–(13.5) for the excess quantities of Gibbs, with the main exception being that the layer now has a non-vanishing volume *VL* and the homogeneous regions do not meet. Following Cahn, we denote the extensive quantities of the layer per

$$\mathbf{y} = \frac{\mathbf{U} - \mathbf{T}\mathbf{S} - \sum_{l} \mu_{l} \mathbf{N}_{l} + \mathbf{p}V}{A} = \frac{\mathbf{U}^{L} - \mathbf{T}\mathbf{S}^{L} - \sum_{l} \mu_{l} \mathbf{N}_{l}^{L} + \mathbf{p}V^{L}}{A},\tag{13.37}$$

physical quantities. On the other hand, we know that the quantity γ = (*K* + *pV*)/*A* does not depend on any

γ = *U* − *TS* −

$$U^{\rm uH} - TS^{\rm uH} + pV^{\rm uH} - \sum_{l} \mu_{l} N_{l}^{\rm uH} = 0;\tag{13.38}$$

$$U^{\beta_H} - T\mathcal{S}^{\beta_H} + pV^{\beta_H} - \sum_l \mu_l N_l^{\beta_H} = \mathbf{0}.\tag{13.39}$$

where we have used the Euler equations for the bulk phases:

Eq. (13[.11)](#page-213-0) [to](#page-213-0) get

we have8

<span id="page-213-0"></span>
$$\mathcal{Y} = [U] - T[\mathcal{S}] + p[V] - \sum_{l} \mu_{l}[N_{l}].\tag{13.40}$$

*i* Therefore

γ = [*U*] − *T*[*S*] + *p*[*V*] −*i* μ*i*[*Ni*]. (13.40) Note espec[ially th](#page-210-1)at the *p* that multiplies [*V*] is the pressure of the *bulk* phases. The layer *L* is inhomogeneous and in a non-hydrostatic state of stress.

$$\mathbf{d}U^L = T\mathbf{d}S^L - p\mathbf{d}V^L + \sum_l \mu_l \mathbf{d}N_l^L + \sigma \,\mathbf{d}A.\tag{13.41}$$

d*UL* = *T* d*SL* − *p* d*VL* +- *i* μ*i* d*NL i* + σ d*A*. (13.41) Note that Eq. (13.14) has no counterpart to the term *p* d*VL* because the Gibbs dividing

$$\sigma = \frac{U^L - TS^L + pV^L - \sum_{i} \mu_i N_i^L}{A} = [U] - T[S] + p[V] - \sum_{l} \mu_l [N_l] = \chi. \tag{13.42}$$

σ = *UL* − *TSL* + *pVL* − *i A* = [*U*] − *T*[*S*] + *p*[*V*] −*i* μ*i*[*Ni*] = γ . (13.42) In Eq. (13.41), one can employ the definitions of the layer quantities per unit area and use

$$\mathbf{d}[U] = T\,\mathbf{d}[\mathbf{S}] - p\,\mathbf{d}[V] + \sum_{l} \mu_{l}\,\mathbf{d}[N_{l}].\tag{13.43}$$

*i* 8Note that this is precisely the same definition of γ as for the Gibbs dividing surface, Eq. (13.10). In the present case, however, *KL* = *K* − *K*α*H* − *K*β*H* = *K* + *p*(*V*α*H* + *V*α*H* ) = *K* + *pV* − *pVL* = *A*γ − *pVL* -= *A*γ because *VL* -= 0.

$$\mathbf{d}\boldsymbol{\lambda} = -\left[\mathbf{S}\right]\mathbf{d}T + \left[V\right]\mathbf{d}p - \sum_{l} \left[N_{l}\right]\mathbf{d}\mu_{l},\tag{13.44}$$

[194 T](#page-210-2)HERMAL PHYSICS Combining Eq. (13.43) with the differential of Eq. (13.40) yields dγ = −[*S*] d*T* + [*V*] d*p* −- *i* [*[N](#page-214-0)i*] dμ*i*, (13.44) which is the counterpart to Eq. (13.20), the Gibbs adsorption equation. As was the case with the Gibbs dividing surface, the κ +2 quantities *T*, *p*,{μ*i*, *i* = 1 ··· κ} cannot be varied independently due to the bulk Gibbs-Duhem equations, Eqs. (13.22) and

<span id="page-214-1"></span>
$$\begin{bmatrix} \begin{bmatrix} Z \end{bmatrix} \begin{bmatrix} X \end{bmatrix} \begin{bmatrix} Y \end{bmatrix} \\ Z^{u} \begin{bmatrix} X^{\alpha} & Y^{u} \\ Z^{\beta} & X^{\beta} & Y^{\beta} \\ X^{\alpha} & Y^{u} & Y^{\beta} \\ X^{\beta} & Y^{\beta} \end{bmatrix}, \tag{13.45}$$

 *Z*/*XY* ≡ [*Z*] [*X*] [*Y*] *Z*α *X*α *Y*α *Z*β *X*β *Y*β *X*α *Y*α , [(13.45](#page-214-1))

$$\mathbf{d}\boldsymbol{\gamma} = -\left[\mathbf{S}/XY\right]\mathbf{d}\mathbf{T} + \left[V/XY\right]\mathbf{d}\boldsymbol{p} - \sum_{l=1}^{n} \left[N_l/XY\right]\mathbf{d}\boldsymbol{\mu}_l \tag{13.46}$$

chosen to be dependent. The result is dγ = −[*S*/*XY*] d*T* + [*V*/*XY*] d*p* −κ *i*[=](#page-212-1)1 [*Ni*/*XY*] dμ*i* (13.46) in which differentials of the entire variabl[e](#page-214-1) [set](#page-214-1) *T*, *p*,{μ*i*, *i* = 1 ··· κ} appear but in which two of the coefficients are zero because of the structure of the determinant Eq. (13.45).

<span id="page-214-0"></span>
$$\mathbf{d}\boldsymbol{\gamma} = -\left[\mathbf{S}/\text{VN}_{\text{I}}\right]\mathbf{d}T - \sum_{l=2}^{k} \left[\mathbf{N}_{l}/\text{VN}_{\text{I}}\right]\mathbf{d}\mu_{l}.\tag{13.47}$$

dγ = −[*S*/*VN*1] d*T* −κ *i*=2 [*Ni*/*VN*1] dμ*i*. ([13.47)](#page-214-1) Equation (13.47) is the same as Eq. (13.29) or Eq. (13.30) of the Gibbs theory, but here we

see from the determinant structure of Eq. (13.45) that the coefficients of these independently variable differentials do not depend on the location of the planes that bound Cahn's

unchanged because both numerator and denominator will contain a factor *n*α*n*β which will cancel.

<sup>9</sup>Equations (13.22) and (13.23) were written in terms of amounts of homogeneous α and homogeneous β that meet at the Gibbs dividing surface whereas Cahn's layer theory pertains to homogenous phases α*H* and β*H* that lie outside the layer. But Eqs. (13.22) and (13.23) are homogeneous so they can be multiplied by any numbers *n*α and *n*β to increase or reduce the amount of each phase. This will leave the ratio of determinants in Eq. (13.45)

$$\mathbf{d}\chi = -\mathbf{[S/VN]}\,\mathrm{d}T,\tag{13.48}$$

 

*Z*β *X*β *Y*β

<span id="page-215-0"></span>   

*Chapter 13* • Thermodynamics of Fluid-Fluid Interfaces 195 layer or the location of the dividing surface of Gibbs. For a one component system, we can

$$\gamma(T) \approx \gamma_0 (1 - T/T_c)^{11/9},\tag{13.49}$$

dγ = −[*S*/*VN*] d*T*, (13.48)

$$\text{[S/VN]} \approx \frac{11}{9} \frac{\nu_0}{T_c} (1 - T/T_c)^{2/9},\tag{13.50}$$

p. 474]),

γ (*T*) ≈ γ0(1 − *T*/*Tc* ) 11/9, (13.49)

$$
\begin{vmatrix} Z \end{vmatrix} \begin{bmatrix} X \end{bmatrix} \begin{bmatrix} Y \end{bmatrix} = \begin{vmatrix} Y \\ Z^{\operatorname{U}} \end{vmatrix} = \frac{1}{A} \begin{vmatrix} Z^{\operatorname{L}} \ X^{\operatorname{L}} & Y^{\operatorname{L}} \\ Z^{\operatorname{U}} \ X^{\operatorname{u}} & Y^{\operatorname{u}} \end{vmatrix} = \frac{1}{A} \begin{vmatrix} Z & X & Y \\ Z^{\operatorname{u}} & X^{\operatorname{u}} & Y^{\operatorname{u}} \\ Z^{\operatorname{\beta}} & X^{\operatorname{\beta}} & Y^{\operatorname{\beta}} \end{vmatrix}, \tag{13.51}
$$

which is nearly constant for *T Tc* but finally becomes zero at *T* = *Tc*. We can see the independence of the layer bounds even more clearly by noting that [*Z*] [*X*] [*Y*] *Z*α *X*α *Y*α = 1 *ZL XL YL Z*α *X*α *Y*α = 1 *ZXY Z*α *X*α *Y*α , (13.51)

 

 

$$[Z/XY] = \frac{1}{A} \frac{\begin{vmatrix} Z & X & Y \\ Z^a & X^a & Y^a \\ Z^\beta & X^\beta & Y^\beta \end{vmatrix}}{\begin{vmatrix} X^a & Y^a \\ X^\beta & Y^\beta \end{vmatrix}},\tag{13.52}$$

 

[*Z*/*XY*] = 1 *A Z*α *X*α *Y*α *Z*β *X*β *Y*β *X*α *Y*α *X*β *Y*β  , (13.52) which clearly relates to the *entire system* and has nothing whatsoever to do with the

location of any bounding planes of a layer or of a dividing surface. As pointed out in the previous footnote, this expression is independent of the amounts of the homogeneous phases, which must be the case for a physically meaningful interfacial quantity. As Cahn points out from the structure of Eq. (13.45), the quantity [*Z*/*XY* ] is the difference, per unit area, in the amount of *Z* in the layer and portions of homogeneous α and β that, in combination, would have the same values of *X* and *Y* as the layer. In other words, if *k*α and *k*β are chosen so that *k*α*X*α + *k*β*X*β = *A*[*X*] and *k*α*Y* α + *k*β*Y* β = *A*[*Y* ], then

[*Z*/*XY* ]=[*Z*] − (*k*α*Z*α + *k*β*Z*β)/*A*. It follows from Eq. (13.52) that the same interpretation is true if one considers the entire system instead of the layer. The foregoing theory is easily extended to the case of planar systems in which multiple homogeneous phases are separated by interfaces. For example, suppose that three phases α, β, and η are in equilibrium with one another. These phases could be separated by two interfaces, one separating α from β and a second separating β from η. Somewhere in the

β phase, but very far from both interfaces, one could place an imaginary plane that would

196 THERMAL PHYSICS

$$\gamma^{a\beta} := \frac{K^{a\beta} + pV^{a\beta}}{A} = \frac{U^{a\beta} - TS^{a\beta} + pV^{a\beta} - \mu_l N_l^{a\beta}}{A};\tag{13.53}$$

$$\nu^{\beta\eta} := \frac{K^{\beta\eta} + pV^{\beta\eta}}{A} = \frac{U^{\beta\eta} - TS^{\beta\eta} + pV^{\beta\eta} - \mu_l N_l^{\beta\eta}}{A} \tag{13.54}$$

divide the system i[nto](#page-210-3) [tw](#page-210-3)o pa[rts,](#page-210-2) [on](#page-210-2)e that we will refer to with superscripts αβ and the other with superscripts βη. Then the quantities γ αβ := *K*αβ + *pV*αβ *A* = *U*αβ − *TS*αβ + *pV*αβ − μ*iN*αβ *i A* ; (13.53) γ βη := *K*βη + *pV*βη *A* = *U*βη − *TS*βη + *pV*βη − μ*iN*βη *i A* (13.54) will be well defined. Both γ αβ and γ βη will depend on the set of intensive variables *T*, *p*,{μ*i*} which will be uniform throughout the system. But in addition to the Gibbs-

<span id="page-216-0"></span>
$$\mathbf{d}\boldsymbol{\gamma}^{\alpha\beta} = -\left[\mathbf{S}^{\alpha\beta}/\mathbf{X}\mathbf{Z}\right]\mathbf{d}\mathbf{T} + \left[\mathbf{V}^{\alpha\beta}/\mathbf{X}\mathbf{Y}\mathbf{Z}\right]\mathbf{d}\boldsymbol{p} - \sum_{l=1}^{\kappa} \left[N_l^{\alpha\beta}/\mathbf{X}\mathbf{Z}\right]\mathbf{d}\boldsymbol{\mu}_l;\tag{13.55}$$

$$\mathbf{d}\boldsymbol{\gamma}^{\beta\eta} = -\left[\mathbf{S}^{\beta\eta}/\mathbf{XYZ}\right]\mathbf{d}T + \left[V^{\beta\eta}/\mathbf{XYZ}\right]\mathbf{d}\boldsymbol{p} - \sum_{l=1}^{k} \left[\mathbf{N}_{l}^{\beta\eta}/\mathbf{XYZ}\right]\mathbf{d}\boldsymbol{\mu}_{l} \tag{13.56}$$

*i*=1

wher[e now](#page-216-0)

$$[W^{a\beta}/XYZ] = \frac{1}{A} \frac{\begin{vmatrix} W^{a\beta} & X^{a\beta} & Y^{a\beta} & Z^{a\beta} \\ W^a & X^a & Y^a & Z^a \\ W^\beta & X^\beta & Y^\beta & Z^\beta \\ W^\gamma & X^\gamma & Y^\gamma & Z^\gamma \\ \hline & X^\beta & Y^\beta & Z^\beta \\ X^\gamma & Y^\gamma & Z^\gamma \end{vmatrix}}{\begin{vmatrix} X^\beta & Y^\beta & Z^\beta \\ X^\gamma & Y^\gamma & Z^\gamma \end{vmatrix}} \tag{13.57}$$

[*W*αβ/*XYZ*] = *A X*α *Y*α *Z*α *X*β *Y*β *Z*β *X*γ *Y*γ *Z*γ (13.57) with a similar expression for[*W*βη/*XYZ*]. Here, *X*, *Y* , *Z* must be distinct members of the set *S*, *V*,{*Ni*} and *W* can be any member of the set. Now, three of the coefficients in each of

Eqs. (13.55) and (13.56) will be zero. Thus for a binary system there would be only one free variable, say *T*. The special case of a single phase interface could occur if the α and β phases are the same but can be distinguished in some other way. Such boundaries can occur in solids, examples being grain boundaries and antiphase boundaries. Although we have not yet discussed the case of solid phases, which involve considerations of surface strain and stress as well as anisotropy, the consequences of having only one Gibbs-Duhem equation

*i*=1

$$\mathbf{d}\boldsymbol{\gamma} = -\left[\mathbf{S}/\mathbf{X}\right]\mathbf{d}T + \left[V/\mathbf{X}\right]\mathbf{d}\boldsymbol{p} - \sum_{l=1}^{\kappa} \left[\mathbf{N}_{l}/\mathbf{X}\right]\mathbf{d}\boldsymbol{\mu}_{l} \tag{13.58}$$

$$\mathbb{E}[Z/X] = \frac{1}{A} \left| \frac{Z^{\alpha} \begin{array}{c} X \\ Z^{\alpha} \end{array}}{X^{\alpha}} \right| = \frac{Z - XZ^{\alpha}/X^{\alpha}}{A} \tag{13.59}$$

*Chapter 13* • Thermodynamics of Fluid-Fluid Interfaces 197

in which *X* is any member of the set *S*, *V*,{*Ni*}. We note that *Z X* 

[*Z*/*X*] = 1 *A Z*α *X*α *X*α = *Z* − *XZ*α/*X*α *A* (13.59) which obviously does not depend on the total amount of α phase.

$$
\begin{vmatrix} Z^L & X^L & Y^L \\ Z^u & X^u & Y^u \\ Z^\beta & X^\beta & Y^\beta \end{vmatrix} = \begin{vmatrix} Z^L & k_a X^a + k_\beta X^\beta & k_a Y^a + k_\beta Y^\beta \\ Z^u & X^u & Y^u \\ Z^\beta & X^\beta & Y^\beta \end{vmatrix}.\tag{13.60}
$$

**Solution 13.2.** First we choose *k*α and *k*β so that *k*α*X*α + *k*β*X*β = *XL* and *k*α*Y*α + *k*β*Y*β = *YL*. Then we substitute for *XL* and *YL* into the middle form of Eq. (13.51) to obtain

$$
\begin{vmatrix} Z^L & X^L \ Y^L \\ Z^u & X^u & Y^u \\ Z^\beta & X^\beta & Y^\beta \end{vmatrix} = \begin{vmatrix} Z^L - k_u Z^u - k_\beta Z^\beta & 0 & 0 \\ Z^u & X^u & Y^u \\ Z^\beta & X^\beta & Y^\beta \end{vmatrix} = (Z^L - k_d Z^u - k_\beta Z^\beta) \begin{vmatrix} X^u & Y^u \\ X^\beta & Y^\beta \end{vmatrix}.\tag{13.61}$$

We multiply the second row by *k*α and the third row by *k*β and subtract the resulting rows from the first row to obtain *ZL XL YL ZL* − *k*α*Z*α − *k*β*Z*β 0 0 

[*Z*/*XY*] = (*ZL* − *k*α*Z*α − *k*β*Z*β)/*A*, (13.62)

 

$$
\langle Z/XY \rangle = (Z^L - k_a Z^a - k_\beta Z^\beta)/A,\tag{13.62}
$$

 

 When we insert this result into the definition of [*Z*/*XY*], the 2 × 2 determinant cancels and we

 

=

 

 

are left with

*Z*α *X*α *Y*α *Z*β *X*β *Y*β

### which was to be proven.

13.2 Curved Interfaces in Fluids To treat curved interfaces in fluids, we return to the comparison system of Gibbs based on a dividing surface. Our main reason for doing this is that the interfacial area can be unambiguously defined; however, for a layer model, one would have to decide what area to use. One side of the dividing surface in the comparison system is assumed to be filled by a homogeneous phase α and the other side by a homogeneous phase β. As in the case of a planar interface, the temperature *T* and the chemical potentials μ*i* are uniform throughout the system. This can be established by considering a layer that extends into the homogeneous phases, similar to the planar case, and studying variations in which there are no changes in the position of the layer. Then one invokes Eq. (13.1) to *define T* and μ*i* within this *fixed* layer and then follows the same procedure as for a planar interface to establish uniformity of *T* and the μ*i* throughout the system. Unlike the case of a planar interface, however, the homogeneous phases can have different pressures, *p*α and *p*β .

γ := *K*xs

$$K^{\infty} = K + p^{\mu}V^{\mu} + p^{\beta}V^{\beta} = K + p^{\mu}V + (p^{\beta} - p^{\mu})V^{\beta}. \tag{13.63}$$

198 THERMAL PHYSICS

Eq. (13.66) reduces to

and leads to Eq. (13.67) instead of Eq. (13.66).

[3, pp. 237-252].

$$\gamma := \frac{K^{\rm cs}}{A} = \frac{K + p^{\mu}V^{\mu} + p^{\beta}V^{\beta}}{A} = \frac{K + p^{\mu}V + (p^{\beta} - p^{\mu})V^{\beta}}{A}. \tag{13.64}$$

same equations, Eqs. (13.2)–(13.6), as in the planar case. Equation (13.8) for the Kramers potential holds as well, but now *K*α = − *p*α*V*α and *K*β = − *p*β*V*β so Eq. (13.9) becomes

*K*xs = *K* + *p*α*V*α + *p*β*V*β = *K* + *p*α*V* + (*p*β − *p*α)*V*β. (13.63) We now define

<span id="page-218-0"></span>
$$\gamma = \frac{K + p^{\mu}V}{4\pi} \frac{1}{r^2} + \frac{(p^{\beta} - p^{\mu})}{3}r,\tag{13.65}$$

Unlike the case for a planar interface, γ for a curved interface *depends* on the choice of the location of the dividing surface. We can illustrate this dependence quite simply for the case in which the β phase is a sphere of radius *r* surrounded by the α phase. Then *A* = 4π*r*2 and *V*β = (4/3)π*r*3 so γ = *K* + *p*α*V* 1 *r*2 + (*p*β − *p*α) *r*, (13.65)

<span id="page-218-1"></span>4π

γ γt

$$(p^{\beta} - p^{\mu}) = \frac{2\gamma}{r} + \frac{\partial \gamma}{\partial r}.\tag{13.66}$$

shows a sketch of γ as a function of *r*. We note that γ has a minimum value10 γ*t* at some value *rt*. We multiply Eq. (13.65) by *r*2 and take its variation with respect to *r* for a fixed physical system, so *K* + *p*α*V* and *p*β − *p*α have no variation with *r*. This results in

$$(p^{\beta} - p^{\mu}) = \frac{2\gamma\epsilon}{r_t}.\tag{13.67}$$

![](_page_218_Figure_12.jpeg)

rrt **FIGURE 13–2** Plot of γ versus *r* according to Eq. (13.65) in arbitrary units (top curve). The lower curve and the

straight line represent the individual terms. The minimum occurs at the surface of tension where *r* = *rt* and γ = γ*t*

10From stability considerations, γ must be positive. Otherwise, the system could lower its free energy indefinitely by creating an infinite amount of area. For an extensive discussion of stability, see Gibbs

*Chapter 13* • Thermodynamics of Fluid-Fluid Interfaces 199 This special choice is the so-called **surface of tension** which was introduced by Gibbs following another course of reasoning that we describe below. Before doing so, however, we [de](#page-219-0)rive the counterpart to Eq. (13.67) for a more general

$$A\frac{\partial \mathcal{V}}{\partial \lambda} \delta \lambda + \mathcal{V} \delta A = (p^{\beta} - p^{\mu}) \delta V^{\beta},\tag{13.68}$$

of discontinuity and similarly situated with respect to it, while the others are obtained by

<span id="page-219-3"></span><span id="page-219-2"></span><span id="page-219-1"></span>*A*∂γ ∂λ

$$
\bar{\delta}V^{\beta} = A\delta\lambda; \quad \delta A = (\mathbf{c}_1 + \mathbf{c}_2)A\delta\lambda. \tag{13.69}
$$

to λ, we obtain

interface that has net concavity.

$$p^{\beta} - p^{\mu} = \chi(\mathbf{c}_1 + \mathbf{c}_2) + \frac{\partial \chi}{\partial \lambda}.\tag{13.70}$$

where from differential geometry11 δ*V*β = *A*[δλ](#page-219-1); δ*A* = (*c*1 + *c*2)*A*δλ. (13.69) We therefore obtain

$$p^{\beta} - p^{\mu} = \gamma \epsilon \left(\frac{1}{R_{1t}} + \frac{1}{R_{2t}}\right). \tag{13.71}$$

If we choose the dividing [surface](#page-219-1) to correspond to the generalized surface of tension where

∂γ /∂λ = 0, Eq. (13.70) becomes12 *p*β − *p*α = γ*t* 1 *R*1*t* + 1 *R*2*t* . (13.71) In the special case of a spherical surface, *R*1*t* = *R*2*t* = *rt* and we recover Eq. (13.67). An equation of the form of Eq. (13.71) (without the subscripts *t*) is attributed to Laplace and pe[rtains](#page-219-1) to a membrane of zero thickness that has the following property: If d*τ* is any infinitesimal vector in that membrane, the membrane on one side of it exerts an attractive force per unit length γ on other side that is perpendicular to d*τ* and tangential to the surface. Equation (13.71) shows that such a relation results from thermodynamic considerations, provided we evaluate the excess surface free energy γ at the surface of tension. As we shall see below, Gi[bbs a](#page-219-1)rrived at the same equation as an approximation based on the idea that the explicit dependence of γ on the curvature of the dividing surface can be ignored for a dividing surface that is very close to the region of transition, provided that the thickness of the region of transition is small relative to either of its principal radii of curvature. In practice, γ is measured experimentally by assuming it to be equal to γ*t*

<span id="page-219-0"></span>in Eq. (13.71) and by assuming that the principal radii of curvature measured by some

technique, usually optical, are essentially the same as *R*1*t* and *R*2*t*.

<sup>11</sup>These are special cases of the integral formulae δ*V*β =

δλ d*A* and δ*A* = (*c*1 + *c*2)δλ d*A* that hold for a normal shift δλ that is a function of position on the surface. 12The quantity that multiplies γ*t* in Eq. (13.71) is called the mean curvature, with the sign convention that the radius is positive for a sphere of the β phase, or for a more general surface if the β phase is on the side of the

200 THERMAL PHYSICS **Example Problem 13.3.** Estimate the capillary rise of water and the capillary depression of mercury in a vertical glass capillary tube of inner diameter 2*r*0 = 1.0mm at a temperature of 20 ◦C. Take γ = 0.073 J/m2 for water and 0.47 J/m2 for mercury. Assume that the density is 1 g/cm3 for water and 13.55 g/cm3 for mercury. See Figure 13–3 for an illustration of the geometry and the contact angle θ where the water meets the glass. For now, assume that the contact angle is an empirical parameter; later in Section 13.3 we provide some theoretical basis for it. The water wets the glass with a contact angle of nearly zero degrees. Mercury does not wet the glass and has an obtuse contact angle of 140◦. Assume that the shape of the liquid-gas

interface is approximately a portion of a sphere (undistorted by gravity) and that the system is open to the atmosphere at a pressure of *pA*. Also assume that these liquids are locally in equilibrium with their vapors but that the rate of evaporation, the solubility of air in either liquid and the density of air are negligible. Take the gravitational acceleration to be 9.8m/s2. What would be the corresponding results if the liquids were between large parallel vertical plates separated by a small distance 2*x*0?

$$h = \frac{2\gamma}{\rho g} \frac{\cos \theta}{r_0} = a^2 \frac{\cos \theta}{r_0},\tag{13.72}$$

2γ /ρ*g* (13.73)

is given by *pA* − *ph* = ρ*gh* = 2γ cos θ/*r*0. Here, ρ*gh* is due to hydrostatic pressure, as explained in Section 11.2. Thus the capillary rise is

where

$$a \coloneqq \sqrt{2\chi/\rho \mathbf{g}}\tag{13.73}$$

![](_page_220_Figure_7.jpeg)

*h* = 2γ ρ*g*

z=h

angle θ, the liquid would be depressed below the surface of the bulk liquid.

cos θ *r*0

*a* := 

z=0 **FIGURE 13–3** Sketch of the rise of a liquid in a capillary tube of internal diameter 2*r*0. The rise *h* is defined to be the distance from the horizontal surface of the bulk liquid to the bottom of the meniscus. The contact angle θ is the angle between the tangent to the meniscus at the tube wall and the tube itself (see Section 13.3). For an obtuse

*Chapter 13* • Thermodynamics of Fluid-Fluid Interfaces 201

### has dimensions of length and is known as the **capillary length**. and *a* ≈ 3.8mm for mercury. The quantity *a* sets the length scale of capillary phenomena. For the example of capillary rise just given, *h* = (*a*2/*r*0) cos θ. For *r*0 = 0.5mm, *h* = 3 cm for water and

<span id="page-221-0"></span>*h* = − 1.4 cm for mercury. For large parallel plates separated by a small distance 2*x*0, one radius of curvature would be infinite and the other would be cos θ/*x*0 so *h* = (1/2)(*a*2/*x*0) cos θ. For *x*0 = *r*0, the magnitude of

$$
\delta U^{\text{xs}} = T \delta S^{\text{xs}} + \mu_l \delta N_l^{\text{xs}} + \sigma \delta A + C_1 \delta \sigma_1 + C_2 \delta \sigma_2,\tag{13.74}
$$

13 At 20 ◦C, *a* ≈ 5.5 mm for water

13.2.1 Gibbs Coefficients of Curvatures

$$\mathbf{C}_{1}\boldsymbol{\delta\mathbf{c}}_{1} + \mathbf{C}_{2}\boldsymbol{\delta\mathbf{c}}_{2} = (\mathbf{1}/2)(\mathbf{C}_{1} + \mathbf{C}_{2})\boldsymbol{\delta(\mathbf{c}_{1} + \mathbf{c}_{2}) + (\mathbf{1}/2)(\mathbf{C}_{1} - \mathbf{C}_{2})\boldsymbol{\delta(\mathbf{c}_{1} - \mathbf{c}_{2}).\tag{13.75}}$$

excess internal energy from a state of equilibrium is given by δ*U*xs = *T*δ*S*xs + μ*i*δ*N*xs *i* + σ δ*A* + *C*1δ*c*1 + *C*2δ*c*2, (13.74) where *C*1 and *C*2 are coefficients of the curvatures. He then employed the identity *C*1δ*c*1 + *C*2δ*c*2 = (1/2)(*C*1 + *C*2)δ(*c*1 + *c*2) + (1/2)(*C*1 − *C*2)δ(*c*1 − *c*2). (13.75) By considering a spherical surface (so that *C*1 − *C*2 = 0) and two different choices of the dividing surface that are essentially parallel to one another but separated by a small distance, he proceeded to show [3, p. 227] that the coefficient *C*1 + *C*2 can be made to change sign by means of a small shift of the dividing surface. Therefore, one can choose a dividing surface such that *C*1 + *C*2 = 0. He then argued that since *C*1 − *C*2 =0 for a planar

$$
\delta U^{\rm xs} = T \delta S^{\rm ss} + \sum_{l} \mu_{l} \delta N_{l}^{\rm ss} + \sigma \delta A,\tag{13.76}
$$

term (1/2)(*C*1 − *C*2)δ(*c*1 − *c*2), ultimately resulting in δ*U*xs = *T*δ*S*xs +- *i* μ*i*δ*N*xs *i* + σ δ*A*, [(1](#page-221-0)3.76) where σ is now dependent on the choice of the dividing surface. Provided that both

principal radii of curvature are large compared to the thickness of the inhomogeneous region, this dividing surface will be quite close to the inhomogeneous region as measured optically in an experiment. Essentially, the Gibbs argument boils down to the following: The position of the dividing surface can be chosen such that the dependence of *U*xs on warping due to

curvatures that are not too large can be neglected. Curvatures only affect *U*xs indirectly through their influence on δ*A*. We can compare our approach to that of Gibbs as follows. We return to Eq. (13.74) and integrate at constant *T*, μ*i*, *c*1, and *c*2, by just making the system larger,14 to obtain the

Euler equation

the center of the sphere, all extensive quantities will be proportional to the size of the cone.

<sup>13</sup>More accurately one should write *a*2 = 2γ /[(ρ − ρair)*g*] but the density ρair is usually negligible. 14For example, for a system consisting of a spherical surface and bulk systems inside a cone with its apex at

$$\mathbf{U}^{\mathbf{x}\mathbf{s}} = \mathbf{T}\mathbf{S}^{\mathbf{x}\mathbf{s}} + \sum_{l} \mu_{l} \mathbf{N}_{l}^{\mathbf{x}\mathbf{s}} + \sigma \mathbf{A}.\tag{13.77}$$

$$\sigma = \frac{U^{\rm xs} - TS^{\rm ss} - \sum_{l} \mu_{l} N_{l}^{\rm xs}}{A} = \frac{U - TS - \sum_{l} \mu_{l} N_{l} + p^{\rm a} V^{\rm a} + p^{\beta} V^{\beta}}{A},\tag{13.78}$$

<span id="page-222-0"></span>*U*xs = *TS*xs +-

$$
\delta U = T \delta S - p^{\mu} \delta V_{\alpha} - p^{\beta} \delta V^{\beta} + \sum_{l} \mu_{l} \delta N_{l} + \nu \delta A + C_{1} \delta c_{1} + C_{2} \delta c_{2}.\tag{13.79}
$$

σ = *U*xs − *TS*xs − *i* μ*iN*xs *i A* = *U* − *TS* − *i* μ*iNi* + *p*α*V*α + *p*β*V*β *A* , (13.78) so σ [=](#page-219-2) γ as given by Eq. [(13.64)](#page-219-3).

$$(p^{\mu} - p^{\beta})\delta V^{\beta} + \chi\delta A + \mathcal{C}_1\delta\mathfrak{c}_1 + \mathcal{C}_2\delta\mathfrak{c}_2 = \mathbf{0}.\tag{13.80}$$

δ*U* = *T*δ*S* − *p*αδ*V*α − *p*β δ*V*β +- *i* μ*i*δ*Ni* + γ δ*A* + *C*1δ*c*1 + *C*2δ*c*2. (13.79) If we now consider [a](#page-222-1) [varia](#page-222-1)tion at c[onstan](#page-219-2)t external volume *V* = *V*α + *V*β , constant *S*, and constant *Ni*, the condition for equilibrium becomes δ*U* = 0 so

<span id="page-222-1"></span>
$$(p^{\beta} - p^{a}) = (\mathbf{c}_{1} + \mathbf{c}_{2})\mathbf{y} - \frac{\mathbf{C}_{1}}{A}\mathbf{c}_{1}^{2} - \frac{\mathbf{C}_{2}}{A}\mathbf{c}_{2}^{2}.\tag{13.81}$$

For a normal shift of the interface by an amount δλ, as considered in the derivation of Eq. (13.70), we have Eq. (13.69) and also δ*c*1 = − *c*2

contact lines and was obtained as part of a complete variation of the system.

δλ Eq. (13.80) becomes

of the form15

$$\frac{\partial \chi}{\partial \lambda} = -\frac{(\mathbf{C}_1 + \mathbf{C}_2)}{2A} (\mathbf{c}_1^2 + \mathbf{c}_2^2) - \frac{(\mathbf{C}_1 - \mathbf{C}_2)}{2A} (\mathbf{c}_1^2 - \mathbf{c}_2^2). \tag{13.82}$$
 
$$\text{As that the Cikho-horizon of the reaction of the division...surface is } \mathbf{c} \cdot \mathbf{n} \text{ that is:} \quad \mathbf{n} = \mathbf{c} \cdot \mathbf{n} \mathbf{n}$$

*A A* 2. (13.81) Substitution of Eq. (13.81) into Eq. (13.70) gives ∂γ ∂λ = −(*C*1 + *C*2) 2*A* (*c*2 1 + *c*2 2) − (*C*1 − *C*2) 2*A* (*c*2 1 − *c*2 2). (13.82)

### From Eq. (13.8[2)](#page-223-0) [we](#page-223-0) [see](#page-223-0) [tha](#page-223-0)t the Gibbs choice of location of the dividing surface to make *C*1 + *C*2 = 0 and his neglect of the term in *C*1 − *C*2 is equivalent to choosing the dividing surface to satisfy ∂γ /∂λ = 0, which leads to Eq. (13.71).

13.3 Interface Junctions and Contact Angles In this section we investigate briefly the mechanical conditions that must be satisfied at the junctions where several fluid phases meet. We begin by considering the twodimensional problem of a triple junction where three phases, α, β, and η meet along a line, as illustrated in Figure 13–4. The line where the phases meet is known as a **triple line** and is perpendicular to the plane of the figure. Our objective is to determine the dihedral angles θα, θβ, and θη where these phases meet. By studying a simple variation of the position of

$$\mathbf{y}^{a\beta}\hat{\mathbf{t}}^{a\beta} + \mathbf{y}^{\beta\eta}\hat{\mathbf{t}}^{\beta\eta} + \mathbf{y}^{\eta\alpha}\hat{\mathbf{t}}^{\eta\alpha} = \mathbf{0},\tag{13.83}$$

<span id="page-222-2"></span>γ αβ*τ*ˆ αβ + γ βη*τ*ˆ βη + γ ηα*τ*ˆ ηα = 0, (13.83)

<sup>15</sup>This equation also follows from a more general result of Gibbs [3, equation 615, p. 281] that holds for curved

<span id="page-223-0"></span>![](_page_223_Figure_1.jpeg)

β α θβ π*−*θα

γηα γαβ

θη θα

η π*−*θη π*−*θβ γβη **FIGU[RE 13–4](#page-222-2)** Three phases α, β, and η that meet at a triple line (left) where they make dihedral angles θα , θβ , and θη. On the right is the corresponding force triangle with forces of magnitudes γ αβ , γ βη, and γ ηα that are directed [away from the](#page-223-0) triple junction, so their vector sum is zero. where *τ*ˆ αβ is a unit vector perpendicular to the line of intersection of the three phases, loca[lly tan](#page-222-2)gent to the αβ interface at the line of intersection, and pointing away from the η

phase. The other unit vectors *τ*ˆ βη and *τ*ˆ ηα are similarly defined with respect to their phases. One can interpret Eq. (13.83) by regarding the quantity γ αβ *τ*ˆ αβ to be a force per unit length that acts on the triple line along the α − β interface, and similarly γ βη*τ*ˆ βη, and γ ηα*τ*ˆ ηα are forces per unit length that act on the triple line along their respective interfaces. Thus, Eq. (13.83) is the condition for zero force acting on the triple line. It also follows that the vectors γ αβ *τ*ˆ αβ, γ βη*τ*ˆ βη, and γ ηα*τ*ˆ ηα form a triangle, as shown in Figure 13–4, [whose](#page-222-2) internal angles are π − θα, π − θβ, and π − θη. This triangle is known

$$\frac{\sin \theta_{\alpha}}{\chi^{\beta \eta}} = \frac{\sin \theta_{\beta}}{\chi^{\prime \eta \alpha}} = \frac{\sin \theta_{\eta}}{\chi^{\alpha \beta}}.\tag{13.84}$$

sin(π − θ ) = sin θ[,](#page-222-2) [it](#page-222-2) [foll](#page-222-2)ows that sin θα

γ βη = sinθβ γ ηα = sinθη γ αβ . (13.84) For such a Neumann triangle to exist, it is necessary for each of its sides to be less than the sum of the other two sides, for example γ βη < γ ηα + γ αβ. Equation (13.83) can also be generalized to junctions where more than three phases

meet, but such configurations might not be stable [3, p. 287]. If crystalline solids are involved, we shall see that γ is anisotropic so Eq. (13.83) must be modified to account for torque terms. To derive Eq. (13.83) from a variational principle, we suppose that all interfaces are pinned at distances that are far from the triple line and vary the position of the triple line by

$$|\ell^{a\beta}\mathbf{r}^{a\beta} - \epsilon| = \sqrt{(\ell^{a\beta})^2 - 2\epsilon \cdot \mathbf{\hat{r}}^{a\beta}\ell^{a\beta} + \epsilon^2} = \ell^{a\beta} - \epsilon \cdot \mathbf{\hat{r}}^{a\beta} \tag{13.85}$$

|αβ τ αβ − | = (αβ)2 − 2 · ˆ*τ* αβαβ + 2 = αβ − · ˆ*τ* αβ (13.85) to first order in /αβ . The corresponding change in distance is therefore − · ˆ*τ* αβ . By treating the other interfaces in a similar way, we see that the total change in energy per unit length for such a variation is

$$(-\epsilon \cdot (\hat{\mathbf{t}}^{a\beta}\gamma^{a\beta} + \hat{\mathbf{t}}^{\beta\eta}\gamma^{\beta\eta} + \hat{\mathbf{t}}^{\eta\alpha}\gamma^{\eta\alpha}) = \mathbf{0},\tag{13.86}$$

204 THERMAL PHYSICS − · (*τ*ˆ [αβγ](#page-223-0) αβ + ˆ*τ* βηγ βη + ˆ*τ* ηαγ ηα) = 0, (13.86) which has been equated to zero as a condition for equilibrium. For arbitrary , the quantity in parentheses must vanish, resulting in Eq. (13.83).

$$\cos\theta_w = \frac{(\chi^{\beta\eta})^2 - (\chi^{\eta\eta})^2 - (\chi^{a\beta})^2}{\chi^{\eta\eta}\chi^{a\beta}}\tag{13.87}$$

result in a triangle similar, but different in size, to that depicted in Figure 13–4, so the angles would be unchanged. However, if the ratios of γ αβ, γ βη, and γ ηα are speci[fied,](#page-222-2) [all](#page-222-2)

### cosines to the triangle in Figure 13–4 to obtain

[3, p. 326] for further discussion.

cos θα = (γ βη)2 − (γ ηα)2 − (γ αβ)2 γ ηαγ αβ (13.87) and similar expressions for cos β and cos η. 13.3.1 Contact Angle The variational derivation that underlies the force balances represented by Eq. (13.83) must be modified for anisotropic interfaces because the orientation of interfaces can change locally when the position of the triple line is varied. This results in additional torque terms. Nevertheless, the concept of force balances can be used to understand

three angles are determined uniquely. This can be seen analytically by applying the law of

we assume that γ *g* , γ *sg* , and γ *s* can be defined.16 Then a variation that involves sliding

**FIGURE 13–5** Contact angle θ for two fluids in contact with a rigid inert amorphous solid. On the left, θ is acute and

the liquid is said to wet the solid. On the right, θ is obtuse and the liquid does not wet the solid.

$$\boldsymbol{\gamma}^{\rm gg} = \boldsymbol{\gamma}^{\rm lg} \cos \theta + \boldsymbol{\gamma}^{\rm gl},\tag{13.88}$$

![](_page_224_Figure_9.jpeg)

Amorphous solid γ θ sg γsl γ θ sg γsl Amorphous solid

16These conditions could deviate considerably from the global equilibrium conditions discussed previously. The solid should behave as if chemically inert, with no solubility of the substances of the liquid or the gas. The gas could contain a substance insoluble in the liquid, and the vapor of the liquid can be in local equilibrium at the solid-liquid interface provided there is negligible evaporation during some period of observation. See Gibbs

$$\cos \theta = \frac{\chi^{\text{sg}} - \chi^{\text{sl}}}{\chi^{\ell \text{g}}}.\tag{13.89}$$

*Chapter 13* • Thermodynamics of Fluid-Fluid Interfaces 205 which may be solved to yield cos θ = γ *sg* − γ *s* γ *g* . (13.89) Equation (13.89) is known as **Young's equation** for the contact angle θ and represents a balance of horizontal forces. Real values of θ only exist when the right-hand side has a magnitude less than or equal to one, which requires |γ *sg* − γ *s*| ≤ γ *g* . If θ exists and γ *sg* − γ *s* > 0, θ ≤ π/2 and the liquid is said to wet the solid. For kerosene on glass, one has

θ ≈ 26◦. Complete wetting occurs for θ = 0, which is approximately the case for water on clean glass. If θ exists and γ *sg* − γ *s* < 0, θ > π/2 and the liquid does not wet the solid. For mercury on glass, one has θ ≈ 140◦. As long as the solid remains rigid and inert, no vertical variation of the contact line is possible, although it is generally supposed that the solid provides a force of adhesion equal to γ *g* sin θ to prevent the *g* interface from pulling away.

Although Young's equation helps us understand the origin of the contact angle, its

### derivation suffers from a lack of rigor. Moreover, experimentally measured contact angles are difficult to reproduce and can d[epend](#page-219-1) sensitively on impurities as well as surface

conditions of the solid. Nevertheless, the use of an empirically measured contact angle can enable one to model liquid shapes in situations of practical importance. 13.4 Liquid Surface Shape in Gravity

The shape of a liquid surface in a uniform gravitational field provides more insight regarding the role of surface tension as well as methods of measuring surface tension experimentally. We shall explore surface shapes for some two-dimensional problems and for some three dimensional problems with axial symmetry. In all [cas](#page-225-0)es we assume that Eq. (13.71) applies and drop the subscripts *t* with the understanding that, strictly speaking, we are dealing with the surface of tension. For a

$$\mathcal{K} \equiv \frac{1}{R_1} + \frac{1}{R_2} = -\frac{\left[z_{\text{xx}}(1+z_{\text{y}}^2) - 2z_{\text{x}}z_{\text{y}}z_{\text{xy}} + z_{\text{yy}}(1+z_{\text{x}}^2)\right]}{\left(1+z_{\text{x}}^2+z_{\text{y}}^2\right)^{3/2}},\tag{13.90}$$

<span id="page-225-0"></span>*K* ≡ 1 *R*1 + 1 *R*2 = − *zxx*(1 + *z*2 *y* ) − 2*zxzyzxy* [+](#page-221-0) *zyy*(1 + *z*2 *x*) 1 + *z*2 *x* + *z*2 *y* 3/2 , (13.90) where subscripts on *z* denote partial differentiation.We treat an isothermal case and single component fluids of densities ρ*g* and ρ and neglect any dependence of γ on the pressure difference17 *p* − *pg* . Moreover, we have d(*p* − *pg* ) = − (ρ − ρ*g* )*g* d*z*. Over the small

distances that are important in capillary phenomena (see the capillary length defined by

or an equivalent approximation.

<sup>17</sup>This is equivalent to eliminating the terms *C*1δ*c*1 + *C*2δ*c*2 in Eq. (13.74) by choice of the surface of tension

approximation,

$$p^{\ell} - p^{\mathrm{g}} = - (\rho^{\ell} - \rho^{\mathrm{g}}) \mathrm{gz} + \mathrm{C},\tag{13.91}$$

206 THERMAL PHYSICS

<span id="page-226-0"></span>
$$\pm \frac{\left[z_{\text{xx}}(1+z_{\text{y}}^2) - 2z_{\text{x}}z_{\text{y}}z_{\text{xy}} + z_{\text{yy}}(1+z_{\text{x}}^2)\right]}{\left(1+z_{\text{x}}^2+z_{\text{y}}^2\right)^{3/2}} = -\frac{(\rho^\ell - \rho^\emptyset)\text{gz}}{\chi} + \text{C.}\tag{13.92}$$

*p* − *pg* = −(ρ − ρ*g* )*gz* + *C*, (13.91) where C is a constant equal to the value of *p* − *pg* in the plane *z* = 0. Equation (13.71) therefore becomes19 ± *zxx*(1 + *z*2 *y* ) − 2*zxzyzxy* + *zyy*(1 + *z*2 *x*) 1 + *z*2 *x* + *z*2 *y* 3/2 = −(ρ − ρ*g* )*gz* γ + *C*. (13.92) The ± sign in Eq. (13.92) must be chosen in accordance with the sign convention in[herent](#page-226-0) in Eq. (13.71), namely that for net positive *K*, the fluid with the greater pressure is on the

### <span id="page-226-1"></span>side of the interface with the greater concavity. Moreover, *z* could be positive or negative or even change sign in the domain of interest. One can treat shapes for which the liquid

is above the gas or below the gas. In many cases, *z*(*x*, *y*) will be a multiple valued function of *x* and *y* so one must be careful [to](#page-226-1) [trea](#page-226-1)t each portion of the surface separately. Explicit choices of the correct sign are best left to examples.

$$\frac{z_{\text{xx}}}{\left(1+z_{\text{x}}^2\right)^{3/2}} = \frac{2}{a^2}z_{\text{x}}\tag{13.93}$$

For two-dimensional problems, there is only one finite radius of curvature and Eq. (13.92) can be simplified to the form *zxx* 1 + *z*2 *x* 3/2 = 2 *a*2 *z*, (13.93) where *a*2 = 2γ /[(ρ − ρ*g* )*g*]. In Eq. (13.93), the sign of the curvature term has been chosen so that for *z* > 0 one must have *zxx* > 0, which will be the case for a gas at essentially constant pressure *pg* on the upper concave side of an interface with a liquid on the lower side whose pressure *p* ≤ *pg* is decreasing with increasing *z*. Alternatively one could have

$$\frac{p\,\mathrm{d}p}{\left(1+p^2\right)^{3/2}} = \frac{2}{a^2}z\,\mathrm{d}z,\tag{13.94}$$

*p* d*p*

which may be integrated to yield

<span id="page-226-2"></span>
$$\text{eld}$$

$$-\frac{1}{\left(1+p^2\right)^{1/2}} = \frac{z^2}{a^2} - 1; \quad z^2 \le a^2. \tag{13.95}$$

− 1 1 + *p*2 1/2 = *z*2 *a*2 − 1; *z*2 ≤ *a*2. (13.95)

be valid if the gas were replaced by a nearly incompressible liquid. 19In a gravitational field, γ can depend implicitly on *z* (see Eqs. (613-614) of Gibbs [3, p. 281]) but this weak dependence is usually negligible.

Here, the constant of integration was evaluated by setting *p* = 0 for *z* = 0. 18For liquids, the compressibility is very small. For an ideal gas, ρ ∝ exp(−*mgz*/*k*B*T*) and *k*B*T*/*mg* is the order of magnitude of 10 m. Usually ρ ρ*g* so we could neglect ρ*g* but we retain it in the formulae which would still

negative square root to obtain

*z*min = −*a*

 

1 − sinθ = −

<span id="page-227-1"></span>*Chapter 13* [• Th](#page-226-2)ermodynamics of Fluid-Fluid Interfaces 207

$$\mathbf{z}_{\text{max}} = a\sqrt{1-\sin\theta} = \sqrt{\frac{2\chi}{(\rho^{\ell}-\rho\mathbb{S})\mathbf{g}}}\sqrt{1-\sin\theta}.\tag{13.96}$$

if π/2 ≤ θ ≤ π. **Solution 13.4.** Since the plate is large, we ignore end effects and treat the problem as two dimensional. First we treat the case 0 ≤ θ ≤ π/2. At the line of contact with the glass, *p* = cot θ ≥ 0 so (1 + *p*2)−1/2 = sin θ ≥ 0. Thus, Eq. (13.95) yields

$$z_{\rm min} = -a\sqrt{1 - \sin\theta} = -\sqrt{\frac{2\chi}{(\rho^\ell - \rho\mathfrak{g})\mathfrak{g}}}\sqrt{1 - \sin\theta}.\tag{13.97}$$

For π/2 ≤ θ ≤ π, *p* = cot θ ≤ 0 at the line of [contact](#page-226-2). For this contact angle, sin θ ≥ 0 but cos θ ≤ 0. Equation (13.95) still applies and can be solved for *z*2 but we must now take the

2γ

(ρ − ρ*g* )*g* For the same value of sin θ, the interface shapes for acute and obtuse contact angles are mirror images of one another in the plane *z* = 0.

 

$$\frac{\mathbf{d}\psi}{\mathbf{ds}} = \frac{2}{a^2} \mathbf{z}.\tag{13.98}$$

1 − sin θ. (13.97)

<span id="page-227-0"></span>hold for both *z*2 > *a*2 and *z*2 < *a*2. This can be handled by introducing the angle ψ where sin ψ = d*z*/d*s* and cos ψ = d*x*/d*s* where *s* is arc length. Then Eq. (13.93) takes the form dψ d*s* = 2 *a*2 *z*. (13.98) In this parametric representation, ψ will continue to increase as *z* and *s* increase, so the

curvature dψ/d*s* will remain positive as *z* increases from zero, or remain negative as *z*

![](_page_227_Figure_11.jpeg)

X X0 **FIGURE 13–6** Shape of the meniscus of a fluid drawn up by a vertical plate at some distance *X*0 along the *X* axis. Of course the actual curve stops at *X*0 where it makes the appropriate contact angle θ with the plate. The maximum height, *Z*max = √1 − sin θ, occurs at the line of contact. By removing the vertical plate, the same curve can be used to treat a plate that makes an angle φ with the *X* axis. If the contact angle is obtuse, one uses a downward sloping curve that is the mirror reflection *Z* → −*Z*. ψ is the angle made by a tangent to the curve and the *X* axis.

208 THERMAL PHYSICS

Figure 13–6.

as illustrated in the next few figures.

<span id="page-228-0"></span>
$$\frac{\mathbf{d}\psi}{\mathbf{d}S} = 2Z;\tag{13.99}$$

<span id="page-228-2"></span>
$$\frac{d\mathbf{x}}{d\mathbf{S}} = \cos\psi;\tag{13.100}$$

$$\frac{dZ}{d\mathbf{S}} = \sin\psi.\tag{13.101}$$

dψ d*[S](#page-228-0)* = 2*Z*; (13.99) d*X* d*S* = cos ψ; (13.100) d*Z* d*S* = sin ψ. (13.101) One could integrate the set Eqs. (13.99)–(13.101[) by starting](#page-227-0) from some contact angle where cos ψ = sin θ, sin ψ = ± cos θ, and *Z* = ± (1 − sin θ )1/2, but a more useful approach is t[o begin](#page-227-1) at a very small value *Z* = at *X* = *Z* = *S* = 0 and to integrate numerically.

This gives a universal curve that can be stopped at any value of *X* that corresponds to the correct contact angle. To get started, however, one needs a compatible starting value of ψ. This can be obtained by combining Eqs. (13.99) and (13.101) to obtain dψ/d*Z* = 2*Z*/ sin ψ which [can](#page-228-1) [be](#page-228-1) readily integrated to give cos ψ = 1−*Z*2. Thus, the starting values for ψ satisfy cos ψ = 1 − 2 and sin ψ = (2 − 2) 1/2. The result [of numerica](#page-227-0)l integration is shown in

<span id="page-228-1"></span>
$$z_{\text{max}} = a\sqrt{1 + \cos(\phi + \theta)}.\tag{13.102}$$

φ with the surface of the bulk fluid, as shown in Figure 13–6. We still have the solution *Z*2 = 1 − cos ψ. For an acute contact angle θ, we have ψ = π − (φ + θ ) ≥ 0 so instead of Eq. (13.96) we have *z*max = *a* 1 + cos(φ + [θ )](#page-228-1). (13.102) In Eq. (13.102), the values of φ are limited because we need ψ ≥ 0 which requires φ ≤ π −θ. In fact, when φ = π −θ, *z*max =0 and the interface remains flat. The opposite limit is φ = 0, √1 + cos θ. As is evident from Figure 13–6, a value of φ very near to

which yields *z*max =*a* zero corresponds to a case where the *X* coordinate of the i[ntersec](#page-228-0)ti[on of th](#page-228-2)e plate with *Z* = 0 tends to *X* → ∞. In other words, moving the plate toward φ = 0 "squeezes" the fluid above *z* > 0 in the negative *X* direction.

For an obt[use con](#page-228-0)tact angle θ > π/2, the corresponding relation at the contact line is ψ = π − (φ + θ ) ≤ 0. Thus *z*min = − *a* √1 + cos(φ + θ ). For θ = π − θ and φ → π − φ, we have *z*min = − *z*max where the latter is given by Eq. (13.102). The detailed shape of the meniscus for two-dimensional problems can be expressed analytically in terms of incomplete elliptic integrals but such a solution is not very enlightening because those integrals must ultimately be evaluated numerically. With the availability of fast computers and software such as NDSolve in MathematicaTM, it is a simple matter to integrate a first order system such as Eqs. (13.99)–(13.101) numerically and then use a parametric plotting routine to display the result. A number of interesting solutions can be obtained by choosing ψ = α at the origin *X* = *Z* = *S* = 0, where 0 ≤ α ≤ π. In view of Eq. (13.99), the curvature is zero at *Z* = 0 and changes sign along any curve that passes through *Z* = 0, where the curve has an inflection. Such an inflection point might not appear on a curve of physical interest, but portions of the remainder of the curve may be relevant. Since the equations are nonlinear, the behavior as α changes is quire diverse

0.5

<span id="page-229-0"></span>![](_page_229_Figure_1.jpeg)

<span id="page-229-1"></span>-2 -1 1 2 –1 -0.5 0.5 X -0.4-0.2 0.20.4 -1 -0.5 X

![](_page_229_Figure_3.jpeg)

-1 -0.5 X -1 -0.5 0.5 1 -1 -0.5 X

**FIG[URE 13–8](#page-229-1)** Two-dimensional interfaces obtained by numerical integration of the system Eqs. (13.99)– (13.101) for α = 1.09 (left) and α = 1.20 (right). The loops that nearly coalesced for α = 0.86 separate. For α = 1.20, portions of

non-wetted vertical plates with the inflection occurring between the plates.

-1 [-0.5](#page-229-0) 0.5 1

[the curve can be used to represent a two-dimensional bubble or a two-dimensional drop with a neck. For](#page-230-0) α = 1.09, the neck nearly vanishes. Figure 13–7 shows some results for a small and intermediate value of α. The nature of the curve changes for about α = 0.86 where the loops coalesce. Only a portion of any curve will be needed to satisfy wetting conditions at bounding surfaces. Part of an upper loop could represent a two-dimensional bubble and part of a lower loop could represent a two-dimensional drop. As α increases, the character of the solution changes, as illustrated in Figure 13–8. Portions of curves could represent a two-dimensional bubble or a twodimensional drop with a neck. Curves for still larger values of α are depicted in Figure 13–9. By using an obtuse angle α, one can rename variables to get equations of the same form as Eqs. (13.99)–(13.101) except for a relative minus sign in Eq. (13.99). Portions of these curves could represent an inverted meniscus (liquid on top) between wetted and

<span id="page-230-0"></span>![](_page_230_Figure_1.jpeg)

-1 -0.5 0.5 1 -1 -0.5 0.5 X -2 -1 1 2 -0.4 -0.2 0.2 X

**FIGURE 13–9** Two-dimensional interfaces obtained by numerical integration of the system Eqs. (13.99)– (13.101) for α = π/2 = 1.5708 (left) and α = 3π/4 = 2.3562 (right). The neck seen for α = 1.20 vanishes at α = π/2 where the curve has vertical points of inflection. For α = 3π/4 the inflection is no longer vertical and [the amp](#page-226-0)litude has decreased. The amplitude would decrease to zero at α = π. Portions of curves that contain the inflection could represent an

### inverted meniscus (liquid on top) between wetted and non-wetted vertical plates with the inflection occurring between the plates. Other portions that do not contain the inflection could represent two-dimensional bubbles or

drops.

<span id="page-230-1"></span>13.4.2 Examples in Three Dimensions

$$\frac{\left[z_{\text{lxi}}(1+z_{\text{y}}^2) - 2z_{\text{lxi}}z_{\text{lxi}} + z_{\text{l}\text{y}}(1+z_{\text{x}}^2)\right]}{\left(1+z_{\text{x}}^2+z_{\text{y}}^2\right)^{3/2}} = \frac{z_{\text{l}\text{y}}}{\left(1+z_{\text{r}}^2\right)^{3/2}} + \frac{1}{r}\frac{z_{\text{r}}}{\left(1+z_{\text{r}}^2\right)^{1/2}}.\tag{13.103}$$

 *[zxx](#page-230-1)*(1 + *z*2 *y* ) − 2*zxzyzxy* + *zyy*(1 + *z*2 *x*) 1 + *z*2 *x* + *z*2 *y* 3/2 = *zrr* 1 + *z*2 *r* 3/2 + 1 *r zr* 1 + *z*2 *r* 1/2 . (13.103) The individual terms on the right-hand side of Eq. (13.103) are principal curvatures, the first being the curvature in the *r*, *z* plane and the second being in a perpendicular plane. The center of curvature of this second curvature lies on the *z* axis, as is well known. The problem associated with *z* being a multiple-valued function on different parts of the surface can be alleviated by introducing the angle ψ between the tangent to the surface and the *r* axis, specifically by d*r*/d*s* = cos ψ and d*z*/d*s* = sin ψ, where *s* is arc length

$$\frac{\mathbf{d}\psi}{\mathbf{ds}} + \frac{\sin\psi}{r},\tag{13.104}$$

d*s* + *r* , (13.104)

<span id="page-230-2"></span>dψ

side of Eq. (13.103) takes the form

which is valid even when *z* is a multiple-valued function of *r*. For a pendant drop, which is a liquid drop hanging from a syringe and surrounded by a gas, we take *z* = 0 at the bottom of the drop so *z* is positive on the actual interface. In Eq. [(13.92)](#page-226-0), the constant *C* = 2/*R*0 > 0 where *R*0 is the radius of curvature at the drop tip[,20](#page-231-0) so we obtain

<span id="page-231-2"></span>
$$\frac{\mathbf{d}\psi}{\mathbf{ds}} + \frac{\sin\psi}{r} = -2\frac{z}{a^2} + \frac{2}{R_0} \tag{13.105}$$

with 0 ≤ ψ ≤ π and *a*2 = 2γ /[(ρ − ρ*g* )*g*]. For a sessile drop, which is a liquid drop resting on a solid surface and surrounded by a gas, we take *z* = 0 to correspond to the maximum height of the drop, so *z* will be negative on the actual interface and *C* = − 2/*R*0 < 0. Then Eq. [(13.92)](#page-226-0) becomes

<span id="page-231-1"></span>
$$\frac{\mathbf{d}\psi}{\mathbf{ds}} + \frac{\sin\psi}{r} = -2\frac{z}{a^2} - \frac{2}{R_0} \tag{13.106}$$

with 0 ≥ ψ ≥ −π. Rather than work with negative *z* and ψ in Eq. [(13.106)](#page-231-1), one can make the transformation *z* → −*z* and ψ → −ψ and then multiply the equation through by −1 to get an equation for the shape of a "sessile bubble." Then one can combine this equation with Eq. [(13.105)](#page-231-2) to obtain

<span id="page-231-3"></span>
$$\frac{\text{d}\psi}{\text{ds}} + \frac{\sin\psi}{r} = \pm 2\frac{z}{a^2} + \frac{2}{R_0}; \quad \frac{-\text{for a pendant drop}}{+\text{for a sessille bubble}} \tag{13.107}$$

with *z* ≥ 0 and 0 ≤ ψ ≤ π.

Equation [(13.107)](#page-231-3) is a nonlinear differential equation that must be integrated numerically to determine the detailed shape of the drop. To do this, we introduce dimensionless length variables *R* := *r*/*R*0, *Z* := *z*/*R*0, and *S* : = *s*/*R*0 to obtain the following set of parametric equations:

<span id="page-231-4"></span>
$$\frac{d\psi}{d\mathcal{S}} = 2 - \frac{\sin\psi}{R} \pm 2\frac{R_0^2}{a^2}Z;\tag{13.108}$$

$$\frac{\text{dR}}{\text{dS}} = \cos \psi;\tag{13.109}$$

<span id="page-231-5"></span>
$$\frac{dZ}{dS} = \sin \psi. \tag{13.110}$$

This set of first order equations can be integrated numerically from starting values ψ = 0, *Z* =*S* =0 and the limiting value (sin ψ)/*R* → 1 as *R* → 0 to produce a shape that depends on the shape parameter *R*2 0/*a*2. By fitting to an experimentally measured shape and measuring the value of *R*0, one can determine the capillary length *a*, and hence γ . For a very small drop or bubble, *R*02/*a*2 1, the last term in Eq. [(13.108)](#page-231-4) becomes very small and the shape becomes nearly spherical. For a very large drop or bubble, *R*02/*a*2 1 and the shapes will be nearly flat at their tips.

Several sessile shapes computed by numerical integration of Eqs. [(13.108)](#page-231-4)–[(13.110)](#page-231-5) with the plus sign are shown in [Figure 13–10.](#page-232-0) Of course the actual shapes stop when they

<span id="page-231-0"></span><sup>20</sup>At the drop tip, the second term in Eq. [(13.104)](#page-230-2) is not easy to evaluate because *r* → 0 but also sin ψ → 0. By symmetry, both radii of curvature are equal at the drop tip, so the total curvature there is just twice the curvature in the *r*, *z* plane. Alternatively, one can see this from the Cartesian representation on the left-hand side of Eq. [(13.103)](#page-230-1).

<span id="page-232-0"></span>![](_page_232_Figure_1.jpeg)

R **FIGURE 13–10** Curves on the left represent sessile shapes in dimensionless coordinates *R*, *Z* scaled with the radius of curvature *R*0 at the drop tip. The top curve is for *R*2 0/*a*2 = 0.1 and the middle and bottom curves are for *R*0 larger by factors of 2.5 and 5, respectively. Note that the shape becomes less spherical for larger *R*0. The curves on the right (which occur in inverted order) are rescaled to reflect true distance in units of *a*/ √ 10 = *a*/3.16, about 1.74 mm for water. The orientation shown is for sessile bubbles; if they are turned upside down they represent sessile drops.

<span id="page-232-1"></span>![](_page_232_Figure_3.jpeg)

R **FIGURE 13–11** Curves on the left represent pendant shapes in dimensionless coordinates *R*, *Z* scaled with the radius of curvature *R*0 at the drop tip. The top curve is for *R*2 0/*a*2 = 0.225, the middle curve for *R*2 0/*a*2 = 0.300 and bottom curve for *R*2 0/*a*2 = 0.625. Note that the shape develops a neck for approximately *R*2 0/*a*2 < 0.300. The curves on the right (that occur in the same order) are rescaled to reflect true distance in units of *a*/ √ 10 = *a*/3.16, about 1.74 mm for water. The orientation shown is for pendant drops; if they are turned upside down they represent pendant bubbles.

reach some bounding surface. For the orientation shown, the shapes represent sessile bubbles attached to the top of some container. If they are turned upside down, they represent sessile drops that rest on a bottom surface.

Several pendant shapes computed by numerical integration of Eqs. [(13.108)](#page-231-4)–[(13.110)](#page-231-5) with the minus sign are shown in [Figure 13–11.](#page-232-1) In this case, a sufficiently small value of approximately *R*2 0/*a*2 < 0.300 gives rise to a drop shape with a neck. As shown, the curves pertain to pendant drops hanging from a syringe; if they are turned upside down they represent "pendant bubbles" that could be produced by means of a syringe that injects gas at the bottom of a liquid.

For a discussion of many other possible shapes of three-dimensional interfaces, including shapes that do not intersect the *z* axis, which is the axis of revolution, see Princen [30, chapter 1].

This page intentionally left blank

# 14

# Thermodynamics of Solid-Fluid Interfaces

In this chapter, we take up solid-fluid interfaces which are regions of discontinuity between an amorphous solid or a crystal and a fluid. This is an advanced topic whose detailed treatment requires some knowledge of elasticity tensors and surface differential geometry. Those not familiar with elasticity tensors can skip [Sections 14.1.1](#page-238-0) and [14.1.2,](#page-240-0) the results of which are not used in the remainder of the chapter. Needed aspects of surface differential geometry are covered in Appendix C.

Many aspects of solid-fluid interfaces are the same as those for fluid-fluid interfaces treated in Chapter 13. Nevertheless, some aspects are very different because solids are quite rigid and can support states of shear over considerable periods of time. In other words, they can behave elastically, except at very high temperatures where they can deform plastically by creep. Consequently, the mechanical properties of solids must be described in terms of stress and strain tensors. Moreover, crystalline solids are anisotropic, which results in anisotropy of the interfacial free energy, γ . Solid surfaces can change their areas in two distinct ways, by stretching and by accretion at their boundaries. Therefore, they must be characterized by strain variables absent for a fluid.

We begin by considering planar solid-fluid interfaces, essentially parallel to our treatment of fluid-fluid interfaces but with new complications, including the fact that the interfacial free energy can be referenced to the area of either a stretched or an unstretched interface. The corresponding Gibbs adsorption equation contains the surface stress tensor that must be defined carefully with respect to the state of strain of the solid. This surface stress tensor is anisotropic for a crystal. Anisotropy of γ is treated by means of an auxiliary vector field, the *ξ* -vector field, introduced by Gibbs, whose properties were developed by Hoffman and Cahn. Anisotropy gives rise to torques that arise when the orientation of a surface element is changed. These torques affect the equilibrium conditions at triple junctions where phases meet. The *ξ* -vector formalism can be extended to orientations for which the derivatives of γ are not well defined by identifying *ξ* with the diameter of a Herring sphere used to determine the Gibbs-Wulff equilibrium shape of a small crystal. Large planar crystal surfaces whose surface orientations are not present on the equilibrium shape can lower their surface free energy by faceting. General conditions for equilibrium at curved surfaces of crystals, described parametrically, are derived by using a variational technique. The equilibrium shape is shown to be similar to that of a polar plot of the *ξ* -vector, suitably truncated to form a convex body. By using a Monge representation of a crystal surface, the Herring formula for local equilibrium is derived. It is shown that

the surface free energy, per unit area of a reference plane from which the surface height is measured, is the Legendre transform of the equilibrium shape, and *vice versa*.

Finally, we make a few remarks about solid-solid interfaces.

### <span id="page-236-3"></span>14.1 Planar Solid-Fluid Interfaces

We now treat planar interfaces, such as depicted in Figure 13–1, except that one phase is a solid (superscript *s*) and the other is a fluid (superscript *F*). The bulk solid is assumed to be homogeneous; in particular, it is in a state of homogeneous stress and strain. If the solid is a crystal, we treat a constrained equilibrium such that the planar interface has a definite direction with respect to the crystallographic axes. Such an interface might not be stable with respect to breakup into a hill and valley structure (made up of facets) but we will examine this possibility later in [Section 14.4.](#page-253-0) For amorphous solids, stability of a planar interface with respect to faceting is not an issue.

When a bulk solid is in equilibrium at temperature *T* with a bulk fluid across a hypothetical surface element with normal **n**ˆ pointing from solid to fluid, the following boundary conditions are valid at that surface element [31–33]:

$$\mu_v^s - T\mathbf{s}_v^s - \sum_l \mu_l^F \rho_l^s = -\mathbf{p}^F;\tag{14.1}$$

<span id="page-236-1"></span><span id="page-236-0"></span>
$$\sum_{\alpha} n_{\beta} \sigma_{\alpha \beta} = -p^F n_{\beta}, \tag{14.2}$$

where *us v* is the internal energy density of the solid, with α and β representing Cartesian coordinates, *ss v* is the entropy density of the solid, ρ*s i* is the partial density of chemical component *i* in the solid, σαβ is the symmetric Cauchy stress tensor in the solid, *pF* is the pressure of the fluid, and μ*F i* is the chemical potential of component *i* in the fluid. Equation [(14.2)](#page-236-0) is just a balance of forces at the surface element. If we take the surface element to be perpendicular to the *z*-axis, it becomes σ*zz* = −*pF* , σ*xz* = σ*yz* = 0, consistent with the fact that a fluid in equilibrium cannot support shear. Equation [(14.1)](#page-236-1) is a thermodynamic condition. If the mobility of the chemical components of the solid was unrestricted and the solid was in chemical equilibrium,[1](#page-236-2) its chemical potentials μ*s i* = μ*F i* . If the solid behaved like a fluid, it would be in a state of hydrostatic stress, so σαβ = −*ps* δαβ and the left-hand side of Eq. [(14.1)](#page-236-1), *via* its Euler equation, would be the negative of its

<span id="page-236-2"></span><sup>1</sup>Generally speaking, solids are quite rigid and mobility of chemical components within them is quite slow, although not zero. On practical time scales, mobility of such components can sometimes be ignored. This leads to the concept of a Gibbs solid in which the "substance of the solid" is fixed and immobile. Alternatively, movement of solid components can be allowed to occur but restricted to obey certain rules. For example, in a Larché-Cahn (LC) solid [31, 32], components that can only reside on a lattice are allowed to move only by virtue of exchange with point defects, namely lattice vacancies. For the LC solid, and with vacancies assumed to be a conserved species within a single crystal, LC define diffusion potentials *Mi* that are formally equal to the differences of chemical potentials of chemical components and chemical potentials of vacancies, calculated in that extended description. So for an LC solid, their *Mi* would be equal to our μ*s i*.

<span id="page-237-0"></span>*Chapter 14* • Thermody[nami](#page-236-0)cs of Solid-Fluid Interfaces 217

pressure *ps*. In that case, Eqs. (14.1) and (14.2) would coalesce and beco[me sim](#page-237-0)ply *ps* = *pF* . But a solid in a general state of stress has no such simple Euler equati[on.](#page-237-0) For a homogeneous solid, however, the left-hand side of Eq. (14.1) is uniform (independent of position) so one can multiply by the volume of the solid *Vs* to obtain *Us* − *TSs* − μ*F i Ns i* = −*pFVs* , pseudo-Euler, homogeneous cylindrical solid, (14.3) which resembles an Euler equation except that μ*F i* and *pF* pertain to the fluid. If such a homogeneous solid were surrounded by a fluid, Eq. (14.2) would compel the solid to be in a state of hydrostatic stress. On the other hand, for a *constrained equilibrium* in which a homogeneous cylindrical solid that [is on](#page-237-0)ly in contact with the fluid across a planar interface perpendicular to the generators of its cylindrical surface, Eq. (14.3) applies and the solid can be in a state of nonhydrostatic stress. The fact that Eq. (14.3) also applies to a homogeneous solid and a homogeneous liquid separated by an actual planar region of discontinuity can be seen by considering a layer bounded by imaginary planes located in

homogeneous phases on opposite sides of the region of discontinuity, just as was done for fluid-fluid interfaces. Then one can study variations in which the layer is unchanged but translates intact in either direction perpendicular to the planes that bound it. For such variations, changes of the homogeneous phases are the same as if the layer did not exist

$$K^{\infty} = U - TS - \sum_{l} \mu_{l}^{F} N_{l} - (U^{\text{g}} - TS^{\text{g}} - \mu_{l}^{F} N_{l}^{\text{g}}) - (U^{F} - TS^{F} - \mu_{l}^{F} N_{l}^{F})$$

$$= U^{\text{gs}} - TS^{\text{gs}} - \sum_{l} \mu_{l}^{F} N_{l}^{\text{gs}} = U - TS - \sum_{l} \mu_{l}^{F} N_{l} + \mu^{F} V,\tag{14.4}$$

*Kxs* = *U* − *TS* −*i* μ*F i Ni* − (*Us* − *TSs* − μ*F i Ns i* ) − (*UF* − *TSF* − μ*F i NF i* ) = *Uxs* − *TSxs* −- *i* μ*F i Nxs i* = *U* − *TS* −- *i* μ*F i Ni* + *pFV*, (14.4) where the last expression is clearly independent of the location of the dividing surface that separates the homogeneous solid from the homogeneous fluid. Here, *Uxs* = *U* − *Us* − *UF* , *Sxs* = *S* − *Ss* − *SF* , and *Nxs i* = *Ni* − *Ns i* − *NF i* but *Vxs* = *V* − *Vs* − *VF* = 0, since the bulk phases meet at the dividing surface. Then we can define an excess potential per unit area by dividing by a suitable area. Following Cahn [28] or [29, pp. 379-399], we distinguish two cases, γ obtained by dividing by the area *A* of the actual strained state and γ0 obtained

<span id="page-237-1"></span>
$$\gamma A = \gamma_0 A_0 = U - TS - \sum_{l} \mu_l^F N_l + \mu^F V = U^{\infty} - TS^{\infty} - \sum_{l} \mu_l^F N_l^{\infty}.\tag{14.5}$$

μ*F*

γ *A* = γ0*A*0 = *U* − *TS* −*i i Ni* + *pFV* = *Uxs* − *TSxs* −*i i Nxs i* . (14.5) We could also use these same definitions of γ and γ0 for a *layer model*, similar to that

μ*F*

*i*

$$\gamma A = \gamma_0 A_0 = U - \text{TS} - \sum_l \mu_l^F N_l + \mathbf{p}^F V = U^L - \text{TS}^L - \sum_l \mu_l^F N_l^L + \mathbf{p}^F V^L,\tag{14.6}$$

*i*

*V* − *Vs* − *VF* -

<span id="page-238-1"></span>218 THERMAL PHYSICS where the bulk phases only extend to the imaginary planes that bound the layer, so *VL* =

$$\mathbf{d}U^{L} = T\mathbf{d}S^{L} - p^{F}\mathbf{d}V^{L} + \sum_{l} \mu_{l}^{F} \mathbf{d}N_{l}^{L} + A \sum_{a\beta} f_{a\beta}^{L} \mathbf{d}\epsilon_{a\beta},\tag{14.7}$$

these locations and do have physical meaning. We treat the more general lay[er mo](#page-240-1)del first and then indicate the slight modification needed to treat the dividing surface model. To do this, we adopt an equation for d*UL* of the form d*UL* = *T*d*SL* − *pF*d*VL* +- *i* μ*F i* d*NL i* + *A* - αβ *f L* αβdεαβ , (14.7) which is similar to [Eq. (1](#page-238-1)3.41) except for the last term. [This](#page-237-1) last term accounts for*stretching* of the interface that accompanies straining of the *bulk solid* and replaces γ d*A* for a

### for an interface perpendicular to the *z*-direction, as above. The 2 × 2 tensor εαβ is a symmetric strain tensor (see Eq. (14.17)) *measured in the bulk homogeneous solid* and *f L*

<span id="page-238-0"></span>fluid-fluid interface. Here, the Cartesian indices α and β take on the values *x* and *y*

is a symmetric stress tensor. This stress tensor must be consistent with the symmetry of the underlying solid, anisotropic if crystalline and isotropic if amorphous.

$$\mathrm{d}\gamma_{0} = -\frac{S^{L}}{A_{0}}\,\mathrm{d}T + \frac{V^{L}}{A_{0}}\,\mathrm{d}\boldsymbol{p}^{F} - \sum_{l} \frac{N_{l}^{L}}{A_{0}}\,\mathrm{d}\mu_{l}^{F} + \frac{A}{A_{0}}\sum_{a,\beta}f_{a\beta}^{L}\,\mathrm{d}\varepsilon_{a\beta},\tag{14.8}$$

αβ

we obtain dγ0 = −*SL A*0 d*T* + *VL A*0 d*pF* −- *i NL i A*0 dμ*F i* + *A A*0 - α,β *f L* αβ dεαβ , (14.8) which is the counterpart to the Gibbs adsorption equation for fluids, Eq. (13.44). Similar to the fluid case, the variables *T*, μ*F i* , *pF* , and εαβ are not independent because of the equations of bulk equilibrium of the solid and fluid phases. Two of these can be chosen as dependent variables and their differentials expressed in terms of the differentials of the others, most elegantly by using the determinant formalism discussed in terms of Cahn's

$$\mathbf{S}^{F}\mathbf{d}T - V^{F}\mathbf{d}p^{F} + \sum_{l} N_{l}^{F}\mathbf{d}\mu_{l}^{F} = \mathbf{0},\tag{14.9}$$

*SF* d*T* − *VF* d*pF* +- *i NF i* dμ*F i* = 0, (14.9) but also an equivalent Gibbs-Duhem equation for a cylinder of homogeneous bulk solid in equilibrium with that fluid across a plane perpendicular to the *z*-axis. This equation can

αβ

*i*

$$S^{\mathcal{S}} \mathbf{d}T - V^{\mathcal{S}} \mathbf{d}p^{F} + \sum_{l} N_{l}^{\mathcal{S}} \mathbf{d}\mu_{l}^{F} - V^{\mathcal{S}} \sum_{a\beta} \sigma_{a\beta}^{\text{lat}} \mathbf{d}\varepsilon_{a\beta} = \mathbf{0},\tag{14.10}$$

where

the fluid, which is just

be written in the form

$$
\sigma_{\alpha,\beta}^{\rm lat} \equiv \sum_{\mathbf{x}',\lambda} \frac{\partial \mathbf{x}'_{\alpha}}{\partial \mathbf{x}_{\mathbf{x}}} (\sigma_{\kappa\lambda} + \mathbf{p}^{F} \delta_{\kappa\lambda}) \frac{\partial \mathbf{x}'_{\beta}}{\partial \mathbf{x}_{\lambda}}.\tag{14.11}
$$

*Chapter 14* • Thermodynamics of Solid-Fluid Interfaces 219 σlat α,β ≡ - κ,λ ∂*x* α ∂*x*κ (σκλ + *pF* δκλ) ∂*x* β ∂*x*λ . (14.11)

<span id="page-239-1"></span>The last term in Eq. (14.10), in which all sums are only over *x* and *y* coordinates, is present

depend on the ch[oice](#page-239-1) [of](#page-239-1) independent variables. Consequently,

either *X* or *Y* is chosen to be *V*.

shear stress of the order of 10 MPa.

μ*F*

$$\mathbf{d}\boldsymbol{\gamma}_{0} = -\mathbf{[(S^{L}/A_{0})/XY]}\mathbf{d}T + \mathbf{[(V^{L}/A_{0})/XY]}\mathbf{d}p^{F} - \sum_{l=1}^{\kappa} \mathbf{[(N_{l}^{L}/A_{0})/XY]}\mathbf{d}\mu_{l}^{F} + \sum_{a,\beta} f_{a\beta}^{C} \mathbf{d}\varepsilon_{a\beta},\qquad(14.12)$$

of a hydrostatic reference state, and the coordinates **x** are those of the actual state. If the solid were in a state of hydrostatic stress in its actual state, σκλ = −*pF* δκλ and the last term would vanish. We can therefore write (with a notation similar to Eq. (13.46)) κ

$$f_{a\theta}^{C} \equiv \frac{1}{A_0} \frac{\begin{vmatrix} A_{ap\theta}^{L} & X^{L} & Y^{L} \\ V^{s} \sigma_{ap\theta}^{\text{half}} & X^{s} & Y^{s} \\ \mathbf{0} & X^{F} & Y^{F} \\ \hline & \begin{array}{c} X^{s} & Y^{s} \\ X^{F} & Y^{F} \end{array} \end{vmatrix}}{\begin{array}{c} \begin{array}{c} X^{s} & Y^{s} \\ X^{F} & Y^{F} \end{array} \end{array}} \tag{14.13}$$

*f C* αβ ≡ 1 *A*0 *Vs* σlat αβ *Xs Ys* 0 *XF YF Xs Ys* (14.13)

$$\left(\frac{\partial \gamma_0}{\partial \varepsilon_{a\beta}}\right)_{A_0 \text{ and } \kappa \text{ independent intensive variables}} = f_{a\beta}^{\mathbb{C}}.\tag{14.14}$$

 ∂γ0 ∂εαβ *A*0 and κ independent intensive variables = *f C* αβ. (14.14) The 2 × 2 tensor *f C* αβ is the surface stress defined by Cahn [28] or [29, pp. 379-399]. As he points out, the application of tractions to the bulk solid usually produces only a small shift in the other intensive variables and can frequently be ignored. If the actual state of the solid is hydrostatic, σlat αβ = 0 and we have simply *f C* αβ = (*A*/*A*0)*f L* αβ . If the actual state

<span id="page-239-0"></span>is taken to be a state of zero strain (coincident with a hydrostatic reference state), then *f C* αβ = *f L* αβ . Note that Eq. (14.12) also holds formally for the Gibbs excess quantities with the understanding that *VL* = 0, which does not require the coefficient of d*pF* to be zero unless

<sup>2</sup>We retain εαβ as independent variables because the application of tractions to the solid makes only a small second-order change to the relationships among the set *T*, μ*F i* , *pF* . An estimate by Sekerka and Cahn [34] for a single component Gibbs solid shows that the equilibrium temperature would be lowered by about 10−3 K for a

<span id="page-240-0"></span>

<span id="page-240-2"></span>
$$\mathbf{d}\mathbf{y} = -\frac{S^L}{A}\mathbf{d}T + \frac{V^L}{A}\mathbf{d}\mathbf{p}^F - \sum_l \frac{N_l^L}{A}\mathbf{d}\mu_l^F + \sum_{a,\beta} f_{a\beta}^L \mathbf{d}\varepsilon_{a\beta} - \mathbf{y}\frac{\mathbf{d}A}{A}.\tag{14.15}$$

14.1.2 Adsorption Equation in the Actual State We now examine the parallel development when γ is defined with reference to the area *A* of the actual state. For the layer model, we combine the differential of Eq. (14.6) with

<span id="page-240-1"></span>
$$\frac{\mathbf{d}A}{A} = \mathbf{d} \ln A = \mathbf{d} \ln \det \left[ \frac{\partial \mathbf{x}_{\alpha}}{\partial \mathbf{x}_{\beta}'} \right] = \sum_{\kappa \lambda} \frac{\partial \mathbf{x}_{\lambda}'}{\partial \mathbf{x}_{\kappa}} \mathbf{d} \frac{\partial \mathbf{x}_{\kappa}}{\partial \mathbf{x}_{\lambda}'} = \sum_{\kappa \lambda \upsilon} \frac{\partial \mathbf{x}_{\lambda}'}{\partial \mathbf{x}_{\kappa}} \frac{\partial \mathbf{x}_{\upsilon}'}{\partial \mathbf{x}_{\kappa}} \mathbf{d} \varepsilon_{\lambda \upsilon} \tag{14.16}$$

From a well-known relation [35, p. 16] in elasticity theory with coordinates **x** in the actual

Eq. (14.7) to obtain

$$\varepsilon_{\mathbf{k}\boldsymbol{\nu}} = \frac{1}{2} \left[ \frac{\partial \mathbf{x}_{\rho}}{\partial \mathbf{x}_{\lambda}^{\prime}} \frac{\partial \mathbf{x}_{\rho}}{\partial \mathbf{x}_{\boldsymbol{\nu}}^{\prime}} - \delta_{\boldsymbol{k}\boldsymbol{\nu}} \right] = \frac{1}{2} \left[ \frac{\partial \boldsymbol{u}_{\boldsymbol{\nu}}}{\partial \mathbf{x}_{\lambda}^{\prime}} + \frac{\partial \boldsymbol{u}_{\boldsymbol{\lambda}}}{\partial \mathbf{x}_{\boldsymbol{\nu}}^{\prime}} + \sum_{\rho} \frac{\partial \mathbf{u}_{\rho}}{\partial \mathbf{x}_{\lambda}^{\prime}} \frac{\partial \mathbf{u}_{\rho}}{\partial \mathbf{x}_{\boldsymbol{\nu}}^{\prime}} \right] \tag{14.17}$$

β κλ λ κλν where

<span id="page-240-3"></span>
$$\sum_{a,\beta} f_{a\beta}^{L} \text{d}\mathbf{x}_{a\beta} - \gamma \frac{\text{d}A}{A} = \sum_{a,\beta} \left[ f_{a\beta}^{L} - \gamma \sum_{\kappa} \frac{\partial \mathbf{x}_{\alpha}^{\prime}}{\partial \mathbf{x}_{\kappa}} \frac{\partial \mathbf{x}_{\beta}^{\prime}}{\partial \mathbf{x}_{\kappa}} \right] \text{d}\mathbf{s}_{a\beta}.\tag{14.18}$$

terms in Eq. (14.15) can be combined to yield

*f A*

∂γ

*A*

ελν = 1 2

d*A*

$$\mathbf{d}\mathbf{y} = -\mathbf{I}(\mathbf{S}^{L}/\mathbf{A})/XY\mathbf{I}\,\mathbf{d}T + \mathbf{I}(V^{L}/\mathbf{A})/XY\mathbf{I}\,\mathbf{d}p^{F} - \sum_{l=1}^{\kappa} \left[ (N_{l}^{L}/\mathbf{A})/XY\right] \mathbf{d}\mu_{l}^{F} + \sum_{a,\beta} f_{a\beta}^{A} \,\mathbf{d}s_{a\beta},\tag{14.19}$$

κ

 

*Xs Ys XF YF*

where

$$f_{a\beta}^{A} = \frac{1}{A} \frac{A[f_{a\beta}^{L} - \chi \sum_{\kappa} (\partial \mathbf{x}_{\alpha}^{\prime}/\partial \mathbf{x}_{\kappa})(\partial \mathbf{x}_{\beta}^{\prime}/\partial \mathbf{x}_{\kappa})] \cdot X^{L} \cdot Y^{L}}{V^{S} \sigma_{a\beta}^{\text{lat}}} \cdot \frac{X^{S} \cdot Y^{S}}{\mathbf{0}} \Bigg|_{}$$
 
$$f_{a\beta}^{A} = \frac{1}{A} \frac{\mathbf{0} \qquad \begin{array}{c} X^{S} \cdot Y^{S} \\ X^{F} \cdot Y^{F} \end{array}}{\begin{array}{c} \begin{array}{c} X^{S} \cdot Y^{F} \\ X^{F} \cdot Y^{F} \end{array} \end{array}} . \tag{14.20}$$

Consequently

$$\left(\frac{\partial \boldsymbol{\gamma}}{\partial \varepsilon_{a\beta}}\right)_{A_0} \text{ and } \boldsymbol{\kappa} \text{ independent intensive variables}$$
 
$$\boldsymbol{\varepsilon} = \begin{bmatrix} \dots & \dots & \dots & \dots & \dots \end{bmatrix}$$

∂εαβ *A*0 and κ independent intensive variables αβ. (14.21) If the actual state of the solid is chosen to be hydrostatic, we have noted previously that σlat αβ = 0, in which case *f A* αβ = *f L* αβ − γ κ (∂*x* α/∂*x*κ )(∂*x* β/∂*x*κ ). If the actual state of the bulk solid is coincident with a hydrostatic reference state, then simply *f A* αβ = *f L* αβ − γ δαβ.

 

$$\boldsymbol{A}f^{\rm A}_{\alpha\beta} = \begin{vmatrix} \boldsymbol{A}f^{\rm L}_{\alpha\beta} & \boldsymbol{X}^{\rm L} & \boldsymbol{Y}^{\rm L} \\ \boldsymbol{V}^{\rm S}\boldsymbol{\sigma}^{\rm lat}_{\alpha\beta} & \boldsymbol{X}^{\rm s} & \boldsymbol{Y}^{\rm s} \\ \boldsymbol{0} & \boldsymbol{X}^{\rm F} & \boldsymbol{Y}^{\rm F} \\ \hline & \boldsymbol{X}^{\rm F} & \boldsymbol{Y}^{\rm F} \end{vmatrix} - \boldsymbol{A}\boldsymbol{\gamma} \sum_{\mathbf{x}} \frac{\partial \boldsymbol{\mathcal{X}}_{\alpha}^{\prime}}{\partial \mathbf{x}_{\mathbf{x}}} \frac{\partial \boldsymbol{\mathcal{X}}_{\beta}^{\prime}}{\partial \mathbf{x}_{\mathbf{x}}}.\tag{14.22}$$

Returning to the general case, we can expand the determinant in the numerator of Eq. (14.20) to obtain

> <span id="page-241-1"></span>

∂γ0 ∂εαβ <span id="page-241-0"></span>

= *A A*0 γ

*Xs Ys*

<span id="page-241-2"></span>
$$f_{\alpha\beta}^{\mathcal{C}} = \frac{A}{A_0} \left[ \gamma \sum_{\kappa} \frac{\partial \mathbf{x}_{\alpha}^{\prime}}{\partial \mathbf{x}_{\kappa}} \frac{\partial \mathbf{x}_{\beta}^{\prime}}{\partial \mathbf{x}_{\kappa}} + f_{\alpha\beta}^{A} \right],\tag{14.23}$$

. (14.22)

*Af A* αβ =

$$\begin{aligned} \frac{\partial \chi_0}{\partial \varepsilon_{a\beta}} &= \frac{A}{A_0} \left[ \gamma \sum_{\kappa} \frac{\partial x_{\alpha}^{\prime}}{\partial \mathbf{x}_{\kappa}} \frac{\partial x_{\beta}^{\prime}}{\partial \mathbf{x}_{\kappa}} + \frac{\partial \gamma}{\partial \varepsilon_{a\beta}} \right]. \end{aligned} \tag{14.24}$$

*f C* αβ = *A A*0 γ κ ∂*x* α ∂*x*κ β ∂*x*κ + *f A* αβ , (14.23) which can also be written

κ

∂*x*κ

∂*x*κ

$$\frac{\partial \chi_0}{\partial \varepsilon_{a\beta}} = \chi \delta_{a\beta} + \frac{\partial \chi}{\partial \varepsilon_{a\beta}}.\tag{14.25}$$

In the case that the actual state of the bulk solid is coincident with a hydrostatic reference state, Eq. (14.24) becomes

∂γ0 ∂εαβ = γ δαβ + ∂γ ∂εαβ . (14.25) If the soli[d beha](#page-241-0)ved like a fluid, then ∂γ /∂εαβ = 0 a[nd](#page-241-1) [the](#page-241-1) [s](#page-241-1)urface [stress w](#page-241-2)ould be isotropic and [equal t](#page-241-1)o γ , as we found previously for a fluid-fluid interface. As Cahn points out, the relationship Eq. (14.25) can be based on the fact that γ0*A*0 = γ *A*

$$\frac{\partial \mathcal{y}_0}{\partial \varepsilon_{a\beta}} \approx \left(1 + \sum_{\nu} \varepsilon_{\nu \nu}\right) \left[\gamma (\delta_{a\beta} - 2\varepsilon_{a\beta}) + \frac{\partial \gamma}{\partial \varepsilon_{a\beta}}\right] \approx \gamma \delta_{a\beta} + \frac{\partial \gamma}{\partial \varepsilon_{a\beta}}\tag{14.26}$$

∂γ0 ∂εαβ ≈ 1 +- ν ενν γ (δαβ − 2εαβ) + ∂γ ∂εαβ ≈ γ δαβ + ∂γ ∂εαβ (14.26) to [lowest order.](#page-236-3) This is a linearized version of Eq. (14.24) and happens to agree with the exact Eq. (14.25) for the special states chosen in that case. So Eq. (14.23) and equivalently Eq. (14.24) are always true for geometrical reasons, even in the nonlinear case. Note, however, that these derivatives of γ0 and of γ are only simply related to *f L* αβ when σlat αβ is

zero unless the actual bulk solid is hydrostatic or the small effect of shear stress on the

a definite direction with respect to the crystallographic axes. In this section, we treat the

αβ ) is negligible.

σlat

bulk equilibrium (embodied by *Vs*

14.2 Anisotropy of γ In Section 14.1, we defined the excess free energy γ for a constrained equilibrium such that the planar interface of a homogeneous bulk crystal in equilibrium with a fluid has 222 THERMAL PHYSICS explicit dependence of γ on the interface orientation, which we characterize by its unit

normal vector **n**ˆ. Thus we write γ (**n**ˆ), where **n**ˆ points from crystal3 to fluid, and in which

$$\mathbf{P} \coloneqq P\hat{\mathbf{n}},\tag{14.27}$$

respect to one of them while holding the other two constant. Therefore, to treat the angular

<span id="page-242-2"></span>-

α *P*α

dγ˜ = -

α

∂*P*α

∂*P*α

$$\check{\gamma}(\mathbf{P}) \coloneqq P\gamma(\hat{\mathbf{n}}) = P\gamma(\mathbf{P}/P),\tag{14.28}$$

developed in detail by Hoffman and Cahn [36, 37]. In order to facilitate the definition of *ξ* , we introduce a three-dimensional vector field **P** := *P***n**ˆ, (14.27)

$$\sum_{a} P_{a} \frac{\partial \tilde{\boldsymbol{\gamma}}(\mathbf{P})}{\partial P_{a}} = \tilde{\boldsymbol{\gamma}}(\mathbf{P}).\tag{14.29}$$

which is a homogeneous function of degree 1 in the components *P*α of **P**. Thus, by means of the Euler theorem of homogeneous functions, one can take partial derivatives of γ (˜ **P**)

<span id="page-242-1"></span>
$$\xi_a(\hat{\mathbf{n}}) := \frac{\partial \tilde{\boldsymbol{\chi}}(\mathbf{P})}{\partial P_a} \tag{14.30}$$

We now define the vector field

to obtain5

<span id="page-242-3"></span>
$$\mathfrak{k}(\hat{\mathbf{n}}) := \nabla p \, \tilde{\mathbf{y}}(\mathbf{P}) = \nabla p [P \mathbf{y}(\mathbf{P}/P)],\tag{14.31}$$
 
$$\dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \dots$$

∂*P*α (14.30) or more succinctly *ξ*(**n**ˆ):= ∇*P*γ (˜ **P**) = ∇*P*[*P*γ (**P**/*P*)], (14.31)

$$
\mathbf{n} \cdot \boldsymbol{\xi} = \boldsymbol{\chi}(\hat{\mathbf{n}}).\tag{14.32}
$$

because it is a homogenous function of degree 0 in the *P*α. Then combining Eqs. (14.29) and (14.30) gives γ˜ = **P** · *ξ* from which

$$\mathbf{d}\tilde{\boldsymbol{\gamma}} = \boldsymbol{\xi} \cdot \mathbf{d}\mathbf{P} + \mathbf{P} \cdot \mathbf{d}\boldsymbol{\xi},\tag{14.33}$$

<span id="page-242-0"></span>Moreover,

of discontinuities in its derivatives.

but also

$$\mathbf{d}\tilde{\boldsymbol{\gamma}} = \sum_{a} \frac{\partial \tilde{\boldsymbol{\gamma}}(\mathbf{P})}{\partial P_a} \, \mathrm{d}P_a = \boldsymbol{\xi} \cdot \mathrm{d}\mathbf{P},\tag{14.34}$$

d*P*α = *ξ* · d**P**, (14.34)

3For some crystals, γ (**n**ˆ) -= γ (−**n**ˆ) in which case one needs to distinguish which interface is being considered. 4These are the independent variables that appear in Eq. (14.19). In this section, we write dγ for brevity but it

should be understood that the only variable that is allowed to change is the orientation **n**ˆ. 5For now we assume that γ (**n**ˆ) is differentiable with continuous derivatives and later discuss the implications

<span id="page-243-1"></span><span id="page-243-0"></span>
$$
\hat{\mathbf{n}} \cdot \mathbf{d}\xi = 0.\tag{14.35}
$$

$$\mathbf{d}\boldsymbol{\gamma}(\hat{\mathbf{n}}) = \boldsymbol{\xi} \cdot \mathbf{d}\hat{\mathbf{n}}.\tag{14.36}$$

by Eq. (14.30), so the second term on the right of Eq. (14.33) must vanish. Thus **n**ˆ · d*ξ* = 0. (14.35)

$$\perp$$

Equation (14.32) plus either Eq. (14.35) or Eq. (14.36) completely defines the vector field *ξ* (**n**ˆ), although Eq. (14.31) is convenient for its actual calculation. We observe that

By combining Eq. (14.35) with the differential of Eq. (14.32), we deduce that

$$\boldsymbol{\gamma}(\hat{\mathbf{n}}) = \boldsymbol{\gamma}\mathbf{0} + \boldsymbol{\gamma}\mathbf{u}(n_x^4 + n_y^4 + n_z^4),\tag{14.37}$$

dγ (**n**ˆ) = *ξ* · d**n**ˆ. (14.36)

**Example Problem 14.1.** For a crystal having cubic symmetry,

**Orouamo:** 1.11** 10** 10** 10** 10** 
$$\tilde{\chi}(\mathbf{P}) = \chi_0 \mathbf{P} + \chi_4 \frac{(P_x^4 + P_y^4 + P_z^4)}{P^3},\tag{14.38}$$

demonstrate explicitly that Eqs. (14.32), (14.35), and (14.36) are satisfied.

$$\nabla p\hat{\boldsymbol{\gamma}}(\mathbf{P}) = \gamma_0 \frac{\mathbf{p}}{P} - 3\gamma_4 \frac{\mathbf{p}}{P} \frac{(P_x^4 + P_y^4 + P_z^4)}{P^4} + 4\gamma_4 \frac{1}{P^3} (P_x^3 \hat{\mathbf{i}} + P_y^3 \hat{\mathbf{j}} + P_z^3 \hat{\mathbf{k}}).\tag{14.39}$$

so

Thus,

ˆ **j** d*ny* + ˆ

$$\boldsymbol{\xi}(\hat{\mathbf{n}}) = \gamma_0 \hat{\mathbf{n}} - 3\gamma_4 \hat{\mathbf{n}} (n_x^4 + n_y^4 + n_z^4) + 4\gamma_4 (n_x^3 \hat{\mathbf{i}} + n_y^3 \hat{\mathbf{j}} + n_z^3 \hat{\mathbf{k}})$$

$$= \hat{\mathbf{n}} \,\gamma(\hat{\mathbf{n}}) + 4\gamma_4 \left[ (n_x^3 \hat{\mathbf{i}} + n_y^3 \hat{\mathbf{j}} + n_z^3 \hat{\mathbf{k}}) - \hat{\mathbf{n}} (n_x^4 + n_y^4 + n_z^4) \right],\tag{14.40}$$

*ξ* (**n**ˆ) = γ0**n**ˆ − 3γ4**n**ˆ(*n*4 *x* + *n*4 *y* + *n*4 *z* ) [+](#page-243-0) 4γ4(*n*3 *x* ˆ **i** + *n*3 *y* ˆ **j** + *n*3 *z* ˆ **k**) = **n**ˆ γ (**n**ˆ) + 4γ4 (*n*3 *x* ˆ **i** + *n*3 *y* ˆ **j** + *n*3 *z* ˆ **k**) − **n**ˆ(*n*4 *x* + *n*4 *y* + *n*4 *z* ) , (14.40)

$$\mathbf{d}\xi = \rho_0 \mathbf{d}\hat{\mathbf{n}} - 3\gamma_4 (n_x^4 + n_y^4 + n_z^4) \,\mathrm{d}\hat{\mathbf{n}} - 12\gamma_4 \hat{\mathbf{n}} (n_x^3 \,\mathrm{d}n_x + n_y^3 \,\mathrm{d}n_y + n_z^3 \,\mathrm{d}n_z)$$

$$+ 12\gamma_4 (n_x^2 \,\hat{\mathbf{i}} \,\mathrm{d}n_x + n_y^3 \,\hat{\mathbf{j}} \,\mathrm{d}n_y + n_z^3 \,\hat{\mathbf{k}} \,\mathrm{d}n_z). \tag{14.41}$$

+ 12γ4(*n*2 *x* ˆ **i** d*nx* + *n*3 *y* ˆ **j** d*ny* + *n*3 *z* ˆ **k** d*nz*). (14.41) When we dot **n**ˆ into d*ξ* , the first two terms vanish because **n**ˆ is perpendicular to d**n**ˆ and the remaining terms cancel one another, so Eq. (14.35) is satisfied. Of course d**n**ˆ = ˆ **i** d*nx* +

*y* d*ny* + *n*3

*x* d*nx* + *n*3

$$\boldsymbol{\xi} \cdot \mathbf{d}\hat{\mathbf{n}} = 4\gamma_4 (n_x^3 \,\mathrm{d}n_x + n_y^3 \,\mathrm{d}n_y + n_z^3 \,\mathrm{d}n_z) = \mathrm{d}\boldsymbol{\gamma},\tag{14.42}$$

*z* d*nz*) = dγ , (14.42)

*ξ* · d**n**ˆ = 4γ4(*n*3

**k** d*nz* so

and Eq. (14.36) is satisfied.

<span id="page-244-0"></span>224 THERMAL PHYSICS

![](_page_244_Figure_1.jpeg)

*ξ*t **ˆt**ξ **ˆn** d**ˆn** dθt

**ˆt ˆt**

(a) (b)

ψ

$$\mathbf{d}\hat{\mathbf{n}} = \hat{\mathbf{t}} \,\mathrm{d}\theta_I \tag{14.43}$$

tangential component *ξ t* of the *ξ*-vector.

illustrated in Figure 14–1. Then

and Eq. (14.36) can be written

$$\frac{\partial \boldsymbol{\gamma}(\hat{\mathbf{n}})}{\partial \theta_l} = \boldsymbol{\mathfrak{k}} \cdot \hat{\mathbf{t}} = \boldsymbol{\mathfrak{k}}_l \cdot \hat{\mathbf{t}},\tag{14.44}$$

d**n**ˆ = **t**ˆ dθ*t* (14.43)

<span id="page-244-1"></span>
$$
\xi_t = \xi - \hat{\mathbf{n}}(\hat{\mathbf{n}} \cdot \xi) = \xi - \hat{\mathbf{n}}\gamma. \tag{14.45}
$$

∂γ(**n**ˆ) ∂θ*t* = *ξ* · **t**ˆ = *ξt* · **t**ˆ, (14.44) where the part of *ξ* that is tangential to the surface is

$$\mathfrak{k}_I = |\mathfrak{k}_I| \hat{\mathfrak{k}}_{\xi} = \frac{\partial \mathcal{Y}(\hat{\mathbf{n}})}{\partial \theta_{\hat{\xi}}} \hat{\mathbf{t}}_{\xi}. \tag{14.46}$$

of θ*t* by θξ , it follows that

$$\frac{\partial \boldsymbol{\gamma}(\hat{\mathbf{n}})}{\partial \theta_l} = \frac{\partial \boldsymbol{\gamma}(\hat{\mathbf{n}})}{\partial \theta_\xi} \hat{\mathbf{t}}_\xi \cdot \hat{\mathbf{t}} = \frac{\partial \boldsymbol{\gamma}(\hat{\mathbf{n}})}{\partial \theta_\xi} \cos \boldsymbol{\psi},\tag{14.47}$$

Then Eq. (14.44) can be written ∂γ(**n**ˆ) ∂θ*t* = ∂γ(**n**ˆ) ∂θξ **t**ˆξ · **t**ˆ = ∂γ(**n**ˆ) ∂θξ cos ψ, (14.47)

where ψ is the angle between **t**ˆ and **t**ˆξ , as illustrated in Figure 14–1. It follows that ∂γ(**n**ˆ)/∂θξ is the maximum value of ∂γ(**n**ˆ)/∂θ*t*. Consider next a small planar element of area *A* having normal **n**ˆ and define **A** = **n**ˆ *A*. Its

$$
\delta \boldsymbol{w} = \mathbf{d}(\boldsymbol{\gamma} \boldsymbol{A}) = \mathbf{d}(\boldsymbol{\xi} \cdot \mathbf{A}) = \boldsymbol{\xi} \cdot \mathbf{d} \mathbf{A}, \tag{14.48}
$$

because **A** · d*ξ* = 0. But

$$
\boldsymbol{\xi} \cdot \mathbf{dA} = \boldsymbol{\xi} \cdot (\hat{\mathbf{n}} \, \mathrm{d}A + A \, \mathrm{d}\hat{\mathbf{n}}) = \boldsymbol{\xi}_n \cdot \hat{\mathbf{n}} \, \mathrm{d}A + A \, \boldsymbol{\xi}_t \cdot \mathrm{d}\hat{\mathbf{n}},\tag{14.49}
$$

δ*w* = d(γ *A*) = d(*ξ* · **A**) = *ξ* · d**A**, (14.48)

*ξ* · d**A** = *ξ* · (**n**ˆ d*A* + *A* d**n**ˆ) = *ξn* · **n**ˆ d*A* + *A ξt* · d**n**ˆ, (14.49)

$$
\mathfrak{k}_n \cdot \hat{\mathbf{n}} \,\mathrm{d}A = \chi \,\mathrm{d}A\tag{14.50}
$$

$$A\,\mathfrak{k}_I \cdot \mathbf{d}\hat{\mathbf{n}} = A\frac{\partial\chi\,(\hat{\mathbf{n}})}{\partial\theta_I} \,\mathrm{d}\theta_I = A\frac{\partial\chi\,(\hat{\mathbf{n}})}{\partial\theta_\xi}\cos\psi \,\mathrm{d}\theta_I \tag{14.51}$$

*Chapter 14* • Thermodynamics of Solid-Fluid Interfaces 225

is the work necessary to change6 the area *A*. The second term *A ξt* · d**n**ˆ = *A*∂γ(**n**ˆ) ∂θ*t* dθ*t* = *A*∂γ(**n**ˆ) ∂θξ cos ψ dθ*t* (14.51) is the work needed to rotate the element of area. The quantity ∂γ(**n**ˆ)/∂θ*t* given by Eq. (14.47) is the torque per unit area and depends on the axis of rotation **n**×**t**ˆ. This torque

$$
\delta w = \mathbf{d}(\gamma A) = \boldsymbol{\xi} \cdot \mathbf{d} \mathbf{A} = \boldsymbol{\xi} \cdot (\mathbf{A}' - \mathbf{A}) = \boldsymbol{\xi} \cdot \mathbf{L}_1 \times \mathbf{dS} = (\boldsymbol{\xi} \times \mathbf{L}_1) \cdot \mathbf{dS}.\tag{14.52}
$$

<span id="page-245-0"></span>The forces that give rise to these free energy changes can be understood by considering the case of a planar area **A** = **L**1 × **L**2, where **L**1 and **L**2 are two sides of a parallelogram, as depicted in Figure 14–2. If **L**2 is replaced by **L** 2 = **L**2 + **dS**, where **dS** is an infinitesimal vector, one can form a rotated and stretched planar area **A** = **L**1 × **L** 2, where **L**1 and **L** 2 are

$$
\sigma = \mathfrak{k} \times \hat{\mathfrak{l}}_1. \tag{14.53}
$$

The external force needed to translate one side of the original parallelogram **L**1 is therefore *ξ* × **L**1. Let ˆ1 be a unit vector along **L**1. Then the force per unit length needed to translate ˆ1 will be *σ* = *ξ* × ˆ1. (14.53) As pointed out by Hoffman and Cahn [36], the tip of *σ* traces out an ellipse in a plane perpendicular to *ξ* as the tip of ˆ1 traces out a circle in the plane of the original surface

$$
\sigma = -\xi \sin \theta \,\hat{\mathbf{i}} + \xi \cos \theta \cos \phi \,\hat{\mathbf{j}},\tag{14.54}
$$

**j**, (14.54)

the *y*-axis. Then the *x* component of ˆ1 can be written cos θ cos φ, its *y* component can be written sin θ, and its *z* component is irrelevant. We therefore compute

**i** + ξ cos θ cos φ ˆ

*σ* = −ξ sinθ ˆ

stretched to form another parallelogram bounded by vectors **L**1 and **L**

Eq. (14.19) must be taken into account.

![](_page_245_Figure_11.jpeg)

**L**1 **FIGURE 14–2** Planar surface in the shape of a parallelogram bounded by vectors **L**1 and **L**2 and then rotated and

2, where **L**

2 = **L**2 + **dS**.

6This change must be done without straining the underlying solid; otherwise surface strain terms as in

expressed as

can be written in the form

$$
\sigma = (\xi_n + \xi_t) \times \hat{\mathfrak{l}}_1 = \boldsymbol{\chi} \cdot \hat{\mathfrak{n}} \times \hat{\mathfrak{l}}_1 + \frac{\partial \boldsymbol{\chi}(\tilde{\mathbf{n}})}{\partial \theta_{\hat{\xi}}} \hat{\mathfrak{t}}_{\xi} \times \hat{\mathfrak{l}}_1. \tag{14.55}
$$

226 THERMAL PHYSICS We can also decompose *σ* as follows: *σ* = (*ξn* + *ξt*) × ˆ1 = γ **n**ˆ × ˆ1 + ∂γ(**n**ˆ) ∂θξ **t**ˆξ × ˆ1. (14.55) Since **n**ˆ and ˆ1 are perpendicular, **t**ˆ1 := **n**ˆ × ˆ1 is a unit vector in the plane of the [surfa](#page-244-1)[ce](#page-246-0)

$$
\boldsymbol{\xi}_{1} \times \boldsymbol{\hat{\ell}}_{1} = \frac{\partial \boldsymbol{\gamma}(\hat{\mathbf{n}})}{\partial \theta_{\xi}} \boldsymbol{\hat{\mathbf{t}}}_{\xi} \times \boldsymbol{\hat{\ell}}_{1} = -\frac{\partial \boldsymbol{\gamma}(\hat{\mathbf{n}})}{\partial \theta_{\xi}} \left(\boldsymbol{\hat{\mathbf{t}}}_{\xi} \cdot \boldsymbol{\hat{\mathbf{t}}}_{1}\right) \boldsymbol{\hat{\mathbf{n}}}.\tag{14.56}
$$

needed to enlarge the area of the element. On the other hand, both **t**ˆξ and ˆ1 lie in the plane of the surface element so **t**ˆξ ×ˆ1 lies along ±**n**ˆ. Since ˆ1 = **t**ˆ1 ×**n**ˆ, we readily compute **t**ˆξ × ˆ1 = −(**t**ˆξ · **t**ˆ1) **n**ˆ. Therefore, the force per unit area in Eq. (14.55) related to *ξ t* can be

<span id="page-246-3"></span><span id="page-246-1"></span>
$$
\boldsymbol{\sigma} = \boldsymbol{\chi}\hat{\mathbf{t}}_1 - (\boldsymbol{\xi}_I \cdot \hat{\mathbf{t}}_1)\,\hat{\mathbf{n}} = \boldsymbol{\chi}\,\hat{\mathbf{t}}_1 - \frac{\partial \boldsymbol{\chi}(\hat{\mathbf{n}})}{\partial \theta_{\hat{\boldsymbol{\xi}}}} (\hat{\mathbf{t}}_{\hat{\boldsymbol{\xi}}} \cdot \hat{\mathbf{t}}_1)\,\hat{\mathbf{n}}.\tag{14.57}
$$

Its magnitude is similar in form to that of the torque per unit are[a give](#page-245-0)n by Eq. (14.47).7 The total force per unit length can therefore be written in the form *σ* = γ **t**ˆ1 − (*ξ t* · **t**ˆ1) **n**ˆ = γ **t**ˆ1 − ∂γ(**n**ˆ) ∂θξ (**t**ˆξ · **t**ˆ1) **n**ˆ. (14.57) Note especially that **t**ˆ1 is perpendicular to ˆ1 and points away from the area being considered. In this respect, the sign convention that applies to Eq. (14.53) should be

$$
\sigma = -\xi \times \hat{\mathfrak{l}}.\tag{14.58}
$$

<span id="page-246-2"></span>bounds an area having normal **n**ˆ is in the direction of the right-hand rule. In that case, the unit vector ˆ := d/d satisfies ˆ = −**t**ˆ1 × **n**ˆ. Thus, ˆ1 = −ˆ and Eq. (14.53) would become *σ* = −*ξ* × ˆ. (14.58)

We point this out because use of the calculus of variations for curved s[urface](#page-246-1)s, wh[ich we](#page-246-2) will consider later, shows that Eq. (14.57) or its equivalent Eq. (14.58) apply generally, not just for the edge of a planar element. The equilibrium conditions at **triple junctions** are also affected by anisotropy, which requires Eq. (13.83) to be modified. By requiring [that](#page-246-3) no work be done by any [smal](#page-244-1)l

<span id="page-246-0"></span>
$$
\sigma^{a\beta} + \sigma^{\beta\eta} + \sigma^{\eta\mu} = 0.\tag{14.59}
$$

must be zero, resulting in *σ* αβ + *σ* βη + *σ*ηα = 0. (14.59) From Eq. (14.57), we see that this balance equation accounts for forces due to both tensions and torques, as discussed by Herring [38, p. 157]. By using Eq. (14.58), Eq. (14.59)

<sup>7</sup>Great care must be made in comparing these formulae, even though they look very much alike. In Eq. (14.47), **t**ˆ is fixed for the entire area in the direction of d**n**ˆ, but in Eq. (14.56) **t**ˆ1 is related to the orientation of ˆ1 by **t**ˆ1 = **n**ˆ × ˆ1.

$$(\xi^{\alpha\beta} + \xi^{\beta\eta} + \xi^{\eta\alpha}) \times \hat{\mathfrak{E}}^{\alpha\beta\eta} = \mathbf{0},\tag{14.60}$$

αβη = 0, (14.60)

*Chapter 14* • Thermodynamics of Solid-Fluid Interfaces 227

### where the normals to the surfaces must be chosen consistently to point from the first named phase to the second. Here, ˆ αβη is a unit vector along the line of the triple junction.

(*ξ*αβ + *ξ* βη + *ξ* ηα) × ˆ

Thus the vector (*ξ* αβ + *ξ* βη + *ξ* ηα) has no component perpendicular to the triple line. For a detailed discussion of a quad junction where four phases meet, see Hoffman and Cahn [36, Eq. (28)]. 14.3 Curved Solid-Fluid Interfaces For an infinitesimal area of a curved solid-fluid interface, one can assume that γ is approximately the same as it would be for a planar solid-fluid interface having the same normal **n**ˆ, provided that the thickness of the region of discontinuity is small compared to the local radii of curvature. This is similar to what is done for fluid-fluid interfaces

except in that case one is able to locate the interface at the surface of tension. No such

$$\mathbf{r} = \hat{\mathbf{n}} \,\mathrm{y}\prime(\hat{\mathbf{n}}) \tag{14.61}$$

rigor is required, the interface could possibly be located at the equimolar surface of some component. A pol[ar plot](#page-256-0) **r** = **n**ˆ γ (**n**ˆ) (14.61) is commonly known as a **gamma-plot**, or γ -plot for short. It gives a pictorial representation of γ as a function of the orientation of **n**ˆ and has a unique positive value for each **n**ˆ. In spherical coordinates, its equation is *r* = γ (θ, ϕ), so γ is the distance from the origin to the γ -plot at given θ and ϕ. Since *ξ* is a function of **n**ˆ, one can also obtain a corresponding **xi**-**plot**, or *ξ* -plot for short, by allowing **n**ˆ to take on all orientations. In this case, the magnitude ξ of *ξ* can be a multiple-valued function of the unit vector **N**ˆ = *ξ*/ξ that points in the direction of *ξ* . An example in two dimensions is shown in Figure 14–3. We shall prove in Section 14.5 that the inner convex hull of the *ξ* -plot has the same shape as the equilibrium shape of a crystal. Note especially that *ξ* (**n**ˆ) is a parametric representation of

*ξ* in terms of the orientation of its surface normal **n**ˆ. In particular, it is *not* [a representa](#page-256-0)tion of *ξ* in terms of its own orientation **N**ˆ . The **equilibrium shape** of a crystal, also known as the **Gibbs-Wulff shape** or sometimes simply the Wulff shape, is that shape taken on by a crystal by minimizing its total surface free energy subject to the constraint of fixed volume. For kinetic reasons, only small crystals can achieve this shape in a reasonable time. For a given γ -plot, this shape can be found by means of the following construction due to Wulff [39]. At every point **n**ˆ γ (**n**ˆ) of the γ -plot, erect a plane perpendicular to **n**ˆ and passing through that point. Then the inner convex hull of those **Wulff planes** is the equilibrium shape. This so-called Wulff theorem was stated without proof by Wulff in the context of polyhedral shapes but has

since been studied extensively and applies also to curved shapes. In Section 14.5, we

<span id="page-248-1"></span>![](_page_248_Figure_1.jpeg)

−1.5 −1.0 (a) (b) −0.5

units. The *ξ* -plot is not a single-valued function of its polar angle in this case but has "ears" that must be truncated leaving a convex body that would have the equilibrium shape of a two-dimensional crystal. (b) Inverted γ -plot (full curve) whose properties are discussed in Section 14.3.2. The dashed lines are added to "convexify" (to make convex) the plot. derive an analytical formula for this [sh](#page-248-0)ape in terms of the *ξ* -vector for differentiable γ (**n**ˆ). Immediately below, we show how *ξ* can be defined for cases for which γ (**n**ˆ) is not

### differentiable. Moreover, the analysis of faceting in Section 14.4 can be used to show that a surface whose orientation does not appear on the Gibbs-Wulff shape is unstable with

**FIGURE 14–3** (a) Illustration of a γ -plot and a *ξ* -plot in two dimensions for γ = 1 +

respect to faceting, consistent with the Gibbs-Wulff shape being the equilibrium shape. 14.3.1 Discontinuous Derivatives of γ The definition of *ξ* , and hence the *ξ* -plot, can be extended to cover cases in which the derivatives of γ are discontinuous. In particular, γ (**n**ˆ) can have sharp grooves (knife edges) or inwardly directed sharp points, including cusps, at special orientations that correspond to low index planes in three dimensions.8 One way of handling this situation is to consider

<span id="page-248-0"></span>
$$\boldsymbol{\gamma}(\hat{\mathbf{n}}) = \boldsymbol{\gamma}\mathbf{o}\left[1 + \boldsymbol{\alpha}\sqrt{\boldsymbol{m}_{\mathcal{X}}^{2} + \boldsymbol{\epsilon}^{2}}\right],\tag{14.62}$$

 2*n*2 *xn*2

*y* + 0.08 in arbitrary

γ (**n**ˆ) = γ0 1 + α *n*2 *x* + 2 , (14.62)

where γ0, α, and 1 are positive constants. Then one readily calculates

entropic effects. See Mullins [40, p. 28] and Herring [41, p. 18] for further discussion.

8In strictly two dimensions, these grooves or sharp points become rounded at finite temperatures due to

$$\xi_{\mathbf{x}} = \gamma_0 \left[ n_{\mathbf{x}} + \alpha n_{\mathbf{x}} \frac{1 + \epsilon^2}{\sqrt{n_{\mathbf{x}}^2 + \epsilon^2}} \right] \approx \gamma_0 \left[ n_{\mathbf{x}} + \alpha \frac{n_{\mathbf{x}}}{|n_{\mathbf{x}}|} \right];\tag{14.63}$$

$$\xi_{\mathcal{Y}} = \gamma_0 \left[ n_{\mathcal{Y}} + \alpha n_{\mathcal{Y}} \frac{\epsilon^2}{\sqrt{n_{\mathcal{X}}^2 + \epsilon^2}} \right] \approx \gamma_0 n_{\mathcal{Y}};\tag{14.64}$$

$$
\xi_z = \wp_0 \left[ n_z + \alpha n_z \frac{\epsilon^2}{\sqrt{n_x^2 + \epsilon^2}} \right] \approx \wp_0 n_z,\tag{14.65}
$$

ξ*y* [=](#page-249-0) γ0 ⎡ ⎣*ny* + α*ny* 2 *n*2 *x* + 2 ⎤ ⎦ ≈ γ0*ny*; (14.64) ξ*z* = γ0 ⎡ ⎣*nz* + α*nz* 2 *n*2 *x* + 2 ⎤ ⎦ ≈ γ0*nz*, (14.65) where the approximate forms are in the limit = 0, where γ = γ0[1 + α|*nx*|]. In this limit, we see that γ is continuous but ξ*x* is discontinuous at *nx* = 0, where it jumps from −γ0α to γ0α. In the plane *nz* = 0, we see for finite but small that ξ*y* ≈ γ0(1 − *n*2 *x*)1/2 is very nearly equal to γ0 for small *nx* while ξ*x* changes considerably as *nx* makes small changes near zero, as shown in Figure 14–4. As becomes very small, the γ -plot tends toward a V-shaped groove and t[he tips of the](#page-250-0) *ξ* -vector lie nearly along a straight line segment corresponding to ξ*y* = γ0 that extends from −γ0α to γ0α. Thus it would be natural for a sharp groove (ε = 0) to *define ξ* , for *nx* = 0, to be multiple-valued, namely the **fan of vectors** having ξ*z* = 0,

<span id="page-249-0"></span>ξ*y* = γ0, and −γ0α ≤ ξ*x* ≤ γ0α. The tails of these vectors are at the origin and their tips lie along a straight line. The corresponding three-dimensional portion of the *ξ* -plot would be a ruled surface. By analogous reasoning, the *ξ* -vectors corresponding to a sharp inwardly directed point of γ would form a cone whose tips lie along a portion of a plane, a facet of

An elegant way of defining *ξ* for general γ that is fully consistent with the foregoing

the *ξ* -plot.

(a)

![](_page_249_Figure_6.jpeg)

(b) *ξ*-plot **FIGURE 14–4** Portions of a γ -plot and the corresponding *ξ* -plot near a groove for three values of in the plane *nz* = 0 according to Eqs. (14.62)– (14.64). For plotting purposes, γ0 = 1, α = √ 2/2, and = 0.1, 0.05, and 0.01 from top to bottom. (a) The upper curves are plots of γ versus *nx* with the origin located at the root of the V-shaped

groove. (b) The lower curves are parametric plots of ξ*y* versus ξ*x* for very small changes of *nx* near *nx* = 0.

<span id="page-250-0"></span>230 THERMAL PHYSICS

![](_page_250_Figure_1.jpeg)

*ξ* **V** γ **ˆn**γ

*ξ*/2

O **FIGURE 14–5** Herring sphere (actually a circle in two dimension) tangent to a segment of the γ -plot and passing through its origin, *O*. The *ξ* -vector lies along a diameter and the center of the sphere is located at *ξ*/2. The vector **V** has magnitude ξ/2 and is perpendicular to the local tangent plane. angle inscribed in a hemisphere is a right angle. Therefore, according to the Wulff theorem, any point on the surface of an equilibrium shape must be located at end of the diameter *ξ* (**n**ˆ) of a sphere that passes through the origin of the γ -plot and satisfies *ξ* · **n**ˆ = γ . Furthermore, this sphere must either be tangent to the γ -plot at a place where its tangent is well defined or else touch the γ -plot at some sharp groove or sharp point where the tangent to the γ -plot is not well defined. For a surface element with definite orientation to actually appear on the equilibrium shape, it is necessary and sufficient that no portion of the γ -plot lies inside the Herring sphere corresponding to that orientation. This is true

because a Wulff plane corresponding to a portion of the γ -plot that lies inside the Herring sphere would c[ut through its](#page-251-0) diameter and exclude that orientation from the inner convex hull. As shown below, the resulting equilibrium shape can have curved sections and flat sections, as well as edges and sharp corners that correspond to missing orientations. Therefore, at any point on the γ -plot for some orientation **n**ˆ at which its derivatives are well defined and continuous, one can erect a Herring sphere that passes through the origin and is tangent to the γ -plot at that point. Then the vector *ξ* is the unique vector from the origin of the γ -plot that passes through the center of that sphere and terminates on its opposite side. For points on the γ -plot for which its derivatives are undefined, *ξ* is multiple-valued because one can construct a continuum of Herring spheres that pass through that point and the origin of the γ -plot and define a fan or cone of *ξ* -vectors, as illustrated in Figure 14–6. This leads to a *ξ* -plot that can have curved surfaces, ruled

surfaces, and planar sections. The resulting *ξ* -plot can be nonconvex and have "ears" that must, however, be truncated to form the equilibrium shape, which is convex. Since any angle inscribed in a hemisphere is a right angle, this extended definition of *ξ* will satisfy γ = *ξ* · **n**ˆ. Other relations can be established as follows. For any point **r** = **n**ˆ γ (**n**ˆ) on the γ -plot, one can erect a vector **V** that points from the center of a Herring sphere to **r**

<span id="page-250-1"></span>*ξ*

$$\frac{\xi}{2} + \mathbf{V} = \mathbf{y} \cdot \hat{\mathbf{n}} = \mathbf{r} \tag{14.66}$$

<span id="page-251-0"></span>![](_page_251_Figure_1.jpeg)

α α *ξ*L *ξ*R C

in two dimensions) that pass through the origin *O* of the γ -plot and the point *C* are shown along with the *ξ* -vectors that lie along their diameters. The two largest circles are tangent to the γ -plot at *C*. The other three circles pass through *C* but are not tangent to the γ [-plot;](#page-250-1) there is [a contin](#page-251-1)uum of such circles that would have that same property. The tips of the *ξ* -vectors lie along a line of length 2γ*c* cos α that stretches from *ξ L* to *ξR*, where γ*c* is the value of γ at the point *C* where each segment of the V-shaped plot makes an angle α with the horizontal.

O **FIGURE 14–6** Fan of *ξ* -vectors corresponding to a V-shaped portion of a γ -plot. Five Herring spheres (actually circles

<span id="page-251-1"></span>
$$\mathbf{dr} \cdot \mathbf{V}_0 = \mathbf{0}.\tag{14.67}$$

with |**V**|=|*ξ* |/2. For a particular point corresponding to **n**ˆ 0, suppose that the γ -plot has a well-defined tangent plane whose equation is (**r**−**r**0)·**V**0 = 0. For a small change d**r** = **r**−**r**0 in this plane, we will have

<span id="page-251-2"></span>
$$(\gamma_0 \,\mathrm{d}\hat{\mathbf{n}} + \hat{\mathbf{n}}_0 \,\mathrm{d}\gamma) \cdot (\gamma_0 \hat{\mathbf{n}}_0 - \xi_0/2) = 0.\tag{14.68}$$

But [since th](#page-243-1)is plane is tangent to the γ -plot, we also have d**r** = d(γ**n**ˆ) = γ0d**n**ˆ + **n**ˆ 0dγ . By

replaced by

$$\mathbf{d}\boldsymbol{\gamma} = \boldsymbol{\xi} \cdot \mathbf{d}\hat{\mathbf{n}}, \quad \boldsymbol{\chi}\text{-plot has well-defined tangent plane,} \tag{14.69}$$

(γ0 d**n**ˆ + **n**ˆ 0 dγ ) · (γ0**n**ˆ 0 − *ξ* 0/2) = 0. (14.68) By computing the dot products and dividing by γ0/2 -= 0 we obtain dγ = *ξ* · d**n**ˆ, γ -plot has well-defined tangent plane, (14.69) where we have dropped the subscript 0 on *ξ* with the understanding that it is to be

evaluated at d**n**ˆ = 0. Then by using dγ = d(*ξ* · **n**ˆ), we can use Eq. ([14.69)](#page-251-1) to obtain **n**ˆ ·d*ξ* = 0. Thus, wherever the γ -plot has a well-defined tangent plane, Eqs. (14.32), (14.35), and (14.36) are all satisfied, as expected. On the other hand, if a Herring sphere that passes through the origin touches the γ -plot at a point where it does not have a well-defined tangent plane, the position of its center

$$
\hat{\mathbf{n}} \cdot \mathbf{d}\sharp = 0,\quad\text{always},\tag{14.70}
$$

**n**ˆ · d*ξ* = 0, always, (14.70) which is the same as for a well-defined tangent plane. But now the vector **V** touches the γ -plot but it is no longer normal to it at the point of touching. Thus Eq. (14.67) must be

d**r** · **V**0 ≥ 0, where the γ -plot has no well-defined tangent plane. (14.71)

$$\mathbf{r} \,\mathrm{d}\mathbf{r} \cdot \mathbf{V}_0 \ge 0, \quad \text{where the } \boldsymbol{\gamma} \text{-plot has no well-defined tangent plane.} \tag{14.71}$$

<span id="page-252-0"></span>
$$\mathbf{d}\boldsymbol{\gamma} \ge \boldsymbol{\xi} \cdot \mathbf{d}\hat{\mathbf{n}}, \quad \text{where the } \boldsymbol{\gamma} \text{-plot has no well-defined tangent plane.} \tag{14.72}$$

$$\frac{\partial \boldsymbol{\gamma}(\hat{\mathbf{n}})}{\partial \boldsymbol{\theta}_{l}} \ge \boldsymbol{\xi}_{l} \cdot \hat{\mathbf{t}}, \quad \text{where the } \boldsymbol{\gamma} \text{-plot has no well-defined tangent plane.} \tag{14.73}$$

The equality holds only if d**r** lies along and is tangent to the curve of a knife edge. Accordingly, Eq. (14.69) is replaced by dγ ≥ *ξ* · d**n**ˆ, where the γ -plot has no well-defined tangent plane. (14.72)

### If we write d**n**ˆ = **t**ˆdθ*t* as in Eq. (14.43), Eq. (14.72) becomes ∂γ(**n**ˆ)

14.3.2 Inverted γ -Plot

∂θ*t* ≥ *ξ t* · **t**ˆ, where the γ -plot has no well-defined tangent plane. (14.73) In this case, Eq. (14.73) replaces Eq. (14.44). Thus, the multiple values of *ξ t* that are associated with a ruled or flat portion of a surface determine the range of torques that can be supported.

$$\mathbf{R} = \hat{\mathbf{n}} \frac{1}{\chi(\hat{\mathbf{n}})},\tag{14.74}$$

the equilibrium shape. This is easy to state but hard to apply. An equivalent criterion that is much easier to apply has been discussed by Frank [42]. It can be obtained by considering the **inverted gamma**-**plot**, namely [the polar plo](#page-248-1)t **R** = **n**ˆ 1 γ (**n**ˆ) , (14.74) or simply *R* = 1/γ (**n**ˆ). On inversion through the origin, a sphere becomes a plane.9 Thus a Herring sphere that is tangent to the γ -plot becomes a tangent plane to the 1/γ -plot. Any portion of a γ -plot that lies i[nside a](#page-242-2) Herring sphere will contribute to planes that cut the 1/γ -plot. It follows that for all orientations to appear on the equilibrium shape, it is necessary and sufficient that the 1/γ -plot be convex. Furthermore, if the 1/γ -plot is not convex, one can form a convex body by means of enveloping it by portions of touching planes that do not cut the plot. See Figure 14–3b for an example in two dimensions, where

the dashed lines are added to "convexify" the plot. The orientations on the nonconvex 1/γ -plot that do not appear on the enveloped convex plot are those that are missing from the equilibrium shape. They actually appear on the ears of the *ξ* -plot. It is easy to show that the normal to the 1/γ (**n**ˆ)-plot is in the direction *ξ*(**n**ˆ). Indeed, the

$$
\xi(\hat{\mathbf{n}}) = \nabla \eta \, [R \, \gamma(\mathbf{R}/R)],
\tag{14.75}
$$

can let **R** play the role of **P** in Eq. (14.31) to obtain *ξ* (**n**ˆ) = ∇*R* [*R*γ (**R**/*R*)], (14.75) which is clearly in the direction of the normal to the 1/γ (**n**ˆ)-plot. This expression can be used to compute the Gauss curvature of the 1/γ (**n**ˆ)-plot and determine when it changes sign, which defines the limits of its convexity. This gives an analytical criterion for the

onset of missing orientations on a three-dimensional equilibrium shape [43]. Herring [44]

<sup>9</sup>In particular, consider the sphere **r** = **n**ˆ(**n**ˆ · *ξ* ), where **n**ˆ varies for fixed *ξ* . When inverted, this sphere becomes **Q** = **n**ˆ(**n**ˆ · *ξ* )−1 or **Q** · *ξ* = 1, which is linear in the components of **Q**. Thus it is a plane that passes through the point **Q** = *ξ*/ξ2.

<span id="page-253-0"></span>

### *Chapter 14* • Thermodynamics of Solid-Fluid Interfaces 233

has given an extensive discussion of the qualitative characteristics of the γ -plot and the resulting equilibrium shapes, with particular attention to corners, cylindrical portions, and facets. 14.4 Faceting of a Large Planar Face

Herring [44] has also consid[ered the pos](#page-253-1)sibility that a large planar surface of a crystal could break up into a hill-and-valley structure composed of facets. Such a consideration is important for kinetic reasons because a large amount of transport would be required to convert a large crystal to its equilibrium shape. It therefore makes sense to consider a state that could occur on a time scale that is very short compared to the time needed to transform an entire crystal to its e[quil](#page-253-2)ibrium shape. To analyze this problem, consider a small area *a*0 on the planar face of a large crystal having unit normal **n**ˆ 0 and free energy γ (**n**ˆ 0) ≡ γ0 per unit area. We then investigate the

$$
\hat{\mathbf{n}}_0 = f_1 \hat{\mathbf{n}}_1 + f_2 \hat{\mathbf{n}}_2 + f_3 \hat{\mathbf{n}}_3,\tag{14.76}
$$

*a*1, *a*2, and *a*3, as illustrated in Figure 14–7. From Gauss's theorem in the form V ∇ ·**k** d3 *x* = *A* **k** · **n**ˆ d2 *x*, where **k** is an arbitrary but constant vector, we can deduce that *A* **n**ˆ d2 *x* = 0. By applying this result to the pyramid just described, we obtain **n**ˆ 0 = *f*1**n**ˆ 1 + *f*2**n**ˆ 2 + *f*3**n**ˆ 3, (14.76) where *fi* = *ai*/*a*0 are area fractions.11 By using reciprocal vectors *τ i* defined such that *τ i* ·

<span id="page-253-1"></span>
$$
\gamma_h = f_1 \gamma_1 + f_2 \gamma_2 + f_3 \gamma_3. \tag{14.77}
$$

pyramid with positive *fi*. The free energy associated with the three faces of the pyramid, measured per unit area of the large planar face, is

**nˆ**3

<span id="page-253-2"></span>Thus

$$
\gamma_{\hbar} = \mathbf{c} \cdot \hat{\mathbf{n}}_{0},\tag{14.78}
$$

![](_page_253_Figure_10.jpeg)

(a) (b) **FIGURE 14–7** (a) Typical pyramid for faceting of a surface. The **n**ˆ*i* are unit normals and *ai* are respective areas of the

10For the entire planar face, this is to be done by using many pyramids but without a change in volume.

faces. (b) Faceted surface in two dimensions, showing facets of different sizes but the same orientation.

11Note that **n**ˆ 0 is the outward normal to the large planar face so it is an inner normal to the pyramid.

234 THERMAL PHYSICS

where **c** := *τ i*γ1 + *τi*γ2 + *τ i*γ3 can be interpreted geometrically as the vector from the origin of the γ -plot to a point defined by the intersections of three Wulff planes drawn perpendicular to **n**ˆ 1, **n**ˆ 2, and **n**ˆ 3 at the points where they intersect the γ -plot. This interpretation follows because **c** · **n**ˆ*i* = γ*i* for *i* = 1, 2, 3. We observe that **c** lies along the diameter of a sphere that passes through four points, **n**ˆ 1γ1, **n**ˆ 2γ2, **n**ˆ 3γ3, and the origin. From the above considerations, it follows that the large planar face will be stable against

faceting if γ*h* > γ0, which means that the point (**c** · **n**ˆ 0)**n**ˆ 0 = γ*h***n**ˆ 0 will lie outside the γ -plot. On the other hand, if the point γ*h***n**ˆ 0 lies inside the γ -plot, the large planar face will be unstable with respect to this type of faceting. However, if the orientation **n**ˆ 0 occurs on the equilibrium shape, it is impossible for point γ*h***n**ˆ 0 to lie inside the γ -plot because at least one of the Wulff planes corresponding to **n**ˆ 1, **n**ˆ 2, or **n**ˆ 3 would cut it off. This results in **Herring's theorem** [44]:

*If a given macroscopic surface of a crystal does not coincide in orientation with some*

*portion of the boundary of the equilibrium shape, there will always exist a hill-andvalley structure which has a lower free energy than a flat surface, while if the given surface does occur in the equilibrium shape, no hill-and-valley structure can be more stable.* With keen geometrical insight, Frank [42] observed that Herring's faceting criterion has a very simple interpretation in terms of the inverted γ -plot. In particular, the tip of the inverted vector **n**ˆ /γ*h* lies on the plane that passes through the points **n**ˆ 1/γ1, **n**ˆ 2/γ2, and **n**ˆ 3/γ3. To see this, let **p**ˆ be a unit vector perpendicular to that plane and pointing away from the origin. Then the distance from the origin to that plane is given by *d* = **p**ˆ · **n**ˆ 1/γ1 = **p**ˆ · **n**ˆ 2/γ2 = **p**ˆ ·**n**ˆ 3/γ3, from which we deduce that **p**ˆ = *d*(*τ i*γ1+*τ i*γ2+*τ i*γ3) = **c** *d*. Thus **p**ˆ ·**n**ˆ /γ*h* = *d*, confirming Frank's observation. Therefore, we can compare **n**ˆ /γ*h* with **n**ˆ /γ and deduce that the free energy will be lowered by faceting only if **n**ˆ /γ lies inside the plane (nearer to the origin) that passes through **n**ˆ 1/γ1, **n**ˆ 2/γ2, and **n**ˆ 3/γ3. This analysis also clarifies that the orientations that are unstable with respect to faceting are those that lie on the ears of the

*ξ* -plot, which result from nonconvex portions of the 1/γ -plot. Indeed, the very notion of a value of γ for unstable orientations requires the concept of a constrained [equilibrium](#page-255-0) state for which faceting is prevented. Herring's analysis was extended by Mullins and Sekerka [45] by using linear programming theory to analyze faceting into shapes having an arbitrary number of orientations. It was shown that a minimum value of γ*h* can always be obtained by using *no more than three* orientations; however, degeneracies can occur such that more than three orientations can lead to the same minimum value of γ*h*. Moreover, the minimum value of γ*h* that can be achieved by faceting corresponds to the distance (**n**ˆ) from the origin to a so-called **contact plane** of the Gibbs-Wulff shape, the latter being a plane that is perpendicular to **n**ˆ and touches but does not cut that shape. In fact, **n**ˆ(**n**ˆ) is the **minimum gamma**-**plot**

(contained in all others) that gives the same Gibbs-Wulff shape as γ (**n**ˆ). Figure 14–8

 2*n*2 *xn*2

*y* + 0.08 in

<span id="page-255-0"></span>![](_page_255_Figure_1.jpeg)

−1.5 −1.0

**FIGURE 14–8** A γ -plot (outer curve) and a *ξ* -plot (inner curve) in two dimensions for γ = 1 +

are negligible.

arbitrary units. The equilibrium Gibbs-Wulff shape is the convex shape found by truncating the ears of the *ξ* -plot. The middle curve is the [-plot, wh](#page-248-1)ich is the smallest that will lead to the same Gibbs-Wulff shape. The distance along any **n**ˆ between γ (**n**ˆ) and (**n**ˆ) represents the maximum possible energy reduction by faceting. Orientations

for which this difference is zero appear on the Gibbs-Wulff shape. illustrates γ (**n**ˆ), (**n**ˆ), and *ξ* (**n**ˆ) in two dimensions. For orientations such that a contact plane is actu[ally tangent t](#page-253-1)o the Gibbs-Wulff shape, that orientation appears on the shape and the corresponding plane is not unstable with respect to faceting. The inverted plot **n**ˆ(**n**ˆ) is just the convex plot obtained by enveloping the plot **n**ˆ /γ (**n**ˆ) by portions of planes,

as illustrated in Figure 14–3b. The portions of planes invert to portions of spheres on (**n**ˆ) that correspond to orientations for which the contact plane is not tangent to the Gibbs-Wulff shape. It is important to recognize that this analysis of faceting provides no size scale for the facets; it deals only with their orientation. In other words, surfaces with large facets have the same free energy as those with small facets. However, one would expect there to be a mixture of facet sizes on a given surface (e.g., colonies of large facets and small facets, as suggested by Figure 14–7b in two dimensions) and the resulting configurational entropy would further lower the free energy of a faceted surface. Modification of the theory to allow for excess energies at edges and corners would change the invariance to size scale. Of course it would also require modification of our concept of an equilibrium shape, which would only be valid for crystals sufficiently large that excess energies at edges and corners

<span id="page-256-0"></span>236 THERMAL PHYSICS

$$K = \cdots \cdots \cdots$$

$$K = \int_{V_s} \boldsymbol{\omega}_v^s \cdot \mathbf{d}V + \int_{V_F} \boldsymbol{\omega}_v^F \cdot \mathbf{d}V + \int_A \boldsymbol{\chi}(\hat{\mathbf{n}}) \, \mathbf{d}A,\tag{14.79}$$

equilibrium shape of a solid in contact with a fluid. Places where it is not differentiable can be handled as limiting cases as explained in Section 14.3.1. We proceed to minimize the grand potential *K* for the entire solid, assumed to be constrained to have a fixed volume and maintained at fixed temperature *T* and chemical potentials μ*i*. We write this potential in the form *K* = *Vs* ω*s v* d*V* + *VF* ω*F v* d*V* + *A* γ (**n**ˆ) d*A*, (14.79) where ω*s v* is the grand potential per unit volume in the solid, which may be crystalline or amorphous, ω*F v* is the grand potential per unit volume in the fluid, *Vs* is the volume of the solid, *VF* is the volume of the fluid, *A* is the area of the interface that separates

<span id="page-256-3"></span><span id="page-256-2"></span>
$$\mathbf{r} = \mathbf{r}_0(\boldsymbol{\mu}, v) + \hat{\mathbf{n}}_0(\boldsymbol{\mu}, v)\boldsymbol{\eta}(\boldsymbol{\mu}, v) \equiv \mathbf{r}_0(\boldsymbol{\mu}, v) + \delta \mathbf{r}(\boldsymbol{\mu}, v), \tag{14.80}$$

represented in terms of parameters *u*, *v* by the equation **r** = **r**(*u*, *v*), as discussed in detail in Appendix C, Section C.2. We write the equilibrium shape in the form **r** = **r**0(*u*, *v*) and make

$$
\delta K = \int_{A} (\boldsymbol{\omega}_{v}^{s} - \boldsymbol{\omega}_{v}^{F}) \eta(\mathbf{u}, v) \, \mathbf{d}A + \delta \int_{A} \boldsymbol{\xi} \cdot \hat{\mathbf{n}} \, \mathbf{d}A,\tag{14.81}
$$

where the infin[itesim](#page-256-1)al quantity η(*u*, *v*) is arbitrary but differentiable. Then the variation of the total Kramers (grand) potential is

> δ*K* = *A* (ω*s*

inte[gral](#page-256-3) [to](#page-256-3) obtain

Eq. (14.80) leads to

<span id="page-256-1"></span>
$$
\delta \int_{A} \boldsymbol{\xi} \cdot \hat{\mathbf{n}} \, \mathrm{d}A = \delta \int_{u,v} \boldsymbol{\xi} \cdot \mathbf{H} \, \mathrm{d}u \, \mathrm{d}v,\tag{14.82}
$$

wh[ere we](#page-256-2) have replaced γ by *ξ* · **n**ˆ. [The](#page-243-0) [se](#page-243-0)cond area integral can be written in the form δ *A ξ* · **n**ˆ d*A* = δ *u*,*v ξ* · **H** d*u* d*v*, (14.82)

$$
\delta \int_{\mu, v} \xi \cdot \mathbf{H} \, \mathbf{d}u \, \mathbf{d}v = \int_{\mu, v} \xi \cdot \delta \mathbf{H} \, \mathbf{d}u \, \mathbf{d}v,\tag{14.83}
$$

δ *u*,*v ξ* · **H** d*u* d*v* = *u*,*v ξ* · δ**H** d*u* d*v*, (14.83)

$$
\delta \mathbf{H} = \hat{\mathbf{n}}_0(\mathbf{u}, v) H_0(\mathbf{u}, v) \eta(\mathbf{u}, v) \,\%_0(\mathbf{u}, v) - H_0(\mathbf{u}, v) \nabla_\mathbf{s} \eta(\mathbf{u}, v),
\tag{14.84}
$$

δ**H** = **n**ˆ 0(*u*, *v*)*H*0(*u*, *v*)η(*u*, *v*) *K*0(*u*, *v*) − *H*0(*u*, *v*)∇*s*η(*u*, *v*), (14.84) where *K*0(*u*, *v*) is the mean curvature of the surface in the unvaried state (see Eq. (C.28) for a general formula) and ∇*s* is the surface gradient operator defined by Eq. (C.35). Thus

$$
\delta \mathcal{K} = \int_A (\boldsymbol{\alpha}_v^s - \boldsymbol{\alpha}_v^F) \boldsymbol{\eta}(\mathbf{u}, v) \, \mathrm{d}A + \int_A \left[ \boldsymbol{\chi} \, \boldsymbol{\mathcal{K}} \, \boldsymbol{\eta}(\boldsymbol{u}, v) - \boldsymbol{\xi} \cdot \nabla_{\boldsymbol{\mathcal{S}}} \boldsymbol{\eta}(\boldsymbol{u}, v) \right] \, \mathrm{d}A,\tag{14.85}
$$

$$-\pounds \cdot \nabla_{\mathfrak{J}} \eta(\mathfrak{u}, v) = -\nabla_{\mathfrak{J}} \cdot [\pounds \eta(\mathfrak{u}, v)] + \eta(\mathfrak{u}, v) \nabla_{\mathfrak{J}} \cdot \mathfrak{g},\tag{14.86}$$

*Chapter 14* • Thermodynamics of Solid-Fluid Interfaces 237

$$\int_{A} \nabla_{\mathcal{S}} \cdot \left[ \mathsf{f} \,\eta(\mu, v) \right] \mathrm{d}A = \oint_{C} \mathsf{f}_{\mathcal{I}} \cdot \widehat{\mathsf{b}} \eta(\mu, v) \, \mathrm{d}\ell + \int_{A} \mathsf{y} \, \mathsf{X} \eta(\mu, v) \, \mathrm{d}A,\tag{14.87}$$

<span id="page-257-2"></span>writing − *ξ* · ∇*s*η(*u*, *v*) = −∇*s* · [*ξ*η(*u*, *v*)] + η(*u*, *v*)∇*s* · *ξ*, (14.86)

$$\delta \boldsymbol{\xi} = \int_{A} \left[ (\boldsymbol{\alpha}_{v}^{\boldsymbol{s}} - \boldsymbol{\alpha}_{v}^{F}) + \nabla_{\boldsymbol{s}} \cdot \boldsymbol{\xi} \right] \boldsymbol{\eta}(\boldsymbol{u}, v) \, \mathrm{d}A - \oint_{C} \boldsymbol{\xi}_{t} \cdot \hat{\mathbf{t}} \, \boldsymbol{\eta}(\boldsymbol{u}, v) \, \mathrm{d}\boldsymbol{\ell}. \tag{14.88}$$

 *A* ∇*s* · [*ξ*η(*u*, *v*)] d*A* = *C ξt* · **t**ˆη(*u*, *v*) d + *A* γ *K*η(*u*, *v*) d*A*, (14.87) where **t**ˆ is a unit tangent vector pointing out of the area along the curve *C*, specifically

$$\mathbf{0} = \delta \mathcal{K} = \int_{A} \left[ (\boldsymbol{\omega}_{v}^{s} - \boldsymbol{\omega}_{v}^{F}) + \nabla_{s} \cdot \boldsymbol{\xi} \right] \boldsymbol{\eta}(\boldsymbol{u}, v) \, \mathrm{d}A. \tag{14.89}$$

δ*K* = *A C* To guarantee that no work is done along the curve *C*, we can take η(*u*, *v*) = 0 along *C* and the equilibri[um](#page-257-0) [crit](#page-257-0)erion becomes

<span id="page-257-0"></span> (ω*s*

<span id="page-257-3"></span>

$$
\alpha_v^F - \alpha_v^s = \nabla_\mathcal{S} \cdot \mathfrak{F}.\tag{14.90}
$$

0 = δ*K* = *A* (ω*s v* − ω*F v* ) + ∇*s* · *ξ* Then since η(*u*, *v*) is arbitrary over the area *A*[, th](#page-257-0)e integrand must vanish, and we obtain

the equilibrium condition ω*F v* − ω*s v* = ∇*s* · *ξ*. (14.90) If the solid is amorphous and therefore isotropic, *ξ* = γ**n**ˆ, ∇*s* · *[ξ](#page-257-1)* = γ *K* by Eq. (C.38), and ω*F v* − ω*s v* = *ps* − *pF* , so the Laplace equation (Eq. (13.71)) for fluids would apply. Equation (14.90) is a nonlinear partial differential equation for the solid-fluid interface shape, so one would have to find a solution that attached to the bounding curve *C*, a

$$\mathbf{r} = \frac{2}{\left(\alpha_v^F - \alpha_v^g\right)} \mathbf{\xi},\tag{14.91}$$

<span id="page-257-1"></span>(see Eq[. (C.41](#page-256-2))) an obvious solution to Eq. (14.90) is **r** = 2 (ω*F v* − ω*s v* ) *ξ*, (14.91) which is the equation for the equilibrium shape of a crystal.12 Note that a result of the same form would be obtained if one varied only the shape of the body while holding its volume constant. This could be done by using a Lagrange multiplier to put in the volume

constraint. The present method identifies that Lagrange multiplier in terms of physical quantities so we obtain the size of the crystal in addition to its shape. Let us return to Eq. (14.88) for a bounding curve *C* that can move in a manner described

by Eq. (14.80). Then the work done by an external force work **f***L* per unit length is given by

are missing orientations. Note in two dimensions that ∇*s* · **r** = 1, so the factor of 2 would be missing.

12As explained in connection with the Wulff theorem, one must truncate the ears to get a convex body if there

238 THERMAL PHYSICS

$$
\delta \mathcal{W} = \oint_C \mathbf{f}_L \cdot \hat{\mathbf{n}} \,\eta(\mu, v) \,\mathrm{d}\ell. \tag{14.92}
$$

$$-\oint_{C} \mathbf{\hat{t}}_{t} \cdot \hat{\mathbf{t}} \,\eta(\boldsymbol{u}, \boldsymbol{v}) \,\mathrm{d}\ell - \oint_{C} \mathbf{f}_{L} \cdot \hat{\mathbf{n}} \,\eta(\boldsymbol{u}, \boldsymbol{v}) \,\mathrm{d}\ell = \mathbf{0}.\tag{14.93}$$

δ*W* = **f***L* · **n**ˆ η(*u*, *v*) d. (14.92)

$$\oint_{C} \left[ \mathbf{f}_{l} \times (\mathbf{d}\ell/\mathbf{d}\ell) + \mathbf{f}_{L} \right] \cdot \hat{\mathbf{n}} \,\eta(\mathbf{u}, v) \,\mathrm{d}\ell = 0. \tag{14.94}$$

− *ξ t* · **t**ˆ η(*u*, *v*) d − **f***L* · **n**ˆ η(*u*, *v*) d = 0. [(14.93)](#page-246-1)

<span id="page-258-1"></span>*C*

$$\left[\mathbf{f}\mathbf{\hat{z}} + \mathbf{\dot{\xi}}_{I} \times (\mathbf{d}\boldsymbol{\ell}/\mathbf{d}\boldsymbol{\ell})\right] \cdot \hat{\mathbf{n}} = \mathbf{0},\tag{14.95}$$

 *C ξ t* × (d/d) + **f***L* · **n**ˆ [η(](#page-240-0)*u*, *v*) d = 0. (14.94) Since η(*u*, *v*) is arbitrary along *C*, we conclude that **f***L* + *ξt* × (d/d) · **n**ˆ = 0, (14.95) which gives a normal force for curved surfaces that is the same as given by Eq. (14.58)

for a planar surface. By considering a variation of the curve *C* in the tangential direction **t**ˆ instead of Eq. (14.80) one can obtain the tangential component of Eq. (14.58). It must

$$\operatorname{d}(\alpha_v^F - \alpha_v^s) = -(\mathbf{s}^F \boldsymbol{\pi}^F - \mathbf{s}^s \boldsymbol{\pi}^s) \operatorname{d}T - (\boldsymbol{\pi}^F - \boldsymbol{\pi}^s) \operatorname{d}\mu,\tag{14.96}$$

tangential force per unit length, as discussed in Section 14.1.2. To evaluate the quantity ω*F v* − ω*s v* for a single component, one usually uses d(ω*F v* − ω*s v* ) = −(*s FnF* − *s s ns* ) d*T* − (*nF* − *ns* ) dμ, (14.96) which is only valid if the effect of shear strain in the solid can be ignored. Here, *sF* is

<span id="page-258-0"></span>
$$\mathbf{d}\mu = -\mathbf{s}^F \mathbf{d}T + (1/n^F) \,\mathrm{d}p^F,\tag{14.97}$$

potential. For the fluid, one also has

gives

$$\operatorname{d}(\alpha_v^F - \alpha_v^s) = -n^s(\mathbf{s}^F - \mathbf{s}^s)\,\mathrm{d}T - \frac{(n^F - n^s)}{n^F}\,\mathrm{d}p^F.\tag{14.98}$$

d(ω*F v* − ω*s v* ) = −*ns* (*s F* − *s s* ) d*T* − (*nF* − *ns*) *nF* d*pF* . (14.98) We can examine two states, both at the same value of *pF* . One such state corresponds to a planar interface for an infinite crystal, so ω*F v* − ω*s v* = 0 and *T* becomes the nominal melting point *T*M for that chosen pressure, where we have chosen the fluid to be a liquid for the sake of illustration. The other state corresponds to the equilibrium state of a small crystal in equilibrium with its liquid melt at temperature *T*. Then integration of Eq. (14.98) with *L*V := *ns* (*sF* − *ss* )*T*M, the latent heat per unit volume of solid, assumed to be constant,

$$L(\boldsymbol{\alpha}_v^F - \boldsymbol{\alpha}_v^s) = L\boldsymbol{\sqrt{T_\mathcal{M} - T}}.\tag{14.99}$$

<span id="page-259-0"></span>
$$T = T_{\rm M} - (T_{\rm M}/L_{\rm V})\nabla_{\rm s} \cdot \boldsymbol{\xi},\tag{14.100}$$

*Chapter 14* • Thermodynamics of Solid-Fluid Interfaces 239

<span id="page-259-1"></span>(ω*F v* − ω*s*

$$T = T_{\rm M} - (T_{\rm M} \gamma / L_{\rm V}) \mathcal{K},\tag{14.101}$$

Thus Eq. (14.90) becomes

*L*

components of the fluid would be unconstrained.

*T* = *T*M − (*T*M/*L*V)∇*s* · *ξ* , (14.100) which is a form of the **Gibbs-Thomson equation** [for anis](#page-259-0)otropic γ . For isotropic γ it becomes

$$
\mu = \mu_{\infty} + \Omega_0 \nabla_{\mathbf{s}} \cdot \mathbf{\dot{g}}.\tag{14.102}
$$

which is well known. Another important option is to keep *T* [fixed](#page-257-3) in Eq. (14.96) but allow μ to vary from its value μ∞ for an infinite crystal with ω*F v* − ω*s v* = 0 to its value μ for a finite crystal. Then by treating 0 =: (*ns* − *nF* ) −1 as a constant, Eq. (14.98) can be integ[rated to](#page-259-0) obtai[n](#page-259-1)

μ = μ∞ + [0](#page-259-1)∇*s* · *ξ* . (14.102) If ∇*s* · *ξ* is evaluated at a point on the surface, Eq. (14.100) is equivalent to the Herring equation, which usually pertains to the case in which the fluid is a gas with negligible density, so that 0 ≈ (*ns*) −1. In the next section, we will develop that equation in detail. The derivation of Eq. (14.90) was carried out in the context of global equilibrium between a crystal and a [fluid, s](#page-258-1)o that Eq. (14.91) is [an equa](#page-259-0)tion for the equilibrium shape of the crystal. Under those conditions, the fluid is homogeneous, so its temperature and chemical potentials are uniform. On the other hand, Eqs. (14.100) an[d (14.10](#page-259-1)2) are frequently regarded as **local equilibrium** conditions that apply at the surface of a crystal having any shape. In that case, for example, Eq. (14.102) would lead to a chemical potential that varied along the surface of the crystal. Such a nonuniform chemical potential would provide a driving force for diffusion processes that would lead to shape changes of the crystal and eventually to an equilibrium shape and a uniform chemical potential. For multicomponent systems, an equation similar in form to Eq. (14.100) can be obtained if the chemical potentials μ*F i* [of the](#page-259-1) fluid can be maintained at fixed values. Then only the term in d*T* in Eq. (14.96) survives and Eq. (14.100) applies with *L*V replaced by V = (*sFnF* − *ss ns* )*T*M, where now *T*M is understood to be the local bulk melting point of the multicomponent alloy. Note that it is not so easy to extend Eq. (14.102) to a multicomponent system because ω = *u*V − *Ts*V − μ*ini*, so more than one chemical potential is involved. Such an extension is sometimes made, however, to the case of a Gibbs solid that has a *fixed* composition (Gibbs called this the substance of the solid) and does not contain other chemical components (if any) that are contained in the fluid. For such a solid, the chemical potential μ*A* of the substance of the solid (regarded as a supercomponent *A* that is made up of appropriate components of the fluid in fixed proportions) would obey Eq. (14.102) at its surface. The chemical potentials of any other 14.6 Herring Formula

ω*F*

240 THERMAL PHYSICS

<span id="page-260-3"></span>
$$\mathbf{x} = \mathbf{u}; \quad \mathbf{y} = v; \quad \mathbf{z} = w(\mathbf{u}, v), \tag{14.103}$$

By explicitly evaluating the quantity ∇*s* · *ξ* that appears in Eq. (14.90) at some point on a surface, one can obtain a formula due to Herring that is often used to calculate local equilibrium at a crystal-fluid interface. This can be accomplished by going to a Monge representation of the surface which requires one to adopt a specific parameterization of the surface of the form

<span id="page-260-0"></span>
$$
\omega_v^F - \omega_v^s = \nabla_\mathbf{s} \cdot \mathbf{\xi} = - (\Phi_{pp} \mathbf{z}_{\mathbf{x}\mathbf{t}} + 2\Phi_{pq} \mathbf{z}_{\mathbf{y}\mathbf{y}} + \Phi_{qq} \mathbf{z}_{\mathbf{y}\mathbf{y}}),
\tag{14.104}
$$

where *x*, *y*, and *z* are Cartesian coordinates, as in Section C.3 of Appendix C. This amounts to writing *z* = *z*(*x*, *y*), where *z* on the right represents the function *w* of *x* and *y* whereas *z* on the left represents the value of that function, a common shorthand notation. Then with *p* = *zx* and *q* = *zy*, where the subscripts denote partial derivatives (see Eq. (C.70)), ω*F v* − ω*s v* = ∇*s* · *ξ* = −(*ppzxx* + 2*pqzxy* + *qqzyy*), (14.104)

<span id="page-260-1"></span>where (*p*, *q*) = γ (*p*, *q*) 1 + *p*2 + *q*2 is the value of the surface free energy γ per unit area of the *x*, *y* plane and subscripts indicate partial derivatives. Explicit values of the derivatives of are given by Eq. (C.71). Equation (14.104) is a rather complicated nonlinear partial differential equation for the shape of the surface *z* = *z*(*x*, *y*).

$$
\boldsymbol{\omega}_{v}^{F} - \boldsymbol{\omega}_{v}^{s} = -(\boldsymbol{\gamma} + \boldsymbol{\gamma}_{pp})\boldsymbol{\varepsilon}_{\rm xx} - 2\boldsymbol{\gamma}_{pq}\boldsymbol{\varepsilon}_{xy} - (\boldsymbol{\gamma} + \boldsymbol{\gamma}_{qq})\boldsymbol{\varepsilon}_{yy}, \quad \text{at a point } \mathbf{x}_{0}, y_{0}, \boldsymbol{z} \text{ along } \hat{\mathbf{n}}_{0}, \tag{14.105}
$$

<span id="page-260-2"></span>gives ω*F v* − ω*s v* = −(γ + γ*pp*)*zxx* − 2γ*pqzxy* − (γ + γ*qq*)*zyy*, at a point *x*0, *y*0, *z* along **n**ˆ 0, (14.105)

where the derivatives are to be evaluated at *p* = *q* = 0, *x* [=](#page-260-2) *x*0, and *y* = *y*0. This is a more general than the Herring formula because it does not require location of the principal axes of the shape under consideration.

$$
\alpha_v^F - \alpha_v^S = \frac{\gamma + \gamma \rho \eta}{R_1} + \frac{\gamma + \gamma \rho \eta}{R_2}, \quad \text{at a point xo, } y_0 \text{, z along } \hat{\mathbf{n}}_0 \text{, principal axes.} \tag{14.106}
$$

ω*F v* − ω*s v* = γ + γ*pp R*1 + γ + γ*qq R*2 , at a point *x*0, *y*0, *z* along **n**ˆ 0, principal axes. (14.106) The **Herring formula** can be obtained by rewriting Eq. (14.106) in terms of the angles θ1 and θ2 made between the normal **n** and **n**0 near *x*0, *y*0 and measured in principal planes.

$$
\alpha_v^F - \alpha_v^s = \frac{\nu + \gamma \rho_1 \rho_1}{R_1} + \frac{\nu + \gamma \rho_2 \rho_2}{R_2}, \quad \text{at a point } \mathbf{x}_0, \mathbf{y}_0, \text{ principal planes}, \tag{14.107}
$$

$$
\mu = \mu_{\infty} + \Omega_0 \left[ \frac{\chi + \chi_{\theta_1 \theta_1}}{R_1} + \frac{\chi + \chi_{\theta_2 \theta_2}}{R_2} \right], \quad \text{at a point } \mathbf{x}_0, y_0, \text{ principal planes.} \tag{14.108}
$$

which is a somewhat more general version of Herring's result. (See Section C.4 for details of this variable change.) The original Herring formula [38, 41] pertained to the case of a solid-vapor interface for a single component for which Eq. [(14.102](#page-260-3)) becomes13

### <span id="page-261-2"></span>μ = μ∞ + 0 γ + γθ1θ1 *R*1 + γ + γθ2θ2 *R*2 , at a point *x*0, *y*0, principal planes. (14.108)

It should be emphasized that the Herring formula applies only at a point on the surface. In particular, it is not a partial differential equation for the surface shape, such as Eq. (14.104). It can, however, serve as a local equilibrium condition for a nonequil[ibrium](#page-260-0) shape, as discussed at the end of Section 14.5.

$$\Phi(p,q) = \frac{\chi}{n_2} = \frac{\chi}{\cos \theta} = \chi(p,q)\sqrt{1+p^2+q^2},\tag{14.109}$$

In a Monge representation, *z* = *z*(*x*, *y*) as introduced in Eq. (14.103), an interesting reciprocal relationship exists between equilibrium shape and the interfacial free energy expressed per unit area of the *x*, *y* plane, namely the quantity14 (*p*, *q*) = γ *nz* = γ cos θ = γ (*p*, *q*) 1 + *p*2 + *q*2, (14.109) where *p* = *zx* and *q* = *zy* as introduced previously in connection with Eq. (14.104). We shall see that (*p*, *q*) and *z* = *z*(*x*, *y*) are essentially Legendre transforms of one another, with an

$$\Phi = Z - pX - qY = Z - X\frac{\partial Z}{\partial X} - Y\frac{\partial Z}{\partial Y},\tag{14.110}$$

Monge representation of the form *Z* = *Z*(*X*, *Y* ), where *X* ≡ ξ*x*, *Y* ≡ ξ*y*, and *Z* ≡ ξ*z*. With this notation we shall show that

<span id="page-261-3"></span><span id="page-261-1"></span>*v* − ω*s*

*p* =

, with the understanding that the square root is positive.

*ξ* = λ**r** with λ = (ω*F*

<span id="page-261-0"></span>
$$Z = \Phi + pX + qY = \Phi - p\frac{\partial\Phi}{\partial p} - q\frac{\partial\Phi}{\partial q}.\tag{14.111}$$

whose inverse is

*Z* = + *pX* + *qY* = − *p* ∂ ∂*p* − *q* ∂ ∂*q* . (14.111)

$$n_{\mathbf{x}} \, \mathbf{d}X + n_{\mathbf{y}} \, \mathbf{d}Y + n_{\mathbf{z}} \, \mathbf{d}Z = \mathbf{0}.\tag{14.112}$$

, (14.113)

We begin with Eq. (14.35) which we write in the form

Then we calculate

$$p = \left(\frac{\partial Z}{\partial X}\right)_Y = -\frac{n_\chi}{n_\varepsilon}; \quad q = \left(\frac{\partial Z}{\partial Y}\right)_X = -\frac{n_\chi}{n_\varepsilon},\tag{14.113}$$

∂*X Y nz* ∂*Y X nz* 13Herring actually treated a substitutional crystal with atoms and vacancies located on lattice sites, so μ

; *q* =

here is actually equal to the difference between his chemical potential of atoms and his chemical potential of vacancies in an extended variable set. μ is also equal to the chemical potential of atoms in the vapor. 14With a Monge representation, it is necessary to use single-valued functions to represent various parts of a body, which amounts to choosing the sign of *nz* = cos θ. Here we choose cos θ > 0 to obtain a positive value of

which allows Eq. [(14.112)](#page-261-0) to be written in the form

<span id="page-262-0"></span>
$$\mathbf{d}Z = p\,\mathbf{d}X + q\,\mathbf{d}Y.\tag{14.114}$$

By using Eq. [(14.32)](#page-242-3), we deduce

$$\Phi = \frac{n_{\mathbf{X}}\mathbf{X} + n_{\mathbf{Y}}\mathbf{Y} + n_{\mathbf{Z}}\mathbf{Z}}{n_{\mathbf{Z}}} = \mathbf{Z} - p\mathbf{X} - q\mathbf{Y},\tag{14.115}$$

which establishes Eq. [(14.110)](#page-261-1). Note that *n*2 *z* = 1 − *n*2 *x* − *n*2 *y* = 1 − *n*2 *z* (*p*2 + *q*2) which can be solved for *nz*, resulting in

$$1/n_z = \sqrt{1+p^2+q^2},\tag{14.116}$$

consistent with Eq. [(14.109)](#page-261-2). To establish the inverse transform, we calculate

$$\mathbf{d}\Phi = \mathbf{d}Z - p\mathbf{d}X - X\,\mathrm{d}p - q\,\mathrm{d}Y - Y\,\mathrm{d}q = -X\,\mathrm{d}p - Y\,\mathrm{d}q,\tag{14.117}$$

where Eq. [(14.114)](#page-262-0) has been used. From this differential we calculate

$$X = -\left(\frac{\partial \Phi}{\partial p}\right)_q; \quad Y = -\left(\frac{\partial \Phi}{\partial q}\right)_p,\tag{14.118}$$

which justifies the second part of Eq. [(14.111)](#page-261-3).

These Legendre transforms can also be established without using the *ξ* -vector by using the calculus of variations with the surface represented by a Monge representation, as shown in Appendix C, Section C.4.1.

### 14.8 Remarks About Solid-Solid Interfaces

Solid-solid interfaces are quite complicated if both phases are crystals, which are anisotropic. For example, specification of the interface between two crystals has five degrees of freedom (geometrical parameters), three to specify the relative orientations of the crystals (say, three Euler angles) and two to specify the orientation of the interface (grain boundary) that separates them. Structure and properties vary considerably with these five parameters because certain angles give rise to special lattice matchings. Moreover, most such interfaces are characterized by rather intricate dislocation arrays. The situation would be much simpler if one or both solids were amorphous.

For a detailed treatment of crystal-crystal interfaces, the reader is referred to *Interfaces in Crystalline Materials* by Sutton and Ballufi [46]. The first four chapters are devoted to interface structure and are well beyond the scope of the present book. Chapter 5 is devoted to thermodynamics of interfaces. Much of the formalism resembles that for fluid-fluid and solid-fluid interfaces but the variable set *T*, *p*, {μ*i*} must be augmented by interfacial strain variables εαβ and the geometrical parameters mentioned above. Considerations of excess free energies and forces that are used for fluid-fluid and solid-fluid interfaces can sometimes be used for solid-solid interfaces; however, they should be used with great care and might be completely inapplicable in some cases. For reasons of stability against cleavage, the size of γ for a solid-solid interface cannot exceed the sum of the free energies per unit area of the individual free surfaces. Heterophase interfaces typically have values of γ that are several times larger than those for homophase interfaces. Grain boundary free energies per unit area are usually less than those of a free surface because the number of nearest neighbors of an atom in a grain boundary is comparable to that of an atom in the bulk.

This page intentionally left blank

![](_page_265_Picture_0.jpeg)

This page intentionally left blank

# 15

# Entropy and Information Theory

The entropy *S*, which was introduced in Chapter 3 as a state function in connection with the second law of thermodynamics, plays a special role in statistical mechanics. Unlike the internal energy *U*, whose existence is an extension, although not a trivial one, of the concept of energy in mechanics, the entropy is intrinsically statistical and has no counterpart in mechanics. In thermodynamics, it is the conjugate variable to the absolute temperature, which also has no counterpart in mechanics. Nevertheless, the entropy, known since the time of Rudolf Clausius circa 1854, has its roots in information theory. This connection had been appreciated for a long time but not quantified. In a letter to Irving Langmuir, August 5, 1930, Gilbert Norton Lewis wrote [47, p. 400]:

*It is not easy for a person brought up in the ways of classical thermodynamics to come around to the idea that the gain of entropy eventually is nothing more nor less than loss of information.*

The quantification of information in the context of communication theory was developed somewhat later (1948) by Claude Shannon [48, 49]. Subsequently, Shannon's communication theory was given a firm basis in probability theory by A.I. Khinchin [50].

### 15.1 Entropy as a Measure of Disorder

In order to understand the physical basis of entropy, it is often stated that entropy is a measure of disorder in a system, although this concept is sometimes objected to on the basis that common notions of disorder can disagree. Nevertheless, Shannon's information function, which we shall represent by the symbol *D* and refer to as the **disorder function**, gives a mathematically precise definition of information, the opposite of which is disorder. This disorder function is in complete agreement with the entropy of statistical mechanics, for all of its ensembles, except for the value of a multiplicative constant that simply accounts for units that are compatible with those chosen for energy and temperature. In addition, the function *D* plays the same role (except for opposite sign) as the dynamical function H(*t*) (also denoted by E(*t*) in Boltzmann's writings) that enters Boltzmann's Eta theorem [51].

### 15.1.1 The Disorder Function

We consider a set of mutually exclusive events *Ai* for *i* = 1, 2, ... , *N* that have respective probabilities *pi*. Mutual exclusivity means that only one of them can occur for a given trial. Khinchin calls this a "finite scheme." We introduce a disorder function

$$D(p_l) = D(p_1, p_2, \dots, p_N) \tag{15.1}$$

that depends only on the set of probabilities {*pi*} and has the following additional properties:

- **1.** *D*{*pi*} takes on its minimum value, zero, when one of the *pi* is equal to unity and all of the others are zero. This makes sense because the outcome of a trial is then certain, so there is complete information and therefore no disorder.
- **2.** *D*{*pi*} takes on its maximum value *J*(*N*) when the probabilities are all equal, that is, *pi* = 1/*N* for all *i*. This is reasonable because the outcome of any trial could equally well result in any of the possible events, so as little as possible is known about the outcome. Specifically,

$$J(N) \coloneqq D(1/N, 1/N, \dots, 1/N). \tag{15.2}$$

- **3.** *J*(*N*) should be a monotonically increasing function of *N* because a measure of disorder (lack of information) should increase if there is a larger possible number of outcomes.
- **4.** The measure *D* should be independent of any manner in which the events are batched and the disorder of the batching is added to the weighted respective disorders of the batches. Thus if there are *B* batches (necessarily *B* ≤ *N*) labeled by an index *j* with each batch having a probability *qj*, then

<span id="page-268-0"></span>
$$D(p_l) = D(q_l) + \sum_{j=1}^{B} q_j D(p_l/q_j)_{p_l \subset q_l}.\tag{15.3}$$

Here, the notation *pi* ⊂ *qj* means that *pi* belongs to the batch *qj* in which case *qj* = *pi*⊂*qj i pi*. It therefore follows that *pi*⊂*qj i pi*/*qj* = 1, so *pi*/*qj* is the probability of *Ai* within the batch *j*. For example, for *N* = 5 such a batching might be *q*1 = *p*1 + *p*2 and *q*2 = *p*3 + *p*4 + *p*5, so *p*1/*q*1 = *p*1/(*p*1 + *p*2), *p*2/*q*1 = *p*2/(*p*1 + *p*2), etc.

Under these conditions, we shall proceed to demonstrate that the disorder function is

<span id="page-268-2"></span>
$$D(p_l) = -k \sum_l p_l \ln p_l,\tag{15.4}$$

where *k* is a positive constant. For a rigorous proof that this result is unique provided that *D*{*pi*} is continuous with respect to all of its arguments, see Khinchin [50, p. 9].

We first consider a special case of Eq. [(15.3)](#page-268-0) for which all *pi* = 1/(*BN*) where *B* and *N* are integers, so *D*{*pi*} = *J*(*BN*). We divide into *B* batches, each with *N* elements, so *qj* = (1/*B*) and *pi*/*qj* = 1/*N*. Thus Eq. [(15.3)](#page-268-0) becomes

$$J(BN) = J(B) + \sum_{j=1}^{B} \frac{1}{B} J(N),\tag{15.5}$$

so

<span id="page-268-1"></span>
$$J(BN) = J(B) + J(N). \tag{15.6}$$

We differentiate Eq. [(15.6)](#page-268-1) partially with respect to *B* and then set *B* = 1 in the result to obtain

$$Nl'(N) = l'(1) \equiv k = \text{constant},\tag{15.7}$$

where the prime indicates the derivative of a function with respect to its argument. The solution to this differential equation, subject to *J*(1) = 0 which follows from condition (1), i[s1](#page-269-0)

<span id="page-269-1"></span>
$$J(N) = k \ln N.\tag{15.8}$$

Armed with the functional form Eq. [(15.8)](#page-269-1), we return to Eq. [(15.3)](#page-268-0) with *pi* = 1/*N* for all *i* but with arbitrary batches having probabilities *qj*, in which case it becomes

$$J(N) = D(q_{\!\!\!/}) + \sum_{\!\!\!/} q_{\!\!\!/} J(Nq_{\!\!\!/}) \tag{15.9}$$

or

<span id="page-269-2"></span>
$$k \ln N = D(q_j) + \sum_j q_j (k \ln q_j + k \ln N). \tag{15.10}$$

After cancellation of the term *k* ln *N*, Eq. [(15.10)](#page-269-2) becomes

<span id="page-269-3"></span>
$$D(q_j) = -k \sum_j q_j \ln q_j,\tag{15.11}$$

in agreement with Eq. [(15.4)](#page-268-2).

From Eq. [(15.11)](#page-269-3), condition (2) can be demonstrated by setting the result of partial differentiation with respect to *qi* equal to zero, subject to the constraint *j qj* = 1, which is easily handled by means of a Lagrange multiplier λ, that is, ∂/∂*qi*[*D*{*qj*} − λ *j qj*] = 0. Details are left to the reader to show that all *qi* will be equal.

Since logarithms to any base are simply proportional to those for any other base, it is customary in information theory to use logarithms to the base two and then to set the overall constant equal to unity, resulting in the function

$$H_2(p_j) = -\sum_j p_j \log_2 p_j,\tag{15.12}$$

in which case the units of *H*2 are known as bits. For the 128 ASCII characters, the maximum value of *H*2 would be *J*(128) = log2 128 = 7 bits.

To obtain the entropy function of statistical mechanics, one retains the natural logarithm but chooses *k* to be Boltzmann's constant *kB* = 1.38065 × 10−23 J K−1. Thus the entropy

$$S(p_j) = -k_B \sum_j p_j \ln p_j,\tag{15.13}$$

<span id="page-269-0"></span>1Since we seek only to discover a functional form, we have treated *B* as a continuous variable but the result also satisfies Eq. [(15.6)](#page-268-1) when *B* is an integer.

250 THERMAL PHYSICS

$$S(p_\uparrow) = -k_B \sum_{j=1}^{\Omega} (1/\Omega) \ln(1/\Omega) = k_B \ln \Omega. \tag{15.14}$$

the constraints of the ensemble under consideration. For example, for the microcanonical ensemble to be considered in Chapter 16, one considers an isolated system having known energy *E* and makes the assumption that all compatible stationary quantum microstates, which number , are equally probable. Then *pj* = 1/ for all *j*, so 

For the canonical ensemble (see Chapter 19), one finds that each *pj* is proportional to its Boltzmann factor, which results in *S* = (*U* − *F*)/*T*, a valid thermodynamic equation. In Chapter 22, we examine in detail the relationship between the disorder function *D* and

$$\mathbf{S}^{(1)} = -k\mathbf{g} \sum_{l} p_l^{(1)} \ln p_l^{(1)}; \quad \mathbf{S}^{(2)} = -k\mathbf{g} \sum_{j} p_j^{(2)} \ln p_j^{(2)},\tag{15.15}$$

(1/)ln(1/) = *kB* ln . (15.14)

**Example Problem 15.1.** Suppose2 that Eq. (15.13) gives the entropy of two systems, (1) and (2), so *S*(1) = −*kB* - *p*(1) *i* ln*p*(1) *i* ; *S*(2) = −*kB* - *p*(2) *j* ln *p*(2) *j* , (15.15)

$$S = -k_B \sum_{lj} P_{lj} \ln P_{lj}.\tag{15.16}$$

⎦ , (15.17)

probabilities *Pij*, the entropy of the composite system will be *S* = −*kB* - *Pij* ln *Pij*. (15.16)

*ij* If the subsystems (1) and (2) are very [weakly](#page-270-0) inter[acting,](#page-270-1) show that the entropy is additive, *S* = *S*(1) + *S*(2).

$$\mathbf{S} = -k_{\mathcal{B}} \sum_{\mathcal{Y}} p_l^{(1)} p_f^{(2)} \left[ \ln p_l^{(1)} + \ln p_f^{(2)} \right] = -k_{\mathcal{B}} \left[ \sum_l p_l^{(1)} \ln p_l^{(1)} + \sum_j p_j^{(2)} \ln p_j^{(2)} \right],\tag{15.17}$$

*S* = −*kB* - *ij p*(1) *i p*(2) *j* ln *p*(1) *i* + ln *p*(2) *j* = −*kB* ⎣ - *i p*(1) *i* ln *p*(1) *i* +- *j p*(2) *j* ln *p*(2) *j*

<span id="page-270-0"></span>*S*{*pj*}=−*kB*

<span id="page-270-1"></span>*i*

where *p*(1)

Show that *S* < *S*(1) + *S*(2).

-

*j*=1

where we have used the normalizations *i p*(1) *i* = 1 and *j p*(2) *j* = 1. **Example Problem 15.2.** Suppose Eqs. (15.15) and (15.16) apply but the systems interact such that they are no longer statistically independent, so there are correlations and *Pij* = *p*(1) *i p*(2) *j* .

2This example and the one immediately following are based on problems in the book by Reif [52, p. 236].

$$\mathbf{p}_{l}^{(1)} = \sum_{j} P_{lj}; \quad \mathbf{p}_{j}^{(2)} = \sum_{l} P_{lj}; \quad \sum_{\mathbf{j}} P_{l\mathbf{j}} = 1. \tag{15.18}$$

$$\frac{S - S^{(1)} - S^{(2)}}{k_B} = -\sum_{\mathcal{Y}} P_{\mathcal{Y}} \ln P_{\mathcal{Y}} + \sum_{l} p_l^{(1)} \ln p_l^{(1)} + \sum_{j} p_j^{(2)} \ln p_j^{(2)}.\tag{15.19}$$

*Chapter 15* • Entropy and Information Theory 251

*p*(1) *i* = - *Pij*; *p*(2) *j* = - *Pij*; - *Pij* = 1. (15.18)

*Pij* ln *Pij* +-

*ij*

$$\sum_{l} p_{l}^{(1)} \ln p_{l}^{(1)} + \sum_{j} p_{j}^{(2)} \ln p_{j}^{(2)} = \sum_{\mathcal{U}} \left[ P_{\mathcal{U}} \ln p_{l}^{(1)} + P_{\mathcal{U}} \ln p_{j}^{(2)} \right]. \tag{15.20}$$

*i* +-

*S* − *S*(1) − *S*(2) *kB*

> *p*(1) *i* ln *p*(1)

*kB*

function *f* (**v**,*t*) such that3

[52, p. 523] for such a treatment.

-

= −-

We have

$$\frac{S - S^{(1)} - S^{(2)}}{k_B} = \sum_{jl} P_{lj} \ln \left( \frac{p_l^{(1)} p_j^{(2)}}{P_{lj}} \right). \tag{15.21}$$

*j* . (15.19)

*p*(2) *j* ln *p*(2)

*i j ij* Thus, *S* − *S*(1) − *S*(2) *kB* = - *Pij* ln ⎛ ⎝ *p*(1) *i p*(2) *j Pij* ⎞ ⎠ . (15.21)

*p*(1) *i* ln *p*(1)

$$\frac{S - S^{(1)} - S^{(2)}}{k_B} \le \sum_{ij} P_{\mathcal{Y}} \left( \frac{p_l^{(1)} p_j^{(2)}}{P_{\mathcal{Y}}} - 1 \right) = \sum_{ij} \left( p_l^{(1)} p_j^{(2)} - P_{\mathcal{Y}} \right) = 0,\tag{15.22}$$

*i p*(2)

*j* . We see that correlations

for *x* < 0. Therefore *S* − *S*(1) − *S*(2) ≤ - *Pij* ⎛ *p*(1) *i p*(2) *j* − 1 ⎞ ⎠ = - *p*(1) *i p*(2) *j* − *Pij* = 0, (15.22)

*ij*

*ij*

with equality holding only for the uncorrelated case *Pij* = *p*(1)

⎝

*Pij*

reduce the disorder, and therefore lead to a smaller entropy *S* of the composite system.

15.2 Boltzmann Eta Theorem In 1872, Ludwig Boltzmann (1838-1906), one of the pioneers of statistical mechanics, proved an important theorem, known as the Eta theorem, relating to the dynamics of an ideal gas of hard spheres as it approaches equilibrium by means of elastic collisions [51]. The treatment was, of course, classical since quantum mechanics did not emerge until about 1925. Boltzmann therefore described a homogenous gas in terms of a distribution

<sup>3</sup>A more general Boltzmann equation for a nonhomogeneous gas can be based on a distribution function *f* (**r**, **v**,*t*) such that *f* (**r**, **v**,*t*) d3 *r* d3*v* is the probability that a sphere will have a position located in a volume element d3*r* centered about position **r** and a velocity located in a volume element d3*v* centered about velocity **v**. See Reif

<span id="page-272-2"></span>
$$f(\mathbf{v}, t) \,\mathrm{d}^3 v$$

### 252 THERMAL PHYSICS

*f* (**v**,*t*) d3 *v* (15.23) is the number of hard spheres per unit volume of actual space that have a velocity located in a volume element d3 *v* in velocity space centered about velocity **v**. 15.2.1 Boltzmann Equation

$$\frac{\partial f(\mathbf{v},t)}{\partial t} = r^{\text{sl}} - r^{\text{so}},\tag{15.24}$$

assumed that only binary collisions occur and that the probability distribution function for pairs is given by *f* (**v**1, **v**2,*t*) = *f* (**v**1,*t*)*f* (**v**2,*t*) which he based on an assumption of "molecular chaos," which we discuss later. He then set up a balance equation according to which ∂*f* (**v**,*t*)

∂*t* = *r*si − *r*so, (15.24) where *r*sid3 *v* is the rate per unit volume of actual space at which spheres are scattered into d3 *v* centered about **v** and *r*sod3 *v* is the rate per unit volume of actual space at which spheres are scattered out of the volume element d3 *v* in velocity space, all by means of

binary elastic collisions. To treat a hard sphere gas, we first consider only two hard spheres, subscripts 1 and 2, having velocities **v**1 and **v**2 before a collision and **v** 1 and **v** 2 after that collision. Each

$$v_1^2 + v_2^2 = v_1'^2 + v_2'^2\tag{15.25}$$

collisions. Since energy and momentum are conserved for elastic collision of hard spheres, we have

<span id="page-272-3"></span><span id="page-272-1"></span>
$$\mathbf{v}_1 + \mathbf{v}_2 = \mathbf{v}_1' + \mathbf{v}_2'.\tag{15.26}$$

and **v**1 + **v**2 = **v** 1 + **v** 2. (15.26)

<span id="page-272-0"></span>*v* 2 1 + *v* 2

**v** 2 − **v**

$$\mathbf{g} = \mathbf{v}_2 - \mathbf{v}_1; \quad \mathbf{g}' = \mathbf{v}_2' - \mathbf{v}_1'.\tag{15.27}$$

after collision, namely **g** = **v**2 − **v**1; **g** = **v** 2 − **v** 1. (15.27) By squaring **g** and **g** as well as squaring Eq. (15.26) and using Eq. (15.25), one sees readily that *g*2 − *g*2 = 0, so **g** and **g** have the same magnitude but differ in direction, as expected for an elastic collision. Let *-*ˆ be a unit vector along the line of centers of the spheres at the

$$\mathbf{g} \cdot \hat{\boldsymbol{\ell}} = -\mathbf{g}' \cdot \hat{\boldsymbol{\ell}}; \quad \mathbf{g} \times \hat{\boldsymbol{\ell}} = \mathbf{g}' \times \hat{\boldsymbol{\ell}}.\tag{15.28}$$

**g** · *-*ˆ = −**g** · *-*ˆ; **g** × *-*ˆ = **g** × *-*ˆ. (15.28) By crossing *-*ˆ into the second member of Eq. (15.28), one readily obtains **g** = **g** − 2(**g** · *-*ˆ)*-*ˆ,

$$\mathbf{v}'_2 - \mathbf{v}'_1 = \mathbf{g} - 2(\mathbf{g} \cdot \hat{\mathbf{t}})\hat{\mathbf{t}}.\tag{15.29}$$

<span id="page-273-3"></span><span id="page-273-2"></span>
$$\mathbf{v}_1' = \mathbf{v}_1 + [(\mathbf{v}_2 - \mathbf{v}_1) \cdot \hat{\boldsymbol{\ell}}] \hat{\boldsymbol{\ell}} \tag{15.30}$$

<span id="page-273-1"></span><span id="page-273-0"></span>
$$\mathbf{v}_2' = \mathbf{v}_2 - [(\mathbf{v}_2 - \mathbf{v}_1) \cdot \hat{\mathcal{L}}] \hat{\mathcal{L}},\tag{15.31}$$

*Chapter 15* • Entropy and Information Theory 253

Equation (15.29) can now be solved simultaneously with Eq. (15.26) to obtain **v** 1 = **v**1 + [(**v**2 − **v**1) · *-*ˆ]*-*ˆ (15.30)

**v** 2 = **v**2 − [(**v**2 − **v**1) · *-*ˆ]*-*ˆ, (15.31) which [comple](#page-273-0)tely determines **v** 1 and **v** 2 as functions of **v**1 and **v**2 and two spher[ical an](#page-273-1)gles,

$$
\sigma^{\rm sl} \mathbf{d}^3 v_1 = \frac{a^2}{4} \int \, \mathbf{d} \Omega \int \, \mathbf{d}^3 v_2' \left\{ |\mathbf{v}_2' - \mathbf{v}_1'| f(\mathbf{v}_2', t) f(\mathbf{v}_1', t) \right\} \, \mathbf{d}^3 v_1'. \tag{15.33}
$$

all spheres 2 in a cylinder of [real sp](#page-273-2)ace [of leng](#page-273-3)th |*g*| d*t* and cross sectional area (*a*2/4) d will collide with sphere 1 and scatter into solid angle d = sin θ dθ dφ, so4 *r*sod3 *v*1 = *a*2 4 d d3 *v*2 |**v**2 − **v**1|*f* (**v**2,*t*) *f* (**v**1,*t*) d3 *v*1 (15.32)

*r*sid3 *v*1 = *a*2 d d3 *v* |**v** 2 − **v** 1|*f* (**v** [2,](#page-272-1)*t*)*f*(**v** 1,*t*) d3 *v* 1. (15.33)

4

**v**

volume element d3

<span id="page-273-4"></span>*v* 1 d3 *v*

prove a very important theorem.

integral sign.

$$\mathbf{d}v_1^{'2} + \mathbf{d}v_2^{'2} = \mathbf{d}v_1^2 + \mathbf{d}v_2^2,\tag{15.34}$$

integrations are only over and **v** 2 with **v**1 fixed. Thus in Eq. (15.33), we need to think of 1 as a function of **v** 2, **v**1, and *-*ˆ through the relation **v** 1 = **v**1 − [(**v** 2 − **v** 1) · *-*ˆ]*-*ˆ. By differentiation of Eqs. (15.30) and (15.31), however, one can show that d*v* 2 1 + d*v* 2 2 = d*v* 2 1 + d*v* 2 2 , (15.34)

$$r^{\rm so} = \frac{a^2}{4} \int_{\mathbf{v}} \mathrm{d}\Omega \int \mathrm{d}^3 v_2 \left\{ |\mathbf{v}_2 - \mathbf{v}_1| f(\mathbf{v}_2, t) f(\mathbf{v}_1, t) \right\} \tag{15.35}$$

$$r^{\rm sl} = \frac{a^2}{4} \int \mathrm{d}\Omega \int \mathrm{d}^3 v_2 \left\{ |\mathbf{v}_2 - \mathbf{v}_1| f(\mathbf{v}_2', t) f(\mathbf{v}_1', t) \right\}. \tag{15.36}$$

*r*so = *a*2 4 d d3*v*2 |**v**2 − **v**1|*f* (**v**2,*t*)*f*(**v**1,*t*) (15.35) *r*si = *a*2 4 d d3*v*2 |**v**2 − **v**1|*f* (**v** 2,*t*)*f*(**v** 1,*t*) . [(15](#page-273-4).36)

$$\frac{\partial f(\mathbf{v}_1, t)}{\partial t} = \frac{a^2}{4} \int d\Omega \int d^3 v_2 \left\{ |\mathbf{v}_2 - \mathbf{v}_1| \left[ f(\mathbf{v}_2', t) f(\mathbf{v}_1', t) - f(\mathbf{v}_2, t) f(\mathbf{v}_1, t) \right] \right\}. \tag{15.37}$$

∂*f* (**v**1,*t*) ∂*t* = *a*2 4 d d3*v*2 |**v**2 − **v**1| [*f* (**v** 2,*t*)*f* (**v** 1,*t*) − *f*(**v**2,*t*)*f*(**v**1,*t*)] . (15.37) This is a complicated equation and its solution is a field of study unto itself. See Reif [52, chapters 13-14] for more detail on its derivation and approximate solution. It can be generalized to treat inhomogeneous systems as well as particles other than hard spheres. We shall follow Boltzmann by using the simplified Boltzman equation (Eq. (15.37)) to

<sup>4</sup>See [53] for a more detailed discussion of the collision geometry that leads to the factor *a*2/4. For collision of particles other than hard spheres, this factor can be replaced by the collision cross section *A*(*g*, θ ) under the

254 THERMAL PHYSICS

15.2.2 Eta Theorem

<span id="page-274-0"></span>
$$\text{Eta}(t) \equiv \text{E}(t) \equiv \text{H}(t) = \int \text{d}^3 vf(\mathbf{v}, t) \ln f(\mathbf{v}, t). \tag{15.38}$$

$$\frac{\text{dH}(t)}{\text{d}t} \le 0.\tag{15.39}$$

defining the function of time Eta(*t*) ≡ E(*t*) ≡ H(*t*) = [d3](#page-274-0)*vf* (**v**,*t*)ln *f* (**v**,*t*). (15.38) Then by clever manipulation, Boltzmann showed that

dH(*t*) d*t* ≤ 0. (15.39)

$$\frac{\mathrm{d}\mathbf{H}(t)}{\mathrm{d}t} = \int \mathrm{d}^3 v_1 \frac{\partial f(\mathbf{v}_1, t)}{\partial t} \left[1 + \ln f(\mathbf{v}_1, t)\right]. \tag{15.40}$$

of the previous section. In other words, H(*t*) is expected to relate to the negative of the entropy.

$$\frac{\mathrm{d}\mathbf{H}(t)}{\mathrm{d}t} = \frac{\sigma^2}{4} \int \mathrm{d}^3 v_1 \int \mathrm{d}^3 v_2 \int \mathrm{d}\Omega \left\{ |\mathbf{v}_2 - \mathbf{v}_1| \, |f(\mathbf{v}_2', t) f(\mathbf{v}_1', t) \right. \tag{15.41}$$

$$-f(\mathbf{v}_2, t) f(\mathbf{v}_1, t) \big] \left[ 1 + \ln f(\mathbf{v}_1, t) \right].$$

dH(*t*) d*t* =*a*2 4 d3*v*1 d3 *v*2 d |**v**2 − **v**1| [*f* (**v** 2,*t*)*f* (**v** 1,*t*) (15.41)

<span id="page-274-1"></span>
$$\left\{ \left| \mathbf{v}_{2} - \mathbf{v}_{1} \right| \left[ f(\mathbf{v}_{2}', t) f(\mathbf{v}_{1}', t) - f(\mathbf{v}_{2}, t) f(\mathbf{v}_{1}, t) \right] \right\} \left[ 1 + \ln f(\mathbf{v}_{2}, t) \right]. \tag{15.42}$$

Because of the symmetry of the portion of the integrand in brackets {}, we can get the same result by interchanging **v**1 and **v**2. Thus the integrand can also [be](#page-274-1) [wri](#page-274-1)tten

*v*

|**v**2 − **v**1| and d3

$$\frac{\mathrm{d}\mathbf{H}(t)}{\mathrm{d}t} = \frac{a^2}{4} \int \mathrm{d}^3 v_1 \int \mathrm{d}^3 v_2 \int \mathrm{d}\Omega \frac{1}{2} \left\{ |\mathbf{v}_2 - \mathbf{v}_1| \left[ f(\mathbf{v}_2', t) f(\mathbf{v}_1', t) \right. \right. \tag{15.43}$$

$$-f(\mathbf{v}_2, t) f(\mathbf{v}_1, t) \left[ \left[ 2 + \ln f(\mathbf{v}_1, t) f(\mathbf{v}_2, t) \right] \right.$$

d*t* =*a*2 4 d 2 2,*t*)*f* (**v** 1,*t*) (15.43) −*f* (**v**2,*t*)*f* (**v**1,*t*)] 2 + ln *f*(**v**1,*t*)*f*(**v**2,*t*) .

$$\frac{1}{2}\left[|\mathbf{v}_2 - \mathbf{v}_1| \left[ f(\mathbf{v}_2, t) f(\mathbf{v}_1, t) - f(\mathbf{v}_2', t) f(\mathbf{v}_1', t) \right] \right] \left[2 + \ln f(\mathbf{v}_1', t) f(\mathbf{v}_2', t) \right]. \tag{15.44}$$

1 2 |**v**2 − **v**1| [*f* (**v**2,*t*)*f* (**v**1,*t*) − *f* (**v** 2,*t*)*f*(**v** 1,*t*)] 2 + ln *f* (**v** 1,*t*)*f* (**v** 2,*t*) . (15.44)

$$\frac{\mathrm{dH}(t)}{\mathrm{d}t} = \frac{\sigma^2}{4} \int \mathrm{d}^3 v_1 \int \mathrm{d}^3 v_2 \int \mathrm{d}\Omega \frac{1}{4} \left[ |\mathbf{v}_2 - \mathbf{v}_1| \left| f(\mathbf{v}_2', t) f(\mathbf{v}_1', t) \right. \right. \tag{15.45}$$

$$-f(\mathbf{v}_2, t) f(\mathbf{v}_1, t) \left| \left[ \ln f(\mathbf{v}_1, t) f(\mathbf{v}_2, t) - \ln f(\mathbf{v}_1', t) f(\mathbf{v}_2', t) \right] \right.$$

$$f_0(\mathbf{v}_2')f_0(\mathbf{v}_1') = f_0(\mathbf{v}_2)f_0(\mathbf{v}_1). \tag{15.46}$$

ln *f*0(**v**

2 + 2**vr** · (**v**

2 + **v**

1) = (*v*1)

In Eq. (15.49), the squared terms cancel by conservation of energy, Eq. (15.25), and the terms

the entropy, that can only increase for an isolated system that changes from one state to

2) + ln *f*0(**v**

By taking the logarithm of Eq. (15.46), we obtain

collision.

(**v**

(*v* 1) 2 + (*v* 2)

$$
\ln f_0(\mathbf{v}_2') + \ln f_0(\mathbf{v}_1') = \ln f_0(\mathbf{v}_2) + \ln f_0(\mathbf{v}_1),
\tag{15.47}
$$

1) = ln *f*0(**v**2) + ln *f*0(**v**1), (15.47)

At equilibrium, dH/d*t* = 0 and the distribution functions *f* (**v**,*t*) become independent of time, so we designate them by *f*0(**v**), resulting in the equilibrium condition *f*0(**v** 2)*f*0(**v** 1) = *f*0(**v**2)*f*0(**v**1). (15.46)

which looks like a conservation condition for some property of spheres 1 and 2 before and after collision. It must be related to the conservation of energy and momentum during a

<span id="page-275-0"></span>
$$M(\mathbf{v} - \mathbf{v}_I) = A \exp[- (m/2k_B T)(\mathbf{v} - \mathbf{v}_I)^2]; \quad A = \left[ m/(2\pi k_B T) \right]^{3/2},\tag{15.48}$$

**Example Problem 15.3.** Show that Eq. (15.47) is satisfied by the Maxwell-Boltzmann distri-

bution [functi](#page-275-0)on *M*(**v** − **v***r* ) = *A* exp[−(*m*/2*kBT*)(**v** − **v***r* ) 2]; *A* [=](#page-272-3) [\[](#page-272-3)*m*/(2π*kBT*)] 3/2, (15.48) where **v***r* is some reference velocity. This is a slight generalization of Eq. (19.70) that we derive

$$(v_1')^2 + (v_2')^2 + 2\mathbf{v}_\mathbf{r} \cdot (\mathbf{v}_2' + \mathbf{v}_1') = (v_1)^2 + (v_2)^2 + 2\mathbf{v}_\mathbf{r} \cdot (\mathbf{v}_2 + \mathbf{v}_1). \tag{15.49}$$

2 + 2**vr** · (**v**2 + **v**1). (15.49)

sides and can be canceled. Then we divide both sides by −(*m*/2*kBT*) to obtain (**v** 2 − **v***r* )2 + 1 − **v***r* )2 = (**v**2 − **v***r* )2 + (**v**1 − **v***r* )2. Multiplying out the squares and canceling *v*2 *r* gives

2 + (*v*2)

dotted into **vr** cancel by conservation of momentum, Eq. (15.26). In Boltzmann's day, there were many objections to his Eta theorem on the grounds that the equations of classical mechanics are invariant under time reversal. What was not recognized, however, was that Boltzmann's assumption of molecular chaos, *f* (**v**1, **v**2,*t*) = *f* (**v**1,*t*)*f* (**v**2,*t*), (Stosszahlansatz in German, which literally means collision frequency assumption) was a statistical assumption, not based on mechanics. For a detailed discus-

sion, see [53, p. 20]. The assumption of molecular chaos, not deterministic mechanics, causes the system to evolve to a more probable state. The Eta theorem as presented here should be regarded as a demonstration that for a simple system there is a function −H(*t*), given by the negative of Eq. (15.38), that can only increase in time for an isolated system, which of course would have constant energy. This function has the same characteristics that we ascribe to the thermodynamic function *S*, 256 THERMAL PHYSICS

another. Note also that −H(*t*) has the same structure as the disorder function *D*{*qj*} given by Eq. (15.11). The Eta theorem therefore demonstrates that the assumption of molecular chaos leads to evolution to a more probable state. It is not a substitute for the second law of thermodynamics, for which the entropy of any isolated thermodynamic system is postulated to increase, subject to any internal constraints, until it reaches its maximum possible value at equilibrium. The validity of the second law can be bolstered by statistical analysis of more complex systems, but ultimately rests on agreement with experiments.

16 Microcanonical Ensemble The general approach to statistical mechanics is based on the idea of an **ensemble**. An

ensemble is an imaginary collection of microstates that are compatible with a specified macrostate of a thermodynamic system. A **macrostate** is specified by giving a complete set of *macro*scopic state variables. The number of state variables necessary to constitute a complete set depends on the complexity of the system; usually only a few are necessary. The members (microstates) of the ensemble differ from one another *micro*scopically and are usually extremely large in number, approaching infinity in the thermodynamic limit. Each microstate that makes up an ensemble occurs with a probability that depends on which set of macroscopic state variables are used to specify the macrostate. This

probability is chosen so that the ensemble represents, in a statistical sense, the macrostate. Specifically, the ensemble is chosen such that averages of measurable quantities computed by using it will lead to values representative of the macrostate. Such an approach is necessary in statistical mechanics because specification of a macrostate constitutes incomplete information. We believe that quantum mechanics ultimately governs all systems, even if classical mechanics is a good approximation for some purposes. Therefore, we identify the microstates of a system in equilibrium with a set of **stationary quantum states** of that system. Since we specify a macroscopic system by a small number of state variables, we cannot know the total wave function of the system, which would constitute a specific knowledge of a linear combination (time-dependent) of its stationary states; such a state is called a **pure state**. All we will know for a system in equilibrium is a set of probabilities of its stationary states. We will delay the formal quantum mechanical description of such

quantum systems until Chapter 26 where we introduce density operators and use them to describe pure states and **statistical states**, also known as mixed states. Until then, it will suffice to know only the set of probabilities of the stationary states of an ensemble. A classical system is described by specification of the coordinates and momenta of every particle in the system at some given time. As time evolves, the particles will move and the sy[stem can be imagined to progress th](http://dx.doi.org/10.1016/B978-0-12-803304-3.00016-8)rough other microstates that are compatible with the given set of macroscopic state variables. Clearly there is a continuum of such microstates, which are infinite in number. Therefore, for a classical system it will only be possible to specify a probability density function for a given hypervolume of **phase space** (the space of all coordinates and momenta) since the probability of having a specific

classical microstate would be 0. In the present chapter, we present the microcanonical ensemble which is applicable to an **isolated system** whose macrostate is specified by its total energy and additional exten-

sive macrovariables, such as volume and number of particles, that altogether constitute

of each microstate is 1/-

the temperature.

<span id="page-278-2"></span><span id="page-278-1"></span>.

258 THERMAL PHYSICS

### a complete set. This ensemble is of fundamental theoretical importance but its practic[al](#page-278-0) usefulness is limited because of the complexity of computations required to enumerate

the microstates. In later chapters, we will introduce other more useful ensembles such as the canonical ensemble, where temperature instead of energy is specified, and the grand canonical ensemble where temperature instead of energy and chemical potential instead of particle number are specified. 16.1 Fundamental Hypothesis of Statistical Mechanics For an isolated thermodynamical system, we consider all **microstates** compatible with a **macrostate**. For the sake of illustration, we will specify this macrostate by its total energy1 *E*, its volume *V*, and its number of particles *N* ; more complex systems can be treated by adding additional extensive state variables, specifying subsystems, etc. We consider our system to be governed by quantum mechanics and therefore associate each microstate

with a stationary quantum state for the given quantities *E*, *V*, *N* . Since our system is macroscopic, the difference between *E* and the energy levels of one of its particles is very large compared to the differences among the energy levels of a particle. Thus, there is massive degeneracy and hence a huge number of microstates for each macrostate. This ensemble is usually referred to as the **microcanonical ensemble**.

The **fundamental hypothesis** is that every microstate of an isolated thermodynamic system that is compatible with a given macrostate of such a system is *equally probable*. If -

$$
\langle \mathbf{y} \rangle = (1/\Omega) \sum_{\nu=1}^{\Omega} \mathbf{y}_{\nu} \tag{16.1}
$$

system is given by *y* = (1/-)- - *y*ν , (16.1)

$$S = k_{\mathbb{B}} \ln \mathfrak{Q},\tag{16.2}$$

<span id="page-278-0"></span>system is defined to be *S* = *k*B ln -, (16.2) where *k*B is Boltzmann's constant. Equation (16.2) is exactly the function given by Eq. (15.14) that was based on the disorder function *D*{*pi*} for the case *pi* = 1/-. The

classical counterpart to Eq. (16.2) was proposed by Boltzmann and will be discussed in the next chapter. Since *S* is a monotonically increasing function of -, maximizing is consistent with

the second law of thermodynamics, according to which *S* for an isolated system will be a 1This is the total internal energy of the system which excludes macroscopic kinetic energy associated with motion of the center of mass. Here, we use the symbol *E* instead of *U* to make a subtle distinction because we *specify* the energy rather than calculating its average value from a knowledge of other state variables, for example,

*Chapter 16* • Microcanonical Ensemble 259 maximum at equilibrium, with respect to variations of its internal extensive parameters and subject to any internal constraints. To better illustrate what this means, we consider a

$$\mathcal{S} = k_{\mathcal{B}} \ln \mathfrak{Q} = k_{\mathcal{B}} \ln(\mathfrak{Q}_1 \mathfrak{Q}_2) = k_{\mathcal{B}} \ln(\mathfrak{Q}_1) + k_{\mathcal{B}} \ln(\mathfrak{Q}_2) = \mathcal{S}_1 + \mathcal{S}_2. \tag{16.3}$$

<span id="page-279-0"></span>weakly interacting and statistically independent so that - = -1(*E*1, *V*1, *N*1)-2(*E*2, *V*2, *N*2), where the total quantities *E* = *E*1+*E*2, *V* = *V*1+*V*2, and *N* = *N*1+*N*2. So even with *E*, *V*, and

*N* held constant, -

-

$$\frac{\partial \ln \Omega}{\partial E_1} = \frac{1}{\Omega_1} \frac{\partial \Omega_1}{\partial E_1} + \frac{1}{\Omega_2} \frac{\partial \Omega_2}{\partial E_2} \frac{\partial E_2}{\partial E_1} = \frac{1}{\Omega_1} \frac{\partial \Omega_1}{\partial E_1} - \frac{1}{\Omega_2} \frac{\partial \Omega_2}{\partial E_2} = 0. \tag{16.4}$$

*S* = *k*B ln - = *k*B ln(-1-2) = *k*B ln(-1) + *k*B ln(-2) = *S*1 + *S*2. (16.3) With *E*, *V*, *N* , *V*1, and *N*1 held constant, maximizing ln with respect to *E*1 gives ∂ ln- ∂*E*1 = 1 -1 ∂-1 ∂*E*1 + 1 -2 ∂-2 ∂*E*2 ∂*E*2 ∂*E*1 = 1 -1 ∂-1 ∂*E*1 − 1 -2 ∂-2 ∂*E*2 = 0. (16.4) But (1/-1)∂-1/∂*E*1 = (1/*k*B)∂*S*1/∂*E*1 = *T*1/*k*B and similarly (1/-2)∂-2/∂*E*2 = *T*2/*k*B, so Eq. (16.4) is equivalent to equality of absolute temperature, *T*1 = *T*2. Similarly, maximizing

with respect to *V*1 gives equality of pressure, and maximizing with respect to *N*1 gives equality of chemical potential. If a system cannot be decomposed into statistically independent subsystems, will not factor and it will be difficult to enumerate the microstates, but the maximization of and hence *S* will still be a valid criterion for equilibrium. The considerations of the preceding paragraph are still valid if the two subsystems are actually portions of the same system that are initially isolated from one another by constraints that forbid exchange of energy, volume, and mole numbers. Then = - (*E* , *V* , *N* )-(*E* , *V* , *N* ). As these constraints are gradually relaxed, each [subsy](#page-278-1)stem can proceed through a series of equilibrium states until - = - is maximized. We can therefore say that is proportional to the probability of a macrostate. The quantity 1/ is the probability of each microstate of the ensemble that represents that macrostate. For further support that is proportional to the probability of a macrostate, the reader is referred to Section 19.1.3 in which the number of ways *W*ens of constructing an ensemble from members, each of which is in a single eigenstate *i*, is related to the probability *Pi* of occurrence of that eigenstate in the ensemble. If every member of the ensemble has the *same* energy, as it would for the microcanonical ensemble, *W*ens will be a maximum when all probabilities are equal. See also Chapter 22 where the entropy of any ensemble is discussed in terms of maximizing a probability. Moreover, since *S* given by Eq. (16.2) is proportional to the maximum value of the disorder function *D*{*qi*} given by Eq. (15.11), a macrostate of maximum entropy, and hence maximum -, is a state of maximum disorder, equivalent to a state with minimum information content, compatible with

constraints. In some books on statistical mechanics, there is an attempt to justify the fundamental assumption of equal probability of each compatible microstate from other considerations.

tractable.

particles. See Section 16.4 for further details.

260 THERMAL PHYSICS

$$
\bar{\mathbf{y}} = \frac{1}{\pi} \int_0^\pi \mathbf{y}(t) \,\mathrm{d}t.\tag{16.5}
$$

<span id="page-280-0"></span>every allowed volume of phase space with equal probability. This is sometimes called the **ergodic hypothesis**. The quantum analog would be to assume t[hat](#page-280-0) [e](#page-280-0)very microstate is

$$
\langle \mathbf{y} \rangle = \mathbf{\bar{y}} \tag{16.6}
$$

is given by a time average of the form *y*¯ = 1 τ τ 0 *y*(*t*) d*t*. (16.5) Thus, the time average would be equal to the ensemble average, that is, *y* = *y*¯ (16.6)

for a system in equilibrium. In this book, we shall assume that Eq. (16.6) is true. In the last analysis, Eqs. (16.1), (16.2), and (16.6) are hypotheses that have borne up under the test of experiment. In Chapter 26, we introduce the statistical density operator and give a more detailed discussion of ensemble averages and time averages in the context of quantum mechanics. Under conditions for which a macros[co](#page-280-1)pic system can be described approximately by a set of *N* particles that obey classical mechanics, we do not have access to the concept of stationary quantum states. As discussed in the next chapter, we take to be proportional to the volume of phase space (volume of momentum space times volume of actual space) in a thin shell near a hypersurface that corresponds to the total energy, *E*. It turns out that the volume of the shell itself is not important. Indeed, isolation of a system is only an idealization and therefore an approximation, so there will always be a small uncertainty in its energy. Landau and Lifshitz [7] refer to such systems as being quasi-isolated. Nevertheless, to agree ultimately with quantum mechanics, it is necessary

<span id="page-280-1"></span>to assume that the number of microstates in a volume element (d*p* d*q*)3*N* is given by (d*p* d*q*/*h*)3*N* where *h* is Planck's constant.2 This is an artificial prescription that has no real basis in classical mechanics, for which Planck's constant is effectively 0. The microcanonical ensemble is easy to define but very hard to use because of the difficulty in cataloging and enumerating the microstates that are compatible with specificati[on of the m](#page-287-0)acrostate. For simple systems this is possible, as we shall illustrate for two-state subsystems, simple harmonic oscillators and ideal gases. The main value of the microcanonical ensemble is its theoretical importance, and we shall use it later to

derive the canonical ensemble and the grand canonical ensemble which are much more

<sup>2</sup>This result holds for **identical but distinguishable particles**. For an ideal gas, the number of microstates is approximately (d*p* d*q*/*h*)3*N* (1/*N* !) at high temperature and low density. The extra Gibbs factor of 1/*N* ! is needed to make the entropy an extensive function and follows from quantum mechanics for identical indistinguishable

(its degeneracy) is

s[maller.](#page-282-0)

*M* = *E*/ε must be regarded as an extensive quantity.

*Chapter 16* • Microcanonical Ensemble 261 16.2 Two-State Subsystems We consider a system consisting of *N* subsystems (particles) fixed in a solid, each having

two quantum states that correspond to nondegenerate energy levels, 0 and ε. The particles are assumed to be identical except for their locations (their positions in the solid) which makes them distinguishable. We might think of each particle as a quantum system having spin 1/2 under conditions for which the two states "spin up" and "spin down" have

$$\mathfrak{\Omega}(\mathcal{N}, E) = \frac{\mathcal{N}!}{(\mathcal{N} - \mathcal{M})! \mathcal{M}!} = \mathbf{g}(\mathcal{N}, \mathcal{M}).\tag{16.7}$$

sufficient to enable them to come to equilibrium with one another. If we consider a quantum state of the system in which *M* particles are in the state with

$$S = k_{\rm B} \ln \Omega = k_{\rm B} (\ln \mathcal{N}! - \ln(\mathcal{N} - \mathcal{M})! - \ln \mathcal{M}!). \tag{16.8}$$

-(*N* , *E*) = *N* ! = *g*(*N* ,*M*). (16.7)

<span id="page-281-2"></span><span id="page-281-0"></span>
$$\mathcal{S} \sim k_{\rm B} [\mathcal{N} \ln \mathcal{N} - (\mathcal{N} - \mathcal{M}) \ln(\mathcal{N} - \mathcal{M}) - \mathcal{M} \ln \mathcal{M}].\tag{16.9}$$

The quantity *g*(*N* ,*M*) is sometimes call[ed the](#page-281-0) **multiplicity function**. Thus *S* = *k*B ln - = *k*B[ln *N* ! − ln(*N* − *M*)! − ln*M*!]. (16.8) By using the first two terms in Stirling's approximation in the form of Eq. (A.1), we obtain *S* ∼ *k*B[*N* ln *N* − (*N* − *M*)ln(*[N](#page-281-1)* − *M*) − *M*ln*M*]. [(16.9)](#page-281-2)

Note that the second term in Stirling's approximation (see Appendix A) makes no contribution to this result because of an exact cancellation. Other terms in Stirling's approxim[ation](#page-281-0)

$$\mathcal{S} = -\mathcal{N}k_{\mathbb{B}}\mathbb{I}(1 - \mathcal{M}/N)\ln(1 - \mathcal{M}/N) + (\mathcal{M}/N)\ln(\mathcal{M}/N)\mathbb{I},\tag{16.10}$$

To see that the entropy given by Eq. (16.9) is an extensive function, we can write it in the form *S* = −*N k*B[(1 − *M*/*N* )ln(1 − *M*/*N* ) + (*M*/*N* )ln(*M*/*N* )], (16.10) in which the substitution *M*= *E*/ε yields the fundamental equation, *S*(*E*, *N* ), of the system. The ratios *M*/*N* = *E*/(ε*N* ) are intensive3 variables, so the form of Eq. (16.10) shows it to be the product of an extensive quantity *N* and an intensive quantity in square

<span id="page-281-1"></span>brackets, which shows explicitly that *S* is extensive. This is not apparent from Eq. (16.9) because expressions such as *N* ln *N* are not extensive. Figure 16–1 shows a plot of *S*/(*N k*B) versus *M*/*N* . For convenience we show a continuous curve, although only integer values of *M* are allowed. This is justified because *N* is very large, perhaps of order 1020, so changes of *M*/*N* are of order 10−20 as *M* changes by unity. We observe that the curve is symmetric about its maximum, which occurs at

*M*/*N* = 1/2. It has a positive slope for *M*/*N* ≤ 1/2, zero slope for *M*= 1/2, and a negative 3We know that Stirling's approximation is only valid for large numbers, so one might worry about small values of *M*. However, only values of *M* that are comparable to *N* 1 will lead to significant results. Therefore,

<span id="page-282-0"></span>262 THERMAL PHYSICS

solved to yield

<span id="page-282-1"></span>0.1

*N*

*M*/*N* < 1/2. See Figure 16–3 for better resolution of the shape near *T* = 0.

populations of states having high energies are greater than those having lower energies.

kBT/ε

![](_page_282_Figure_1.jpeg)

0.2 0.3 0.4 S/(*N*kB)

0.2 0.4 0.6 0.8 1 *M*/*N* **FIGURE 16–1** Dimensionless entropy *S*/(*N k*B) versus dimensionless energy *M*/*N* = *E*/(*N* ε) for a two-state system according to Eq. (16.10). The portion of the curve for *M*/*N* > 1/2 corresponds to negative temperatures, which do not represent equilibrium states in thermodynamics.

slope for *M*/*N* > 1/2. As we shall see subsequently, this slope is proporti[onal](#page-282-1) [to](#page-282-1) 1/*T* so

$$\frac{1}{T} = \left(\frac{\partial S}{\partial E}\right)_{\mathcal{N}} = k_{\mathbb{B}} \frac{\mathrm{d}\mathcal{M}}{\mathrm{d}E} \left(\frac{\partial \ln \mathrm{g}}{\partial \mathcal{M}}\right)_{\mathcal{N}} = -\frac{k_{\mathbb{B}}}{\varepsilon} \ln \left(\frac{\mathcal{M}/\mathcal{N}}{1 - \mathcal{M}/\mathcal{N}}\right). \tag{16.11}$$

Since *M* is a nearly continuous variable, we can calculate the absolute temperature as a derivative, 1 *T* = ∂*S* ∂*E* = *k*B d*M* d*E* ∂ ln *g* ∂*M* = −*k*B ε ln *M*/*N* 1 − *M*/*N* . (16.11)

*N*

![](_page_282_Figure_7.jpeg)

*M*/*N* **FIGURE 16–2** Dimensionless temperature *k*B*T*/ε versus dimensionless energy *M*/*N* = *E*/(*N* ε) for a two-state system according to Eq. (16.11). Only positive values of *T* are thermodynamically significant and these correspond to

4Fictitious negative temperatures are sometimes used to characterize nonequilibrium states in which the

<span id="page-283-1"></span>
$$p_1 \coloneqq \frac{\mathcal{M}}{\mathcal{N}} = \frac{\exp(-\varepsilon/k\mathbb{B}\,T)}{1 + \exp(-\varepsilon/k\mathbb{B}\,T)}\tag{16.12}$$

<span id="page-283-2"></span>
$$p_0 \coloneqq \frac{\mathcal{N} - \mathcal{M}}{\mathcal{N}} = 1 - p_1 = \frac{1}{1 + \exp(-\varepsilon/k_\mathcal{B}T)}.\tag{16.13}$$

*p*1 := *M N* = exp(−ε/*k*B*T*) 1 + exp(−ε/*k*B*T*) (16.12) for the probability *p*1 of occupation of the state ε. The probability of occupation of the ground state is *p*0 := *N* − *M N* = 1 − *p*1 = 1 1 + exp(−ε/*k*B*T*) . (16.13) The quantity exp(−ε/*k*B*T*) is called a **Boltzmann factor**; it is very small for low temper-

atures and nearly equal to 1 at very high temperatures. Thus, at very high temperatures, *p*0 = *p*1 = 1/2 and the levels have equal population, a condition known as **[equipartiti](#page-283-0)on**.

$$E = \mathcal{N}\varepsilon \frac{\exp(-\varepsilon/k_{\rm B}T)}{1 + \exp(-\varepsilon/k_{\rm B}T)}.\tag{16.14}$$

might take place in a laser. Substitution of *M* = *E*/ε into E[q. (16.12) give](#page-284-0)s the energy5 of the system as a function of temperature, namely

$$\mathcal{S} = -\mathcal{N}k_{\mathcal{B}}(p_0 \ln p_0 + p_1 \ln p_1). \tag{16.15}$$

<span id="page-283-0"></span>As *T* increases from 0, the energy increases from 0 to *N* ε/2, as shown in Figure 16–3. An expression for the entropy as a function of temperature can be obtained by substitution of Eqs. (16.12) and (16.13) into Eq. (16.10) to obtain *S* = −*N k*B(*p*0 ln *p*0 + *p*1 ln *p*1). (16.15)

![](_page_283_Figure_10.jpeg)

E/(*N*ε)

populated so that the average energy per particle is ε/2.

total energy *E* would contain an additional term *N* ε0.

0.5 1 1.5 2 2.5 3 3.5 4 kBT/ε **FIGURE 16–3** Dimensionless energy *E*/(*N* ε) versus dimensionless temperature *k*B*T*/ε for a two-state system according to Eq. (16.14). At *T* = 0, all particles are in the ground state. As *T* → ∞, the states become equally

5If the ground state of the particle had been at energy ε0, its excited state would have energy ε0 + ε and the

<span id="page-284-0"></span>264 THERMAL PHYSICS

0.1

![](_page_284_Figure_1.jpeg)

0.2 0.3 0.4 S/(*N*kB)

1 2 3 4

kBT/ε **FIGURE 16–4** Dimensionless entropy *S*/(*N k*B) versus dimensionless temperature *k*B*T*/ε for a two-state system according to Eq. (16.15). At *T* = 0, all particles are in the ground state and *S* = 0. As *T* → ∞, the states become equally populated so *S*/(*N k*B) → ln 2 = 0.693. The case of two-state subsystems is sufficiently simple that one can calculate explicitly the relationship between the multiplicity functions of two subsystems and the multiplicity function of the combined system that results when these subsystems are combined and come to thermal equilibrium. In their book *Thermal Physics* [6], Kittel and Kroemer show that the multiplicity function for a spin system is highly peaked about the value *s* = 0 where *s* = *N* /2 −*M* is called the **spin excess** of the ground state. Thus, 2*s* is the number of spins in the ground state ("spin up") minus the number of spins in the state having higher energy ("spin down"). When two spin subsystems are combined and come to thermal equilibrium, the combined system will have a multiplicity function that depends on the narrow region of overlap between the high peaks of the subsystems. We follow

combined. **Example Problem 16.1.** Consider an isolated system having energy *E* and consisting of *N* identical but distinguishable subsystems, each having two energy levels that are degenerate. One level has energy 0 and degeneracy *d*0 and the other level has energy ε and degeneracy *d*1.

Kittel and Kroemer and carry out this calculation in more detail in Appendix D where we also demonstrate explicitly the additivity of entropy when two such systems are

(*N* − *M*)!*M*!

*S*/*k*B = *N* ln *N* − (*N* − *M*)ln(*N* − *M*) − *M*ln*M* + (*N* − *M*)ln *d*0 + *M*ln *d*1. (16.17)

Use the microcanonical ensemble to compute the entropy of this system and then compute its temperature and the probability of occupation of the level with energy ε.

(*N* − *M*)

$$
\Omega_d(\mathcal{N}, E) = \frac{\mathcal{N}!}{(\mathcal{N} - \mathcal{M})! \mathcal{M}!} (\mathcal{N} - \mathcal{M})^{d_0} (\mathcal{M})^{d_1}.\tag{16.16}
$$

**Thus the contour is given by

-

multiplicity function is

$$\mathcal{S}/\text{k}_{\mathbb{B}} = \mathcal{N}\ln\mathcal{N} - (\mathcal{N} - \mathcal{M})\ln(\mathcal{N} - \mathcal{M}) - \mathcal{M}\ln\mathcal{M} + (\mathcal{N} - \mathcal{M})\ln d_{0} + \mathcal{M}\ln d_{1}.\tag{16.17}$$

$$\frac{1}{k_{\rm B}T} = \frac{\partial \Omega_d}{\partial E} = \frac{1}{\varepsilon} \ln \left[ \frac{(\mathcal{N} - \mathcal{M})d\mathbb{0}}{\mathcal{M}d_1} \right],\tag{16.18}$$

1 *k*B*T* = ∂-

*d* ∂*E* = 1

$$\frac{\mathcal{M}}{\mathcal{N}} = \frac{d_1 \exp(-\varepsilon/k_\mathcal{B}T)}{d_0 + d_1 \exp(-\varepsilon/k_\mathcal{B}T)}.\tag{16.19}$$

, (16.18)

. (16.19)

The temperature is given by

(*N* − *M*)*d*0 *Md*1

ε ln

### which can be solved for *M* to give the req[uir](#page-285-0)ed probability *M N* = *d*1 exp(−ε/*k*B*T*)

*d*0 + *d*1 exp(−ε/*k*B*T*) The form of this result can be understood by using the canonical ensemble, Chapter 19. 16.3 Harmonic Oscillators We consider a system of *N* harmonic oscillators, each fixed in a solid and having an infinite number of nondegenerate energy levels6 ε*n* = *n*ε = *nh*¯ ω where the integer *n* = 0, 1, 2, ... . The symbol *h*¯ = *h*/2π, where *h* = 6.626069 × 10−34 J s is Planck's constant, is pronounced

<span id="page-285-1"></span>"h-bar" and appears frequently in the equations of quantum mechanics. It has the value *h*¯ = 1.054572 × 10−34 J s = 1.054572 × 10−27 erg s. A useful related constant is *h*¯ /*kB* = 7.638234 K s. See http://physics.nist.gov/cuu/constants for the latest internationally recommended values of physical constants. We consider a macrostate of the system having total energy *E* =*M*ε and denote the multiplicity function for this state by *gH*(*N* ,*M*). We can calculate *gH* by means of the following device illustrated in Figure 16–5. Between fixed ends of a box, we place *N* −1 movable partitions. These partitions divide the

$$\Omega(\mathcal{N}, E) = \frac{(\mathcal{N} - 1 + \mathcal{M})!}{(\mathcal{N} - 1)!\mathcal{M}!} = \mathbf{g}_{\mathcal{H}}(\mathcal{N}, \mathcal{M}).\tag{16.20}$$

![](_page_285_Figure_10.jpeg)

number of distinct arrangements of the X symbols and the movable partitions, namely

the X symbols and the movable partitions, namely 27!/(15! 12!) = 17,383,860.

<span id="page-285-0"></span>end end XXXXXXXXXXXX **FIGURE 16–5** Diagram illustrating an algorithm for calculating the multiplicity function for the harmonic oscillator. Between fixed ends of a box (long lines) we place *N* −1 = 15 movable partitions (short lines). These partitions divide the box into *N* = 16 intervals, each representing a particle. The number of X symbols in an interval designates the energy of that particle in units of ε. The total energy is *E* = *M*ε = 12ε, where *M* = 12 is the number of X symbols. As shown, there are eight particles with energy 0, five particles with energy ε, two particles with energy 2ε, and one particle with energy 3ε. The multiplicity function *gH*(*N* ,*M*) = *gH*(16, 12) is the number of distinct arrangements of

6We omit the zero point energy *h*¯ω/2 for simplicity since it only shifts the overall energy by *Nh*¯ω/2.

<span id="page-286-1"></span>
$$\mathbf{S} = k_{\rm B} \ln \mathbf{g}_{H}(\mathcal{N}, \mathcal{M}); \quad \mathcal{M} = E/\mathfrak{s}. \tag{16.21}$$

266 THERMAL PHYSICS

Therefore,

$$S = k \boxtimes [\ln(\mathcal{N} - 1 + \mathcal{M})! - \ln(\mathcal{N} - 1)! - \mathcal{M} \ln \mathcal{M}!].\tag{16.22}$$

This same result can be derived by using a generating function, as shown below in Section 16.3.1. For a thermodynamic system consisting of *N* harmonic oscillators, the entropy will be

$$\mathcal{S} \sim k_{\rm B} [(\mathcal{N} + \mathcal{M}) \ln(\mathcal{N} + \mathcal{M}) - \mathcal{N} \ln \mathcal{N} - \mathcal{M} \ln \mathcal{M}]$$

$$= -\mathcal{N} k_{\rm B} \left[ \frac{\mathcal{M}}{\mathcal{N}} \ln \frac{\mathcal{M}}{\mathcal{N} + \mathcal{M}} + \ln \frac{\mathcal{N}}{\mathcal{N} + \mathcal{M}} \right],\tag{16.23}$$

Again we use Stirling's approximation and consistent with this we approximate *N* −1 ≈ *N*

1 *T* =  ∂*S* ∂*E N*

and smaller relative to *N* . It would be inconsistent to keep 1 relative to *N* .

to obtain7

*M*

<span id="page-286-0"></span>
$$\frac{1}{T} = \left(\frac{\partial \mathcal{S}}{\partial E}\right)_{\mathcal{N}} = \frac{\partial \mathcal{M}}{\partial E} \left(\frac{\partial \mathcal{S}}{\partial \mathcal{M}}\right)_{\mathcal{N}} = \frac{k_{\mathcal{B}}}{\varepsilon} \ln \frac{\mathcal{N} + \mathcal{M}}{\mathcal{M}},\tag{16.24}$$

where the second form demonstrates that *S* is extensive. Thus the absolute temperature can be calculated from

$$\frac{\mathcal{M}}{\mathcal{N}} = \frac{1}{\exp(\varepsilon/k_{\mathbb{B}}T) - 1},\tag{16.25}$$

where we have used the first form of Eq. (16.23) to ease calculation of the derivative with respect to *M*. Hence, Eq. (16.24) yields

$$E = \mathcal{N}s \, \frac{1}{\exp(\varepsilon/k_{\rm B}T) - 1}. \tag{16.26}$$

or equivalently *E* = *N* ε 1 . (16.26)

$$
\langle n(T) \rangle \coloneqq \frac{\mathcal{M}}{\mathcal{N}} = \frac{1}{\exp(\varepsilon/k\mathbb{B}T) - 1}. \tag{16.27}
$$

oscillator, the average quantum number of an oscillator is given by *n*(*T*):= *M N* = 1 exp(ε/*k*B*T*) − 1 . (16.27) As *T* increases from 0, *n* increases very slowly and tends to the value *k*B*T*/ε as *T* becomes large. Since a given oscillator has an infinite number of states, both *n* and *E* continue to increase linearly with *T* at large *T*. In fact, *E* ≈ *N k*B*T* independent of ε for large *T*. This is

consistent with the fact that the average thermal energy of a classical harmonic oscillator is independent of its oscillation frequency, as will be seen later.

$$S = -\mathcal{N}k_{\mathbb{B}}\left[\ln\left(\frac{1}{1+\langle n\rangle}\right) + \langle n\rangle \ln\left(\frac{\langle n\rangle}{1+\langle n\rangle}\right)\right].\tag{16.28}$$

1 + *n* 1 + *n* 7By using Stirling's approximation, we are already assuming that *N* 1 and dropping terms of order ln *N*

$$S = -\mathcal{N}k_{\rm B} \left[ \ln(1 - \mathbf{e}^{-\mathbf{x}}) - \frac{\mathbf{x} \,\mathbf{e}^{-\mathbf{x}}}{(1 - \mathbf{e}^{-\mathbf{x}})} \right],\tag{16.29}$$

*Chapter 16* • Microcanonical Ensemble 267

$$\mathcal{S} \approx \mathcal{N}k\mathbb{B}\left[-\ln\mathfrak{x} + 1\right] = \mathcal{N}k\mathbb{B}\left[\ln(k\mathfrak{x}T/\mathfrak{s}) + 1\right].\tag{16.30}$$

This expression can also be written in the form *S* = −*N k*B ln(1 − e−*x*) − *x* e−*x* (1 − e−*x*) , (16.29)

where *x* = ε/*k*B*T*. As *T* increases from 0, *S* increases slowly from 0. For large *T*, *x* becomes

 = *N k*B 

### ver[y small](#page-285-1) and we can expand Eq. (16.29) to obtain *S* ≈ *N k*B −ln *x* + 1

⎛ ⎝-∞

*j*=0 *tj* ⎞ ⎠ *N*

Thus, due to the availability of an infinite number of energy levels of a given oscillator, the entropy continues to increase with *T*. See Section 18.3 for an alternative derivation and relevant graphs.

ln(*k*B*T*/ε) + 1

$$\left(\sum_{j=0}^{\infty} t^j\right)^{\mathcal{N}} = (1 + t + t^2 + \dotsb)^{\mathcal{N}} = \sum_{\mathcal{M}} \mathbf{g} \boldsymbol{\mu}(\mathcal{N}, \mathcal{M}) t^{\mathcal{M}}.\tag{16.31}$$
 
$$\mathbf{p} \dots$$

 

**Lunt.**

$$\sum_{j=0}^{\infty} t^j = \frac{1}{1-t},\tag{16.32}$$

. (16.30)

But

$$\log_H(\mathcal{N}, \mathcal{M}) = \frac{1}{\mathcal{M}!} \left(\frac{\mathbf{d}}{\mathbf{d}t}\right)^{\mathcal{M}} \left(\frac{1}{1-t}\right)^{\mathcal{N}} \Bigg|_{t=0} . \tag{16.33}$$

so we have

<span id="page-287-0"></span>*gH* (*N* ,*M*) = 1 *M*! d d*t M* 1 1 − *t N t*=0 . (16.33) Carrying out the required differentiation and evaluation at *t* = 0 readily yields Eq. (16.20). In principle, this method can also be used for subsystems having any finite number of states equally spaced in energy, but the results can be cumbersome. Thus, for two-state subsystems one could find the coefficient of *tM* in the expansion of (1 + *t*)*N* which would

lead immediately to Eq. (16.7). For subsystems with three equally spaced states, one would

of volume *V* that they *share*. Therefore, our macroscopic view of the system precludes

# require the coefficient of *tM* in the expansion of (1 + *t* + *t*2)*N* .

16.4 Ideal Gas The monatomic ideal gas is a tractable example of a system of **identical indistinguishable particles** that can be treated by means of the microcanonical ensemble. It is especially important because it serves as a link between quantum statistical mechanics and classical statistical mechanics, as we shall see in Chapter 17. Atoms of the gas are confined to a box

268 THERMAL PHYSICS knowledge of which atoms occupy any particular sub-volume of the box. This is quite different from the case of identical particles in a solid that are essentially immobile and may be distinguished by virtue of their position. An important advance in proper counting of such microstates was made by Gibbs in the context of classical statistical mechanics. For a monatomic gas of *N* particles, Gibbs reasoned that one should divide the volume of phase space occupied by the particles by *N* ! to correct for the fact that there are *N* ! permutations of the particles that do not lead to states of the system that can be distinguished macroscopically. Without this division by *N* !, the calculated entropy is not an extensive function, so it is surely incorrect and leads to an inconsistency known as the **Gibbs paradox**. 8 As we shall see, we can readily count the states of *N* free quantum particles in a box as if the particles were distinguishable. If we use the Gibbs correction factor of 1/*N* ! to correct this count, we obtain an entropy that is extensive. This is satisfying and gives a good result for an ideal gas at high temperatures and low density. It is, however, not a correct quantum mechanical result under other conditions. To get a correct quantum mechanical result, one must construct a total wave function of the gas that is either an antisymmetric or a symmetric function on

### number densities. We defer detailed treatment of such quantum statistical effects until Section 26.7. Here, we give only an approximate treatment based on the Gibbs correction

**k** = 2π

process that is clearly reversible. See Pathria [8, p. 22] for details.

*V*1/3 [*nx* ˆ

**i** + *ny* ˆ

interchange of any two particles, depending on whether they are fermions or bosons, respectively. This will result in corrections that are important at low temperatures and high

factor. 16.4.1 Monatomic Ideal Gas with Gibbs Correction Factor We give a pseudo-quantum mechanical treatment of a monatomic ideal gas, including the

$$
\psi_{\mathbf{k}}(\mathbf{r}) = V^{-1/2} \exp(i\mathbf{k} \cdot \mathbf{r}),
\tag{16.34}
$$

of volume *V*, the wave function is

$$
\hat{\mathcal{H}}\psi\mathbf{k} = s\mathbf{k}\psi\mathbf{k}\tag{16.35}
$$

which satisfies *H*ˆ ψ**k** = ε**k**ψ**k** (16.35)

$$\mathbf{k} = \frac{2\pi}{V^{1/3}} [n_x \hat{\mathbf{i}} + n_y \hat{\mathbf{j}} + n_z \hat{\mathbf{k}}],\tag{16.36}$$

**k**], (16.36)

8According to the Gibbs paradox, the additional entropy from mixing identical gases, each having the same temperature and pressure as the final mixture, turns out to be positive rather than zero, as it should be for a

**j** + *nz* ˆ

<span id="page-289-0"></span>
$$n_x^2 + n_y^2 + n_z^2 = 2ms\,\,V^{2/3}/h^2.\tag{16.37}$$

*Chapter 16* • Microcanonical Ensemble 269 where ˆ **i**, ˆ **j**, ˆ **k** are the Cartesian unit vectors and *nx*, *ny*, *nz* are positive and negative integers

*n*2

within

$$\sum_{r=1}^{3N} n_r^2 = 2mE \, V^{2/3} / h^2 = R^2,\tag{16.38}$$

The total energy *E* will be the sum of the energies of the individual particles because particles of an ideal gas do not, by definition, have an interaction energy. The number of quantum states for *N distinguishable* particles is therefore equal to the number of allowed solutions to9 - 3*N r*=1 *n*2 *r* = 2*mE V*2/3/*h*2 = *R*[2,](#page-289-0) (16.38)

where *R* := (2*mE V*2/3/*h*2)1/2 is the dimensionless radius of a hypersphere in 3*N* dimensional space. Allowed solutions are those for which each *nr* is a positive or negative integer or zero. Of course no such solutions exist unless *R*2 is an integer, but to circumvent this technicality we shall actually count solutions in a thin shell corresponding to energies between *E* − *E* and *E*, or equivalently between *R* − *R* and *R*, where *R*/*R* ≈ *E*/(2*E*).

$$V_R = \frac{\pi^{3N/2}}{(3N/2)!} R^{3N} = V^N \frac{(mE/2\pi\hbar^2)^{3N/2}}{(3N/2)!}.\tag{16.39}$$

3*N* of the space. A simple derivation is given by Pathria [8, p. 504] and results in *VR* = π[3](#page-289-0)*N*/2 (3*N* /2)! *R*3*N* = *V N* (*mE*/2π*h*¯ 2)3*N*/2 (3*N* /2)! . (16.39) Here, (3*N* /2)! should be interpreted as the gamma function (3*N* /2 + 1) in case *N* is an

$$\mathcal{F} \coloneqq 1 - \left(1 - \frac{\Delta R}{R}\right)^{3N} \approx 1 - \exp(-3N\Delta R/R) \approx 1 - \exp(-3N\Delta E/2E). \tag{16.40}$$

*F* := 1 − 1 − *R* 3*N*

0 = *FVR* = [1 − exp(−3*N*

*R*

-

the count of the number of microstates.

$$
\Omega_0 = \mathcal{F}V_R = \left[1 - \exp(-3\mathcal{N}\Delta E/2E)\right]V_R \approx V_R.\tag{16.41}
$$

*E*/2*E*)]*VR* ≈ *VR*. (16.41)

<span id="page-289-2"></span><span id="page-289-1"></span>*E*/2*E*). (16.40)

9To simplify the notation, for particle number 1 we let *nx* = *n*1, *ny* = *n*2, *nz* = *n*3 and for particle number 2 we let *nx* = *n*4, *ny* = *n*5, *nz* = *n*6, etc. The wave function of the whole system can be made up of products of the wave functions of the individual particles, consistent with the additivity of particle energies. Nevertheless, true quantum mechanical considerations also restrict the symmetry of the wave function under an interchange of identical particles, which is discussed in detail in Section 26.7. Here, in the spirit of treating a classical ideal gas, we omit that complication but make up for it by using the Gibbs factor *N* ! in Eq. (16.44) to correct approximately

Thus,10

$$
\ln \Omega \mathfrak{a} = \ln V \mathfrak{a} + \ln(1 - \exp(-3\mathcal{N}\Delta E/2E)) \approx \ln V \mathfrak{a} - \exp(-3\mathcal{N}\Delta E/2E).\tag{16.42}
$$

270 THERMAL PHYSICS

$$
\ln \Omega_0 \approx \ln V_R \sim \mathcal{N} \ln \left\{ V \left( \frac{mE}{3\pi \hbar^2 \mathcal{N}} \right)^{3/2} \right\} + \frac{3}{2} \mathcal{N}, \tag{16.43}
$$

ln-0 = ln *VR* + ln[1 − exp(−3*N E*/2*E*)] ≈ ln *VR* − exp(−3*N E*/2*E*). (16.42) The second term is clearly negligible, so substitution of Eq. (16.39) and use of Stirling's approximation gives

ln-0 ≈ ln *VR* ∼ *N* ln *V mE* 3π*h*¯ 2*N* 3/2 + 3 2 *N* , (16.43) essentially independent of any reasonable choice for *E*. As shown in the following example and elsewhere [8, p. 17], this result is the same as would be obtained for wave functions that vanish on the walls of the box. One might be tempted to equate the entropy to *k*B ln -0 but that would be incorrect

$$
\Omega \approx \frac{\Omega_0}{N!} = V^N \frac{(mE/2\pi\hbar^2)^{3N/2}}{N!(3N/2)!}.\tag{16.44}
$$

<span id="page-290-1"></span><span id="page-290-0"></span>0 by the number of

no way of distinguishing the particles. We follow Gibbs and divide -

Thus

because ln -

$$\mathbf{S} = k \mathbf{\bar{n}} \ln \mathfrak{Q} \approx k \mathbf{\bar{g}} [\ln \mathfrak{Q} \mathbf{o} - \mathcal{N} \ln \mathcal{N} + \mathcal{N}] \tag{16.45}$$

- ≈ [-](#page-290-0)0 *N* ! = *V N* (*mE*/2π*h*¯ 2)3*N*/2 *N* !(3*N* /2)! . (16.44)

*S* = *N k*B ln

precise analysis shows that the neglected term is much smaller than usually claimed.

*n*Q/*n* + 5 2

$$\mathbf{S} = \mathcal{N}k_{\mathrm{B}} \ln \left\{ \frac{V}{\mathcal{N}} \left( \frac{mE}{3\pi \hbar^{2} \mathcal{N}} \right)^{3/2} \right\} + \frac{5}{2} \mathcal{N}k_{\mathrm{B}}.\tag{16.46}$$

(where Stirling's approximation has been used), which results in *S* = *N k*B ln *V N mE* 3π*h*¯ 2*N* 3/2 + 5 2 *N k*B. (16.46)

$$\mathbf{S} = \mathcal{N}k_{\mathbf{B}} \ln \left( n_{\mathbf{Q}}/n \right) + \frac{5}{2} \mathcal{N}k_{\mathbf{B}},\tag{16.47}$$

*N k*B, (16.47)

the entropy in the form

where 10Many treatments take the volume of the spherical shell to be (d*VR*/d*R*) *R* = *VR*3*N R*/*R* = *VR* 3*N E*/2*E* and then argue that ln(*VR* 3*N E*/2*E*) ≈ ln *VR*. That result would be obtained if the exponential in the expression for *F* were expanded, which procedure is incorrect for huge *N* . A more accurate expression can be obtained by setting *y* = (1 − *R*/*R*)3*N* so ln *y* = 3*N* ln(1 − *R*/*R*) ≈ −3*N R*/*R*, and then exponentiating. In fact, isolation of a system is only an idealization which is the rationale for some finite *E*, notwithstanding implications of the uncertainty principle. Thus if atoms near the surface of a body were to interact weakly with its environment, one might expect *E*/*E* ∼ *N* 2/3/*N* = *N* −1/3 so 3*N E*/2*E* ∼ *N* 2/3 which is huge. After taking ln -0, the additive term ln *F* is negligible with respect to ln*VR*, so ultimately one arrives at the same result as usually quoted. Our more

$$m_{\mathbf{Q}}(T) := \left(\frac{mk_{\mathbf{B}}T}{2\pi\hbar^2}\right)^{3/2} \tag{16.48}$$

*Chapt[er](#page-290-0) [16](#page-290-0)* • Microcanonical Ensemble 271 *n*Q(*T*):= *mk*B*T* 2π*h*¯ 2 3/2 (16.48)

$$\mu = -T \left( \frac{\partial S}{\partial N} \right)_{E,V} = k_\text{B} T \ln(n/n_\text{Q}) = k_\text{B} T \ln[p/(n_\text{Q} k_\text{B} T)].\tag{16.49}$$

concentration *n* is small compared to the quantum concentration *n*Q. This will be the case at sufficiently high temperatures and low densities and will be borne out by a complete quantum mechanical analysis. From Eq. (16.46), we can calculate the chemical potential μ = −*T* ∂*S* 

$$p/T = \left(\frac{\partial S}{\partial V}\right)_{N,E} = \left(\frac{\partial S}{\partial V}\right)_{N,T} = Nk_\mathsf{B}/V,\tag{16.50}$$

(∂*S*/∂*N* )*T*,*V* because *E* = (3/2)*N k*B*T*. On the other hand, the relationship between *E* and *T* does not involve *V* for an ideal gas. Thus the pressure of an ideal gas can be computed

<span id="page-291-0"></span>*p*/*T* =

 ∂*S* ∂*V* 

by ho[lding e](#page-289-1)ither *E* or *T* constant, resulting in

function ψ = 0 on the walls of the box.

∂*N*

sion of -

*N*,*E N*,*T* which is the familiar ideal gas equation of state.

**Example Problem 16.2.** Show for an ideal gas in a box having the shape of a rectangular parallelepiped with dimensions *H*, *K*, *L* that one obtains the same result for -0 as given by

= ∂*S* ∂*V* 

$$\mathbf{k} = 2\pi \left[ \frac{n_x}{H} \hat{\mathbf{i}} + \frac{n_y}{K} \hat{\mathbf{j}} + \frac{n_z}{L} \hat{\mathbf{k}} \right],\tag{16.51}$$

<span id="page-291-1"></span>= *N k*B/*V*, (16.50)

**Solution 16.2.** We still have ε = *h*¯ 2*k*2/2*m* and for periodic boundary conditions, **[k](#page-291-0)** = 2π *nx H* ˆ **i** + *ny K* ˆ **j** + *nz L* ˆ **k** , (16.51)

$$\mathbf{k} = \pi \left[ \frac{n_{\mathcal{X}}}{H} \hat{\mathbf{i}} + \frac{n_{\mathcal{Y}}}{K} \hat{\mathbf{j}} + \frac{n_{\mathcal{Z}}}{L} \hat{\mathbf{k}} \right],\tag{16.52}$$

**k** = π *nx H* ˆ **i** + *ny K* ˆ **j** + *nz L* ˆ **k** , (16.52) but now *nx*, *ny* , *nz* are only positive integers (because negative integers would only result in a change of phase, not a linearly independent eigenfunction). In the case of Eq. (16.51), *nx ny nz* = *HKL*/(2π )3 *kx ky kz* so the density of states in **k** space for a single particle is *V*/(2π )3 where the volume *V* = *HKL*. For *N* particles, the density of states is therefore *V*/(2π )3 *N* . In the case of Eq. (16.52), *nx ny nz* = *HKL*/(π )3 *kx ky kz* so the density of states in **k** space for a single particle is *V*/(π )3, and for *N* particles it is [*V*/(π )3] *N* . The volume of an entire hypersphere in 3*N* -dimensional **k** space with radius (2*mE*/*h*¯ 2)1/2 is

$$V_k = \frac{\pi^{3N/2}}{(3N/2)!} (2mE/\hbar^2)^{3N/2}.\tag{16.53}$$

272 THERMAL PHYSICS

$$\left(\frac{V}{(2\pi)^3}\right)^N V_k = V^N \frac{(mE/2\pi\hbar^2)^{3N/2}}{(3N/2)!},\tag{16.54}$$

*N* , resulting in the same

multiply *Vk* by *V*/(2π )3 *N* . But for the case of ψ = 0 on the walls, only positive values of *ki* are

### Gibbs factor) is *V*

net factor [*V*/(2π )3]

express -

(2π )3 *Vk* = *V N* (*mE*/2π*h*¯ 2)3*N*/2 (3*N* /2)! , [(1](#page-289-0)6.54) the same as *VR* given by Eq. (16.39). 16.4.2 Scaling Analysis As noted by Pathria [8, p. 16], many important results for the ideal gas can be ascertained

*N* of *Vk*. So in either case, the number of states (not yet corrected by the

$$
\Omega = \tilde{\Omega} (\mathcal{N}) V^{\mathcal{N}} E^{(3\mathcal{N}/2)},\tag{16.55}
$$

<span id="page-292-1"></span><span id="page-292-0"></span>, (16.55)

*N* particles we expect to be proportional to *V N* . Moreover, the form of Eq. (16.38) shows that will depend on *E* and *V* only in the combination *EV*2/3, so we can immediately

allowed, so we must first multiply *Vk* by (1/23)*N* and then by [*V*/(π )3]

*N*

$$S = k_{\rm B} [\ln \tilde{\Omega}(N) + \mathcal{N} \ln V + (3\mathcal{N}/2) \ln E],\tag{16.56}$$

-= -

we readily deduce the following:

- where -(˜ *N* ) is some unknown function of *N* . Then from *[S](#page-292-0)* = *k*B[[ln](#page-292-1) -( ˜ *N* ) + *N* ln *V* + (3*N* /2)ln *E*], (16.56)

$$E = (\mathbf{3} \mathcal{N} / 2) \mathbf{k}_{\mathbf{B}} T. \tag{16.57}$$

- **1.** From 1/*T* = (∂*S*/∂*E*)*V*,*N* = (3*N k*B/2*E*), we see that *E* is independent of *V* and has the form
( ˜ *N* )*V N E*(3*N*/2)

$$pV = \mathcal{N}k_{\mathcal{B}}T.\tag{16.58}$$

**2.** From *p*/*T* = (∂*S*/∂*V*)*E*,*N* = *N k*B/*V*, we deduce the familiar ideal gas law *pV* = *N k*B*T*. (16.58)

- Combining Eqs. (16.57) and (16.58) gives *p* = (2/3)(*E*/*V*), which relates pressure to energy density. **3.** For an isentropic transformation at constant *N* , the constancy of *S* requires *VE*3/2 =

$$\mathbf{d}E = -(2/3)(E/V)\,\mathrm{d}V = -p\,\mathrm{d}V,\tag{16.59}$$

d*E* = −(2/3)(*E*/*V*) d*V* = −*p* d*V*, (16.59) so the only change in energy for this reversible adiabatic transformation comes from reversible work δ*W* = *p* d*V* done by the system. By eliminating *E* from *VE*3/2 =

- 

$$\mathbf{C}_{V} = (\partial E / \partial T)_{V, \mathcal{N}} = (\mathbf{3} / 2) \mathcal{N} \mathbf{k}_{\mathbf{B}}; \quad \mathbf{C}_{p} = (\partial H / \partial T)_{p, \mathcal{N}} = (\mathbf{5} / 2) \mathcal{N} \mathbf{k}_{\mathbf{B}}, \tag{16.60}$$

*Chapter 16* • Microcanonical Ensemble 273

-A =

What we would like to calculate is -

*h*3

### constant, we also deduce the scaling laws *VT*3/2 = constant, *T*5/2/*p* = constant, and *pV*5/3 = constant for an isentropic transformation of a monatomic ideal gas.

**4.** The enthalpy *H* = *E* + *pV* = (5/3)*E* = (5/2)*N k*B*T*. Therefore, the heat capacities are *CV* = (∂*E*/∂*T*)*V*,*N* = (3/2)*N k*B; *[Cp](#page-290-1)* = (∂*H*/∂*T*)*p*,*N* = (5/2)*N k*B, (16.60) so *Cp*/*CV* = 5/3.

16.5 Multicomponent Ideal Gas

$$\Omega_{\rm A} = \left(\frac{V}{h^3}\right)^{N_{\rm A}} \frac{(2\pi m_{\rm A} E_{\rm A})^{3N_{\rm A}/2}}{N_{\rm A}!(3N_{\rm A}/2)!}; \quad \Omega_{\rm B} = \left(\frac{V}{h^3}\right)^{N_{\rm B}} \frac{(2\pi m_{\rm B} E_{\rm B})^{3N_{\rm A}/2}}{N_{\rm B}!(3N_{\rm B}/2)!}. \tag{16.61}$$

generalization to a larger number of chemical components is straightforward. We consider *N*A atoms of *A*, each with mass *m*A, giving rise to a total energy *E*A for all *A* atoms, and similarly for *B* atoms. Applying Eq. (16.44) to each gas we obtain *V N*A (2π*m*A*E*A)3*N*A/2 *V N*B (2π*m*B*E*B)3*N*B/2

$$
\Omega(E) = \sum_{E_{\rm B}} \Omega_{\rm A}(E - E_{\rm B}) \Omega_{\rm B}(E_{\rm B}) \tag{16.62}
$$

energy; however, we do not yet know how the energies of *A* and *B* are partitioned. Hence, we will have to accept all possible partitions of energy and sum over them to obtain -(*E*) = - *E*B -A(*E* − *E*B)-B(*E*B) (16.62) in an abbreviated notation where symbols other than the energy are suppressed. This would appear to be a very difficult calculation were it not for the fact that all we need is a sufficient approximation to ln which is given by the largest term in the

$$
\ln \mathcal{T}_{\text{max}} \le \ln \mathcal{S} \le \ln \mathcal{T}_{\text{max}} + \ln \mathcal{M}.\tag{16.63}
$$

Following McQuarrie, we let *T*max be the largest term in a sum *S* of *M*positive terms. Then *T*max ≤ *S* ≤ *MT*max. Thus ln *T*max ≤ ln *S* ≤ ln *T*max + ln*M*. (16.63) If, in order of magnitude, *T*max ∼ *AM* where *A* = *O*(1) and *M* 1, we have ln *T*max ∼

$$
\ln \mathcal{S} \approx \ln \mathcal{T}_{\text{max}}.\tag{16.64}
$$

*M*ln *A* and ln *S* ≈ ln *T*max. (16.64)

$$E_{\rm A}^{3N_{\rm A}/2} E_{\rm B}^{3N_{\rm B}/2} = (E - E_{\rm B})^{3N_{\rm A}/2} E_{\rm B}^{3N_{\rm B}/2} \tag{16.65}$$

*E*3*N*A/2 A *E*3*N*B/2 B = (*E* − *E*B) 3*N*A/2*E*3*N*B/2 B (16.65) and *N*A and *N*B are huge numbers for all cases of interest. To find a maximum, we

$$-\left(3\text{N}/2\right)E_{\text{A}}^{\left(3\text{N}_{\text{A}}/2\right)-1}E_{\text{B}}^{3\text{N}_{\text{B}}/2} + \left(3\text{N}/2\right)E_{\text{A}}^{3\text{N}_{\text{A}}/2}E_{\text{B}}^{\left(3\text{N}_{\text{B}}/2\right)-1} = 0,\tag{16.66}$$

<span id="page-294-2"></span>
$$
\mathcal{N}_{\rm A}/E_{\rm A} = \mathcal{N}_{\rm B}/E_{\rm B} = \mathcal{N}/E,\tag{16.67}
$$

$$S = k \ln \left[ \Omega_{\rm A} \left( E \frac{\mathcal{N}_{\rm A}}{\mathcal{N}} \right) \Omega_{\rm B} \left( E \frac{\mathcal{N}_{\rm B}}{\mathcal{N}} \right) \right] = k \ln \Omega_{\rm A} \left( E \frac{\mathcal{N}_{\rm A}}{\mathcal{N}} \right) + k \ln \Omega_{\rm B} \left( E \frac{\mathcal{N}_{\rm B}}{\mathcal{N}} \right)$$

$$= \mathcal{N}_{\rm A} k \ln \left\{ \frac{V}{\mathcal{N}_{\rm A}} \left( \frac{4 \pi m_{\rm A} E}{3 h^{2} \mathcal{N}} \right)^{3/2} \right\} + \frac{5}{2} \mathcal{N}_{\rm A} k + \mathcal{N}_{\rm B} k \ln \left\{ \frac{V}{\mathcal{N}_{\rm B}} \left( \frac{4 \pi m_{\rm B} E}{3 h^{2} \mathcal{N}} \right)^{3/2} \right\} + \frac{5}{2} \mathcal{N}_{\rm B} k. \tag{16.68}$$

*E*A = *EN*A/*N* and *E*B = *EN*B/*N* where *N* = *N*A + *N*B, in which case11

+ 5 2

$$\frac{1}{T} = \left(\frac{\partial S}{\partial E}\right)_{V, \mathcal{N}_{\text{A}}, \mathcal{N}_{\text{B}}} = \frac{3}{2} k \frac{\mathcal{N}}{E},\tag{16.69}$$

+ 5 2

<span id="page-294-1"></span><span id="page-294-0"></span>*N*B*k*. (16.68)

= *NAk* ln *V N*A 4π*m*A*E* 3*h*2*N* 3/2 

-A *E N*A *N* -B *E N*B *N*

multicomponent ideal gases.

*S* = *k* ln

From Eq. (16.68) we co[mpute t](#page-294-1)he temperature: 1 ∂*S* = 3 *k N*

4π*m*B*E* 3*h*2*N*

*T* = ∂*E V*,*N*A,*N*B 2 *E* , (16.69) which leads immediately to

*V N*B

*S*(*T*, *V*, *N*A, *N*B) = *N*A*k* ln *V N*A *n*QA + *N*B*k* ln *V N*B *n*QB + 5 [2](#page-294-0) *N k*, (16.70) where *n*QA := [*m*A*kT*/(2π*h*¯ 2)] 3/2 = [2π*m*A*kT*/*h*2] 3/2 is the quantum concentration of *A* and *n*QB is defined similarly. Examination of Eq. (16.70) in view of Eq. (16.47) allows for an immediate physical interpretation, namely that the entropy of the combined ideal ga[ses of](#page-291-1) *A* and *B* atoms at temperature *T* in a volume *V* is the sum of the entropies they would have if each were

at temperature *T* and occupied the volume *V* separately. According to Callen [2, p. 69], this is often referred to as **Gibbs's theorem**. 12 In fact, Eq. (16.67) is precisely the condition

$$\frac{p}{T} = \left(\frac{\partial S}{\partial V}\right)_{E, \mathcal{M}_\hbar, \mathcal{M}_\mathbb{B}} = k \frac{\mathcal{N}}{V},\tag{16.71}$$

*p T* = ∂*S* ∂*V E*,*N*A,*N*B = *k N V* , (16.71) so *pV* = *N kT*[, th](#page-294-2)e same as for a monocomponent gas. From Eq. (16.50), we see that the pressures of *A* and *B* separately in volume *V* would be *p*A = *N*A*kT*/*V* = (*N*A/*N* )*p* and *p*B =

*N*B*kT*/*V* = (*N*B/*N* )*p*. These are called **partial pressures** of *A* and *B*. Such an additivity of

to get a pure gas of *A* atoms.

13From Eq. (16.67), it follows that *N*A/*E*A = *N*B/*E*B = *N* /*E* = 2/(3*k*B*T*).

partial pressures is unique to ideal gases because they do not interact.

<sup>11</sup>In this and the next section, we deal with *A* and *B* gases so we drop the subscript *B* on the Boltzmann constant *k*B to avoid confusion. 12An equivalent statement is that the Helmholtz free energy of a mixture of ideal gases at temperature *T* in a volume *V* is additive, that is, *F*(*T*, *V*, *N*A, *N*B) = *F*A(*T*, *V*, *N*A) + *F*B(*T*, *V*, *N*B). It would be incorrect to apply this formula to a pure gas by assuming that *A* and *B* atoms are identical. The correct procedure would be to let *N*B = 0

$$\mu_{\rm A} = -T \left( \frac{\partial S}{\partial N_{\rm A}} \right)_{E, V, \mathcal{N}_{\rm B}} = -T \left( \frac{\partial S_{\rm A}(E_{\rm A}, V, \mathcal{N}_{\rm A})}{\partial N_{\rm A}} \right)_{E_{\rm A}, V} = kT \ln \left[ \frac{p_{\rm A}}{n_{\rm Q \rm A} kT} \right]. \tag{16.72}$$

Similarly, one can compute the chemical potential of *A* and *B* in the mixture or,

### alternatively, as if each gas occupied the volume *V* separately. In either case, the result turns out to be the same and one obtains

given by

of other gases.

μA = −*T* ∂*S* ∂*N*A *E*,*V*,*N*B = −*T* ∂*S*A(*E*A, *V*, *N*A) ∂*N*A *E*A,*V* = *kT* ln *p*A *n*QA*kT* . (16.72) Thus, from the standpoint of chemical potential, the presence of another species in a mixture of ideal gases in a volume *V* at temperature *T* is irrelevant.14 16.5.1 Entropy of Mixing

$$\text{SA}(E_{\text{A}}, V_{\text{A}}, \mathcal{N}_{\text{A}}) = \mathcal{N}_{\text{A}} k \ln \left\{ \frac{V_{\text{A}}}{\mathcal{N}_{\text{A}}} \left( \frac{4 \pi m_{\text{A}} E_{\text{A}}}{3 h^{2} \mathcal{N}_{\text{A}}} \right)^{3/2} \right\} + \frac{5}{2} \mathcal{N} \text{A}. \tag{16.73}$$

Thus, in the case of our mixture of *A* and *B* atoms, the *A* atoms would need to be confined

∂*S*A ∂*E*A 

$$
\left(\frac{\partial \mathbf{S_A}}{\partial E_\mathbf{A}}\right)_{V_\mathbf{A}\mathcal{N}_\mathbf{A}} = \frac{3}{2}k\frac{\mathcal{N}_\mathbf{A}}{E_\mathbf{A}} = \frac{3}{2}k\frac{\mathcal{N}}{E} = \frac{1}{T} \tag{16.74}
$$

*N*A 3*h*2*N*A The reciprocal temperature of these *A* atoms would be

<span id="page-295-1"></span>
$$\left(\frac{\partial S_{\rm A}}{\partial V_{\rm A}}\right)_{E_{\rm A}, \mathcal{N}_{\rm A}} = k \frac{\mathcal{N}_{\rm A}}{V_{\rm A}} = k \frac{\mathcal{N}}{V} = \frac{p}{T}.\tag{16.75}$$

and the ratio of their pressure to their temperature would be

$$\text{SA}(T, V_{\text{A}}, \mathcal{N}_{\text{A}}) = \mathcal{N}_{\text{A}} k \ln \left( \frac{V_{\text{A}}}{\mathcal{N}_{\text{A}}} \, n_{\text{QA}} \right) + \frac{5}{2} \mathcal{N}_{\text{A}} k \tag{16.76}$$

<span id="page-295-0"></span>They therefore have the same temperature and pressure as the mixture. We write *S*A(*T*, *V*A, *N*A) = *N*A*k* ln *V*A *N*A *n*QA + 5 2 *N*A*k* (16.76)

$$\Delta S^{\rm diffK} := \mathrm{S}(T, V, \mathcal{N}_{\mathrm{A}}, \mathcal{N}_{\mathrm{B}}) - \mathrm{S}_{\mathrm{A}}(T, V_{\mathrm{A}}, \mathcal{N}_{\mathrm{A}}) - \mathrm{S}_{\mathrm{B}}(T, V_{\mathrm{B}}, \mathcal{N}_{\mathrm{B}})$$

$$= \mathcal{N}_{\mathrm{A}} k \ln(V/V_{\mathrm{A}}) + \mathcal{N}_{\mathrm{B}} k \ln(V/V_{\mathrm{B}})$$

$$= -k \left[ \mathcal{N}_{\mathrm{A}} \ln(\mathcal{N}_{\mathrm{A}}/\mathcal{N}) + \mathcal{N}_{\mathrm{B}} \ln(\mathcal{N}_{\mathrm{B}}/\mathcal{N}) \right] > 0. \tag{16.77}$$

<sup>= −</sup>*k N*A ln(*N*A/*N* ) + *N*B ln(*N*B/*N* ) > 0. (16.77) 14This statement may seem counterintuitive to those familiar with solution chemistry but a different scenario is used in that case. In solution chemistry, one generally considers the difference between the chemical potential of a pure gas *A* at some temperature *T* and pressure *p* (a "standard state") and a mixture of gases at temperature *T* and *total* pressure *p*. In a mixture of ideal gases, the gas of atoms *A* has only a partial pressure *p*A = *pN*A/*N* so the difference in chemical potential per atom, compared to the standard state, is *kT* ln(*p*A/*p*) = *kT* ln(*N*A/*N* ). In our case above, the gas of *N*A atoms in volume *V* has the same pressure *p*A whether it is alone or in the presence

$$S(T, V, \mathcal{N}) = \mathcal{N}k \ln\left(\frac{V}{\mathcal{N}} n_{\mathcal{Q}}\right) + \frac{5}{2} \mathcal{N}k.\tag{16.78}$$

276 THERMAL PHYSICS This result should be compared to the case when a monocomponent gas occupies the entire volume *V*, in which case its entropy is given by Eq. (16.47) which we symbolize in the form

$$S(T, V', \mathcal{N}') = \mathcal{N}' k \ln \left(\frac{V'}{\mathcal{N}'} n_{\mathcal{Q}}\right) + \frac{5}{2} \mathcal{N}' k \tag{16.79}$$

If such a gas is partitioned such that *N* + *N* = *N* with *N* atoms occupying volume *V* = *V N*

and

$$S''(T, V'', N'') = N''k \ln\left(\frac{V''}{N''}\, n_\mathrm{Q}l\right) + \frac{5}{2}N''k.\tag{16.80}$$

*S* (*T*, *V* , *N* ) = *N k* ln *V* + 5 *N k* (16.79)

$$
\Delta S = S(T, V, \mathcal{N}) - S'(T, V', \mathcal{N}') - S'(T, V'', \mathcal{N}'') = 0,\tag{16.81}
$$

*T* and pressure *p*. We note that

*S*(*T*, *V*, *N* ) = *N k* ln *V N n*Q*l* + 2 *N k*. (16.80) The entropy change when the partitioned gases are mixed will then be *S* = *S*(*T*, *V*, *N* ) − *S* (*T*, *V* , *N* ) − *S*(*T*, *V*, *N* ) = 0, (16.81) as expected.

5

$$
\mathfrak{\mathfrak{Q}}^{\text{mkx}} = \frac{\mathcal{N}!}{\mathcal{N}_{\mathbb{A}}! \mathcal{N}_{\mathbb{B}}!} , \tag{16.82}
$$

*S*ideal in

form from them a mixed gas having the same *T* and *p*, the number of configurations of *N*A atoms of *A* and *N*B atoms of *B* that can be obtained by arranging particles is

Section 10.2 where we treated so-called ideal solutions thermodynamically.

$$
\Delta S^{\rm mlx} = k \ln \Omega^{\rm mlx} = -k \left[ \mathcal{N}_{\rm \rm A} \ln(\mathcal{N}_{\rm A}/\mathcal{N}) + \mathcal{N}_{\rm B} \ln(\mathcal{N}_{\rm B}/\mathcal{N}) \right], \tag{16.83}
$$

*N*A!*N*B! where *N* = *N*A + *N*B. Then with Stirling's approximation, *S*mix = *k* lnmix = −*k N*A ln(*N*A/*N* ) + *N*B ln(*N*B/*N* ) , (16.83) which is the same as given by Eq. (16.77). In other words, the ideal entropy of mixing results simply from the number of distinct configurations of *A* and *B* atoms at temperature

*S*mix is exactly the same quantity that we called

17 Classical Microcanonical Ensemble In Chapter 16, we explored the microcanonical ensemble in the context of quantum statistical mechanics. First of all, we believe that quantum mechanics is correct whereas classical mechanics is just an asymptotic (but very useful) approximation. Second, however, quantum statistical mechanics is easier to understand because implementing the fundamental hypothesis is, in principle, a matter of counting quantum states and deciding on their statistical weight (e.g., equally probable for the microcanonical ensemble). In classical mechanics, however, we deal with *continuous* variables so we have to replace counting with integration over a continuous weighting function. On the other hand, classical statistical mechanics was the first to be developed and its study allows us to gain some physical intuition about statistical mechanics without dealing with the abstractions

and statistical nature of quantum mechanics itself. Moreover, there are systems and situations for which quantum effects are not important and for which a treatment by classical statistical mechanics is more tractable. We shall therefore discuss briefly the foundations of classical statistical mechanics and explore briefly the classical version of the microcanonical ensemble. We consider a three-dimensional classical system consisting of *N* identical particles and characterized by generalized coordinates **q** = *q*1, *q*2, ... , *qi*, ... , *q*3*N* and generalized conjugate momenta **p** = *p*1, *p*2, ... , *pi*, ... , *p*3*N* . These variables span a 6*N* -dimensional space known as **phase space**. We denote them collectively by a 6*N* -dimensional vector *ω*.

$$
\dot{\eta}_l = \frac{\partial \mathcal{H}}{\partial p_l}; \quad \dot{p}_l = -\frac{\partial \mathcal{H}}{\partial q_l}, \tag{17.1}
$$

<span id="page-297-0"></span>according to Hamilton's equations *q*˙*i* = ∂*H* ∂*pi* ; *p*˙*i* = −∂*H* ∂*qi* , (17.1) where a dot above a variable denotes differentiation with respect to time. As time evolves, the point **p**, **q** traces out a trajectory in phase space. For the case *H*(**p**, **q**;*t*) = *H*(**p**, **q**), explicitly i[ndependent of time, the total ene](http://dx.doi.org/10.1016/B978-0-12-803304-3.00017-X)rgy *E* is conserved and this trajectory lies on the **hypersurface** *H*(**p**, **q**) = *E*. For an isolated system, the energy will be constant and a fundamental assumption of classical statistical mechanics is that all points on that hypersurface are equally probable.1 This leads to the classical microcanonical

ensemble.

<sup>1</sup>In fact, one usually considers a thin hypershell such that *E* − *E* ≤ *H*(**p**, **q**) ≤ *E* and then assumes that every volume element in that *hypershell* is equally probable. The entropy is assumed to be proportional to the

278 THERMAL PHYSICS 17.1 Liouville's Theorem To gain more insight into the basis for classical statistical mechanics, we digress to discuss Liouville's theorem. We consider an ensemble of identical classical systems governed by Hamilton's equations. Each member of the ensemble corresponds to the same macrostate of some macroscopic system under consideration, but the members of the ensemble differ from one another microscopically, that is, they represent different microstates. Each member of the ensemble is represented by a point in phase space that moves in time from its initial point, which will differ for each member of the ensemble. We assume that there is an enormous number of such points that form a virtual continuum in all accessible

<span id="page-298-0"></span>
$$
\langle \mathbf{y} \rangle = \frac{\int \mathbf{y}(\omega) \rho(\omega; t) \, d\omega}{\int \rho(\omega; t) \, d\omega}. \tag{17.2}
$$

interest, we take the point of view that observed quantities can be calculated by means of an ensemble average. Thus if *y*(*ω*) is some property that depends on the coordinates and momenta of the particles, its ensemble average would be *y* = - *y*(*ω*)ρ(*ω*;*t*) dω - ρ(*ω*;*t*) dω . (17.2)

<span id="page-298-1"></span>In this case, - ρ(*ω*;*t*) dω = *N*ens, the total number of members of the ensemble. We could equally well regard ρ to be a probability density function, in which case it would be normalized such that - ρ(*ω*;*t*) dω = 1. In that case, the denominator in Eq. (17.2) [would](#page-298-1)

$$\frac{\mathbf{d}}{\mathbf{d}t} \int_{a'} \rho(\omega; t) \, \mathbf{d}\omega = -\int_{a'} \rho(\omega; t) \, \dot{\mathbf{u}} \cdot \hat{\mathbf{n}} \, \mathbf{d}d',\tag{17.3}$$

<span id="page-298-2"></span>volume to the net rate at which microsystems enter that volume. Thu[s](#page-298-2) d d*t* ω ρ(*ω*;*t*) dω = − *a* ρ(*ω*;*t*)*ω*˙ · **n**ˆ d*a* , (17.3) where *a* is the area of the sub-volume ω and **n**ˆ is its unit outward normal. Here, *ω*˙ is the

<span id="page-298-3"></span>
$$\int_{\omega'} \left[ \frac{\partial \rho}{\partial t} + \nabla_{\alpha} \cdot (\rho \dot{\omega}) \right] \mathbf{d} \omega = \mathbf{0},\tag{17.4}$$

 ω ∂ρ ∂*t* + ∇ω · (ρ*ω*˙) dω = 0, (17.4)

$$\frac{\partial \rho}{\partial t} + \nabla_{\alpha} \cdot (\rho \dot{\omega}) = 0.\tag{17.5}$$

∂ρ ∂*t* + ∇ω · (ρ*ω*˙) = 0. (17.5) We note that Eq. (17.5) is analogous to the continuity equation for conservation of mass of a classical fluid; in that case, ρ represents the density of the fluid and *ω*˙ represents the barycentric fluid velocity **v**.

<span id="page-299-0"></span>*i*=1

$$
\nabla_{\boldsymbol{\omega}} \cdot (\rho \dot{\boldsymbol{\omega}}) = \dot{\boldsymbol{\omega}} \cdot \nabla_{\boldsymbol{\alpha}} \rho + \rho \nabla_{\boldsymbol{\alpha}} \cdot \dot{\boldsymbol{\omega}}.\tag{17.6}
$$

$$\nabla_{\boldsymbol{\omega}} \cdot \dot{\boldsymbol{\omega}} = \sum_{l=1}^{3N} \left[ \frac{\partial}{\partial p_l} \dot{p}_l + \frac{\partial}{\partial q_l} \dot{q}_l \right] = \sum_{l=1}^{3N} \left[ -\frac{\partial^2 \mathcal{H}}{\partial p_l \partial q_l} + \frac{\partial^2 \mathcal{H}}{\partial q_l \partial p_l} \right] = 0,\tag{17.7}$$

The second term in Eq. (17.5) can be expanded to obtain ∇ω · (ρ*ω*˙) = ˙*ω* · ∇ωρ + ρ∇ω · ˙*ω*. (17.6) We shall proceed to show that the second term on the right in Eq. (17.6) vanishes. Indeed, ∇ω · ˙*ω* = 3*N* ∂ ∂*pi p*˙*i* + ∂ ∂*qi q*˙*i* = 3*N* − ∂2*H* ∂*pi*∂*qi* + ∂2*H* ∂*qi*∂*pi* = 0, (17.7)

$$\dot{\boldsymbol{\omega}} \cdot \nabla_{\alpha} \rho = \sum_{l=1}^{3N} \left[ \frac{\partial \rho}{\partial q_l} \frac{\partial \mathcal{H}}{\partial p_l} - \frac{\partial \rho}{\partial p_l} \frac{\partial \mathcal{H}}{\partial q_l} \right] \equiv \{\rho, \mathcal{H}\} \tag{17.8}$$

incompressible flow. Its interpretation is that the fluid flows in closed loops, which is known as **solenoidal flow**. The first term on the right in Eq. (17.6) can also be written in terms of **p** and **q** in the form

$$\frac{\mathcal{D}\rho}{\mathcal{D}t} \equiv \frac{\partial \rho}{\partial t} + \dot{\mathfrak{a}} \cdot \nabla_{\alpha} \rho = \frac{\partial \rho}{\partial t} + \{\rho, \mathcal{H}\} = 0. \tag{17.9}$$

and is known in classical mechanics as a **Poisson bracket**. It is analogous to a commutator in quantum mechanics. Equation (17.5) can therefore be written in the form *D*ρ *Dt* ≡ ∂ρ ∂*t* + ˙*ω* · ∇ωρ = ∂ρ ∂*t* [+ {](#page-299-0)ρ, *H*} = 0. (17.9) The quantity *D*ρ/*Dt* is a total time derivative of ρ as one follows members of the ensemble through phase space; it is analogous to the substantial derivative of classical fluid dynamics, which is a total time derivative as one follows mass through real space. Equation (17.[9),](#page-299-0) [w](#page-299-0)hich is essentially Liouville's theorem, states that the density of members of the ensemble, as they move through phase space, does not change. An equivalent inter-

pretation is that the volume of phase space occupied by a dense set of points representing members of the ensemble does not change with time, although it can change position and

$$\frac{\partial \rho}{\partial t} = \mathbf{0}, \quad \text{equilibrium ensemble,} \tag{17.10}$$

and Eq. (17.9) yields

<span id="page-299-1"></span>∂ρ

shape.

$$
\langle \rho, \mathcal{H} \rangle = \mathbf{0}.\tag{17.11}
$$

{ρ, *H*} = 0. (17.11) For a system in equilibrium, we shall require ρ(*ω*;*t*) = ρ(*ω*), explicitly independent of *t*. Physical measurements of such a system, which will disturb the system slightly, are really time averages over times that are large compared to the time it takes a system to relax to equilibrium. The system therefore passes through an enormous number of "equilibrium" states during a physical measurement, and its initial state is irrelevant. The time average

of an ensemble average is therefore the same as the ensemble average of a time average

### 280 THE[RMAL](#page-299-1) PHYSICS

<span id="page-300-1"></span><span id="page-300-0"></span>*y* =

[8, p. 37]. In statistical mechanics, one adopts the hypothesis that the observed value of *y*(*ω*) in some macroscopic equilibrium state is its ensemble average. For further discussion, see [7, chapter 1]. 17.2 Classical Microcanonical Ensemble Equation (17.11) is a requirement for an acceptable distribution function and shows the close relationship of ρ to *H*, and hence to the energy *E*. One way to satisfy Eq. (17.11) is to take ρ to be a constant. If the energy is precisely fixed at the value *E*, the members of the ensemble move in phase space on a subspace of phase space that we can regard as an energy hypersurface[.](#page-300-0) [We](#page-300-0) [c](#page-300-0)ould represent ρ as a delta function, with some constant

$$
\langle \mathbf{y} \rangle = \frac{1}{\Delta \alpha \nu} \int_{\Delta \alpha} \mathbf{y}(\omega) \, \mathbf{d} \omega. \tag{17.12}
$$

*E* − *E* ≤ *H* ≤ *E* and then take ρ to be a constant within that shell and zero elsewhere. This choice actually corresponds to the classical microcanonical ensemble. The constant value of ρ, which depends on the normalization of ρ, cancels in Eq. (17.2) which becomes 1 ω

$$
\langle \mathbf{y} \rangle = \frac{1}{\Omega} \sum_{\nu=1}^{\Omega} y_{\nu} \tag{17.13}
$$

(see Eq. (16.1)) 1 

*y* = ν=1 *y*ν , (17.13) where is the degeneracy (multiplicity function) for a fixed energy and ν labels the compatible quantum states of the system, for which *y* has values *y*ν . It remains to establish a relationship between ω, which is some measure of the volume of phase space available to the system, and the entropy *S*. From the quantum

$$\mathbf{S} = k_{\mathbf{B}} \ln(\Delta \omega / a_{\mathbf{0}}),\tag{17.14}$$

one microstate. Classical mechanics provides no answer to this question. We could write *S* = *k*B ln(ω/ω0), (17.14) where *k*B is Boltzmann's constant, but the entropy would still remain undetermined up to an additive "constant," although we would expect ω0 to depend on *N* . We can, however, appeal to quantum mechanics and choose ω0 so that classical mechanics and quantum mechanics will agree in the asymptotic limit where classical mechanics is valid. This can only be done for simple systems, for which the problem is tractable, but presumably ω0 will be the same for all systems, so we can determine it in a simple case. For an ideal gas, one can work out both the classical and quantum mechanical cases and make a comparison

(see also Pathria [8, p. 39] and Chandler [12, p. 191]), as we do in the next section.

and *E*. This volume is

$$
\Delta\omega = \int \mathbf{d}^{3N} q \, \mathbf{d}^{3N} p = V^N \int \mathbf{d}^{3N} p,\tag{17.15}
$$

17.2.1 Classical Ideal Gas

$$2m(E - \Delta E) \le \sum_{r=1}^{3N} p_r^2 \le 2mE \tag{17.16}$$

ω = d3*N q* d3*N p* = *V N* d3*N p*, (17.15) where the momentum inte[gral](#page-300-1) [is](#page-300-1) [o](#page-300-1)ver the hyperspherical shell

$$
\Delta\omega = V^N \mathcal{F} \frac{(2\pi mE)^{3N/2}}{(3N/2)!} \approx V^N \frac{(2\pi mE)^{3N/2}}{(3N/2)!}.\tag{17.17}
$$

of outer radius (2*mE*) 1/2. Proceeding as in the pseudo-quantum mechanical case, we know that the volume of this hyperspherical shell is just the factor *F* in Eq. (16.40) times the

volume of the entire hypersphere, so

and *G* that depend on *S*.

<span id="page-301-1"></span><span id="page-301-0"></span>
$$\frac{\Delta\phi}{\alpha_0} = \frac{V^{\mathcal{N}}}{\alpha_0} \frac{(2\pi mE)^{3\mathcal{N}/2}}{(3\mathcal{N}/2)!}.\tag{17.18}$$

ω [=](#page-301-0) *V N F* (2π*mE*)3*N*/2 (3*N* /2)! ≈ *V N* (2π*mE*)3*N*/2 (3*N* /2)! . (17.17) The entropy is given by Eq. (17.14) with

$$
\omega_0 = h^{3\mathcal{N}} \mathcal{N}!, \quad \text{identical and indistinguishable particles.} \tag{17.19}
$$

To agree with our pseudo-quantum mechanical treatment, specifically Eq. (16.44) for , we deduce that ω0 = *h*3*N N* !, identical and indistinguishable particles. (17.19) The factor *h*3*N* in Eq. (17.19) has the same dimensions as the volume of phase space and can be thought of as dividing phase space into cells. The volume of each cell would be *h*3 per particle, consistent with the Heisenberg uncertainty principle. The factor *h*3*N* will make the ratio (ω/ω0) dimensionless. The factor of *N* ! is the Gibbs correction factor that corrects for indistinguishable particles and makes the entropy an extensive function.

For a dilute gas at high temperatures, it would occur automatically from quantum mechanical considerations that are designed from the start to deal systematically with indistinguishable particles. Although we have derived this factor for an ideal gas, it is presumed to be a universal factor for all classical statistical systems consisting of indistinguishable particles. Of course the *N* ! factor is to be omitted for classical identical but distinguishable particles such as

identical classical harmonic oscillators imbedded in a solid and distinguished by their positions. Since ω0 depends only on *N* , it will make no contribution to the calculation of 1/*T* = (∂*S*/∂*E*)*V*,*N* or to *p*/*T* = (∂*S*/∂*V*)*E*,*N* , but a knowledge of ω0(*N* ) is necessary to get the quantum mechanically correct entropy or any of the thermodynamic potentials such as *F*

which can also be written as

space.

*Z*∗ *C* = 1 *h*3*N N* ! exp[−β *H*(*ω*)] dω =

$$Z_C^* = \frac{1}{h^{3N} \mathcal{N}!} \int \exp[-\beta \cdot \mathcal{H}(\omega)] \,\mathrm{d}\omega = \int \exp[-\beta \cdot \mathcal{H}(\omega)] \,\mathrm{d}(\omega/\omega \bullet). \tag{17.20}$$

$$Z = \sum_{\nu} \exp[-\beta \, E_{\nu}].\tag{17.21}$$

exp[−β *H*(*ω*)] d(ω/ω0). (17.20)

This dimensionless partition function is the analog of the quantum partition function *Z* =

$$E = \frac{p^2}{2m} + \frac{1}{2}kx^2 = \frac{p^2}{2m} + \frac{m\omega^2}{2}x^2,\tag{17.22}$$

exp[−β *E*ν ]. (17.21)

**Example Problem 17.1.** Consider a classical harmonic oscillator with spring constant *k* in one dimension *x* for a particle of mass *m* having linear momentum *p*. Its energy *E* is given by *E* = *p*2 2*m* + 1 2 *kx*2 = *p*2 2*m* + *m*ω2 2 *x*2, (17.22) where ω = *k*/*m* is its angular frequency. The well-known solution to this equation has the form *x* = *A* sin(ω*t* + ϕ), where *t* is the time and *A* and ϕ are constants. Show that the trajectory of the particle orbit in phase space is an ellipse and determine the sizes of its semiaxes. Then compute

the area of the shell in phase space that lies between energies *E* and *E* − *E* and compare with

$$\frac{p^2}{a^2} + \frac{x^2}{b^2} = 1,\tag{17.23}$$

**Solution 17.1.** Equation (17.22) can be written in the form *p*2 *a*2 + *x*2 *b*2 = 1, (17.23) which is the equation of an ellipse with semiaxes *a* = √2*mE* and *b* = 2*E*/*m*ω2. The

$$2\pi E/\alpha - 2\pi (E - \Delta E)/\alpha = 2\pi \Delta E/\alpha. \tag{17.24}$$

2π*E*/ω − 2π(*E* − *E*)/ω = 2π*E*/ω. (17.24)

space area in a shell between *E* and *E* − *E* is therefore

$$
\Delta E = \Delta (n + 1/2)\hbar \omega = \hbar \omega \Delta n.\tag{17.25}
$$

*E* = (*n* + 1/2)*h*¯ ω = *h*¯ω*n*. (17.25)

*n*

$$\frac{\Delta n}{2\pi \Delta E/\omega} = \frac{1}{2\pi \hbar} = \frac{1}{\hbar}.\tag{17.26}$$

*H* = 3*N*

described by Eq. (17.27) into a unit hypersphere *S*1 given by

*i*=1

*p*2 *i* 2*m* +

*i*=1

$$\mathcal{H} = \sum_{l=1}^{3N} \frac{p_l^2}{2m} + \frac{m\omega^2}{2} \sum_{l=1}^{3N} x_l^2. \tag{17.27}$$

17.2.2 Classical Harmonic Oscillators in Three Dimensions For *N* classical harmonic oscillators at fixed locations in three-dimensional space, the

$$\sum_{l=1}^{6N} X_l^2 = 1,\tag{17.28}$$

The volume of phase space for *H* ≤ *E* can be computed by mapping the hyperellipsoid

*Xi* = *pi* √ 2*mE*

Hamiltonian is

$$X_l = \frac{p_l}{\sqrt{2mE}}; \quad X_{l+3N} = x_l \sqrt{m\omega^2 / 2E}; \quad i = 1, 2, \dots, 3N. \tag{17.29}$$

by means of the transfor[mation](#page-301-1)

$$\int_{E} \mathbf{d}^{3\mathcal{N}} p \, \mathbf{d}^{3\mathcal{N}} \mathbf{x} = \int_{S_1} J \mathbf{d}^{6\mathcal{N}} X = J \frac{\pi^{6\mathcal{N}/2}}{(6\mathcal{N}/2)!},\tag{17.30}$$

The corresponding volume of phase space within the entire hyperellipsoid is therefore *E* d3*N p* d3*N x* = *S*1 *J*d6*N X* = *J* π6*N*/2 (6*N* /2)! , (17.30) where the Jacobian *J* = ( √2*mE*)3*N* ( 2*E*/*m*ω2)3*N* = (2*E*/ω)3*N* . As was the case for

$$
\Delta\omega \approx \frac{(2\pi E/\omega)^{3N}}{(3N)!}.\tag{17.31}
$$

hyperellipsoid, so

The entropy is therefore

$$\frac{S}{k_{\rm B}} = \ln \frac{\Delta \omega}{\omega_{0}} = \ln \frac{(2\pi E/\omega)^{3N}}{h^{3N}(3N)!} = 3N \left[ \ln \left( \frac{E}{3N \hbar \omega} \right) + 1 \right],\tag{17.32}$$

*S k*B = ln ω ω0 = ln (2π*E*/ω)3*N h*3*N* (3*N* )! = 3*N* ln *E* 3*Nh*¯ ω + 1 , (17.32)

ω ≈ (2π*E*/ω)3*N*

$$
\mu_0 = h^{3N}, \quad \text{identical but distinguishable particles,} \tag{17.33}
$$

*E* = 3*N k*B*T*. (17.34)

ω0 = *h*3*N* , identical but distinguishable particles, (17.33) because the oscillators are distinguishable due to their fixed locations. The temperature is

$$E = 3\mathcal{N}k_{\mathbb{B}}T.\tag{17.34}$$

In terms of temperature, the entropy is

for one-dimensional oscillators.

*S* = 3*N k*B

at high temperatures, quantum effects having been lost in the classical limit.2

 ln *k*B*T h*¯ ω 

Comparison with Eqs. (16.26) and (16.29) shows that Eqs. (17.34) and (17.35) are only valid

$$S = 3\mathcal{N}k_{\rm B} \left[ \ln \left( \frac{k_{\rm B}T}{\hbar \omega} \right) + 1 \right]. \tag{17.35}$$

. (17.35)

284 THERMAL PHYSICS

+ 1 

<sup>2</sup>The dependence of Eq. (17.35) on *h*¯ results from identification of ω0 = *h*3*N* from quantum mechanical considerations. From a strictly classical point of view, ω0 would be unknown so the entropy would only be determined up to an additive constant, namely *S* = 3*N k*B ln *T* + constant. The factor of 3 would be absent

# 18

Distinguishable Particles with Negligible Interaction Energies In Chapters 16 and 17, we introduced the microcanonical ensemble. This ensemble was useful for stating the fundamental postulates on which statistical mechanics is based, but not useful for practical calculations. From the microcanonical ensemble, we can derive other ensembles, such as the canonical ensemble (Chapter 19) and the grand canonical ensemble (Chapter 21) that are more tractable. Before doing so, however, we pause to develop the special case of the statistical mechanics at constant temperature *T* of **identical but distinguishable particles** having negligible interaction energies. This is a *special case* of the canonical ensemble and allows us to qui[ck](#page-305-0)ly and easily obtain a

number of useful results of practical importance without complication. In Chapter 19, we will derive the canonical ensemble from the microcanonical ensemble for a large system in contact with a heat reservoir at temperature *T*. In Section 19.2.1, we will show that the results in the current chapter can be deduced by means of the factorization theorem. *A more sophisticated reader can skip this chapter temporarily and go directly to Chapter 19.* We consider a system consisting of *N* identical but distinguishable quantum subsystems that we shall refer to as "particles." Each particle has stationary states having energies ε1, ε2, ... , ε*i*, .... The particles are assumed to be distinguishable because of their *fixed location* (e.g., in a sol[id](#page-305-1)) but are otherwise the same. The states of each particle may be finite or infinite in number, and some of them may be degenerate.1 Moreover, the energies ε*i* could possibly depend on the volume *V* of the system. In the derivation that follows,

### <span id="page-305-0"></span>interact sufficiently weakly that their interaction energy is negligible, but to a degree that will allow them eventually to come to equilibrium.

we shall suppress any dependence of ε*i* on *V* until needed. The particles are assumed to

<span id="page-305-1"></span>18.1 Derivation of the Boltzmann Distribution We examine a **[configuration](http://dx.doi.org/10.1016/B978-0-12-803304-3.00018-1)** {*Ni*} = *N*1, *N*2, ... , *N*κ of the system such that *N*1 particles are in a quantum state2 with energy ε1, *N*2 particles are in a quantum state with energy ε2,

etc. Such a configuration is subject to the constraints

<sup>1</sup>Degeneracy arises when there are stationary states of the subsystems having the same energy but a different

set of quantum numbers. 2For brevity we use a single index to denote a quantum state but in fact many quantum numbers may be

286 THERMAL PHYSICS

<span id="page-306-2"></span>
$$\sum_{l} \mathcal{N}_{l} = \mathcal{N} \tag{18.1}$$

and

$$\sum_{l} \mathcal{N}_{l} \varepsilon_{l} = E,\tag{18.2}$$

-

<span id="page-306-0"></span>
$$\mathcal{W}\{\mathcal{N}_l\} := \frac{\mathcal{N}!}{\mathcal{N}_1!\mathcal{N}_2!\cdots\mathcal{N}_k!}.\tag{18.3}$$

- *i Ni*ε*i* = *E*, (18.2) where *E* is the total energy of the system. Since the particles are distinguishable, the number of ways of making a given configuration is[3](#page-306-0)

$$\frac{\partial}{\partial \mathcal{N}_f} [\ln \mathcal{W}(\mathcal{N}_l) - \beta E - \alpha \mathcal{N}] = 0. \tag{18.4}$$

constraints expressed by Eqs. (18.1) and (18.2). Since ln *x* is a monotonically increasing function of *x*, we actually maximize ln *W* subject to these same constraints. To handle the constraints, we introduce Lagrange multipliers β and α and solve the problem

∂ ∂*Nj* [ln *W*{*Ni*} − β*E* − α*N* ] = 0. (18.4)

$$\frac{\partial}{\partial \mathcal{N}_f} \ln \mathcal{W} \langle \mathcal{N}_l \rangle \sim \frac{\partial}{\partial \mathcal{N}_f} \left[ \mathcal{N} \ln \mathcal{N} - \sum_l \mathcal{N}_l \ln \mathcal{N}_l \right] = -\ln \frac{\mathcal{N}_f}{\mathcal{N}}.\tag{18.5}$$

obtain

satisfy the constraints.

$$-\ln\frac{N_f}{N} - \beta\varepsilon_f - \alpha = 0.\tag{18.6}$$

Thus Eq. (18.4) becomes

∂ ∂*Nj*

$$\frac{\mathcal{N}_f}{\mathcal{N}} = \mathbf{e}^{-\alpha} \mathbf{e}^{-\beta e_f}.\tag{18.7}$$

The solution to Eq. (18.6) is *Nj*

ln *W*{*Ni*} ∼

<span id="page-306-1"></span>∂ ∂*Nj* − ln *Nj*

*j*

$$1 = \sum_{j} \frac{N_j}{N} = \mathbf{e}^{-\alpha} \sum_{j} \mathbf{e}^{-\beta \varepsilon_j},\tag{18.8}$$
 
$$\text{which results in}$$

occupation of the quantum states.

which results in

$$\mathbf{e}^{-\alpha} = \mathbf{1}/\mathbf{z},\tag{18.9}$$

e−α = 1/*z*, (18.9) 3Here, *W* plays the same role as for the microcanonical ensemble, but we use a different notation because corresponds to constrained values of *E* and *N* . In the present case, these constraints are replaced by Eqs. (18.1) and (18.2). Ultimately we will specify the temperature *T* and then determine *E* from the probabilities *pi* of

*j*

where

<span id="page-307-3"></span><span id="page-307-0"></span>internal energy is

d*U* = *N* -

*i*

ε*i* d*pi* + *N* -

*i*

<span id="page-307-4"></span>
$$z = \sum_{j} \mathbf{e}^{-\beta \epsilon_{f}} \tag{18.10}$$

*Chapter 18* • Distinguishable Particles with Negligible Interaction Energies 287

<span id="page-307-1"></span>
$$p_l := \frac{\mathcal{N}_l}{\mathcal{N}} = \frac{\mathbf{e}^{-\beta x_l}}{z},\tag{18.11}$$

*z* = - *j* e−βε*j* (18.10)

is known as the **partition fu[nct](#page-307-0)ion**. 4 Thus Eq. (18.7) becomes

<span id="page-307-5"></span>
$$U \coloneqq \langle E \rangle = \mathcal{N} \sum_{l} p_l \varepsilon_l = \mathcal{N} \sum_{l} \frac{\varepsilon_l \mathbf{e}^{-\beta \varepsilon_l}}{z} = -\frac{\mathcal{N}}{z} \frac{\partial z}{\partial \beta} = -\mathcal{N} \frac{\partial \ln z}{\partial \beta}. \tag{18.12}$$

where we have also i[ntrodu](#page-307-1)ced the symbol *pi*, the probability of occupati[on of th](#page-307-2)e *i*th state of a particle.

$$S = k_{\rm B} \ln \mathcal{W}(\mathcal{N}_l) \tag{18.13}$$

*U* := *E* = *N i pi*ε*i* = *N i z* = −*N z* ∂β = −*N* ∂ ln *z* ∂β . (18.12)

<span id="page-307-2"></span>ε*i*e−βε*i*

$$\mathbf{S} = k_{\mathrm{B}} \left[ \mathcal{N} \ln \mathcal{N} - \sum_{l} \mathcal{N}_{l} \ln \mathcal{N}_{l} \right] = -k_{\mathrm{B}} \sum_{l} \mathcal{N}_{l} \ln(\mathcal{N}_{l}/\mathcal{N}) = -\mathcal{N}k_{\mathrm{B}} \sum_{l} p_{l} \ln p_{l}. \tag{18.14}$$

∂*z*

with *Ni* given by Eq. (18.11). With the aid of Stirli[ng](#page-307-3)'s approximation, Eq. (18.13) becomes *S* = *k*B *N* ln *N* −- *i Ni* ln *Ni* = −*k*B - *i Ni* ln(*Ni*/*N* ) = −*N k*B - *i pi* ln *pi*. (18.14) We now proceed to identify the remaining Lagrange multiplier β. In principle, we could do this by specifying the total energy and solving Eq. (18.2) for β, with *Ni* given by Eq. (18.11), but this would necessitate solving a complicated transcendental equation. Instead, we suppose that our system is in equilibrium at fixed temperature *T* and appeal to therm[odyn](#page-307-4)amics to identify β. We do this by relating the above expressions for *U* and

*S* by means of the thermodyna[mic e](#page-307-5)quation d*U* = *T* d*S* − *p* d*V* which holds at constant

*pi*dε*i* = *N* -

$$\mathbf{d}U = \mathcal{N} \sum_{l} \varepsilon_{l} \mathbf{d}p_{l} + \mathcal{N} \sum_{l} p_{l} \mathbf{d}\varepsilon_{l} = \mathcal{N} \sum_{l} \varepsilon_{l} \mathbf{d}p_{l} + \mathcal{N} \sum_{l} p_{l} \frac{\partial \varepsilon_{l}}{\partial V} \mathbf{d}V,\tag{18.15}$$

*i pi* ∂ε*i* ∂*V*

d*V*, (18.15)

ε*i* d*pi* + *N* -

*i*

4In Eq. (18.10), *z* is the partition function for an individual particle. We reserve the symbol *Z* for the partition function of the whole system that we shall later relate to *z*.

5Since the *pi* are probabilities, Eq. (18.12) actually gives the most probable value *E* of energy which we identify with the internal energy *U* that we will ultimately compute from a knowledge of the temperature. 6To get the entropy, we should really compute the logarithm of the total number of microstates by summing all values of ln *W*{*Ni*} that are compatible with the constraints. Instead, we approximate this sum by its

overwhelmingly largest term.

7See Section 19.1.3 for a similar treatment for a more general system.

288 THERMAL PHYSICS

where we have used

Eq. (18.16) we obtain

$$\mathrm{dS} = -\mathcal{N}k_{\mathrm{B}} \sum_{l} (\ln p_{l} + 1) \,\mathrm{d}p_{l} = -\mathcal{N}k_{\mathrm{B}} \sum_{l} \ln p_{l} \,\mathrm{d}p_{l}$$

$$= -\mathcal{N}k_{\mathrm{B}} \sum_{l} (-\beta \varepsilon_{l} - \ln z) \,\mathrm{d}p_{l} = \mathcal{N}k_{\mathrm{B}} \beta \sum_{l} \varepsilon_{l} \,\mathrm{d}p_{l},\tag{18.16}$$

*i*

where we have assumed that the energies of the states depend on the volume of the system. From Eq. (18.14), the differential of the entropy is

$$\mathbf{d}\,\mathbf{d}U = \frac{1}{k_{\mathrm{B}}\beta}\,\mathrm{d}\mathbf{S} + \mathcal{N}\sum_{l}p_{l}\frac{\partial\varepsilon_{l}}{\partial V}\,\mathrm{d}V.\tag{18.17}$$

= −*N k*B *i*

d*S* = −*N k*B

<span id="page-308-0"></span>
$$
\beta = \frac{1}{k_{\text{B}}T}.\tag{18.18}
$$

d*U* = 1 *k*Bβ d*S* + *N i pi* ∂*V* d*V*. (18.17)

-

*i*

-

$$p = -\mathcal{N} \sum_{l} p_{l} \frac{\partial \varepsilon_{l}}{\partial V},\tag{18.19}$$

We also o[btain](#page-308-0) [a](#page-308-0) useful equation for the pressure, namely *p* = −*N* - *pi* ∂ε*i* ∂*V* , (18.19)

$$\mathbf{S} = \frac{U}{T} + \mathcal{N}k_{\mathbf{B}} \ln \mathbf{z}.\tag{18.20}$$

with *U* = *N i pi*ε*i*. By using Eq. (18.11) to rewrite ln *pi*, the entropy given by Eq. (18.14) can be written in the form *S* = *U*

$$F = -\mathcal{N}k\mathfrak{g}\,T\ln z = -\frac{\mathcal{N}}{\beta}\ln z.\tag{18.21}$$

formula for the Helmholtz free energy *F* = −*N k*B*T* ln *z* = −*N* β ln*z*. (18.21) In Section 19.1.3, this derivation will be generalized to an **ensemble** of complicated systems (instead of a collection of weakly interacting particles). Such an ensemble is known as a **canonical ensemble** and allows for each complicated system to consist of

<span id="page-308-1"></span>many interacting particles. For such complicated systems, determination of the quantum

### states and the resulting partition functions can be quite difficult.

18.1.1 Summary of Results

$$p_l := \frac{\mathcal{N}_l}{\mathcal{N}} = \frac{\mathbf{e}^{-\beta e_l}}{\mathbf{z}},\tag{18.22}$$

<span id="page-309-1"></span>
$$z = \sum_{j} \mathbf{e}^{-\beta \varepsilon_{f}} \tag{18.23}$$

<span id="page-309-2"></span>
$$S = -\mathcal{N}k_{\rm B} \sum_{l=1} p_l \ln p_l = -\mathcal{N}k_{\rm B} \beta^2 \frac{\partial}{\partial \beta} \left[ \frac{\ln z}{\beta} \right]. \tag{18.24}$$

ln *z*

where β = 1/(*k*B*T*), *k*B is Boltzmann's constant, *T* is the absolute temperature, and

The internal energy is

$$U = \mathcal{N} \sum_{l=1} p_l s_l = -\mathcal{N} \frac{\partial}{\partial \beta} \ln z \tag{18.25}$$

*S* = −*N k*B -

<span id="page-309-3"></span><span id="page-309-0"></span>
$$F = -\frac{\mathcal{N}}{\beta} \ln z.\tag{18.26}$$

. (18.24)

*U* = *N* - *pi*ε*i* = −*N* ∂ ∂β ln *z* (18.25)

*i*=1

- *i*=1 and the Helmholtz free energy is
- *F* = −*N* β ln *z*. (18.26) In solving problems, one usually proceeds as follows:
	-
- Determine the subsystem states *i* having energies ε*i* from a m[odel](#page-309-0) [or](#page-309-0) from experimental
- data. • Calculate the partition function *z* and deduce the Helmholtz free energy *F* by using
- Eq. (18.26). • Obtain the entropy from *S* = −(∂*F*/∂*T*)*V*,*N* or from Eq. (18.24).

• Obtain the internal energy from *U* = *F* + *TS* or from Eq. (18.25). • Obtain the chemical potential per particle from μ = (∂*F*/∂*N* )*T*,*V* . • If the dependence of the ε*i* on volume *V* is known, determine the pressure from *p* = −(∂*F*/∂*V*)*T*,*N* . In following this procedure, it should be recognized that Eq. (18.26) yields *F* as a function of its natural variables *T*, *V*, and *N*, where *N* = *N* /*N* A is the mole number of particles, *N*A being Avogadro's number. We therefore recover the usual thermodynamic description of a monocomponent system. The volume *V* might enter because each particle occupies a volume *V*/*N* on which the energy levels ε*i* might depend. These particles, although identical, are supposed to be distinguishable by virtue of their position. If all particles were to *share* the same volume and were identical, they would not be distinguishable.

### equations would have to be modified.

18.2 Two-State Subsystems We apply the results of the previous section to a number *N* of identical but distinguishable two-state subsystems, each having nondegenerate energy levels ε1 and ε2. These subsystems are distinguishable because each is assumed to have a fixed location. In order to fo-

Such would be the case for a monatomic ideal gas, so to treat such a system the above

cus ideas, we consider the case in which each of our two-state systems is a particle having

<span id="page-310-0"></span>290 THERMAL PHYSICS

![](_page_310_Figure_1.jpeg)

ε 0

ε1 = *−*m0B [B](#page-310-0)

**FIGURE 18–1** Energy levels ε1 = −*m*0*B* and ε2 = *m*0*B* due to splitting by a magnetic field *B* for a spin 1/2 particle

<span id="page-310-1"></span>
$$\mathbf{z} = \mathbf{e}^{-\beta c_1} + \mathbf{e}^{-\beta c_2} = \mathbf{e}^{m_0 B \beta} + \mathbf{e}^{-m_0 B \beta}.\tag{18.27}$$

spin 1/2 in a magnetic field of strength *B*. Each particle can exist in two states, a state with "spin up" having energy ε1 = −*m*0*B* and a state with "spin down" having energy ε2 = *m*0*B*,

<span id="page-310-2"></span>
$$p_1 = \frac{\mathbf{e}^{-\beta c_1}}{z} = \frac{\mathbf{e}^{m_0 B \beta}}{\mathbf{e}^{m_0 B \beta} + \mathbf{e}^{-m_0 B \beta}} = \frac{1}{1 + \mathbf{e}^{-2m_0 B \beta}}\tag{18.28}$$

of these populations is

thermodynamics.

$$p_2 = \frac{\mathbf{e}^{-\beta c_2}}{z} = \frac{\mathbf{e}^{-m_0 B \beta}}{\mathbf{e}^{m_0 B \beta} + \mathbf{e}^{-m_0 B \beta}} = \frac{\mathbf{e}^{-2m_0 B \beta}}{1 + \mathbf{e}^{-2m_0 B \beta}}.\tag{18.29}$$

and *p*2 = e−βε2 *z* = e−*m*0*B*β e*m*0*B*β + e−*m*0*B*β = e−2*m*0*B*β 1 + e−2*m*0*B*β . (18.29) The latter expressions in Eqs. (18.28) and (18.29) involve only the energy gap ε := 2*m*0*B*

<span id="page-310-3"></span>
$$\frac{p_2}{p_1} = \mathbf{e}^{-2m_0B\beta} = \mathbf{e}^{-2m_0B/k_BT} = \mathbf{e}^{-\beta\varepsilon} \to \begin{cases} \mathbf{0} & \text{as } T \to \mathbf{0} \\ 1 & \text{as } T \to \infty. \end{cases} \tag{18.30}$$

*p*2 = e−2*m*0*B*β = e−2*m*0*B*/*k*B*T* = e−βε → 0 as *T* → 0 1 as *T* → ∞. (18.30)

*p*1 Thus at high temperatures, *p*1 = *p*2 = 1/2 and the states are equally probable.10 8We regard the state with "spin up" as having its magnetic moment in the same direction as the magnetic field,

and hence the lower energy. This unambiguous sign convention avoids the question of the connection between direction of the spin and the sign of the charge of a particle having spin.

9From the forms of Eqs. (18.22) and (18.23), it is clear for any system that the probabilities *pi* are invariant if ε*i* → ε*i* + ε for all energies, so the *pi* are independent of the zero of energy. 10A common misconception by new students of statistical mechanics is that all of the subsystems will be in their highest energy state as *T* → ∞. Nothing could be further from the truth! At sufficiently high temperatures, the entropy dominates the free energy *F*, and the internal energy becomes irrelevant. A state in which *p*2 > *p*1 would correspond formally to a negative temperature. Negative temperatures have been used to represent nonequilibrium states in which the population of the excited state has been "pumped" to some high level by means of some external stimulation, but such negative temperatures are outside the scope of conventional

<span id="page-311-0"></span>![](_page_311_Figure_1.jpeg)

-0.4 -0.2 U/(*N*m0B)

-1

-0.8 -0.6

$$U = \mathcal{N}\frac{\left(-m_0 B \,\mathrm{e}^{m_0 B \beta} + m_0 B \,\mathrm{e}^{-m_0 B \beta}\right)}{\mathrm{e}^{m_0 B \beta} + \mathrm{e}^{-m_0 B \beta}} = -\mathcal{N}m_0 B \,\mathrm{tanh}(\mathbf{x}),\tag{18.31}$$

The energy can be calculated directly from Eq. (18.2), resulting in *U* = *N* −*m*0*B* e*m*0*B*β + *m*0*B* e−*m*0*B*β e*m*0*B*β + e−*m*0*B*β = −*Nm*0*B* tanh(*x*), (18.31)

$$U \to \begin{cases} -\mathcal{N}m_0B & \text{as } T \to 0 \\ 0 & \text{as } T \to \infty. \end{cases} \tag{18.32}$$

dimensionless units. We observe that

−*Nm*0*B* as *T* → 0

*U* →

$$\mathcal{M} = -\frac{U}{B} = \mathcal{M}_0 \tanh(\mathbf{x}),\tag{18.33}$$

*M* = −*U B* = *M*0 tanh(*x*), (18.33) [where](#page-312-0) *M*0 := *Nm*0 is called the *saturation* magnetic moment. *M* decreases from *M*0 at *T* = 0 to zero as *T* → ∞, as shown in Figure 18–3. This type of magnetism, for which the interaction energy between subsystems having a magnetic moment is negligible, in known as **paramagnetism**. For *B* = 0, there is no splitting of the states, and no net magnetic mo-

ment. Ferromagnetic systems, in which there are strong interactions between magnetic subsystems, can have a magnetic moment without an applied magnetic field *B*.

Figure 18–4 shows a plot of *S* versus *T* in dimensionless units. We observe that

$$S = \mathcal{N}k_{\mathbb{B}}\left[\mathbf{x} + \ln(\mathbf{1} + \mathbf{e}^{-2\mathbf{x}}) - \mathbf{x}\tanh(\mathbf{x})\right].\tag{18.34}$$

. (18.34)

*S* = *N k*B

11See Section 19.6 for a general definition of the magnetic moment, *M* = −(∂*F*/∂*B*)*T* = −(∂*U*/∂*B*)*S*.

<span id="page-312-0"></span>![](_page_312_Figure_1.jpeg)

![](_page_312_Figure_2.jpeg)

2 4 6 8 10 0.2 0.4 0.6 *M*/*M*0 k T/ B (m0B) **FIGURE 18–3** Dimensionless magnetic moment 0.1 0.2 0.3 0.4 S/(*N*k ) B **FIGURE 18–4** Dimensionless entropy *S*/(*N k*B) versus

*M*/*M*0 versus dimensionless temperature *k*B*T*/(*m*0*B*) = 1/*x* for a two-state mag[netic](#page-312-1) system according to

1 2 3 4 5 k T/ B (m0B)

$$S \to \begin{cases} 0 & \text{as } T \to 0 \\ Nk_{\mathbb{B}} \ln 2 & \text{as } T \to \infty. \end{cases} \tag{18.35}$$

dimensionless temperature *k*B*T*/(*m*0*B*) = 1/*x* for a two-state magnetic system according to Eq. (18.34). At

proportional to 1/*T*, which is known as Curie's law.

0.5 0.6

<span id="page-312-2"></span>*S* → 0 [as](#page-312-2) *T* → 0 *N k*B ln 2 as *T* → ∞. (18.[35)](#page-312-3)

$$F = -Nk_\mathrm{B}T\ln(\mathbf{e}^\mathbf{x} + \mathbf{e}^{-\mathbf{x}}) = -Nk_\mathrm{B}T[\mathbf{x} + \ln(1 + \mathbf{e}^{-2\mathbf{x}})].\tag{18.36}$$

Alternatively, we can use Eq. (18.26) to obtain the Helmholtz free energy *F* = −*N k*B*T* ln(e*x* + e−*x*) = −*N k*B*T*[*x* + ln(1 + e−2*x*)]. (18.36) Note that Eq. (18.36) also results from *F* = *U* − *TS* with *U* given by Eq. (18.31) and *S* given

by Eq. (18.34). We can also differentiate Eq. (18.36) with respect to *T* to obtain −*S*, and then

<span id="page-312-1"></span>is shown in Figure 18–5. We note that

member of Eq. (18.24).12

$$F \to \begin{cases} -\mathcal{N}m_0B & \text{as } T \to 0 \\ -\mathcal{N}k_\mathbb{B}T\ln 2 & \text{as } T \to \infty. \end{cases} \tag{18.37}$$

<span id="page-312-3"></span>*F* → −*Nm*0*B* as *T* → 0 −*N k*B*T* ln 2 as *T* → ∞. (18.37)

At low temperatures, *F* behaves like the internal energy; however, at high temperatures, it

12For a system having *q* states, *p*1 → 1/*q* as *T* → ∞. Then the middle member of Eq. (18.24) yields *S* =

*N k*B ln *q*. 13Note from Eq. (18.36) that *F*/(*N m*0*B*) = −(1/*x*)[*x* + ln(1 + e−2*x*)].

behaves like −*TS* and becomes linear in *T* as *S* saturates to a constant value.

![](_page_313_Figure_1.jpeg)

1 2 3 4 5 -2.5 -2 -1.5 F/(*N*m0B)0.1 0.2 0.3 C /(*N*k ) BV

k T/ B (m0B)

**FIGURE 18–5** Dimensionless Helmholtz free energy *F*/(*N m*0*B*) versus dimensionless temperature *k*B*T*/(*m*0*B*) = 1/*x* for a two-state magnetic system according to Eq. (18.36). At *T* = 0, *F* is equal to *U*.

-3.5

1.19968.

![](_page_313_Figure_3.jpeg)

1 2 3 4 5 k T/ B (m0B) **FIGURE 18–6** Dimensionless heat capacity *CV* /(*N k*B) versus dimensionless temperature *k*B*T*/(*m*0*B*) = 1/*x* for

For large *T*, *F* is nearly equal to −*TS* with *S* nearly constant. are promoted to the upper state with increasing *T*. As *T* becomes very large, the population of the upper state becomes nearly equal to that of the lower state and can increase very little as *T* increases, resulting in

0.4

$$C_V = \mathcal{N}k_\text{B}\frac{4\mathbf{x}^2}{(\mathbf{e}^\mathbf{x} + \mathbf{e}^{-\mathbf{x}})^2} = \mathcal{N}k_\text{B}\mathbf{x}^2\text{sech}^2(\mathbf{x}),\tag{18.38}$$

a two-state magnetic system according to Eq. (18.38). A Schottky peak occurs at *k*B*T*/(*m*0*B*) ≈ 0.834 as spins

Finally, we can differentiate *U* with respect to *T* to obtain the heat capacity *CV* at constant volume, resulting in

*CV* = *N k*B 4*x*2 (e*x* + e−*x*)2 = *N k*B*x*2sech2(*x*), (18.38) where sech *x* = 1/ cosh *x* is the hyperbolic secant function. A plot of *CV* versus *T* in dimensionless units is shown in Figure 18–6. The peak14 near *m*0*B* = *k*B*T* is called a **Schottky peak** and occurs when the population

of the upper level increases at maximum rate with increasing *T*. At high *T*, *CV* → 0 because

The quantum energy levels of such an oscillator can be obtained in the Schrödinger

### the populations of the states become equal and no more increase in energy is possible as *T* increases.

18.3 Harmonic Oscillators

$$\mathcal{H} = \frac{p^2}{2m} + \frac{1}{2}kx^2,\tag{18.39}$$

*H* = *p*2 2*m* + 1 2 *kx*2, (18.39) where *p* is the momentum, *x* is the coordinate, *m* is the mass, and *k* is the spring constant.

14The actual position of the peak occurs at the positive root of tanh *x* = 1/*x*, which we estimate to be *x* =

$$\mathcal{H}\psi_{n} = \left(-\frac{\hbar^{2}}{2m}\frac{\partial^{2}}{\partial x^{2}} + \frac{1}{2}kx^{2}\right)\psi_{n} = \epsilon_{n}\psi_{n} \tag{18.40}$$

294 THERMAL PHYSICS picture by using the momentum operator *p* = −*ih*¯ ∂/∂*x* and solving the time-independent Schrödinger equation

<span id="page-314-0"></span>
$$
\epsilon_{\hbar} = \hbar \omega (n + 1/2),
\tag{18.41}
$$

to determine the wave functions ψ*n* and the energies *n* of the stationary states. The fact that the w[ave fu](#page-314-0)nctions ψ*n* have [to go](#page-314-1) to zero far outside the potential well (*k*/2)*x*2 leads to a set of allowable wave functions having parity (−1)*n*, where *n* = 0, 1, 2, ... is zero or a positive integer and nondegenerate energy levels15

<span id="page-314-2"></span>
$$
\varepsilon_{\hbar} = \hbar \alpha n. \tag{18.42}
$$

where ω := *k*/*m* is the classical angular frequency of the oscillator. The quantity *h*¯ ω/2 is known as the zero-point energy. Since energies in thermodynamics have an arbitrary zero, we will calculate the thermodynamic functions by using the shifted set of en[ergy le](#page-314-2)vels

*H*ψ*n* =

<span id="page-314-1"></span> − *h*¯ 2 2*m* ∂2

$$z = \sum_{n=0}^{\infty} \exp(-\beta \varepsilon_{\mathbb{R}}) = \sum_{n=0}^{\infty} \exp(-\beta \hbar \omega n) = \sum_{n=0}^{\infty} y^n,\tag{18.43}$$

ε*n* = *h*¯ ω*n*. (18.42)

potentials [will b](#page-309-0)e lowered by the constant amount *Nh*¯ ω/2. The partition function *z* = -∞ exp(−βε*n*) = -∞ exp(−β*h*¯ ω*n*) = -∞ *yn*, (18.43)

$$z = \frac{1}{1 - \mathbf{e}^{-\mathbf{x}}}.\tag{18.44}$$

summed by noting16 that *yz* = *z* − 1 which leads to *z* = 1/(1 − *y*) or

<span id="page-314-4"></span>*n*=0

$$F = \mathcal{N}k_{\mathbf{B}}T\ln(1 - \mathbf{e}^{-\mathbf{x}}).\tag{18.45}$$

. (18.47)

From Eq. (18.26), we determine the Helmholtz free energy to be

The entropy is therefore

<span id="page-314-3"></span>
$$S = -\frac{\partial F}{\partial T} = -\mathcal{N}k \mathbf{\tilde{s}} \left[ \ln(1 - \mathbf{e}^{-\mathbf{x}}) - \frac{\mathbf{x} \mathbf{e}^{-\mathbf{x}}}{1 - \mathbf{e}^{-\mathbf{x}}} \right],\tag{18.46}$$

*S* = −∂*F* ∂*T* = −*N k*B ln(1 − e−*x*) − *x* e−*x* 1 − e−*x* , (18.46)

$$U = F + TS = \mathcal{N}k_\mathcal{B}T\frac{\mathbf{x}\,\mathbf{e}^{-\mathcal{X}}}{1 - \mathbf{e}^{-\mathcal{X}}} = \mathcal{N}\hbar\omega\frac{1}{\mathbf{e}^{\mathcal{X}} - 1}.\tag{18.47}$$

e*x* − 1 15See practically any book on quantum mechanics for details. See Appendix I for an algebraic solution by

means of creation and annihilation operators. 16For any finite temperature, e−*x* < 1, so the series converges.

<span id="page-315-3"></span>
$$\langle n(T)\rangle := \frac{1}{\mathbf{e}^{\mathbf{x}} - 1} = \frac{1}{\exp(\hbar\omega/k_{\rm B}T) - 1} \tag{18.48}$$

*Chapter 18* • Distinguishable Particles with Negligible Interaction Energies 295

<span id="page-315-1"></span>
$$U \approx \mathcal{N} \hbar \omega \exp(-\hbar \omega / k_{\mathbb{B}} T), \quad \text{low } T. \tag{18.49}$$

quantity

$$\langle n(T)\rangle = \frac{1}{1 + \mathbf{x} + \mathbf{x}^2/2 + \cdots - 1} = \frac{1}{\mathbf{x} + \mathbf{x}^2/2 + \cdots} \approx \frac{1}{\mathbf{x}} = \frac{k_\mathbf{B}T}{\hbar\omega}.\tag{18.50}$$

temperatures, *[n](#page-315-0)*(*T*) ≈ exp(−*h*¯ ω/*k*B*T*), so

<span id="page-315-0"></span>
$$U \approx \mathcal{N}k_{\mathbb{B}}T,\quad\text{high }T.\tag{18.51}$$

At high *T*, we have *n*(*T*) = [1](#page-315-1) 1 + *x* + *x*2/2 +···− 1 = 1 *x* + *x*2/2 +··· ≈ 1 *x* = *k*B*T h*¯ ω . (18.50) Th[us](#page-315-2) *U* ≈ *N k*B*T*, high *T*. (18.51) Note that Eq. (18.51) is independent of ω and so would be true for *any* one-dimensional harmonic oscillator, irrespective of mass or force constant. We shall see later that the

<span id="page-315-2"></span>result given by Eq. (18.51) is the same as would be given by classical statistical mechanics (continuum of energies, no quantum states) at all temperatures. Indeed, as ω → 0 we have *x* → 0 so the expansion in Eq. (18.50) would be valid for any *T* > 0. Planck recognized that the result at low temperatures would be significantly different if the energy levels were quantized. Figure 18–7 shows a plot of the internal energy versus temperature. At low temperatures, hardly any oscillators can be excited to the first excited state, so *n*(*T*) 1.

Therefore, *U* remains very small until *x* ≈ 1, or *k*B*T* ≈ *h*¯ ω, at which temperature *U* begins to rise significantly, ultimately becoming linear in *T* as more and more quantum states

U/(*N*¯hω)

increases very little. For large *T*, Eq. (18.51) shows that *U* increases nearly linearly with *T*.

![](_page_315_Figure_11.jpeg)

k T/ B (¯hω) **FIGURE 18–7** Dimensionless internal energy *U*/(*Nh*¯ω) = *n*(*T*) versus dimensionless temperature *k*B*T*/(*h*¯ ω) = 1/*x* for one-dimensional harmonic oscillators according to Eq. (18.47). As *T* increases from zero, Eq. (18.49) shows that *U*

$$p_n = \exp[n\beta\hbar\omega]/z = \mathbf{e}^{-n\mathbf{x}}/z = \mathbf{e}^{-n\mathbf{x}}(1 - \mathbf{e}^{-\mathbf{x}}),\tag{18.52}$$

*n* = -∞

*npn* = *z*−1 -

∞

296 THERMAL PHYSICS

$$\langle n \rangle = \sum_{n=0}^{\infty} n p_n = z^{-1} \sum_{n=0}^{\infty} n \,\mathrm{e}^{-n\chi} = -z^{-1} \frac{\partial}{\partial \mathbf{x}} z = -\frac{\partial}{\partial \mathbf{x}} \ln z = 1/(\mathbf{e}^{\mathbf{x}} - 1). \tag{18.53}$$

**Solution 18.1.** From Eqs. (18.11), (18.42), and (18.44) we have *pn* = exp[*n*β*h*¯ ω]/*z* = e−*nx*/*z* = e−*nx*(1 − e−*x*), (18.52) where *x* = β*h*¯ω. Thus

*z* = − ∂

*n*=0 *n*[=](#page-316-0)0 ∂*x* ∂*x* Equation (18.53) is equivalent to calculating the average energy of a single oscillator from

<span id="page-316-1"></span>*n* e−*nx* = −*z*−1 ∂

$$C_V = Nk_\mathbf{B} \frac{\mathbf{x}^2 \mathbf{e}^\mathbf{x}}{(\mathbf{e}^\mathbf{x} - 1)^2},\tag{18.54}$$

ln *z* = 1/(e*x* − 1). (18.53)

The heat capacity of *N* one-di[mensi](#page-314-4)onal harmonic oscillators is *x*2 e*x*

<span id="page-316-0"></span>*CV* = *N k*B (e*x* − 1)2 , (18.54) which is plotted in Figure 18–8. Note at high temperatures that *CV* approaches the

constant value *N k*B. Unlike the two-state system, the harmonic oscillator has an infinite number of states, so *U* continues to increase with *T* as described by Eq. (18.51).

1

2

Similarly, the entropy does not saturate as *T* increases, as it would for subsystems

![](_page_316_Figure_13.jpeg)

0.5 1 1.5 2 2.5 3 k T/(¯hω) B **FIGURE 18–8** Dimensionless heat capacity *CV* /(*N k*B) versus dimensionless temperature *k*B*T*/(*h*¯ ω) = 1/*x* for one-dimensional harmonic oscillators according to Eq. (18.54). At high temperatures, *CV* tends to a constant, *N k*B, a behavior very different from that of

two-state subsystems, Figure 18–6.

![](_page_316_Figure_15.jpeg)

0.5 1 1.5 2 2.5 3 k T/ B (¯hω) **FIGURE 18–9** Dimensionless entropy *S*/(*N k*B) versus dimensionless temperature *k*B*T*/(*h*¯ ω) for one-dimensional harmonic oscillators according to Eq. (18.46). At low temperatures, *S* remains near zero until the first excited state is populated. At high temperatures, *S* continues to increase with *T* because

there is an infinite number of states to occupy.

![](_page_317_Figure_1.jpeg)

-1 -0.5 F/(*N*¯hω)

$$S \approx \mathcal{N}k_{\mathbb{B}} \left[ 1 + \ln(k_{\mathbb{B}}T/\hbar\omega) \right], \quad \text{high } T. \tag{18.55}$$

dimensional harmonic oscillators according to Eq. (18.45). *F* decreases with increasing *T* at an ever increasing rate, as described by Eq. (18.56).

**FIGURE 18–10** Dimensionless Helmholtz free energy *F*/(*Nh*¯ω) versus dimensionless temperature *k*B*T*/(*h*¯ ω) for one-

Figure 18–10 shows a plot of the Helmholtz free energy versus temperature. Since ∂*F*/∂*T* = −*S* < 0, *F* decreases with increasing *T*. From Eq. (18.45) we see that it diverges logarithmi-

$$F \approx -\lambda' k \lg T \ln(k \lg T / \hbar \omega), \quad \text{high } T. \tag{18.56}$$

### cally, that is,

-2

-1.5

*F* ≈ −*N k*B*[T](#page-316-1)* ln(*k*B*T*/*h*¯ ω), high *T*. (18.56) 18.3.1 Application: Heat Capacity of a Crystal The heat cap[acity of a on](#page-316-0)e-dimensional crystal can be modeled by considering a system made up of one-dimensional harmonic oscillators. Atoms in a crystal vibrate about their equilibrium positions with increasing amplitudes as the temperature increases.

$$\mathbf{C}_{\rm E} = \mathcal{N}k_{\rm B} \frac{\mathbf{x}_{\rm E}^{2} \exp(\mathbf{x}_{\rm E})}{[\exp(\mathbf{x}_{\rm E}) - 1]^{2}}; \quad \mathbf{x}_{\rm E} := \frac{T_{\rm E}}{T}, \tag{18.57}$$

*C*E = *N k*B *x*2 E exp(*x*E) [exp(*x*E) − 1]2 ; *x*E := *T*E *T* , (18.57) where the Einstein temperature *T*E := *h*¯ ωE/*k*B. Of course a graph of *C*E/(*N k*B) versus *T*/*T*E looks just like Figure 18–8. The point of inflection is located at about *T* = 0.4261*T*E, so *T*E is roughly at the knee of the curve, after which *C*E is practically constant. The Einstein model yields a curve with about the right shape, but it is wrong in detail at low temperatures. For a three-dimensional solid, the corresponding heat capacity would be larger by a factor of

3 because oscillations in different directions are decoupled. A better model can be based on a treatment that allows for vibrating atoms to be coupled to one another. In solid state physics courses, it is shown that oscillations of the

atoms can be described in terms of a set of spatially delocalized waves, each with its own

$$\mathcal{D}(\omega) = \frac{2N}{\pi} \frac{1}{\sqrt{1 - (\alpha/\omega_0)^2}} \frac{1}{\omega_0} \text{ for } \omega \le \alpha_0; \quad \mathcal{D}(\omega) = 0 \text{ for } \omega > \alpha_0. \tag{18.58}$$

frequency. Furthermore, each of these waves has the same nondegenerate energy levels as a one-dimensional harmonic oscillator at some appropriate frequency. For nearest neighbor interactions only, it can be shown that the allowed angular frequencies are distributed according to a distribution function

$$\int_{0}^{\omega_{0}} \mathcal{D}(\omega) \, \mathrm{d}\omega = \mathcal{N}. \tag{18.59}$$

Thus, the [numbe](#page-315-3)r of oscillators that have frequencies between ω and ω + dω is *D*(ω) dω.

1

1 − (ω/ω0)2

1 ω0

<span id="page-318-0"></span>*D*(ω) = 2*N* π

*U* =

*C* = ∂*U*

ω0

$$U = \int_0^{a_0} \mathcal{D}(\omega) \langle \eta \rangle \hbar \omega \,\mathrm{d}\omega = \int_0^{a_0} \mathcal{D}(\omega) \frac{\hbar \omega}{\exp(\hbar \omega / k_B T) - 1} \,\mathrm{d}\omega,\tag{18.60}$$

0 *D*(ω) dω = *N* . (18.59) To get the total internal energy, we form the integral

$$U \approx \int_{0}^{\omega_{0}} \mathcal{D}(\omega) \, k_{\mathbb{B}} T \, \mathrm{d}\omega = \mathcal{N} k_{\mathbb{B}} T,\tag{18.61}$$

0

where Eq. (18.48) has been used. At high temperatures, we can expand the exponential in Eq. (18.60) to get

$$C = \frac{\partial U}{\partial T} = k_{\mathbb{B}} \int_{0}^{\omega \rho} \mathcal{D}(\omega) \frac{\exp(\hbar \omega / k_{\mathbb{B}} T)}{(\exp(\hbar \omega / k_{\mathbb{B}} T) - 1)^{2}} \left(\frac{\hbar \omega}{k_{\mathbb{B}} T}\right)^{2} d\omega. \tag{18.62}$$

At any temperature, we can calculate the heat capacity

$$C = \mathcal{N}k_{\rm B} \frac{2}{\pi} \left(\frac{k_{\rm B}T}{\hbar \omega_{\rm 0}}\right) \int_{0}^{\mathcal{Y}0} \frac{\mathcal{Y}^{2} \mathbf{e}^{\mathbf{y}}}{\left(\mathbf{e}^{\mathbf{y}} - 1\right)^{2}} \frac{1}{\sqrt{1 - \left(\mathbf{y}/\mathcal{Y}_{\rm 0}\right)^{2}}} \,\mathrm{d}\mathbf{y},\tag{18.63}$$

*C* = *N k*B 2 π *k*B*T h*¯ω0 *y*0 0 *y*2 e*y* (e*y* − 1)2 1 1 − (*y*/*y*0)2 d*y*, (18.63)

$$\mathbf{C} = \mathcal{N}k \mathfrak{s} \frac{2\pi}{3} \left(\frac{k_{\rm B}T}{\hbar \omega_{0}}\right), \quad \text{low } T. \tag{18.64}$$

*C* = *N k*B 2π 3 *k*B*T h*¯ω0 , low *T*. (18.64) Equation (18.64) shows that *C* is linear in *T* at low *T* and not exponentially small, as it would be for the Einstein model (see Eq. (18.54) for large *x*). In three dimensions,

calculations along similar lines show that *C* = 3*N k*B*T* at high *T* and *C* ∝ *T*3 at low *T*.

18.3.2 Application: Blackbody Radiation Planck [55, 56] reasoned that radiation from a very small hole in a cavity, which is known as **blackbody radiation**, could be treated by assuming that the radiation was in equilibrium *Chapter 18* • Distinguishable Particles with Negligible Interaction Energies 299

<span id="page-319-1"></span>with harmonic oscillators that make up the vibrating atoms of the cavity. In particular, Planck assumed that the energy of that radiation at frequency ν could only be emitted in amounts *h*ν where *h* = 6.626 × 10−34 m2 kg s−1 is what we now call Planck's constant. This

$$\mathbf{E} = \mathbf{E}\rho \,\mathrm{e}^{\mathrm{i}(\mathbf{k}\cdot\mathbf{r}-\omega t)},\tag{18.65}$$

hole will reflect many times from the cavity walls and is very unlikely to exit, so the body behaves like a nearly perfect absorber.17 Radiation is made up of electromagnetic waves having electric and magnetic vectors perpendicular to their direction of propagation. The electric field for such a wave can be represented in [com](#page-319-0)plex notation by

<span id="page-319-2"></span>
$$\nabla^2 \mathbf{E} = \frac{1}{c^2} \frac{\partial^2 \mathbf{E}}{\partial t^2},\tag{18.66}$$

a complex amplitude, **r** = (*x*, *y*, *z*) is the position vector in Cartesian coordinates, **k** = (*kx*, *ky*, *kz*) is a wave vector that points in the direction of propagation, ω is an angular

$$
\omega = \sigma \mathbf{k},\tag{18.67}
$$

∇2**E** = 1 *c*2 ∂2**E** ∂*t*2 , (18.66) which results in18 ω = *ck*, (18.67) where *k* = (*k*2 *x* + *k*2 *y* + *k*2 *z* )1/2 is the magnitude of the wave vector. The electric field must also satisfy ∇ · **E** = 0 which requires **k** · **E**0 = 0, so **E** is perpendicular to the direction of propagation. Thus, there are two independent modes, known as polarizations, corresponding to two orthogonal orientations of the electric field in the plane perpendicular to the direction of propagation. Accompanying the electric field given by Eq. (18.65) is a magnetic field **B** that can be written in the same form. Then from the Maxwell equation

<span id="page-319-0"></span>**∇** × **E** = −(1/*c*)∂**B**/∂*t*, we can deduce **B** = ˆ **k** × **E**, where ˆ **k** = **k**/*k* is a unit vector in the direction of propagation. This shows that the corresponding magnetic [field i](#page-319-1)s at right angles to the electric field and in phase. We must also apply boundary conditions to account for the walls of the cavity. This can be done simply by assuming the cavity to be a cubical box of edge length *L* whose edges are parallel to Cartesian axes. This idealization is meaningful because the radiation emitted by two different blackbodies at the same temperature must be the same; otherwise, radiant energy could be transmitted from one body to another in the absence of a temperature difference, a violation of the second law of thermodynamics. Moreover, this must be true in each frequency range by means of the same argument with the addition of a filter to eliminate other frequencies. We could use real functions for the fields and make them

vanish on the walls of the box, but for traveling waves of the form of Eq. (18.65) it easier

18By working in Cartesian coordinates, it is easy to show that **∇** · **E** = *i***k** · **E**, ∇2**E** = −*k*2**E** and **∇** × **E** = *i***k** × **E**.

<sup>17</sup>In German, it is known as hohlraum, literally hollow space, or cavity.

$$k_{\mathbf{x}} = 2\pi \,\mathrm{n_{x}/L}; \quad k_{\mathbf{y}} = 2\pi \,\mathrm{n_{y}/L}; \quad k_{\mathbf{z}} = 2\pi \,\mathrm{n_{z}/L},\tag{18.68}$$

300 THERMAL PHYSICS to use periodic boundary conditions. Thus, we require **E**(*x*, *y*, *z*,*t*) = **E**(*x* + *L*, *y*, *z*,*t*) and similarly for the *y*- and *z*-directions to deduce *kx* = 2π*[nx](#page-315-3)*/*L*; *ky* = 2π*ny*/*L*; *kz* = 2π*nz*/*L*, (18.68) where *nx*, *ny*, and *nz* are integers, both positive and negative.19 Thus, the frequencies

ω(*k*) = ω(|**k**|) of the modes are known and form a discrete set. However, it is important to recognize that this is all based on classical electromagnetic theory and has nothing to do with quantum mechanics. The quantization actually enters from the quantum theory

$$U = 2\sum_{\mathbf{k}} \frac{\hbar\omega(|\mathbf{k}|)}{\exp(\hbar\omega(|\mathbf{k}|)/k_{\rm B}T) - 1},\tag{18.69}$$

inspired hypothesis. We can therefore use Eq. (18.48) for the thermal average, *n*(*T*), of the quantum number *n*. Thus, the thermal energy of the radiation is given by *U* = 2 - **k** *h*¯ ω(|**k**|) exp(*h*¯ ω(|**k**|)/*k*B*T*) − 1 , (18.69) where ω(|**k**|) is the frequency of an electromagnetic wave having wave vector **k**. This sum can be converted to an integral by recognizing that for sufficiently large *L* the

$$\sum_{\mathbf{k}} \mathcal{F}(\mathbf{k}) = \sum_{k_x} \sum_{k_y} \sum_{k_z} \frac{V}{(2\pi)^3} \Delta k_x \Delta k_y \Delta k_z \mathcal{F}(\mathbf{k}) \to \frac{V}{(2\pi)^3} \int_{\text{all }\mathbf{k}} \mathbf{d}^3 k \, \mathcal{F}(\mathbf{k}).\tag{18.70}$$

function *F*(**k**), - **k** *F*(**k**) = - *kx* - *ky* - *kz V* (2π )3 *kx ky kz F*(**k**) → *V* (2π )3 all **k** d3*k F*(**k**). (18.70)

$$\sum_{\mathbf{k}} \mathcal{F}(|\mathbf{k}|) \to \frac{V}{(2\pi)^3} \int_0^\infty 4\pi k^2 \,\mathrm{d}k \,\mathcal{F}(|\mathbf{k}|). \tag{18.71}$$

- **k** *F*(|**k**|) → *V* (2π )3 ∞ 0 4π*k*2 d*k F*(|**k**|). (18.71)

$$\sum_{\mathbf{k}} \mathcal{F}(|\mathbf{k}|) \to \frac{V}{2\pi^2} \frac{1}{c^3} \int_0^\infty \omega^2 \,\mathrm{d}\omega f(\boldsymbol{\alpha}).\tag{18.72}$$

ω2 dω*f* (ω). (18.72)

2π2

*c*3

0

20See, for example, Schiff [57, p. 517].

-

**k**

known result

<sup>19</sup>If real functions that vanish at the walls of the box are used, these wave vectors are reduced by a factor of 2, but the integers are only positive. This leads to a different density of modes in **k** space that is eight times larger, so the final outcome of calculations will be the same. See Example Problem 16.2 and Section 23.1 for treatment

of a rectangular box and more detail in a related context.

Thus, Eq. (18.69) becomes

<span id="page-321-0"></span>
$$U = \frac{V}{\pi^2} \frac{1}{c^3} \int_0^\infty \omega^2 \,\mathrm{d}\omega \frac{\hbar \omega}{\exp(\hbar \omega / k_\mathrm{B} T) - 1}. \tag{18.73}$$

*Chapter 18* • Distinguishable Particles with Negligible Interaction Energies 301

π2

*f*geo := 1 4π <span id="page-321-1"></span> 2π 0

dϕ

0

*c*3

0

$$U = \frac{V(k_{\rm B}T)^4}{\pi^2 c^3 \hbar^3} \int_0^\infty \, \text{d}x \frac{\mathbf{x}^3}{\mathbf{e}^\mathbf{x} - 1}. \tag{18.74}$$

*U* = *V* 1 ∞ ω2 dω *h*¯ ω

$$
\mu_V := \frac{U}{V} = \frac{(k_B T)^4 \pi^2}{15c^3 \hbar^3}.\tag{18.75}
$$

*U* = *V*(*k*B*T*)4 π2*c*3*h*¯ 3 ∞ 0 d*x x*3 e*x* − 1 . (18.74) The value of the integral turns out to be π4/15, so the energy density

*uV* := *U V* = (*k*B*T*)4π2 15*c*3*h*¯ 3 . (18.75) Equation (18.74) can be used to calculate the flux,*J*, of blackbody radiation from a small hole in the cavity by recognizing that the radiation propagates at speed *c* and falls onto a

given area from all directions that point from a hemisphere to its center. The flux results

$$J = \frac{1}{4} \text{cu}_V = \sigma_{\text{SB}} T^4,\tag{18.77}$$

confirmed experimentally.

Thu[s](#page-321-0)

<span id="page-321-2"></span>
$$
\sigma_{\rm SB} := \frac{\pi^2 k_{\rm B}^4}{60 \hbar^3 c^2} = 4.67 \times 10^{-8} \text{ watt m}^2 \,\text{K}^{-4} \tag{18.78}
$$

4

where σSB := π2*k*4 B

60*h*¯ 3*c*2 = 4.67 × 10−8 watt m2 K−4 (18.78) is known as the **Stefan-Boltzmann constant**. This *T*4 law for blackbody radiation has been

$$j_{\mu} = \frac{\hbar}{4\pi^2 c^2} \frac{\omega^3}{\exp(\hbar \omega / k_B T) - 1}; \quad \int_0^\infty j_\mu \, d\omega = J. \tag{18.79}$$

*j*ω = *h*¯ 4π2*c*2 ω3 exp(*h*¯ ω/*k*B*T*) − 1 ; ∞ 0 *j*ω dω = *J*. (18.79)

The quantity *j*ω dω is therefore the power per unit area of radiation emitted in the angular frequency interval dω centered about ω. We can investigate the shape of this spectral distribution as a function of temperature by introducing an arbitrary reference temperature *T*0, a dimensionless temperature

*t* := *T*/*T*0, and a dimensionless angular frequency *W* := *h*¯ ω/*k*B*T*0. Then *j*ω dω = *JW* d*W* = 15 *W*3

π4 σSB*T*4 0 exp(*W*/*t*) − 1 d*W*. (18.80) Figure 18–11 shows a plot of the dimensionless spectral distribution of radiation according

to Eq. (18.80) as a function of dimensionless frequency, *W*, for three dimensionless

<span id="page-322-0"></span>302 THERMAL PHYSICS

3

![](_page_322_Figure_1.jpeg)

1 2 *W*3 exp(*W/t*)*−*1t = 1 t = 1.25

2 4 6 8 10

W

**FIGURE 18–11** Plot of the dimensionless spectral distributi[on according to E](#page-322-0)q. (18.80) as a function of dimensionless frequency, *W*, for three dimensionless temperatures, *t* = 1, *t* = 1.25, and *t* = 1.5. The peaks of these curves increase in height as 1.42 *t*3, broaden in proportion to *t*, and move to higher frequencies *W* = 2.82 *t* wi[th increa](#page-321-1)sing *t*. The area under each curve is (π4/15)*t*4. temperatures, *t*. As *t* [increa](#page-321-2)ses, the peaks of these curves increase in height and move to

higher frequencies. The peaks occur for *h*¯ ω/*k*B*T* = *W*/*t* = 2.82, which is evident from the lower curve for which *T* = *T*0. This is sometimes referred to as **Wien's displacement law** and can be used to estimate the temperature of stars from their dominant frequency of radiation. The peak heights of the curves in Figure 18–11 are 1.42 *t*3 and the area under each curve is (π4/15)*t*4, so ∞ 0 *JW* d*W* = σSB*T*4 = *J*, in agreement with Eq. (18.77).

Note that the spectral distribution of radiation given by Eq. (18.80) is in agreement with the following familiar observation: As a body is heated to higher and higher temperatures, it begins to glow, first a dull cherry red, then a somewhat brighter orange, then yellow, then

$$\int_0^\infty \mathbf{j}_\mu \, \mathbf{d}\mu = \frac{1}{4\pi^2 \mathbf{c}^2} \int_0^\infty k \mathbf{p} \, T \omega^2 \, \mathbf{d}\mu = 2\pi \mathbf{c} \int_0^\infty k \mathbf{p} \, T \lambda^{-4} \, \mathbf{d}\lambda,\tag{18.81}$$

<span id="page-322-1"></span>1] → *k*B*T*, so ∞ 0 *j*ω dω = 1 4π2*c*2 ∞ 0 *k*B*T*ω2 dω = 2π*c* ∞ 0 *k*B*T*λ−4 dλ, (18.81) where the wavelength λ = 2π*c*/ω. These integrals do not converge, the former at ω → ∞ and the latter at λ → 0. Prior to the advent of quantum mechanics, this was known as the ultraviolet catastrophe. Quantum mechanics resolves this problem at large ω because *j*ω ∼ ω3 exp(−*h*¯ ω/*k*B*T*) which is strongly damped because of the extremely low probability

of exciting the high energy quanta*h*¯ ω. Planck's energy quantization hypothesis [55, 56] was the key to removing this singularity and stimulated the development of quantum theory.21

advancement of Physics by his discovery of energy quanta."

<sup>21</sup>The citation of Planck's 1918 Nobel Prize in Physics reads: "In recognition of the services he rendered to the

<span id="page-323-0"></span>
$$
\varepsilon(\mathbf{j}) = \mathbf{j}(\mathbf{j} + \mathbf{1})\varepsilon\mathbf{a},\tag{18.82}
$$

18.4 Rigid Linear Rotator We consider a system for which each particle is a rigid linear rotator, such as a diatomic molecule with only two degrees of rotational freedom. See Section 21.3.2 and Appendix F

$$\mathbf{z} = \sum_{j=0}^{\infty} (2j+1) \exp[-j(j+1)\mathbf{x}],\tag{18.83}$$

Here, *I* is the moment of inertia22 of the rotator with two degrees of freedom having principal moments of inertia (*I*, *I*, 0). In this case, the energy levels are degenerate, each corresponding to 2*j* + 1 states. The partition function for each particle is therefore ∞

*z* = *j*=0 (2*j* + 1) exp[−*j*(*j* + 1)*x*], (18.83)

$$z \approx \int_0^\infty (2j+1) \exp[-j(j+1)\mathbf{x}] \, \mathrm{d}j \, \mathrm{d}j \, \mathrm{d}k \, \tag{18.84}$$

leve[ls.](#page-309-3) For high temperatures, *x* is small and the energy levels are practically continuous. We

*x*

0

$$z = \frac{1}{x} \int_0^\infty \exp[-y] \,\mathrm{d}y = \frac{1}{x} = \frac{k_\mathrm{B}T}{\varepsilon_0} = \frac{1}{\beta \varepsilon_0}.\tag{18.85}$$

We set *y* = *j*(*j* + 1)*x* in which case d*y* = (2*j* + 1)*x* d*j* and Eq. (18.84) becomes *z* = 1 ∞ = 1

$$\text{Im}_{\text{T}}(\text{wenn}_{\text{}}, \text{wennum}_{\text{}}, \text{wennum}_{\text{}}) = \lambda \text{Im}_{\text{}}(\ln \beta + \ln \varepsilon_{0}) = \frac{\mathcal{N}}{\beta} = \mathcal{N}k_{\text{B}}T\tag{18.86}$$

Eq. (18.25[) we re](#page-309-3)adily obtain *U* = *N* ∂ ∂β (ln β + ln ε0) = *N* β = *N k*B*T* (18.86)

independent of ε0. This turns out to be the same result as would be obtained for a classical rotator. The corresponding heat capacity is *C* = *N k*B, which explains why diatomic gases have a correspondingly higher heat capacity (by *R* per mole) than monatomic gases.

$$z \approx 1 + 3\mathbf{e}^{-2\mathbf{x}} + 5\mathbf{e}^{-6\mathbf{x}} + \cdots \,\,\,\,\,\,\,\,\tag{18.87}$$

*z* ≈ 1 + 3e−2*x* + 5e−6*x* +··· . (18.87)

*U*

∂*x*

From Eq. (18.25), we obtain

which leads to

$$\frac{U}{\mathcal{N}\varepsilon_0} = -\frac{\partial}{\partial \mathbf{x}} \ln z = \frac{6\mathbf{e}^{-2\mathbf{x}} + 3\mathbf{0}\mathbf{e}^{-6\mathbf{x}}}{1 + 3\mathbf{e}^{-2\mathbf{x}} + 5\mathbf{e}^{-6\mathbf{x}}} + \cdots \,\,\,\,\,\tag{18.88}$$

*N* ε0 22For a diatomic molecule made up of point masses *m*1 and *m*2 separated by a distance 0, *I* = 2 0*m*1*m*2/ (*m*1 + *m*2).

<span id="page-324-0"></span>304 THERMAL PHYSICS

![](_page_324_Figure_1.jpeg)

0.4 0.6 C/(*N*k 

0.5 1 1.5 2 2.5 3

*C Nk*B = 1 + *x*2 45 +

0.2

)

B

$$\mathbf{C} = 12Nk_{\mathbf{B}}\mathbf{x}^{2}\mathbf{e}^{-2x}.\tag{18.89}$$

rigid rotator. Note especially t[he overshoot of th](#page-324-0)e asymptotic value, which is quite different from the monotonic increase of *C* for the harmonic oscillator.

To leading order, the low-temperature heat capacity is *C* = 12*N k*B*x*2e−2*x*. (18.89) We observe that *C* vanishes exponentially as *T* → 0 and therefore rises very slowly as *T* first increases. For intermediate values of the temperature, one must resort to series expansions or

numerical computations. A plot of the dimensionless heat capacity versus dimensionless temperature is shown in Figure 18–12. Unlike the heat capacity of the harmonic oscillator,

945 + *O*(*x*4)

$$\frac{C}{Nk_{\rm B}} = \left(1 + \frac{\mathbf{x}^2}{45} + \frac{16\mathbf{x}^3}{945} + O(\mathbf{x}^4)\right). \tag{18.90}$$

. (18.90)

Maclaurin sum formula discussed in Appendix H and results in

Eq. (18.90) shows clearly that *C* asymptotes *N k*B from larger values as *T* → ∞.

16*x*3

19 Canonical Ensemble In Chapter 16, we introduced the microcanonical ensemble which is based on the fundamental hypothesis that all microstates of an isolated system, compatible with a given macrostate and having a fixed energy and other specified macrovariables, are equally probable. This ensemble is of great theoretical importance but difficult to use because of the formidable problem of counting the number of microstates. We shall therefore use it to derive a more useful ensemble, known as the **canonical ensemble**, that is much more tractable. To do this, we give up a precise knowledge of the energy of our system of interest and specify instead its temperature. Nevertheless, its average energy will still be known

### temperature of our system can be imposed by contact with a heat reservoir, in which case our system is not isolated. The classical version of this ensemble, discussed in the

next chapter, was developed by Gibbs who named it "the distribution of phase called canonical" [4, p. 32]. 19.1 Three Derivations The canonical ensemble can be derived in a number of ways, all of which lead to the same final result in the thermodynamic limit. Because of the importance of this ensemble, we present three derivations, each of which emphasizes an aspect of the ensemble that is not transparent from the others. The methodology of the second derivation will be used

to high precision and will play the role of the internal energy of thermodynamics. The

### in Chapter 21 to derive the grand canonical ensemble and the methodology of the third derivation will be used in Chapter 22 to derive a number of ensembles from a general

expression for the entropy. 19.1.1 Derivation from Microcanonical Ensemble I We derive the canonical ensemble from the microcanonical ensemble by applying the fundamental hypothesis to an isolated total system with fixed energy *E*T, consisting of a reservoir *R* and a system *I* [of](http://dx.doi.org/10.1016/B978-0-12-803304-3.00019-3) [interest.](http://dx.doi.org/10.1016/B978-0-12-803304-3.00019-3) [The](http://dx.doi.org/10.1016/B978-0-12-803304-3.00019-3) [sy](http://dx.doi.org/10.1016/B978-0-12-803304-3.00019-3)stem *I* may, itself, be very large and consist of a number of subsystems, or particles, that may interact with one another. We assume that the system *I* has quantum states *Ei* and that its extensive macrovariables, other than

energy, are fixed. The index *i* indicates a specific quantum state, so it actually represents a complete set of quantum numbers. Suppose that the system *I* is in a *definite* quantum state *i* having energy *Ei*. Then the reservoir has energy *E*T − *Ei*. For the total system, the number of microstates can be expressed as a product of the number of microstates of the reservoir, -R, and the number of microstates of the system of interest, -, in the form

<span id="page-326-4"></span>
$$
\Omega_\Gamma^l = \Omega_\mathbb{R} (E_\Gamma - \mathcal{E}_l) \Omega(\mathcal{E}_l) = \Omega_\mathbb{R} (E_\Gamma - \mathcal{E}_l) \times \mathbf{1} = \Omega_\mathbb{R} (E_\Gamma - \mathcal{E}_l). \tag{19.1}
$$

306 THERMAL PHYSICS *i* T = -R(*E*T − *Ei*)-(*Ei*) = -R(*E*T − *Ei*) × 1 = -R(*E*T − *Ei*). (19.1)

$$\frac{P_l}{P_f} = \frac{\Omega_\mathrm{R}(E_\mathrm{T} - \mathcal{E}_l)}{\Omega_\mathrm{R}(E_\mathrm{T} - \mathcal{E}_f)} = \frac{\exp[\mathrm{Sq}_\mathrm{R}(E_\mathrm{T} - \mathcal{E}_l)/k_\mathrm{B}]}{\exp[\mathrm{Sq}_\mathrm{R}(E_\mathrm{T} - \mathcal{E}_f)/k_\mathrm{B}]},\tag{19.2}$$

Section 16.1, the probability of a system being in a given macrostate with energy *E*, volume *V*, and number of particles *N* is proportional to -(*E*, *V*, *N* ), which is the sum of its number of equally probable microstates. Therefore, the ratio of the probability *Pi* of system *I* being in the eigenstate *i* to the probability *Pj* of system *I* being in the eigenstate *j* is

$$\mathrm{S_R}(E_\mathrm{T} - \mathcal{E}_l) = \mathrm{S_R}[(E_\mathrm{T} - \mathcal{E}_f) + (\mathcal{E}_f - \mathcal{E}_l)] = \mathrm{S_R}(E_\mathrm{T} - \mathcal{E}_f) + (\mathcal{E}_f - \mathcal{E}_l)\frac{\partial S_\mathrm{R}}{\partial E_\mathrm{R}} + \cdots$$

$$= \mathrm{S_R}(E_\mathrm{T} - \mathcal{E}_l) + \frac{\mathcal{E}_l - \mathcal{E}_l}{T_\mathrm{R}} + \cdots,\tag{19.3}$$

expanding in [a Tay](#page-326-1)lor series we obtain1 *S*R(*E*T − *Ei*[)](#page-326-2) = *S*R[(*E*T − *Ej*) + (*Ej* − *Ei*)] = *S*R(*E*T − *Ej*) + (*Ej* − *Ei*) ∂*S*R ∂*E*R +···

= *S*R(*E*T − *Ej*) +

<span id="page-326-3"></span><span id="page-326-1"></span>
$$\frac{P_l}{P_l} = \frac{\exp(-\mathcal{E}_l/k_B T_\mathrm{R})}{\exp(-\mathcal{E}_l/k_B T_\mathrm{R})}.\tag{19.4}$$

where *T*R is the temperature of the reservoir. Substitution into Eq. (19.2) and cancellation of the factor exp[*S*R(*E*T − *Ej*)/*k*B] gives *Pi Pj* = exp(−*Ei*/*k*B*T*R) exp(−*Ej*/*k*B*T*R) . (19.4) Equation (19.4) [stat](#page-326-3)es that the probability *Pi* of system *I* being in eigenstate *i* is

$$Z = \sum_{j} \exp(-\beta \mathcal{E}_j) \tag{19.5}$$

<span id="page-326-0"></span>partition function

-

$$P_l = \frac{\exp(-\beta \mathcal{E}_l)}{Z},\tag{19.6}$$

<span id="page-326-2"></span>to obtain *Pi* = exp(−β*Ei*) *Z* , (19.6) where β = 1/(*k*B*T*). In Eq. (19.5), the sum is over all of the quantum states of the system of interest. Equation (19.5) resembles our former equation for the occupation probabilities

*Z* = -

derivation, the canonical ensemble will relate thermodynamically to the Helmholtz free energy.

*j*

*pi* = exp(−βε*i*)/*z* of weakly interacting distinguishable subsystems except that we are now 1The ratio of the second-order term to the first-order term is −(*Ej* −*Ei*)/(2*C*R*T*R), where *C*R is the heat capacity

of the reservoir. We assume that *C*R is so large that this term and higher order terms are negligible. This is essentially the definition of a heat reservoir. 2We must still bear in mind, however, that the canonical ensemble applies to a system in contact with a heat reservoir of constant temperature *T*. Given that other extensive variables of the system are held constant in this

$$U = \sum_{l} P_{l} \mathcal{E}_{l} = -\frac{\partial \ln Z}{\partial \beta},\tag{19.7}$$

*Chapter 19* • Canonical Ensemble 307

dealing with the states and energy levels of a *whole system*. The internal energy of our system is

$$F - T\frac{\partial F}{\partial T} = U,\tag{19.8}$$

which resembles *U* = −*N* ∂ ln *z*/∂β except that the factor of *N* is now missing because we are dealing with *Z* for the [whole](#page-327-0) system.

*U* = -

<span id="page-327-1"></span>*F* + β ∂*F*

<span id="page-327-0"></span>*i*

$$F + \beta \frac{\partial F}{\partial \beta} = -\frac{\partial \ln Z}{\partial \beta}.\tag{19.9}$$

*F* − *T* ∂*F* ∂*T* = *U*, (19.8) which, in terms of β, can be rewritten in the form

<span id="page-327-2"></span>
$$F = -\frac{1}{\beta} \ln Z + \frac{a}{\beta},\tag{19.10}$$

The left-hand side of Eq. (19.9) is recognized immediately to be ∂(β*F*)/∂β, so it [may be](#page-327-1) integrated to obtain

<span id="page-327-3"></span>
$$S = \frac{U - F}{T} = \frac{U}{T} + k_{\text{B}} \ln Z - k_{\text{B}} a. \tag{19.11}$$

where *a* is a function of integration (independent of β). The entropy is therefore *S* = *U* − *F T* = *U T* + *k*B ln *Z* − *k*B*a*. (19.11)

$$S(T \to 0) = k_{\rm B} \ln \mathbf{g}_0 - k_{\rm B} a.\tag{19.12}$$

*Z* →*g*0 exp(−β*E*0) and ln *Z* → ln *g*0−β*E*0. Similarly, as *T* →0 we have *U* →*E*0, so Eq. (19.11) becomes

practically zero.

$$\mathbf{S}(T \to \mathbf{0}) = k_{\mathrm{B}} \ln \mathbf{g}_{\mathrm{0}},\tag{19.13}$$

Consistent with Eq. (16.2), however, we require3

*F* = − 1 β

$$F = -\frac{1}{\beta} \ln Z \tag{19.14}$$

ln *Z* (19.14)

3Note that the value of *S*(*T* →0) according to Eq. (19.13) is not zero due to the possibility of degeneracy of the ground state. It would be strictly zero for a nondegenerate ground state for which *g*0 = 1. If this degeneracy were massive, say of order *g*0 = *qN* , where *q* is some integer and *N* is the number of subsystems or "particles" in the system, then *S*(*T* →0) would be *N k*B ln *q* which would be extensive and significant. Otherwise, *S*(*T* →0) is 308 THERMAL PHYSICS

macroscopic picture (on the right). Moreover,

*Pi* = -

*i* T -

the form

$$\sum_{j} \exp(-\beta \mathcal{E}_{j}) = \exp(-\beta F),\tag{19.15}$$

. (19.16)

$$\mathbf{S} = \frac{U}{T} - \frac{F}{T} = k_{\mathbf{B}} \boldsymbol{\beta} \boldsymbol{U} + k_{\mathbf{B}} \ln Z = -k_{\mathbf{B}} \sum_{l=1}^{\kappa} P_l \ln P_l = -k_{\mathbf{B}} \boldsymbol{\beta}^2 \frac{\partial}{\partial \boldsymbol{\beta}} \left[ \frac{\ln Z}{\boldsymbol{\beta}} \right]. \tag{19.16}$$

*j* exp(−β*Ej*) = exp(−β*F*), (19.15) which shows the relationship between the microscopic picture (on the left) and the

### *S* = *U T* [−](#page-326-4) *F T* = *k*Bβ*U* + *k*B ln *Z* = −*k*B κ *Pi* ln *Pi* = −*k*Bβ2 ∂ ∂β ln *Z*

<span id="page-328-0"></span>*i*=1 β Note that the quantity −κ *i*=1 *Pi* ln *Pi* = *D*{*Pi*} is the disorder function of information theory discussed in Section 15.1. 19.1.2 Derivation from Microcanonical Ensemble II

We give an alternative derivation of the canonical ensemble from the microcanonical

$$P_l = \frac{\mathfrak{D}_\Gamma^l}{\mathfrak{D}_\Gamma(E_\Gamma)} = \frac{\mathfrak{D}_\mathbb{R}(E_\Gamma - \mathcal{E}_l)}{\mathfrak{D}_\Gamma(E_\Gamma)} = \frac{\exp[\mathcal{S}_\mathbb{R}(E_\Gamma - \mathcal{E}_l)/k_\mathbb{B}]}{\exp[\mathcal{S}_\Gamma(E_\Gamma)/k_\mathbb{B}]}.\tag{19.17}$$

T given by Eq. (19.1) to the total number [of](#page-328-0) [mic](#page-328-0)rostates interest is *not restricted* to a specific microstate. Thus

$$\mathcal{S}_T(E_\Gamma) = \mathcal{S}_\mathbb{R}(E_\Gamma - U) + \mathcal{S}(U),\tag{19.18}$$

Since the entropy of a composite system is additive, we have *ST* (*E*T) = *S*R(*E*T − *U*) + *S*(*U*), (19.18)

$$P_l = \frac{\exp[-\mathcal{S}(U)/k_\mathcal{B}]\exp[\mathcal{S}_\mathcal{R}(E_\mathcal{T}-\mathcal{E}_l)/k_\mathcal{B}]}{\exp[\mathcal{S}_\mathcal{R}(E_\mathcal{T}-U)/k_\mathcal{B}]}.\tag{19.19}$$

Eq. (19.19) yields

succinct form

But

of *i*

<span id="page-328-1"></span>
$$\mathrm{S_R}(E_\mathrm{T} - \mathcal{E}_l) = \mathrm{S_R}[(E_\mathrm{T} - U) + (U - \mathcal{E}_l)] = \mathrm{S_R}(E_\mathrm{T} - U) + \frac{U - \mathcal{E}_l}{T_\mathrm{R}} + \dotsb,\tag{19.20}$$

*S*R [*E*T − *Ei*] = *S*R[(*E*T − *U*) + (*U* − *Ei*)] = *S*R(*E*T − *U*) + *U* − *Ei T*R +··· , (19.20)

$$P_l = \exp[-\mathcal{S}(U)/k_\mathcal{B}] \exp[U/k_\mathcal{B}T_\mathcal{R}] \exp[-\mathcal{S}_l/k_\mathcal{B}T_\mathcal{R}].\tag{19.21}$$

*Pi* = exp[−*S*(*U*)/*k*B] exp[*U*/*k*B*T*R] exp[−*Ei*/*k*B*T*R]. (19.21) Dropping the subscript on *T*R and using β = 1/*k*B*T*, Eq. (19.21) can be written in the

$$P_l = \exp(\beta F) \exp(-\beta \mathcal{E}_l),\tag{19.22}$$

$$\exp(-\beta F) = \sum_{l} \exp(-\beta \mathcal{E}_l) = Z \tag{19.23}$$

*Chapter 19* • Canonical Ensemble 309

where *F* = *U* − *TS* is the Helmholtz free ene[rg](#page-329-0)y. Since *i Pi* = 1, Eq. (19.22) yields exp(−β*F*) = - *i* exp(−β*Ei*) = *Z* (19.23) in agreement with our previous result[s, E](#page-329-1)qs. (19.14) and (19.15). 19.1.3 Derivation III: Most Probable Distribution In this section, we give yet another derivation of the canonical ensemble but from the point of view of the most probable distribution. We consider a large number *N*ens of

$$\sum_{l=1}^{r} P_l = 1.\tag{19.24}$$

members of the ensemble are in an eigenstate having energy *Ei* such that the probability of occurrence of that eigenstate is *Pi* = *Ni*/*N*ens. The set {*Ni*} = *N*1, *N*2, ... , *Nr* is such that *r i* =1 *Ni* = *N*ens which is equivalent to5

is essentially no problem even if *r* → ∞.

<span id="page-329-3"></span><span id="page-329-2"></span>
$$\sum_{l=1}^{r} P_l \mathcal{E}_l = E. \tag{19.25}$$

Since *r i*=1 *NiEi* = *N*ens*E*¯ , we also have

*r*

*i*=1

$$\mathcal{W}_{\rm ens} \{ \mathcal{N}_l \} := \frac{\mathcal{N}_{\rm lens}!}{\mathcal{N}_1! \mathcal{N}_2! \cdots \mathcal{N}_r!}. \tag{19.26}$$

The number of ways of constructing such an ensemble is *W*ens{*Ni*} := *N*ens! *N*1!*N*2!··· *Nr* ! . (19.26) We would like to choose the set {*Ni*}to maximize *W*ens{*Ni*} subject to the constraints above

<span id="page-329-0"></span>
$$
\ln \mathcal{W}_{\rm ens} = \mathcal{N}_{\rm ens} \ln \mathcal{N}_{\rm ens} - \sum_{l=1}^{r} \mathcal{N}_{l} \ln \mathcal{N}_{l} = -\mathcal{N}_{\rm ens} \sum_{l=1}^{r} P_{l} \ln P_{l}. \tag{19.27}
$$

<span id="page-329-1"></span>ln *W*ens = *N*ens ln *N*ens −*r Ni* ln *Ni* = −*N*ens *r Pi* ln *Pi*. (19.27)

*D*{*Pi*}=−-

*i*=1

$$D(P_l) = -\sum_{l=1}^{r} P_l \ln P_l,\tag{19.28}$$

*Pi* ln *Pi*, (19.28)

4If other extensive variables are necessary to specify our system of interest, they are also the same for all members of the ensemble. 5If a system has a number of eigenstates *r*, we certainly need *Ni* > *r* to represent the ensemble. But ultimately we can take the limit *N*ens → ∞ in such a way that *Ni* → ∞ but the ratio *Pi* = *NiN*ens remains finite. Thus, there <span id="page-330-1"></span>310 THERMAL PHYSICS

$$S = -k_{\rm B} \sum_{l=1}^{r} P_l \ln P_l = k_{\rm B} D(P_l),\tag{19.29}$$
 
$$\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\mathbf{1}_{\mathbf{1}_{\cdots}}}}}}}}}}}}}}}}}}}} \tag{\}} \quad \mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\mathbf{1}_{\mathbf{1}_{\cdots}}}}}}\}}}} \mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\mathbf{1}_{\mathbf{1}_{\cdots}}}}\}}\}}} \mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\{\mathbf{1}_{\mathbf{1}_{\cdots}}}}\}}\}}} \tag{19.20}$$

the number of microstates of the whole ensemble, so *k*B ln *[W](#page-329-2)*ens represents the entropy of the whole ensemble. Thus, *S* = (1/*N*ens)*k*B ln *W*ens is the entropy per system of the ensemble. It therefore plays the role of the thermodynamic entropy of the system that the ensemble represents. We therefore have *S* = −*k*B *r i*=1 *Pi* ln *Pi* = *k*B*D*{*Pi*}, (19.29)

where *D*{*Pi*} is seen to be a dimensionless measure of the entropy. We note that *D*{*Pi*} is the same as the disorder function of Section 15.1, where we have shown (see the first

$$\frac{\partial}{\partial P_{l}}\left(-\sum_{l=1}^{r} P_{l} \ln P_{l} - \beta \sum_{l=1}^{r} P_{l} \mathcal{E}_{l} - \alpha \sum_{l=1}^{r} P_{l}\right) = 0\tag{19.30}$$

In the maximization process, we handle the constraints by means of Lagrange multipliers β and α and solve the problem

<span id="page-330-2"></span>*i*=1

example problem) from its form that it is additive for a composite system. But here we are

$$-\ln P_f - 1 - \beta \mathcal{E}_f - \alpha = \mathbf{0},\tag{19.31}$$

∂*Pj i*=1

write the reversible work in the form

∂

 − *r*

$$P_f = \mathbf{e}^{-u-1} \mathbf{e}^{-\beta \mathcal{E}_f}.\tag{19.32}$$

− ln *Pj* − 1 − β*Ej* − α = 0, (19.31) which may be exponentiated to give *Pj* = e−α−1 e−β*Ej* . (19.32)

*i*=1

$$P_{\parallel} = \frac{\exp(-\beta \mathcal{E}_{\parallel})}{Z}.\tag{19.33}$$

*i Pi*∂*Ei*/∂*Yj*.

<span id="page-330-0"></span>*Pj* = exp(−β*Ej*) *Z* . (19.33) It remains to determine the Lagrange multiplier β. Formally, this could be done in terms of *E*¯ by satisfying the constraint Eq. (19.25) but this would lead to a difficult transcendental equation for β. Therefore, one takes instead an alternative approach by appealing to thermodynamics which allows β to be identified as a physical quantity. To strengthen this identification, we recognize that the energies *Ei* of the eigenstates

*j fj* d*Yj*, where the *fj* are generalized forces. Then *fj* = −

depend on the volume *V* of the system6 and its number of particles *N* . Then

<sup>6</sup>This is convenient but not essential to the identification of β. It simply allows the system to do reversible work δ*W* = *p* d*V*. If *Ei* were to depend on a set of extensive mechanical parameters *Yj* instead of just *V*, one could

$$\mathbf{d}\cdot\ddot{\mathbf{E}} = \sum_{l=1}^{r} \mathcal{E}_{l} \mathbf{d}P_{l} + \sum_{l=1}^{r} P_{l} \mathbf{d}\mathcal{E}_{l} = \sum_{l} \mathcal{E}_{l} \mathbf{d}P_{l} + \sum_{l=1}^{r} P_{l} \frac{\partial \mathcal{E}_{l}}{\partial V} \mathbf{d}V + \sum_{l=1}^{r} P_{l} \frac{\partial \mathcal{E}_{l}}{\partial \mathcal{N}} \mathbf{d}\mathcal{N}.\tag{19.34}$$

<span id="page-331-1"></span>*i*=1

into Eq. (19.34) th[en](#page-331-2) [giv](#page-331-2)es

the form

<span id="page-331-2"></span>*r*

<span id="page-331-0"></span>
$$\mathbf{dS} = -k_{\mathrm{B}} \sum_{l=1}^{r} (1 + \ln P_l) \, \mathrm{d}P_l = -k_{\mathrm{B}} \sum_{l=1}^{r} \ln P_l \, \mathrm{d}P_l = k_{\mathrm{B}} \beta \sum_{l=1}^{r} \mathcal{E}_l \, \mathrm{d}P_l,\tag{19.35}$$

d*E*¯ = *r Ei* d*Pi* +*r Pi* d*Ei* = - *Ei* d*Pi* +*r Pi* ∂*Ei* ∂*V* d*V* +*r Pi* ∂*Ei* ∂*N* d*N* . (19.34)

$$\mathrm{d}E = (k_{\mathrm{B}}\rho)^{-1}\mathrm{d}S + \sum_{l=1}^{r} P_{l} \frac{\partial \mathcal{E}_{l}}{\partial V} \mathrm{d}V + \sum_{l=1}^{r} P_{l} \frac{\partial \mathcal{E}_{l}}{\partial \mathcal{N}} \mathrm{d}\mathcal{N}.\tag{19.36}$$

d*S* = −*k*B *i*=1 *i*=1 *i*=1 *Ei* d*Pi*, (19.35) where *i* d*Pi* = 0 has been used in the second and third steps. Substitution of Eq. (19.35)

$$p = -\sum_{l=1}^{r} P_l \frac{\partial \mathcal{E}_l}{\partial V}; \quad \mu = \sum_{l=1}^{r} P_l \frac{\partial \mathcal{E}_l}{\partial \mathcal{N}}.\tag{19.37}$$

Comparison of Eq. (19.36) with d*U* = *T* d*S* − *p* d*V* + μd*N* and the identification *E*¯ = *U* shows that β = 1/(*k*B*T*) as expected. We also deduce *p* = −*r i*=1 *Pi* ∂*Ei* ∂*V* ; μ = *r i*=1 *Pi* ∂*Ei* ∂*N* . [(19](#page-329-2).37) According to Eq. (19.37), the pressure *p* can be interpreted heuristically as if ∂*Ei*/∂*V* were a force per unit area associated with each state and ∂*Ei*/∂*N* were an energy per particle associated with each state. From the forms of Eqs. (19.35) and (19.36), we see that a change

d*S* in entropy results from a change in populations *Pi* [at](#page-330-1) fixed *Ei*[; how](#page-330-2)ever, reversible work results from a change d*E*¯ of energy at constant *S*, and therefore from a change of *Ei* at constant population *Pi* and fixed particle number *N* . Similarly, the chemical potential μ results from a change in *Ei* with *N* at constant population *Pi* and fixed *V*.

$$U = \sum_{l=1}^{r} P_l \mathcal{E}_l,\tag{19.38}$$

*U* = *r*

$$\text{TS} = -k_{\text{B}}T\sum_{l=1}^{r}P_{l}(-\beta\mathcal{E}_{l} - \ln Z) = U + k_{\text{B}}T\ln Z. \tag{19.39}$$

*TS* = −*k*B*T* -*Pi*(−β*Ei* − ln *Z*) = *U* + *k*B*T* ln *Z*. (19.39)

Thus the Helmholtz free energy

$$F = U - T\mathbf{S} = -k_{\mathbf{B}}T\ln Z\tag{19.40}$$

*F* = *U* − *TS* = −*k*B*T* ln *Z* (19.40)

*i*=1

in agreement with Eq. (19.14) or (19.23). As an alternative procedure, we could have identified β by comparing d*U* with d*S* at constant *V* and *N* , in which case d*U* = *T* d*S*. Then we could calculate *S* from Eq. (19.39) and the results in Eq. (19.37) could be obtained from *p* = − ∂*F*/∂*V*, μ = − ∂*F*/∂*N* and Eq. (19.33).

312 THERMA[L PHYS](#page-329-3)ICS

$$
\langle \mathcal{N}_{l} \rangle = \frac{\sum_{\{\mathcal{N}_{l}\}} \mathcal{N}_{l} \mathcal{W}_{\text{ens}} \{\mathcal{N}_{l}\}}{\sum_{\{\mathcal{N}_{l}\}} \mathcal{W}_{\text{ens}} \{\mathcal{N}_{l}\}},\tag{19.41}
$$

Before leaving this section, we remark that instead of the most probable values of *Pj* or, equivalently *Nj* = *N*ens*Pj*, we could deal with the *mean* values *Nj* with respect to the quantities *W*ens{*Ni*} given by Eq. (19.26). Specifically, *Nj* = {*Ni*} *NjW*ens{*Ni*} {*Ni*} *W*ens{*Ni*} , (19.41)

### where the sums are to be taken over *all* values of the set {*Ni*} that are compatible with the constraint Eqs. (19.24) and (19.25), written in terms of the *Ni*. By means of a somewhat

technical and lengthy calculation (e.g., see Schrödinger [99, p. 27] or Pathria [8, p. 46]), it can be shown that *Nj* and *Nj* calculated for the most probable distribution are the same in the limit *N*ens → ∞. 19.2 Factorization Theorem

$$Z = \prod_{\ell=1}^{M} Z^{(\ell)},\tag{19.42}$$

partition function of the system factors into the product of partition functions of the elements. Thus

exp[−β*Ejk*] = -

*Z* = *M* =1 *Z*( ), (19.42) where *Z*( ) is the partition function of the element ( ).

$$
\mathcal{E}_{jk} = \mathcal{E}_f^{(1)} + \mathcal{E}_k^{(2)},\tag{19.43}
$$

, (19.44)

*k* ]. (19.45)

to any number of elements by further decomposition. We replace the single quantum number *i* by the composite quantum numbers *jk* and write

$$Z = \sum_{jk} \exp[-\beta \mathcal{E}_{jk}] = \sum_{jk} \exp[-\beta \mathcal{E}_j^{(1)}] \exp[-\beta \mathcal{E}_k^{(2)}] = Z^{(1)} Z^{(2)},\tag{19.44}$$

where

*Z* = -

*jk*

*Z*(1) = -

*j*

$$Z^{(1)} = \sum_{j} \exp[-\beta \mathcal{E}_{j}^{(1)}]; \quad Z^{(2)} = \sum_{k} \exp[-\beta \mathcal{E}_{k}^{(2)}].\tag{19.45}$$

*Z*(2)

*k* ] = *Z*(1)

negligible energy of interaction) identical but distinguishable particles (subsystems) by

exp[−β*E*(1)

*j* ]; *Z*(2) = -

19.2.1 Distinguishable Particles with Negligible Interaction We can recover our former results (Chapter 18) for *N* very weakly interacting (meaning

*k*

*j* ] exp[−β*E*(2)

<span id="page-333-0"></span>
$$Z = \sum_{l} \exp(-\beta \mathcal{E}_l) = \sum_{jl \ell \cdots} \exp[-\beta(\varepsilon_j^{(1)} + \varepsilon_k^{(2)} + \varepsilon_\ell^{(3)} + \cdots)] = \prod_{m}^{N} \sum_{n} \exp(-\beta \varepsilon_n^{(m)}) = \mathcal{Z}^{N}.\tag{19.46}$$

$$
\ln Z = \mathcal{N} \ln z, \quad \text{identical distinguish particles}, \tag{19.47}
$$

quantum states *n*. Thus *Z* = - *i* exp(−β*Ei*) = - *jk* ··· exp[−β(ε(1) *j* + ε (2) *k* + ε (3) +··· )] = *N m* - *n* exp(−βε(*m*) *n* ) = *zN* . (19.46)

From Eq. (19.46), we obtain ln *Z* = *N* ln *z*, identical distinguishable particles, (19.47) and our former equations (see Section 18.1.1 for a summary) for identical but distinguishable particles with negligible interaction energies are recovered. *The reader is encouraged to study the numerous examples in Chapter 18.* If the particles are identical but not distinguishable, for example particles of an ideal gas that share the same volume, then occupation of individual particle states does not constitute an independent state and the factorization theorem requires modification, as

illustrated [in the](#page-333-0) next section for a classical ideal gas. If the particles are identical fermions

### or identical bosons, their wave functions must obey quantum statistics so the occupation of their quantum states is correlated and factorization of the canonical partition function

is not possible. In Chapter 21, we introduce the grand canonical ensemble which enables factorization of the grand partition function for ideal Fermi and Bose gases. 19.3 Classical [Idea](#page-333-0)l Gas For a classical ideal gas, the identical particles do not interact, but since they *share* the same volume they are not distinguishable. In this case, the simple decomposition that led to Eq. (19.46) is not applicable. This is because an interchange of particles does not constitute a new quantum state. Nevertheless, if the gas is very dilute, in the sense that the number of particles is much smaller than the number of accessible single particle quantum states, the probability of multiply-occupied states will be very small. By **accessible quantum state**, we mean a state whose Boltzmann factor makes a significant contribution to the single-par[ticle](#page-333-1) [p](#page-333-1)artition function at the temperature under consideration. We can

$$Z \approx \frac{z^N}{N!}, \quad \text{dilute indstinguishable particles}, \tag{19.48}$$

so that

$$
\ln Z \approx \mathcal{N} \ln \mathbf{z} - \ln \mathcal{N} \approx \mathcal{N} \ln(\mathbf{z}/\mathcal{N}) + \mathcal{N}, \quad \text{dilute indistinguishable particles}, \tag{19.49}
$$

<span id="page-333-2"></span>, dilute indistinguishable particles, (19.48)

ln *Z* ≈ *N* ln *z* − ln *N* ! ≈ *N* ln(*z*/*N* ) + *N* , dilute indistinguishable particles, (19.49)

*Ei* → ε

where Stirling's approximation for ln *N* ! has been used.

Note that Eq. (19.48) is based on

<span id="page-333-1"></span>*Z* ≈ *zN*

$$\mathcal{E}_l \to \mathfrak{s}_j^{(1)} + \mathfrak{s}_k^{(2)} + \mathfrak{s}_\ell^{(3)} + \dotsb \tag{19.50}$$

314 THERMAL PHYSICS and the fact that it no longer matters *which* particles (subsystems) are in a given state. If all of the terms on the right-hand side of Eq. (19.50) correspond to *different* single particle

### the single particle states are the same, then *N* ! would be an overestimate. If, however, the system is dilute in the sense that the probability of multiple occupation of a single

particle state is negligible, then *N* ! is a good estimate of the overcount and Eq. (19.48) holds approximately.7 The factor 1/*N* ! is the same Gibbs correction factor that we discussed in Section 16.4.1 in connection with the microcanonical ensemble, but now we are in a position to better understand the conditions for its applicability.

states, the result in Eq. (19.46) would be too large by exactly a factor of *N* !. If some of

$$
\varepsilon_{\mathbf{n}_x, \mathbf{n}_y, \mathbf{n}_z} = \frac{\hbar^2}{2m} (2\pi)^2 \left[ \left(\frac{\mathbf{n}_x}{H}\right)^2 + \left(\frac{\mathbf{n}_y}{K}\right)^2 + \left(\frac{\mathbf{n}_z}{L}\right)^2 \right]. \tag{19.51}
$$

boundary conditions ψ(*x* + *H*, *y*, *z*) = ψ(*x*, *y*, *z*), ψ(*x*, *y* + *K*, *z*) = ψ(*x*, *y*, *z*), and ψ(*x*, *y*, *z* +

gives

[12, pp. 100-103] for further discussion.

<span id="page-334-0"></span>
$$z = \sum_{n_x, n_y, n_z} \exp(-\beta \varepsilon_{n_x, n_y, n_z})$$

$$= \sum_{n_x} \exp\left[-\beta \frac{\hbar^2}{2m} \left(\frac{2\pi n_x}{H}\right)^2\right] \sum_{n_y} \exp\left[-\beta \frac{\hbar^2}{2m} \left(\frac{2\pi n_y}{K}\right)^2\right] \sum_{n_z} \exp\left[-\beta \frac{\hbar^2}{2m} \left(\frac{2\pi n_z}{L}\right)^2\right]$$

$$= \sum_{k_x} \exp\left[-\beta \frac{\hbar^2}{2m} k_x^2\right] \sum_{k_y} \exp\left[-\beta \frac{\hbar^2}{2m} k_y^2\right] \sum_{k_z} \exp\left[-\beta \frac{\hbar^2}{2m} k_z^2\right]. \tag{19.52}$$

<span id="page-334-1"></span>= - *kx* exp −β *h*¯ 2 2*m k*2 *x* - *ky* exp −β *h*¯ 2 2*m k*2 *y* [-](#page-334-1) *kz* exp −β *h*¯ [2](#page-334-1) 2*m k*2 *z* . [(19.52)](#page-334-0) Equation (19.52) shows that the single particle partition function factors, one factor for

each direction in three-dimensional space. Moreover, if *k*B*T* is large compared to the splittings between states, the sums in Eq. (19.52) can be approximated by integrals, *viz*., *h*¯ 2 2 *h*¯ 2 ∞ *h*¯ 2

*nx* exp −β 2*m* 2π*nx H* = *kx* exp −β 2*m k*2 *x* ≈ *H* 2π −∞ d*kx* exp −β 2*m k*2 *x* . (19.53) The factor of *H*/(2π ) on the right-hand side of Eq. (19.53) arises because *kx* changes by 2π/*H* as *nx* changes by one. Applying Eq. (19.53) to each of the products in Eq. (19.52)

<sup>7</sup>An alternative derivation of this result can be based on use of the grand canonical ensemble, which allows the number of particles to be indefinite but specifies the chemical potential. See Section 21.2.4 and Chandler

$$z = \frac{H\mathcal{K}}{(2\pi)^3} \int_{-\infty}^{\infty} \mathrm{d}k_x \exp\left[-\beta \frac{\hbar^2}{2m} k_x^2\right] \int_{-\infty}^{\infty} \mathrm{d}k_\mathcal{V} \exp\left[-\beta \frac{\hbar^2}{2m} k_\mathcal{V}^2\right] \int_{-\infty}^{\infty} \mathrm{d}k_z \exp\left[-\beta \frac{\hbar^2}{2m} k_z^2\right]$$

$$= \frac{V}{(2\pi)^3} \int_{\mathbf{k}} \mathrm{d}^3k \, \exp\left[-\beta \frac{\hbar^2}{2m} k^2\right] = V \left(\frac{mk_\mathcal{B}T}{2\pi\hbar^2}\right)^{3/2}. \tag{19.54}$$

*Chapter 19* • Canonical Ensemble 315 *z* = *HKL* (2π )3 ∞ −∞ d*kx* exp −β *h*¯ 2 2*m k*2 *x* ∞ −∞ d*ky* exp −β *h*¯ 2 2*m k*2 *y* ∞ −∞ d*kz* exp −β *h*¯ 2 2*m k*2 *z* 

<span id="page-335-0"></span>
$$\frac{1}{V} \sum_{\mathbf{k}} \to \frac{1}{(2\pi)^3} \int_{\mathbf{k}} \mathbf{d}^3 k,\tag{19.55}$$

result, one can eith[er](#page-335-0) [do](#page-335-0) [t](#page-335-0)he individual Cartesian integrals, each of which has the same value (*mk*B*T*/2π*h*¯ 2)1/2, or do the three-dimensional integral in polar coordinates. The prescription

In Eq. (19.54), the integral on the second line is over all of **k** space. To get the final

<span id="page-335-1"></span>(2π )3

which is valid when the state energies are closely spaced compared to *k*B*T*, becomes exact

1 *V* - → 1 d3*k*, (19.55)

**k**

λB ∼ λT :=

−β *h*¯ 2 2*m k*2 = *V*

of states whose separations tend to zero.

$$z = \text{Vn}_{\text{Q}},\tag{19.56}$$

in the limit *V* → ∞, in which case the sum on the left-hand side is over an infinite number

= *V* (2π )3 **k** d3 *k* exp

$$n_{\rm Q} \coloneqq \left(\frac{mk_{\rm B}T}{2\pi\hbar^2}\right)^{3/2} \tag{19.57}$$

where *n*Q := *mk*B*T* 2π*h*¯ 2 3/2 (19.57)

$$
\lambda_{\rm B} \sim \lambda_{\rm T} := \left(\frac{2\pi\hbar^2}{mk_{\rm B}T}\right)^{1/2},\tag{19.58}
$$

**wavelength**

which leads to

$$n_{\mathcal{Q}} = \frac{1}{\lambda_{\mathcal{T}}^3}.\tag{19.59}$$

*n*Q = 1 λ3 T . (19.59) To see when our approximation of a dilute gas is valid, we note that the magnitude of the partition function *z* is a rough measure of the number of single particle quantum states accessible to a particle at a given temperature. We therefore want *z* to be much greater than the number of particles, that is, *z*/*N* 1. By substituting *z* from Eq. (19.56), we obtain *n*Q *N* /*V* =: *n* or alternatively (λ3 T) - *V*/*N* = 1/*n*. In other words, the concentration of the gas must be sufficiently low that the volume per particle, 1/*n* is very large compared to the cube of the thermal wavelength. For situations in which this inequality is not satisfied, quantum effects become important and the particles must be treated either as fermions or bosons, depending on whether their spin is half integral or integral.

(per particle) is

<span id="page-336-1"></span>
$$
\ln Z = \mathcal{N} \ln(V/\mathcal{N}) + \mathcal{N} \ln n_{\mathcal{Q}} + \mathcal{N}, \quad \text{ideal gas.} \tag{19.60}
$$

$$F = -N\mathbf{k}_{\rm B}T\ln(V/N) - N\mathbf{k}_{\rm B}T\ln n_{\rm Q} - N\mathbf{k}_{\rm B}T,\quad\text{ideal gas,}\tag{19.61}$$

<span id="page-336-0"></span>Substitution of Eq. (19.56) into Eq. (19.49) yields

$$U = -\frac{\partial}{\partial \beta} [\mathcal{N} \ln(V/\mathcal{N}) + \mathcal{N} \ln n_{\mathcal{Q}} + \mathcal{N}] = \frac{3}{2} \mathcal{N} \frac{\partial \ln \beta}{\partial \beta} = \frac{3}{2} \mathcal{N} k_{\mathcal{B}} T, \quad \text{ideal gas}, \tag{19.62}$$

*F* [= −](#page-336-1)*N k*B*T* ln(*V*/*N* ) − *N k*B*T* ln *n*Q − *N k*B*T*, ideal gas, (19.61) which is an extensive function, as required. By applying Eq. (19.7) to ln *Z* expressed by Eq. (19.60), we obtain *U* = − ∂ 3 *N* ∂ lnβ

$$\text{dimension amount or Eq. (12.5.17) to account.}$$

$$p = -\frac{\partial F}{\partial V} = \mathcal{N} \text{kg} \, T \frac{\partial \ln V}{\partial V} = \frac{\mathcal{N} \text{kg}}{V} = \frac{\text{NRT}}{V}, \quad \text{ideal gas,} \tag{19.63}$$

<span id="page-336-2"></span>term in *n*Q contributes to Eq. (19.62) so this same result would have been obtained if we had used the (incorrect) partition function *Z* = *zN* . The pressure can be determined by differenti[ation o](#page-336-2)f Eq. (19.61) to obtain *p* = − ∂*F* ∂ ln *V*

**Lemma**
**a**
o
o.**
uamarar
o
y
umar
uamarar
o
i.
uag
(
$$\ln \rho_Q$$
)
o
o.
o.
uag
uamar
o.

$$S = -\frac{\partial F}{\partial T} = \mathcal{N}k_\mathcal{B}[\ln(n_Q V/N) + (5/2)], \quad \text{ideal gas.}\tag{19.64}$$

if we had used the (incorrect) partition function *Z* = *zN* . On the other hand, the entropy can be obtained by differentiation of Eq. (19.61) to obtain *S* = −∂*F* ∂*T* = *N k*B[ln(*n*Q*V*/*N* ) + (5/2)], ideal gas. (19.64) Equation (19.64) is known as the **Sackur-Tetrode equation** and requires use of the correct

$$\mathbf{S} = \mathcal{N}\mathbf{k}_{\rm B}[\ln(V/N) + (3/2)\ln T] + \mathcal{N}\mathbf{s}_{0}, \quad \text{ideal gas}, \tag{19.65}$$

mechanical. Classical thermodynamics alone would yield *S* = *N k*B[ln(*V*/*N* ) + (3/2)ln *T*] + *N s*0, ideal gas, (19.65)

$$\mu = \frac{\partial F}{\partial N} = k_{\text{B}} T \ln[N/(V \text{n}_{\text{Q}})] = k_{\text{B}} T \ln[p/(n_{\text{Q}} k_{\text{B}} T)], \quad \text{ideal gas}, \tag{19.66}$$

μ = ∂*F* ∂*N* = *k*B*T* ln[*N* /(*Vn*Q)] = *k*B*T* ln[*p*/(*n*Q*k*B*T*)], ideal gas, (19.66) and requires use of the correct partition function. In the second form of this expression,

the quantity *p*Q := *n*Q*k*B*T* ∝ *T*5/2 plays the role of a quantum pressure.

8See Fermi [1, chapter VIII] for an excellent discussion of the entropy of mercury vapor.

$$\frac{\hbar^2 k^2}{2m} \to \frac{1}{2}mv^2,\tag{19.67}$$

19.4 Maxwell-Boltzmann Distribution We can obtain the well-known Maxwell-Boltzmann (MB) distribution function for the velocities of ideal gas molecules by using Eq. (19.51) in the classical limit

$$M(\mathbf{v}) = A \exp\left(-\frac{mv^2}{2k_\mathrm{B}T}\right). \tag{19.68}$$

<span id="page-337-1"></span>where *v* 2 = *v* 2 *x* + *v* 2 *y* + *v* 2 *z* . By the argument following Eq. (19.50), we note that the approximate correction factor 1/*N* ! gives equal weighting to every single particle state, so it can be ignored in calculating the probability density function *M*(**v**) for the velocity **v** = *vx*ˆ **i** + *vy*ˆ **j** + *vz* ˆ **k** of a single particle, which takes the form

$$1 = \int M(\mathbf{v}) \, \mathrm{d}^3 v = 4\pi A \int_0^\infty v^2 \exp\left(-\frac{mv^2}{2k_B T}\right) \, \mathrm{d}v = A \left(\frac{2\pi k_B T}{m}\right)^{3/2},\tag{19.69}$$

a gas molecule having a velocity in the infinitesimal volume element d3

arbitrary units.

Therefore, th[e norm](#page-337-0)alization is

1 = 

<span id="page-337-0"></span>
$$M(\mathbf{v}) = \left(\frac{m}{2\pi k_{\rm B}T}\right)^{3/2} \exp\left(-\frac{mv^2}{2k_{\rm B}T}\right). \tag{19.70}$$

*v* centered about **v**.

<span id="page-337-2"></span>0 2*k*B*T m* which leads to *M*(**v**) = *m* 3/2 exp  − *mv* 2 . (19.70)

2π*k*B*T* 2*k*B*T* As shown in Section 20.1, Eq. (19.70) can also be obtained by using the classical canonical ensemble rather than from the classical limit of the quantum mechanical result as

![](_page_337_Figure_12.jpeg)

(a) *−|***v***| |***v***|* (b) **FIGURE 19–1** Maxwell-Boltzmann distributions for an ideal gas. (a) The velocity distribution, *M*(**v**), according to Eq. (19.70). (b) The speed distribution *M*˜ (*v*) according to Eq. (19.75). In both (a) and (b), for the sake of illustration, the curves with the higher peaks correspond to 2*k*B*T*/*m* = 1 and those with the lower peaks to 2*k*B*T*/*m* = 2, in

**distribution**. The mean *velocity* is

**v** := 

<span id="page-338-3"></span>**v** *M*(**v**) d3

*M*(**v**) d3*v* =

*i*=*x*,*y*,*z*

*v* =

$$\mathbf{v}(\mathbf{v}) := \int \mathbf{v} M(\mathbf{v}) \, \mathbf{d}^3 v = \left(\frac{m}{2\pi k_\mathrm{B} T}\right)^{3/2} \int \mathbf{v} \exp\left(-\frac{mv^2}{2k_\mathrm{B} T}\right) \, \mathbf{d}^3 v = \mathbf{0}.\tag{19.71}$$

318 THERMAL PHYSICS speed. The form on the right-hand side of Eq. (19.70) is known as a **normalized Gaussian**

 *m* 3/2 **v** exp  − *mv* 2 d3*v* = 0. (19.71)

2π*k*B*T* 2*k*B*T* This can be seen by writing **v** = *vx*ˆ **i**+*vy*ˆ **j**+*vz* ˆ **k**, *v* 2 = *v* 2 *x* +*v* 2 *y* +*v* 2 *z* , d3 *v* = d*vx* d*vy* d*vz* and doing the integrals in Cartesian coordinates, *viz*.,

$$M(\mathbf{v})\,\mathrm{d}^3v = \prod_{l=x,y,z} \left(\frac{m}{2\pi k_\mathrm{B}T}\right)^{1/2} \exp\left(-\frac{mv_l^2}{2k_\mathrm{B}T}\right)\,\mathrm{d}v.\tag{19.73}$$

even function of *vx*. In fact, the velocity distribution factors into normalized distribution functions for each Cartesian velocity compon[ent:9](#page-337-1)

<span id="page-338-2"></span>
$$
\langle v^2 \rangle := \int v^2 \, M(\mathbf{v}) \, \mathbf{d}^3 v \tag{19.74}
$$

<span id="page-338-0"></span>Therefore, the average value of any odd power of a velocity component will vanish. The mean squared velocity is *v* 2 := *v* 2 *M*(**v**) d3*v* (19.74)

$$\tilde{M}(v) := \int_0^{2\pi} \, \mathrm{d}\Phi \int_0^{\pi} \sin \Theta \, \mathrm{d}\Theta \, v^2 M(\mathbf{v}) = 4\pi \left(\frac{m}{2\pi k_B T}\right)^{3/2} v^2 \exp\left(-\frac{mv^2}{2k_B T}\right). \tag{19.75}$$

*speed* distribution function 2π π

d

0

0

*M*˜ (*v*) is normalized such that

*M*˜ (*v*) :=

the form

$$\int_{0}^{\infty} \tilde{M}(v) \, \mathbf{d}v = 1. \tag{19.76}$$

<span id="page-338-1"></span> ∞ 0 *M*˜ (*v*) d*v* = 1. (19.76) The speed distribution function *M*˜ (*v*) is sketched in Figure 19–1b. Note that this function peaks at a positive value of *v* because of the *v* 2 that comes from the volume element d3 *v*. *M*˜ (*v*) d*v* is therefore the probability of finding a particle with speed between *v* and *v* + d*v*, or alternatively the probability of finding a particle with velocity in a spherical shell of inner radius *v* and outer radius *v* + d*v*. Equation (19.74) may therefore be written in

9Given *N* numbers *a*1, ... , *aN* , their product is denoted by *N j*=1*aj* = *a*1×*a*2×· · ·×*aN* . Note that if α is constant, this implies that *N j*=1α*aj* = α*NN j*=1*aj*.

$$\langle v^2 \rangle = \int_0^\infty v^2 \tilde{M}(v) \, \mathrm{d}v = 4\pi \left(\frac{m}{2\pi k_\mathrm{B} T}\right)^{3/2} \int_0^\infty v^4 \exp\left(-\frac{mv^2}{2k_\mathrm{B} T}\right) \, \mathrm{d}v = \frac{3k_\mathrm{B} T}{m}.\tag{19.77}$$

$$
\frac{1}{2}m\langle v^2\rangle = \frac{3}{2}k_\text{B}T.\tag{19.78}
$$

*v* 2 = ∞ 0 *v* 2 *M*˜ (*v*) d*v* = 4π *m* 2π*k*B*T* 3/2 ∞ 0 *v* 4 exp − *mv* 2 2*k*B*T* d*v* = 3*k*B*T m* . (19.77) In view of Eq. (19.73), we have *v* 2 *x* =*v* 2 *y* =*v* 2 *z* = (1/3)*v* 2 = *k*B*T*/*m*. According to Eq. (19.77), the average kinetic energy is 1 2 *mv* 2 = 3 2 *k*B*T*. (19.78) Equation (19.78) can be interpreted to mean that there is (1/2)*k*B*T* of average kinetic energy associated with each of the translational degrees of freedom in the three Cartesian (*x*, *y*, *z*) directions, which is consistent with the principle of equipartition of energy which is valid in the classical limit of high temperatures (see Sections 20.2 and 20.3). The heat capacity of one mole of an ideal gas would therefore be 3*R*/2, or about 3 cal/mol. Recall

that the average energy of a one-dimensional harmonic oscillat[or at h](#page-338-0)igh temperature is *k*B*T*; in this case, there is also equipartition of energy, but (1/2)*k*B*T* comes from kinetic

Eq. (19.73) to obtain

three dimensions because *v* =

energy and (1/2)*k*B*T* comes from potential energy. Thus the heat capacity of one mole of a solid, which behaves as if each atom were a three-dimensional harmonic oscillator, would be 3*R*, or about 6 cal/mol at high temperatures.

 *m*

3/2 ∞

$$\langle v \rangle = \int_0^\infty v \tilde{M}(v) \, \mathrm{d}v = 4\pi \left(\frac{m}{2\pi k_\mathrm{B} T}\right)^{3/2} \int_0^\infty v^3 \exp\left(-\frac{mv^2}{2k_\mathrm{B} T}\right) \, \mathrm{d}v = \left(\frac{8k_\mathrm{B} T}{\pi m}\right)^{1/2} . \tag{19.79}$$

dist[ributio](#page-338-3)n. **Solution 19.1.** We use the speed distribution function given by Eq. (19.75) to obtain

*v* = ∞ 0 *vM*˜ (*v*) d*v* = 4π 2π*k*B*T* 0 *v* 3 exp − *mv* 2 2*k*B*T* d*v* = π*m* . (19.79) Although the average velocity vanishes, the average of the always-positive speed does not.

**Example Problem 19.2.** Find the average speed of a particle that moves only in the *x*direction according to the MB distribution.

$$M(v_{\mathbf{x}})\,\mathrm{d}v_{\mathbf{x}} = \left(\frac{m}{2\pi k_{\mathrm{B}}T}\right)^{1/2} \exp\left(-\frac{mv_{\mathbf{x}}^2}{2k_{\mathrm{B}}T}\right)\,\mathrm{d}v_{\mathbf{x}}.\tag{19.80}$$

8*k*B*T*

1/2

*M*(*vx*) d*vx* = *m* 2π*k*B*T* 1/2 exp − *mv* 2 *x* 2*k*B*T* d*vx*. (19.80)

$$\langle |v_{\mathbf{x}}| \rangle = \int_{-\infty}^{\infty} |v_{\mathbf{x}}| M(v_{\mathbf{x}}) \, \mathrm{d}v_{\mathbf{x}} = 2 \int_{0}^{\infty} v_{\mathbf{x}} \left( \frac{m}{2\pi k \mathfrak{g}T} \right)^{1/2} \exp\left( -\frac{m v_{\mathbf{x}}^2}{2k\mathfrak{g}T} \right) \, \mathrm{d}v_{\mathbf{x}}.\tag{19.81}$$
 
$$\text{This is equivalent to using only positive } \kappa \text{, and normalizing. The result for the nonzero mode is}$$

|*vx*| = ∞ −∞ |*vx*|*M*(*vx*) d*vx* = 2 0 *vx* 2π*k*B*T* 2*k*B*T* d*vx*. (19.81) This is equivalent to using only positive *vx* and renormalizing. The result for the average speed in the *x*-direction is |*vx*| = 2*k*B*T*/π*m*1/2 , which is not simply related to the average speed in *v*2 *x* + *v*2 *y* + *v*2

*z* .

320 THERMAL PHYSICS 19.5 Energy Dispersion The canonical ensemble is applicable to a system in equilibrium with a heat reservoir such that its temperature *T* is the same as that of the reservoir. Therefore, the energy of such a system is not precisely fixed, even though its average energy *E*, which we identify as the

$$
\langle (\Delta E)^2 \rangle \, \coloneqq \langle (E - U)^2 \rangle = \langle E^2 - 2EU + U^2 \rangle = \langle E^2 \rangle - U^2,\tag{19.82}
$$

average value, *E* =*U*. [Dynam](#page-326-3)ically speaking, we can think of the energy of such a system

where

$$
\langle E^2 \rangle = \sum_l \mathcal{E}_l^2 \, P_l. \tag{19.83}
$$

(*E*) 2 := (*E* − *U*) 2=*E*2 − 2*EU* + *U*2=*E*2 − *U*2, (19.82)

$$\frac{\partial^2 Z}{\partial \beta^2} = \sum_l \mathcal{E}_l^2 \exp(-\beta \mathcal{E}_l),\tag{19.84}$$

$$
\langle E^2 \rangle = \frac{1}{Z} \left( \frac{\partial^2 Z}{\partial \theta^2} \right)_{\mathcal{N}, V} \,. \tag{19.85}
$$

which yields

$$
\langle \langle \Delta E \rangle^2 \rangle = \frac{1}{Z} \frac{\partial^2 Z}{\partial \beta^2} - \frac{1}{Z^2} \left( \frac{\partial Z}{\partial \beta} \right)^2 = \frac{\partial^2 \ln Z}{\partial \beta^2} = - \left( \frac{\partial U}{\partial \beta} \right)_{N,V} \tag{19.86}
$$

Therefore, 1 ∂2*Z* ∂β2 − 1 ∂*Z*

<span id="page-340-0"></span>*Z*2

<span id="page-340-1"></span>∂2*Z*

$$
\langle (\Delta E)^2 \rangle = k_\mathcal{B} T^2 C_V,\tag{19.87}
$$

Since d*T*/dβ = − *k*B*T*2, this result can also be written

(*E*)

2 =

*Z*

(*E*) 2 = *k*B*T*2*CV* , (19.87) where t[he heat](#page-340-0) capacity *CV* = ∂*U*/∂*T*. For a system having a large number *N* of particles, we can see that this dispersion is

*i*

$$\frac{\sqrt{\langle (\Delta E)^2 \rangle}}{\mathcal{N}} = \frac{\sqrt{\mathbf{k}_{\mathbb{B}} T^2 \mathbf{c}_{\mathbb{V}}}}{\sqrt{\mathcal{N}}},\tag{19.68}$$

*N* = √*N* , (19.88) where the expression on the left is a measure of the dispersion of energy per particle. Typically, *cV* is of the order of *k*B, so the right-hand side of Eq. (19.88) is of the order of *k*B*T*/ √*N* = 10−11*k*B*T* for *N* = 1022. For example, for a monatomic ideal gas, *cV* = (3/2)*k*B and Eq. (19.88) becomes

$$\frac{\sqrt{\langle (\Delta E)^2 \rangle}}{\mathcal{N}} = \sqrt{3/2} \,\frac{k_\mathcal{B} T}{\sqrt{\mathcal{N}}}.\tag{19.89}$$

$$\frac{\sqrt{\langle (\Delta E)^2 \rangle}}{U} = \sqrt{2/3} \,\frac{1}{\sqrt{N}}.\tag{19.90}$$

 (*E*)2 *N* = 3/2 *k*B*T* √ *N* . (19.89) Alternatively for a monatomic ideal gas, we have *U* = (3/2)*N k*B*T* relative to a zero of energy such that *U* = 0 when *T* = 0. In that case, Eq. (19.87) leads to (*E*)2 *U* = 2/3 1 √ *N* . (19.90)

In any case, as *N* → ∞, there is no dispersion of energy, which is the limit in which

### thermodynamics becomes precise. For the microcanonical ensemble, we regard the energy to be fixed precisely, so the temperature is not precisely defined. Later we shall

consider the grand canonical ensemble, for which even the number of particles of a system has dispersion about its average value. In the thermodynamic limit, however, this dispersion also tends to zero. 19.6 Paramag[net](#page-341-0)ism The phenomenon of paramagnetism pertains to systems that have no net magnetic

moment in the absence of an applied magnetic field but acquire a net magnetic moment in the direction of an applied magnetic field. Roughly speaking, it can be thought of as resulting from the alignment of magnetic dipoles when a magnetic field is applied. As the temperature increases at fixed magnetic field strength, entropic effects become more

$$\mathbf{d}U = T\,\mathbf{dS} - p\,\mathbf{d}V + \left(\frac{\partial U}{\partial \mathbf{B}}\right)_{S,V,\mathcal{N}}\,\mathbf{d}\mathbf{B} + \mu\,\mathbf{d}\mathcal{N}.\tag{19.91}$$

magnetic field strength10 *B*. Thus,

∂*B*

*T*,*V*,*N*

∂*U*

$$\mathbf{d}F = -\mathbf{S}\,\mathrm{d}T - p\,\mathrm{d}V + \left(\frac{\partial U}{\partial \mathbf{B}}\right)_{\mathrm{S,V,N}}\mathrm{d}B + \mu\,\mathrm{d}N,\tag{19.92}$$

the *z* component of the magnetic field by *B*.

<span id="page-341-0"></span>from which we see that

<span id="page-341-1"></span>
$$
\left(\frac{\partial F}{\partial \mathbf{B}}\right)_{T,V,\mathcal{N}} = \left(\frac{\partial U}{\partial \mathbf{B}}\right)_{\mathbf{S},V,\mathcal{N}}.\tag{19.93}
$$

∂*F* ∂*B* = ∂*U* ∂*B* . (19.93)

$$\mathcal{M} := -\left(\frac{\partial F}{\partial B}\right)_{T,V,\mathcal{N}} = -\left(\frac{\partial U}{\partial B}\right)_{S,V,\mathcal{N}},\tag{19.94}$$

∂*B*

*S*,*V*,*N*

<sup>10</sup>The magnetic field is a vector but for simplicity we consider a magnetically isotropic system and represent

$$\mathbf{d}dU = T\,\mathbf{dS} - p\,\mathbf{d}V - \mathcal{M}\,\mathbf{d}B + \mu\,\mathbf{d}\mathcal{N};\tag{19.95}$$

$$\mathbf{d}\mathbf{F} = -\mathbf{S}\,\mathrm{d}T - p\,\mathrm{d}V - \mathcal{M}\,\mathrm{d}\mathbf{B} + \mu\,\mathrm{d}\mathcal{N}.\tag{19.96}$$

322 THERMAL PHYSICS

which is an extensive thermodynamic quantity. The above differentials therefore become

$$\mathbf{d}\tilde{U} = T\,\mathbf{dS} - p\,\mathbf{d}V + B\,\mathbf{d}\mathcal{M} + \mu\,\mathbf{d}\mathcal{N};\tag{19.97}$$

<span id="page-342-3"></span>
$$\mathbf{d}\tilde{F} = -\mathbf{S}\,\mathrm{d}T - p\,\mathrm{d}V + B\,\mathrm{d}\mathcal{M} + \mu\,\mathrm{d}\mathcal{N},\tag{19.98}$$

*B* is an intensive variable, so the corresponding Euler equations are *U* = *TS*−*pV* +μ*N* and *F* = − *pV* + μ*N* , which have the same form as in the absence of a magnetic field.

One can also employ potentials *U*˜ := *U* + *BM* and *F*˜ := *U*˜ − *TS* = *U* − *TS* + *BM* which are Legendre transforms of *U* and *F*. Then

$$F = -(1/\beta)\ln Q(\beta B)\tag{19.99}$$

<span id="page-342-2"></span>d*F*˜ = −*S* d*T* − *p* d*V* + *B* d*M* + μd*N* , (19.98)

∂ ln *Z* ∂*B* 

*T*,*V*,*N*

= *Q* (β*B*) *Q*(β*B*)

*M* = 1 β

$$\text{mean wins:} \text{new}. \text{ return} \text{
ormalfont
ormalsize:}$$

$$\mathcal{M} = \frac{1}{\beta} \left( \frac{\vartheta \ln Z}{\vartheta B} \right)_{T, V, N} = \frac{Q'(\beta B)}{Q(\beta B)}; \quad U = -\left( \frac{\partial \ln Z}{\partial \beta} \right)_{B, V, N} = -\frac{Q'(\beta B)}{Q(\beta B)} B. \tag{19.100}$$

*F* = − (1/β)ln *Q*(β*B*) [(19.99)](#page-342-0) from which we readily compute

<span id="page-342-0"></span>
$$\mathcal{M} = -\frac{U}{B},\tag{19.101}$$

Here, *Q* is just the derivative of *Q* with respect to its argument. Thus, in this special case, we have *M* = −*U B* , (19.101) which is a ratio rather than a derivative. For more general systems, however, Eq. (19.101) does not [hold](#page-342-1) and one must compute *M* by differentiation, according to Eq. (19.94). Note in this special case that the Legendre transformed potentials *U*˜ = 0 and *F*˜ = − *TS*. This occurs because the functional form *Z* = *Q*(β*B*) is valid whenever the only relevant

energy levels have energies that are proportional to *B*. For a more detailed discussion of energy in magnetic systems, see Callen [2, appendix B], but note that his *U* is the same as

need to integrate the relevant Boltzmann factor over angles in phase space and the overall constant is irrelevant.

### <span id="page-342-1"></span>our *U*˜ .

θ with a magnetic field **B** is

19.6.1 Classical Treatment For historical reasons, we first calculate the magnetization by means of classical statistical mechanics.11 The classical energy of a dipole of magnetic moment *µ***c** that makes an angle

$$
\boldsymbol{\varepsilon}\boldsymbol{\varepsilon} = -\boldsymbol{\mu}_{\mathbf{c}} \cdot \mathbf{B} = -\mu_{\mathbf{c}} B \cos \theta. \tag{19.102}
$$

11See Eq. (20.3) and Chapter 20 for details of the classical partition function. For present purposes, we only

εθ = −*µ***c** · **B** = −μc*B* cos θ. (19.102)

$$z_{\rm c} = \text{const} \int_0^{2\pi} \, \text{d}\varphi \int_0^{\pi} \sin\theta \, \text{d}\theta \, \exp(\beta\mu_\text{c}B\cos\theta) = \text{const} \, 4\pi \frac{\sinh(\beta\mu_\text{c}B)}{\beta\mu_\text{c}B}.\tag{19.103}$$

*Chapter 19* • Canonical Ensemble 323

$$\mathcal{M} = \frac{\mathcal{N}}{\beta} \frac{\partial}{\partial B} \ln \frac{\sinh(\beta \mu_{\mathcal{C}} B)}{\beta \mu_{\mathcal{C}} B} = \mathcal{N} \mu_{\mathcal{C}} L(\mathbf{x}_{\mathcal{C}}),\tag{19.104}$$

*z*c = const 2π dϕ π 0 sinθ dθ exp(βμc*B* cos θ ) = const 4π sinh(βμc*B*)

$$L(\mathbf{x}) \coloneqq \coth \mathbf{x} - \mathbf{1}/\mathbf{x}.\tag{19.105}$$

Accordingly, for *N* identical but independent distinguishable dipoles, the total partition function *Z*C = *zN* c so *F* = − (*N* /β)ln *z*c. Thus

0

*L*(*x*c)

it does not account properly for quantum effects.

$$L(\mathbf{x}) = \begin{cases} \frac{\mathbf{x}}{3} - \frac{\mathbf{x}^3}{45} + \frac{2\mathbf{x}^5}{945} + \mathcal{O}(\mathbf{x}^7) & \mathbf{x} \ll 1\\ 1 - \frac{1}{\mathbf{x}} + 2\mathbf{e}^{-2\mathbf{x}} & \mathbf{x} \gg 1 \end{cases} \tag{19.106}$$

The Langevin function has the properties *L*(*x*) = ⎧ ⎪⎪⎨ *x* 3 − *x*3 45 + 2*x*5 945 + *O*(*x*7) *x* - 1 (19.106)

$$\mathcal{M} \approx \frac{\mathcal{N}\mu_{\rm c}^{2}}{3k_{\rm B}T}B.\tag{19.107}$$

<span id="page-343-0"></span>*x*c 1 and the magnetic moment saturates at a value *M*= *N* μc. For high temperatures or very very weak fields, *x*c -1 and

⎪⎪⎩

<span id="page-343-1"></span>1 − 1 *x*

$$\chi := \frac{\partial \mathcal{M}}{\partial B} = \frac{\mathcal{N} \mu_{\text{c}}^2}{3k_{\text{B}} T} = \frac{\mathcal{C}}{T},\tag{19.108}$$

The magnetic susceptibility is then given by **Curie's law**, χ := ∂*M* ∂*B* = *N* μ2 c 3*k*B*T* = *C T* , (19.108)

![](_page_343_Figure_14.jpeg)

*µ*c*B/*(*k*B*T*) *k*B*T/*(*µ*c*B*) **FIGURE 19–2** The Langevin function *L*(*x*c) given by Eq. (19.105) with *x*c = μc*B*/(*k*B*T*). The plot on the left can be interpreted as the dimensionless magnetic moment as a function of dimensionless magnetic field strength at constant *T*. The plot on the right is against 1/*x*c and can be interpreted as the dimensionless magnetic moment versus dimensionless temperature at fixed *B*; it gives incorrect results at small *T*, including a nonzero slope, because

<span id="page-344-1"></span>

324 THERMAL PHYSICS

<span id="page-344-0"></span>
$$\mathcal{H}'_{\rm B} = \frac{e\hbar}{2mc}(\mathbf{L} + 2\mathbf{S}) \cdot \mathbf{B} + \frac{e^2 B^2}{8mc^2} \sum_{l} (\mathbf{x}_l^2 + \mathbf{y}_l^2),\tag{19.109}$$

19.6.2 Quantum Treatment For an atom12 in a uniform magnetic field **B** along the *z*-axis, the part of the Hamiltonian that depends on **B** can be written in Gaussian units in the form13 *H* B = *eh*¯ 2*mc* (**L** + 2**S**) · **B** + *e*2*B*2 8*mc*2 - (*x*2 *i* + *y*2 *i* ), (19.109)

*i*

$$\mathcal{H}_{\rm B} = \mu_{\rm B}(\mathbf{L} + 2\mathbf{S}) \cdot \mathbf{B},\tag{19.110}$$

total orbital angular momentum, and **S** is the total spin angular momentum. Both angular momenta are measured in units of *h*¯ and are therefore dimensionless. The sum on *i* is over all electrons. The term in *B*2 contributes to diamagnetism, but here we deal only the linear term in **B**, which is usually written in the form *H*B = μB(**L** + 2**S**) · **B**, (19.110)

$$
\hat{L}^2|LSJM\rangle = L(L+1)|LSJM\rangle; \qquad \hat{f}^2|LSJM\rangle = I(J+1)|LSJM\rangle
$$

$$
\hat{S}^2|LSJM\rangle = S(S+1)|LSJM\rangle; \qquad \hat{f}_2|LSJM\rangle = M|LSJM\rangle \tag{19.111}
$$

the operators *L*ˆ 2, *S*ˆ2, ˆ *J*2, and ˆ *Jz*, where ˆ **J** = **L**ˆ + **S**ˆ. Such states |*LSJM* satisfy the relations *L*ˆ 2|*LSJM* = *L*(*L* + 1)|*LSJM*; ˆ *J*2|*LSJM* = *J*(*J* + 1)|*LSJM*

$$
\langle LSJM'|\hat{L}_z + 2\hat{S}_z|LSJM\rangle = \mathbf{g}M\,\delta_{MM'},\tag{19.112}
$$

and have a degeneracy of 2*J* + 1 because *M* = − *J*, −*J* + 1, ... ,*J* − 1,*J*. Based on addition theorems for angular momenta,15 one can show that

where

$$\mathbf{g} := \frac{3}{2} + \frac{1}{2} \left[ \frac{S(S+1) - L(L+1)}{J(J+1)} \right] \tag{19.113}$$

(19.113)

2 + 2 *J*(*J* + 1) 12We use the word atom but we will frequently actually treat an ion in some crystal. For example, the rare earth elements (atomic numbers 58-71) have similar chemistry governed by a pair of 6*s* valence electrons. They form salts that contain rare earth ions, each having from 1 to 14 electrons in their inner *f*-shells. These ions have

*S*(*S* + 1) − *L*(*L* + 1)

net magnetic moments that can be aligned by a magnetic field. For a table summarizing details, see Ashcroft and Mermin [58, p. 652]. For an extensive discussion, see van Vleck [100, p. 228].

13For a derivation, see [58, p. 646]. To covert to SI units, replace *eB*/*c* by *eB*. The *g*-factor for spin, which is

*LSJM* 

*g* := 3

can be treated by Hund's rules, see Ashcroft and Mermin [58, p. 650].

1

approximately 2.0023, has been taken to be exactly 2 for simplicity. 14μB = 9.274 × 10−21 erg/gauss. In SI units, μB = *eh*¯ /2*m* = 9.274 × 10−24 joule/tesla. 15The proof is based on the Wigner-Eckart theorem which leads to operator equivalents [59, p. 707]. For a thorough discussion of the allowable ground states and examples of ions having partially filled *d*- or *f*-shells that

$$
\hat{\mathbf{L}} + 2\hat{\mathbf{S}} = \mathbf{g}\hat{\mathbf{J}}\tag{19.114}
$$

*Chapter 19* • Canonical Ensemble 325

$$
\hat{\mu} \coloneqq -\mu_{\text{B}} \mathbf{g} \hat{\mathbf{j}} \tag{19.115}
$$

is known as the **Lande** *g*-**factor**. In fact, within the subspace of such states having the same values of *L*, *S*, *J*, and *M*, one has the operator equivalence

in terms of which the Hamiltonian

$$
\hat{\mathcal{H}}_{\rm B} = -\hat{\mu} \cdot \mathbf{B},
\tag{19.116}
$$

for all vector components. Therefore, one can define a magnetic moment operator *µ*ˆ := − μB*g*ˆ **J** (19.115)

<span id="page-345-0"></span>
$$
\hat{\mathcal{H}}_{\rm B}|LSJM\rangle = \mu_{\rm B} \text{gMB}|LSJM\rangle,\tag{19.117}
$$

*H*ˆ B =−ˆ*µ* · **B**, (19.116) which resembles the classical expression for the energy of a dipole of magnetic moment *µ*

in a magnetic field **B**. For a magnetic field along the *z*-axis, we therefore have

$$\mathbf{z} = \sum_{M=-J}^{J} \exp(\beta \mu_B \mathbf{g} \mathbf{R} \mathbf{M}) = \sum_{M=-J}^{J} [\mathbf{e}^{\chi/I}]^M,\tag{19.118}$$

<span id="page-345-1"></span>The canonical partition function for a single atom is therefore *z* = - *J M*=−*J* exp(βμB*gBM*) = [-](#page-342-2) *J M*=−*J* [e*x*/*J* ] *M* , (19.118)

$$z = \sinh\left[x\left(1 + \frac{1}{2l}\right)\right] \Big/ \sinh\left(\frac{x}{2l}\right). \tag{19.119}$$

can be readily summed to yield *z* = sinh 1 sinh *x* 

*x*

1 +

$$\mathcal{M} = \mathcal{N}\mu_{\mathbb{B}}\mathbf{g} \mathbf{J} \mathbf{B} \boldsymbol{\gamma}(\mathbf{x}),\tag{19.120}$$

From the total partition function *Z* = *zN* and Eq. (19.100), we readily compute

properties:

states as well as the second-order term in Eq. (19.109).

where

$$B_I(\mathbf{x}) = \left(1 + \frac{1}{2I}\right) \coth\left[\mathbf{x}\left(1 + \frac{1}{2I}\right)\right] - \left(\frac{1}{2I}\right) \coth\left(\frac{\mathbf{x}}{2I}\right); \quad I \neq \mathbf{0},\tag{19.121}$$

*BJ*(*x*) = 1 + 1 2*J* coth *x* 1 + 1 2*J* −  1 2*J* coth *x* 2*J* ; *J* = 0, (19.121) is called the **Brillouin function**. It is depicted in Figure 19–3 and has the following

16For the special case *J* = 0, one has no degeneracy, *M* = 0 and there is no first-order effect of a magnetic field. In that case, the ground state has no magnetic moment and one must consider interaction with excited *µ*B*gJB/*(*k*B*T* )

We fix the value of μc and choose the product *g*

*BJ*(*x*) = 1 3 1 [+](#page-343-1) 1 *J x* − 1 45  1 + 2 *J* + 3 2*J*2 +

<span id="page-346-0"></span>![](_page_346_Figure_1.jpeg)

5 10 15 20 0.2 0.4 0.6 *BJ*(*x*) *BJ*(*x*) 1 2 3 4 5 0.2 0.4 0.6

$$B_{I}(\mathbf{x}) = \frac{1}{3} \left( 1 + \frac{1}{I} \right) \mathbf{x} - \frac{1}{45} \left( 1 + \frac{2}{I} + \frac{3}{2l^2} + \frac{1}{2l^3} \right) \mathbf{x}^3 + \mathcal{O}(\mathbf{x}^5); \quad \mathbf{x} \ll 1,\tag{19.122}$$

$$B_I(\mathbf{x}) = 1 - \frac{1}{I} \exp(-\mathbf{x}/I); \quad \mathbf{x} \gg 1 \text{ with } I \text{ finite}, \tag{19.123}$$

$$B\chi(\mathbf{x}) = L(\mathbf{x}); \quad I \to \infty \text{ with } \mathbf{x} \text{ finite.} \tag{19.124}$$

*x*3 + *O*(*x*5); *x* -

*BJ*(*x*) = 1 − 1 *J* exp(−*x*/*J*); *x* 1 with *J* finite, (19.123)

$$\mathcal{M} = \frac{\mathcal{N}\mu_\text{B}^2 \text{g}^2 I(J+1)}{3k_\text{B}T} \text{B.} \tag{19.125}$$

1, (19.122)

<span id="page-346-1"></span>*k*B*T/*(*µ*B*gJB*)

For high temperatures, Eq. (19.122) is valid and the first term gives

<span id="page-346-2"></span>1 2*J*3 

$$
\mu_{\rm c} = \mu_{\rm B} \mathbf{g} \sqrt{f(J+1)}.\tag{19.126}
$$

Comparison with Eq. (19.107) for the classical treatment gives the correspondence μc = μ[B](#page-346-2)*g J*(*J* + 1). (19.126)

$$\mathbf{x_{c}} = \mathbf{x}\sqrt{(l+1)/l}.\tag{19.127}$$

the correspondence *x*c = *x* (*J* + 1)/*J*. (19.127) It would be incorrect to make a comparison by matching the saturation magnetic moments at low temperatures and high magnetic field strengths, in which case both *x* and *x*c become very large, because the classical treatment is not valid under those conditions. The saturation magnetic moment for the quantum treatment is *N* μB*gJ* whereas for the classical treatment it is *N* μc. By using Eq. (19.126), we see that *N* μc is a factor of √(*J* + 1)/*J*

larger than the quantum mechanical value *N* μB*gJ*. We can make a comparison between quantum results and classical results as follows. √*J*(*J* + 1) so that Eq. (19.126) is satisfied.

<span id="page-347-0"></span>![](_page_347_Figure_1.jpeg)

0.2

0.2 0.4 0.6 0.8 1 1.2 1.4

*k*B*T/µ*c*B*

**[FIGURE](#page-347-0) [19–4](#page-347-0)** Comparison of quantum and classical results under the constraint that both agree at high temperatures. The top curve is the Langevin function *L*(*x*c). The other curves are calculated from the Brillouin function in the form of Eq. (19.128). From the bottom up, they correspond to *J* = 1/2, 1, 2, 4. The respective saturation values for

$$\mathcal{M} = \mathcal{N}\mu_{\mathbb{C}}\sqrt{J/(J+1)}\mathcal{B}\chi\left(\mathbf{x}_{\mathbb{C}}\sqrt{J/(J+1)}\right). \tag{19.128}$$

This will make quantum and classical results agree for high temperatures. Then *x* will be related to *x*c by Eq. (19.127), which allows Eq. (19.120) to be written *M* = *N* μc *J*/(*J* + 1)*BJ x*c *J*/(*J* + 1) . (19.128) Figure 19–4 shows a plot of *M*/*N* μc versus 1/*x*c = *k*B*T*/(μc*B*) for the classical result (Langevin function) and for quantum results for several values of *J*. For fixed high tem-

<span id="page-347-1"></span>
$$\mathcal{M}^* = \mathcal{N}\mu_\mathbf{B}\mathbf{g}I = \mathcal{N}\mu_\mathbf{B}\left\{\frac{3f}{2} + \frac{1}{2}\left[\frac{\mathbb{S}(\mathbb{S}+1) - L(L+1)}{f+1}\right]\right\},\tag{19.129}$$

[values are](#page-344-1) *M*∗ = *N* μB*gJ* = *N* μB 3*J* 2 + 1 2 *S*(*S* + 1) − *L*(*L* + 1) *J* + 1 , (19.129)

where Eq. (19.113) has been used, so one should take great care in [discus](#page-342-0)sing general

### trends with *J*.

*M/*(*Nµ*c)

the quantum results are

19.6.3 Properties of Paramagnetic Systems We digress here to explore some useful properties of the paramagnetic system treated in Section 19.6.2 that are not necessarily obvious. The first concerns the sign of the magnetic moment *M*. From Eq. (19.101), we see for this particular model that *M*= − *U*/*B* so *M* has the opposite sign of the internal energy *U*. In general, the internal energy is undefined up to an additive constant, so it can be positive or negative, but Eq. (19.101) is only true because the partition function depends on *B* and β only in the combination *y* = *B*β, as

$$z = \sum_{l} \mathbf{e}^{\beta a_l B} = \frac{1}{2} \sum_{l} (\mathbf{e}^{\beta a_l B} + \mathbf{e}^{-\beta a_l B}) = \sum_{l} \cosh(a_l y). \tag{19.130}$$

∂ [∂](#page-340-1)*B*

$$U = -\mathcal{N}\frac{\partial}{\partial \beta} \ln z = -\frac{\mathcal{N}}{z} \sum_{l} a_l \tanh(a_l y) B \le 0 \tag{19.131}$$

Therefore, the partition function [for a single par](#page-344-1)ticle can be written the form

*z* = *i* eβ*aiB* = 1 2 *i* (eβ*aiB* + e−β*aiB*) = *i* cosh(*aiy*). (19.130) Thus, *U* = −*N* ∂ ∂β ln *z* = −*N z* - *i ai* tanh(*aiy*)*B* ≤ 0 (19.131) and it follows that *M* ≥ 0 with the equal sign corresponding to *B* = 0 or *T* =∞.

<span id="page-348-0"></span>
$$\frac{\text{tr}[\mathbf{e}^{-\beta\mathcal{H}}(\hat{M} - \langle \hat{M} \rangle)]}{\text{tr}[\mathbf{e}^{-\beta\hat{\mathcal{H}}}]} = (\hat{M} - \langle \hat{M} \rangle) = \mathbf{0}.\tag{19.132}$$

Hamiltonian *H* and define a *total* magnetic moment operator *M*ˆ = − ∂*H*/∂*B* = *N* μ*z*. For clarity, we now denote the magnetic moment itself by *M*ˆ , which is the thermal average of *M*ˆ in the canonical ensemble. Then it follows that tr[e−β*H*(*M*ˆ − *M*ˆ )] tr[e−β*H*] = *M*ˆ − *M*ˆ = 0. (19.132)

$$\frac{\partial}{\partial B} \text{tr}[\mathbf{e}^{-\beta \mathcal{H}} (\hat{M} - \langle \hat{M} \rangle)] = \text{tr}[\mathbf{e}^{-\beta \mathcal{H}} \beta \hat{M} (\hat{M} - \langle \hat{M} \rangle) - \mathbf{e}^{-\beta \mathcal{H}} \delta \langle \hat{M} \rangle / \beta B] = \mathbf{0}.\tag{19.133}$$

tion (see Chapter 26 for more detail). We now differentiate the numerator of the first term in Eq. (19.132) with respect to *B* to obtain

<span id="page-348-1"></span>
$$
\langle \hat{M}^2 \rangle - \langle \hat{M} \rangle^2 = \chi / \beta,\tag{19.134}
$$

We then divide by tr[e−β*H*] and recognize ∂*M*ˆ /∂*B* = χ, the susceptibility, to obtain *M*ˆ 2−*M*ˆ 2 = χ/β, (19.134)

$$
\chi/\beta = \langle (\bar{M} - \langle \bar{M} \rangle)^2 \rangle > 0. \tag{19.135}
$$

(*M*ˆ − *M*ˆ )2, which leads to χ/β = (*M*ˆ − *M*ˆ ) 2 > 0. (19.135) Thus the susceptibility χ is positive at any finite temperature. We note the similarity of Eqs. (19.87)–(19.135) for the heat capacity in terms of the dispersion of energy, which could have been derived in the same way. One subtle difference, however, is that the Hamiltonian always commutes with itself but there could be cases for which parts of the Hamiltonian do not commute with the magnetic moment operator, in which case the above derivation would not hold. We remark that for the special case we have been treating

> d*M* d*y*

$$\frac{d\mathcal{M}}{dy} = \langle (\hat{M} - \mathcal{M})^2 \rangle > 0. \tag{19.136}$$

$$-\operatorname{d}(\mathcal{M}B) = T\,\mathrm{d}S - \mathcal{M}\,\mathrm{d}B,\tag{19.137}$$

*Chapter 19* • Canonical Ensemble 329

which yields

gauss = 5 × 10−5 tesla.

$$\mathbf{dS}/k_{\mathbb{B}} = -\mathbf{y} \,\mathrm{d}\mathcal{M} = -\mathbf{y} \frac{\mathrm{d}\mathcal{M}}{\mathrm{d}\mathbf{y}} \,\mathrm{d}\mathbf{y} = \mathbf{y}^{3} \frac{\mathrm{d}\mathcal{M}}{\mathrm{d}\mathbf{y}} \,\mathrm{d}(1/\mathrm{y}).\tag{19.138}$$

tonically increasing function of 1/*y* = *k*B*T*/*B*. To do this, we substitute *U* = − *MB* into Eq. (19.95) at constant *V* and *N* to obtain − d(*MB*) = *T* d*S* − *M*d*B*, (19.137)

### d*S*/*k*B = − *y* d*M*= − *y* d*M* d*y* = *y*3 d*M*

d*y* d*y* From Eq. (19.136) we see that the coefficient of d(1/*y*) in Eq. (19.138) is posit[ive](#page-349-0), so *S* is a monotonically increasing function of 1/*y* = *k*B*T*/*B*. This result will be used in the next section. 19.6.4 Adiabatic Demag[netiza](#page-342-3)tion Adiabatic demagnetization is an experimental technique that can be used to cool mag-

$$T_E = T_\mathbf{0} \, B_E / B_\mathbf{0}.\tag{19.139}$$

<span id="page-349-1"></span>d(1/*y*). (19.138)

strong magnetic field *B*0 is applied. Then the sample is thermally insulated and the magnetic field is slowly and carefully lowered to as small a value as possible,17 say *BE*. As we shall show subsequently, the temperature of the sample will be lowered to

$$\text{S/}k_{\text{B}} = \ln Q(\beta B) - (\beta B)Q'(\beta B)/Q(\beta B). \tag{19.140}$$

This [simple r](#page-349-1)esult can be understood by examining the entropy *S* of the sample. Since *S* = (*U* − *F*)/*T*, we can use Eqs. (19.99) and (19.100) to obtain *[S](#page-345-1)*/*k*B = ln *Q*(β*B*) − (β*B*)*Q* (β*B*)/*Q*(β*B*). (19.140) The entropy is therefore only a function of the product β*B*, or for our purposes the ratio *T*/*B*. The [stage of the](#page-350-0) process in which the sample is thermally insulated and the magnetic field is slowly and carefully lowered is adiabatic and practically reversible, so it is approximately isentropic, that is, *S* = constant. If *T*/*B* is constant, then surely

<span id="page-349-0"></span>*S* will be constant. In Section 19.6.3, however, we showed that *S* is a monotonically increasing function of 1/*y* = *k*B*T*/*B*. Therefore, if *S* is constant, *T*/*B* will also be constant and Eq. (19.139) follows.

$$\mathcal{S}/(\mathcal{N}k_{\mathcal{B}}) = \ln(2\cosh\mathbf{x}) - \mathbf{x}\tanh\mathbf{x} \tag{19.141}$$

*S*/(*N k*B) = ln(2 cosh *x*) − *x* tanh *x* (19.141) as illustrated in Figure 19–5. Results for other values of *J* are qualitatively similar. During reversible adiabatic demagnetization from the point 0, the dimensionless entropy would

17The lowest possible field *BE* will probably be the order of the magnetic field of the Earth, about 0.5

remain at the value 0.6 and the temperature would drop in proportion to the field strength.

function, namely18

simplicity.

<span id="page-350-0"></span>![](_page_350_Figure_1.jpeg)

0.5 1 1.5 2 2.5 3 0.1 0.2 0.3 *S/*(*Nk*B)2*k*B*T/*(*µ*B*gB*0)

**FIGURE 19–5** Entropy as a function of temperature for *J* = 1/2. From right to left, the curves are for *B* = *B*0, *B*0/2,

and *B*0/10. For sufficiently high *T*, all curves would saturate at ln 2 = 0.693. In a hypothetical process of adiabatic demagnetization, suppose that the sample were magnetized in a strong field *B*0 at temperature *T*0, so that it is represented by the point 0 which has dimensionless entropy 0.6. If the sample were now insulated and reversibly demagnetized isentropically to the point *I*, its temperature would become *T*0/2. If the isentropic demagnetization were continued to the point *E*, its temperature would become *T*0/10. One might wonder how the temperature of the system could drop without extracting heat. The answer to this mystery lies in the initial stage of the process wherein the system is magnetized by applying the high field *B*0. If the cooling fluid is able to maintain the system at temperature *T*0 throughout this process, and if the process is reversible, an amount of heat |*Q*|=−*T*0*S* would be extracted from the system. We know that *S* < 0 because *S* increases with *T* at fixed *B* and therefore *S* decreases with *B* at fixed *T*. If the initial magnetization process is not reversible, even more heat would have to be extracted.

### will go up slightly and one will achieve a final temperature slightly higher than that calculated for the reversible process.

Similarly, if the d[em](#page-350-1)agnetization process is not quite reversible, the entropy of the system

*j*

<span id="page-350-1"></span>19.7 Partition Function and Density of States Under suitable circumstances, the energy levels of the quantum states of a system can be treated as quasi-continuous. Specifically, the spacing between levels must be small compared to *k*B*T*, which is often possible for large systems if the temperature is not too

$$Z(\beta) = \sum_{j} \exp(-\beta \mathcal{E}_j),\tag{19.142}$$

18*Z* will generally depend on other parameters such as the volume *V* but we suppress these variables for

<span id="page-351-0"></span>
$$Z(\beta) = \int_0^\infty \mathbf{e}^{-\beta E} \mathcal{D}(E) \,\mathrm{d}E,\tag{19.143}$$

*Chapter 19* • Canonical Ensemble 331 can be approximated by an integral of the form

$$\mathcal{D}(E) = \frac{1}{2\pi i} \int_{B\mathbf{r}} \mathbf{e}^{\beta E} Z(\beta) \,\mathrm{d}\beta \tag{19.144}$$

where *D*(*E*) is known as the **density of states** and accounts for the spacing and degeneracy of the quantum states. Specifically, *D*(*E*) is a distribution function such that *D*(*E*) d*E* is the number of quantum states in the energy interval between *E* and *E* +d*E*. Equation (19.143) has the same form as a Laplace transform with transform variable β. Therefore, one can use the Laplace inversion formula *D*(*E*) = 1 eβ*EZ*(β) dβ (19.144)

2π*i*

*Br*

to compute *D*(*E*)from a knowledge of *Z*(β). In Eq. (19.144), β is regarded as a complex variable and the integration is over a c[ontour](#page-333-1) *Br* in th[e comp](#page-335-1)lex plane known as the Bromwich

contour. This contour starts out at β = −*i*∞, goes to the right of all singularities19 of *Z*(β) and ends up at β = *i*∞. One can use Cauchy's theorem to deform the contour and thus calculate *D*(*E*) by standard methods of contour integration.

**Example Problem 19.3.** Calculate the Laplace transform *Z*(β) of the partition function for *N*

$$Z(\beta) = \frac{(Vn_Q)^{\mathcal{N}}}{\mathcal{N}!} = \frac{V^{\mathcal{N}}}{\mathcal{N}!} \left(\frac{m}{2\pi\hbar^2\beta}\right)^{3N/2}.\tag{19.145}$$

for *N* atoms of a monatomic ideal gas is given by

corresponding function -

<span id="page-351-1"></span>
$$\mathcal{D}(E) = \frac{V^N}{\mathcal{N}!} \left(\frac{m}{2\pi\hbar^2}\right)^{3N/2} \frac{1}{2\pi i} \int_{B\tau} \frac{\mathbf{e}^{\beta E}}{\beta^{3N/2}} \,d\beta. \tag{19.146}$$

Thus, *D*(*E*) = *V N N* ! *m* 2π*h*¯ 2 3*N*/2 1 2π*i Br* eβ*E* β3*N*/2 *d*β. (19.146) The integrand certainly has a singularity at β = 0 but if *N* is an odd integer, one also needs a branch cut, usually taken from β = 0 to β = −∞ along the real axis to make it analytic. But *N* is large so we do not really care if it is odd or even. Therefore, we temporarily pretend that it is even, in which case the integrand has a pole of order 3*N* /2 at the origin. We can therefore close

$$\int_{B\tau} \frac{\mathbf{e}^{\beta E}}{\rho^{3N/2}} \, \mathrm{d}\beta = 2\pi i \, \mathrm{Residue} \left[ \frac{\mathbf{e}^{\beta E}}{\rho^{3N/2}} \right] = 2\pi i \frac{E^{3N/2 - 1}}{(3N/2 - 1)!},\tag{19.147}$$

 *Br* β3*N*/2 dβ = 2π*i* Residue eβ*E* β3*N*/2 = 2π*i E*3*N*/2−1 (3*N* /2 − 1)!

$$\mathcal{D}(E) = \frac{V^N}{\mathcal{N}!(3\mathcal{N}/2 - 1)!} \left(\frac{mE}{2\pi\hbar^2}\right)^{3N/2} \frac{1}{E}.\tag{19.148}$$

, (19.147)

*N* !(3*N* /2 − 1)!

2π*h*¯ 2

19Such singularities are poles where *Z*(β) becomes infinite or branch cuts needed to make it single-valued.

332 THERMAL PHYSICS

Note that Eq. (19.148) can be written in terms of the gamma function in the form

$$\mathcal{D}(E) = \frac{V^{\mathcal{N}}}{\mathcal{N}!\Gamma(3\mathcal{N}/2)} \left(\frac{mE}{2\pi\hbar^2}\right)^{3\mathcal{N}/2} \frac{1}{E}.\tag{19.149}$$

should be. In the present case, we can easily check our result because Eq. (16.44) gives an expression for -, which is the total number of microstates having energies less than *E*. Differentiation with respect to *E* shows that (∂-/∂*E*)*N* ,*V* = *D*(*E*) as it should (see Eq. (19.154)

*D*(*E*) = *V N N* !(3*N* /2) *mE* 2π*h*¯ 2 3*N*/2 1 *E* . (19.149) Of course (3*N* /2) makes sense even when 3*N* /2 is a half integer, so we suspect that Eq. (19.149)

$$z(\beta) = Vn_{\rm Q} = V \left(\frac{m}{2\pi\hbar^2\beta}\right)^{3/2},\tag{19.150}$$

We remark that this same Laplace transform relationship holds between the density of

for more detail).

$$\mathcal{D}_1(\varepsilon) = \frac{V}{\Gamma(3/2)} \left(\frac{m\varepsilon}{2\pi\hbar^2}\right)^{3/2} \frac{1}{\varepsilon} = \frac{V}{(1/2)\pi^{1/2}} \left(\frac{m\varepsilon}{2\pi\hbar^2}\right)^{3/2} \frac{1}{\varepsilon}, \quad \text{no spin degeneracy,} \tag{19.151}$$

2π*h*¯ 2β so *D*1(ε) = *V* (3/2) *m*ε 2π*h*¯ 2 3/2 1 ε = *V* (1/2)π1/2 *m*ε 2π*h*¯ 2 3/2 1 ε , no spin degeneracy, (19.151)

$$\frac{\mathcal{D}_1(\varepsilon)}{V} = \frac{1}{(1/2)\pi^{1/2}} \left(\frac{m\varepsilon}{2\pi\hbar^2}\right)^{3/2} \frac{1}{\varepsilon},\tag{19.152}$$

<span id="page-352-0"></span>often deals with the intensive quantity *[D](#page-352-0)*1(ε) *V* = 1 *m*ε 3/2 1 , (19.152)

(1/2)π1/2 2π*h*¯ 2 ε which is also called the density of states and has units of (volume energy)−1. One must therefore be careful to ascertain from the context just what density of states is being used! Strictly speaking, one should have *D*(*E*) = (1/*N* !) ∂*V*R/∂*E*, where *V*R given by Eq. (16.39)

$$\mathcal{D}(E) = \frac{\partial(\Omega/\mathcal{F})}{\partial E} = \frac{1}{\mathcal{F}} \frac{\partial \Omega}{\partial E} + \frac{\Omega}{\mathcal{F}^2} \frac{3\mathcal{N}\Delta E}{2E^2} \exp\left(-\frac{3\mathcal{N}\Delta E}{2E}\right). \tag{19.153}$$

*D*(*E*) = ∂(-/*F*) ∂*E* = 1 *F* ∂- ∂*E* + - *F*2 3*N E* 2*E*2 exp −3*N E* 2*E* . (19.153) The second term in Eq. (19.153) is negligible compared to the first (because of the

$$\mathcal{D}(E) \approx \frac{\partial \mathcal{Q}(E)}{\partial E} \tag{19.154}$$

to an excellent approximation.

exponential) and *F* ≈ 1, so

<span id="page-353-1"></span><span id="page-353-0"></span>
$$\mathbf{S} = \frac{U - F}{T} = k_{\mathbb{B}} \left( \ln Z + \frac{U}{k_{\mathbb{B}} T} \right) = k_{\mathbb{B}} \ln \left( Z \,\mathrm{e}^{U/k_{\mathbb{B}} T} \right). \tag{19.155}$$

$$
\ln(\mathfrak{Q}(E)) \sim \ln(\tilde{\mathfrak{Q}}(U)) \equiv \ln(Z \,\mathrm{e}^{U/k_{\mathrm{B}}T}).\tag{19.156}
$$

canonical ensemble as follows. For the microcanonical ensemble, we have *S* = *k*B ln -(*E*); however, for the canonical ensemble *S* = *U* − *F T* = *k*B ln *Z* + *U k*B*T* = *k*B ln *Z* e*U*/*k*B*T* . [(19.](#page-353-0)155) If *E* and *U* are nearly the same, we should have ln(-(*E*)) ∼ ln(-( ˜ *U*)) ≡ ln(*Z* e*U*/*k*B*T* ). (19.156)

$$
\mathfrak{\Omega}(E) \sim \tilde{\Omega}(U) \equiv Z \,\mathrm{e}^{U/k\mathfrak{g}T},\tag{19.157}
$$

the canonical ensemble for which the temperature is specified, so only the average energy *U*(*T*) is specified. Therefore, if we exponentiate both sides of Eq. (19.156) we obtain

for which the energy *E* of each microstate is specified, whereas -

$$\tilde{\Omega}(U) = \frac{1}{N!} V^N \left(\frac{mU}{3\pi\hbar^2\mathcal{N}}\right)^{3N/2} \mathbf{e}^{3N/2}.\tag{19.158}$$

For example, for an ideal gas, for which *U* = (3/2)*N k*B*T*, we have

-

-(˜ *U*) = 1

neglected.

form

$$
\Omega(E) = V^{\mathcal{N}} \frac{(mE/2\pi\hbar^2)^{3\mathcal{N}/2}}{\mathcal{N}!(3\mathcal{N}/2)!}.\tag{19.159}
$$

According to Eq. (16.44), we have -(*E*) = *V N* (*mE*/2π*h*¯ 2)3*N*/2 *N* !(3*N* /2)! . (19.159)

$$
\tilde{\Omega}(U) \sim \sqrt{3\pi N} \, V^{\mathcal{N}} \frac{(mU/2\pi\hbar^2)^{3\mathcal{N}/2}}{\mathcal{N}(3\mathcal{N}/2)!}.\tag{19.160}
$$

-( ˜ *U*) ∼ √ 3π*N V N* (*mU*/2π*h*¯ 2)3*N*/2 *N* !(3*N* /2)! . (19.160)

$$
\ln \tilde{\Omega}(U) = \ln \Omega(E) + (1/2) \ln(3\pi N) \tag{19.161}
$$

ln-( ˜ *U*) = ln -(*E*) + (1/2)ln(3π*N* ) (19.161) in which the last term is sub-extensive, and therefore negligible. It is also illuminating to use Eq. (19.148) with *E* → *U* to express -(˜ *U*) in terms of the density of states evaluated at

$$
\tilde{\Omega}(U) \sim \sqrt{2\pi} \frac{U}{\sqrt{3N/2}} \mathcal{D}(U) = \sqrt{2\pi} \sqrt{3N/2} \, k_{\mathbb{B}} T \mathcal{D}(U). \tag{19.162}
$$

*Z* =

integral in Eq. (19.169) can be approximated by −∞.

<span id="page-354-2"></span>
$$
\tilde{\Omega}(U) \sim \sqrt{2\pi} \sqrt{\langle (\Delta E)^2 \rangle} \mathcal{D}(U),
\tag{19.163}
$$

334 THERMAL PHYSICS

$$\mathbf{R}_1(\mathbf{s}) \sim \mathbf{z} \cdot \mathbf{C} \mathbf{z} \quad \text{(2.162)} \\ \mathbf{R}_1(\mathbf{s}) \sim \mathbf{z} \cdot \mathbf{z} \exp(i\mathbf{k}/k_B T) = \mathbf{z} \cdot \mathbf{e}^{3/2}, \tag{19.164}$$
 
$$\Omega_1(\mathbf{s}) \sim \mathbf{z} \exp(i\mathbf{k}/k_B T) = \mathbf{z} \cdot \mathbf{e}^{3/2}, \tag{19.164}$$

-( ˜ *U*) ∼ √ 2π (*E*)2 *D*(*U*), (19.163)

which demonstrates clearly that the density of states *D*(*U*) must be multiplied by the spread of energy to approximate the number of microstates -(˜ *U*). For a single ideal gas particle, the correspondence implied by Eq. (19.157) would give

$$Z = \int_0^\infty \mathcal{D}(E) \, \mathbf{e}^{-\beta E} \, \mathrm{d}E = \int_0^\infty \mathbf{e}^{[-\beta E + \ln D(E)]} \, \mathrm{d}E \tag{19.165}$$

which illustrates that *z* is essentially a measure of the number of states available to an individual particle at temperature *T*. Another way of evaluating -˜ in Eq. (19.157) is to evaluate approximately the partition function

$$\mathbf{0} = \frac{\partial}{\partial E} [-\beta E + \ln D(E)] \\ \mathbf{E}^* = -\beta + [\ln D(E^*)]',\tag{19.166}$$

by expanding about the most probable state. To do this, we recognize that *D*(*E*) is a rapidly increasing function of *E* and e−β*E* is a rapidly decreasing function of *E*. Thus the integrand has a sharp maximum at the most probable value *E*∗ that satisfies

<span id="page-354-1"></span><span id="page-354-0"></span>
$$-\beta E + \ln D(E) = -\beta E^* + \ln D(E^*) - (1/2)\alpha (E - E^*)^2 + \cdots,\tag{19.167}$$

where the prime indicates a derivative. We can therefore expand the exponent in the right-

$$\alpha := -\left[\ln D(E^*)\right]'' > 0\tag{19.168}$$

where

gives a numerical factor of order 1 and the result greatly resembles Eq. (19.162).

$$Z \approx \mathcal{D}(E^*) \,\mathrm{e}^{-\beta E^*} \int_{-E^*}^{\infty} \mathrm{e}^{-(a/2)\xi^2} \,d\xi \approx \sqrt{2\pi} \,\frac{1}{\sqrt{a}} \mathcal{D}(E^*) \,\mathrm{e}^{-\beta E^*},\tag{19.169}$$

*Z* ≈ *D*(*E*∗) e−β*E*∗ ∞ −*E*∗ e−(α/2)ξ2 dξ ≈ √ 2π 1 √α *D*(*E*∗) e−β*E*∗ , (19.169)

$$
\tilde{\Omega} \sim \sqrt{2\pi} \frac{1}{\sqrt{\alpha}} \mathcal{D}(E^*) \,\mathrm{e}^{-\beta(E^*-U)}.\tag{19.170}
$$

-˜ ∼ √ 2π 1 √α *D*(*E*∗) e−β(*E*∗−*U*) . (19.170) But the difference20 between *E*∗ and *U* is of order *k*B*T*, so the exponential in Eq. (19.170)

<sup>20</sup>In this Gaussian approximation, there is negligible difference between *E*∗ and *U* if the lower limit of the

Specifically for a monatomic ideal gas, Eq. [(19.148)](#page-351-1) shows that *D*(*E*) = *AE*3*N* /2−1 so *E*∗ = (3*N* /2 −1)*k*B*T* and α = (3*N* /2 −1)/(*E*∗) 2. Since *U* = (3*N* /2)*k*B*T*, Eq. [(19.170)](#page-354-0) becomes

$$\tilde{\Omega} \sim \sqrt{2\pi} \frac{E^*}{\sqrt{3N/2 - 1}} \mathcal{D}(E^*) \mathbf{e} = \sqrt{2\pi} \frac{U}{\sqrt{3N/2 - 1}} \mathcal{D}(U) \, \mathbf{e} \, (E^*/U)^{3N/2}. \tag{19.171}$$

But

$$(E^*/U)^{3N/2} = \left(\frac{3N/2 - 1}{3N/2}\right)^{3N/2} = \left(1 - \frac{2}{3N}\right)^{3N/2} \sim \left(\mathbf{e}^{-2/3N}\right)^{3N/2} = \mathbf{e}^{-1}.\tag{19.172}$$

Therefore, Eq. [(19.170)](#page-354-0) reduces to

$$
\tilde{\Omega} \sim \sqrt{2\pi} \frac{U}{\sqrt{3N/2 - 1}} \mathcal{D}(U) = \sqrt{2\pi} \sqrt{\langle (\Delta E)^2 \rangle} \mathcal{D}(U),
\tag{19.173}
$$

in excellent agreement with Eq. [(19.163)](#page-354-2) because the 1 in the square root is negligible.

This page intentionally left blank

20

# Classical Canonical Ensemble

For the canonical ensemble[,1](#page-357-0) the temperature rather than the energy is fixed. Therefore, the members of the ensemble have various energies. Members of the ensemble having a given energy must still obey the Liouville theorem and hence Eq. (17.11). This possibility can be accommodated by choosing the density ρ in phase space to be some function of the classical Hamiltonian *H*, in which case Eq. (17.11) becomes

$$
\langle \rho(\mathcal{H}), \mathcal{H} \rangle = \frac{\mathbf{d}\rho}{\mathbf{d}\mathcal{H}} \langle \mathcal{H}, \mathcal{H} \rangle = \mathbf{0}.\tag{20.1}
$$

Proceeding with the same arguments as in the quantum mechanical case, it can be inferred for a system in contact with a heat reservoir at temperature *T* that the probability of a system having energy *E* is proportional to the Boltzmann factor exp(−β*E*), where β = 1/(*k*B*T*) as usual. Since *H* = *E* for such a system, the appropriate probability distribution function is

<span id="page-357-1"></span>
$$\mathcal{P}(\mathbf{p}, \mathbf{q}) := \frac{\exp[-\beta \, \mathcal{H}(\mathbf{p}, \mathbf{q})]}{Z_{\mathbb{C}}},\tag{20.2}$$

where where **p** and **q** are 3*N* -dimensional vectors representing the canonical momenta and coordinates, respectively. The function

<span id="page-357-2"></span>
$$Z_{\mathbb{C}} := \int \exp[-\beta \, \mathcal{H}(\mathbf{p}, \mathbf{q})] \, \mathrm{d}\omega,\tag{20.3}$$

where dω ≡ d3*N p* d3*N q* and the integration is over all phase space. *P*(**p**, **q**) dω is the probability that the system will be in the volume element dω of phase space centered about the point **p**, **q**. The factor *Z*C in the denominator of Eq. [(20.2)](#page-357-1) is needed to insure normalization, that is,

$$
\int \mathcal{P}(\mathbf{p}, \mathbf{q}) \, \mathrm{d}\omega = 1. \tag{20.4}
$$

If *Y* (**p**, **q**) is some function of **p** and **q**, then the average value of *Y* is

$$\mathcal{P}(Y) := \int Y(\mathbf{p}, \mathbf{q}) \, \mathcal{P}(\mathbf{p}, \mathbf{q}) \, \mathrm{d}\omega. \tag{20.5}$$

<span id="page-357-0"></span>1Those interested in the historical development of classical statistical mechanics are encouraged to read the original work of J.W. Gibbs [4]. Based on Hamilton's classical dynamical equations that we discussed in Chapter 17, Gibbs developed the classical canonical ensemble in Chapter IV, the microcanonical ensemble in Chapter X, and the grand canonical ensemble in Chapter XV. The integral form of Liouville's theorem that we presented in Section 17.1 is what Gibbs called the "conservation of probability of phase." If ρ = eη is the probability density function in phase space, Gibbs called η the "index of probability." Then he referred to a "canonical distribution" as one in which the index of probability is a linear function of the energy.

Comparison of Eqs. [(20.2)](#page-357-1) and [(20.3)](#page-357-2) with Eqs. (19.5) and (19.6) shows that the function *Z*C plays the role of a classical partition function. In fact, the formula Eq. (19.7) for the average internal energy has exactly the same form in the classical case. Thus,

$$U := \langle \mathcal{H} \rangle = \int \mathcal{H}(\mathbf{p}, \mathbf{q}) \, \mathcal{P}(\mathbf{p}, \mathbf{q}) \, \mathrm{d}\omega = -\frac{1}{Z_{\mathbb{C}}} \frac{\partial Z_{\mathbb{C}}}{\partial \beta} = -\frac{\partial \ln Z_{\mathbb{C}}}{\partial \beta}. \tag{20.6}$$

But in some other respects, the correspondence of *Z*C with the quantum mechanical partition function is incorrect. Unlike the quantum partition function, *Z*C is not dimensionless and does not account for the number of quantum states that need to be associated with a volume of phase space. For *N* identical particles that occupy the same volume, one can define a dimensionless classical partition function

<span id="page-358-2"></span>
$$Z_{\mathbb{C}}^{*} := \frac{Z_{\mathbb{C}}}{\alpha_{0}} = \frac{1}{\alpha_{0}} \int \exp[-\beta \, \mathcal{H}(\mathbf{p}, \mathbf{q})] \, \mathrm{d}\alpha. \tag{20.7}$$

The factor ω0 is the same factor as in Eq. (17.14) that allows us to convert from volume of phase space to microscopic states. For identical distinguishable particles we have ω0 = *h*3*N* and for identical indistinguishable classical particles we have approximately ω0 = *h*3*N N* !. In other words, dω has been replaced by the dimensionless quantity dω/ω0, which is the differential of the number of microscopic states. Doing this gives rise to the correct entropy constant at high temperatures, where classical statistics are valid approximately. In this respect, we could view Eq. [(20.2)](#page-357-1) in the form

$$\mathcal{P}(\mathbf{p}, \mathbf{q}) \, \mathrm{d}\omega = \frac{\exp[-\beta \, \mathcal{H}(\mathbf{p}, \mathbf{q})]}{Z_{\mathrm{C}}^{*}} \left(\frac{\mathrm{d}\omega}{\omega_{\mathrm{0}}}\right) . \tag{20.8}$$

In this manner, we can also relate properly to the Helmholtz free energy, namely

$$F = -k_{\rm B} T \log Z_{\rm C}^* \tag{20.9}$$

and the entropy will be correctly given by

$$S = -\frac{\partial F}{\partial T}.\tag{20.10}$$

### 20.1 Classical Ideal Gas

To illustrate the classical canonical ensemble, we shall treat a classical ideal gas and rederive the Maxwell-Boltzmann distribution function. The Hamiltonian is

<span id="page-358-1"></span>
$$\mathcal{H} = \sum_{l=1}^{3N} \frac{p_l^2}{2m} \tag{20.11}$$

for *N* particles of mass *m*. The *pi* are just the Cartesian momenta of the particles. We can use Eq. [(20.2)](#page-357-1) to calculate the average value of some function *f* (**v**1) = *f* (**p**1/*m*) of the velocity of particle number 1, resulting in

<span id="page-358-0"></span>
$$
\langle f(\mathbf{v}_1) \rangle = \int f(\mathbf{p}_1/m) \mathcal{P}(\mathbf{p}, \mathbf{q}) \, \mathrm{d}\boldsymbol{\omega} = \int f(\mathbf{p}_1/m) \, \frac{\exp[-\beta \, \mathcal{H}(\mathbf{p}, \mathbf{q})]}{Z_{\mathbb{C}}} \, \mathrm{d}^{3N} p \, \mathrm{d}^{3N} q. \tag{20.12}
$$

In Eq. [(20.12)](#page-358-0), all integrals relating to *q* and to particles other than particle number 1 cancel with the corresponding factors in *Z*C. We therefore obtain

$$\langle f(\mathbf{v}_1) \rangle = \frac{\int f(\mathbf{p}_1/m) \, \exp[-\beta \, p_1^2 / 2m] \, \mathbf{d}^3 p_1}{\int \exp[-\beta \, p_1^2 / 2m] \, \mathbf{d}^3 p_1} = \frac{\int f(\mathbf{v}_1) \, \exp[-\beta \, m v_1^2 / 2] \, \mathbf{d}^3 v_1}{\int \exp[-\beta \, m v_1^2 / 2] \, \mathbf{d}^3 v_1}. \tag{20.13}$$

The denominator on the right-hand side can be evaluated to give

$$\int \exp[-\beta \, m v_1^2 / 2] \, \mathrm{d}^3 v_1 = \left(\frac{2\pi \, k_\mathrm{B} T}{m}\right)^{3/2}.\tag{20.14}$$

Thus

$$
\langle f(\mathbf{v}_1) \rangle = \left(\frac{m}{2\pi k_\mathrm{B} T}\right)^{3/2} \int_{-\infty}^{\infty} f(\mathbf{v}_1) \, \exp[-\beta \, m v_1^2 / 2] \, \mathrm{d}^3 v_1. \tag{20.15}
$$

A similar result would be obtained for any other particle since they are all equivalent. The normalized distribution function for the velocity **v** of any particle is therefore

<span id="page-359-0"></span>
$$M(\mathbf{v}) = \left(\frac{m}{2\pi k_{\rm B}T}\right)^{3/2} \exp[-mv^2/2k_{\rm B}T],\tag{20.16}$$

in agreement with Eq. (19.70) and known as the **Maxwell-Boltzmann distribution** function.

Note that Eq. [(20.16)](#page-359-0) can be factored into normalized distributions for each Cartesian component by writing *v* 2 = *v* 2 *x* + *v* 2 *y* + *v* 2 *z* and apportioning the normalization factor, resulting in

$$M(\mathbf{v}) = \prod_{l=\mathbf{x}, \mathbf{y}, \mathbf{z}} \left(\frac{m}{2\pi k_{\mathbf{B}}T}\right)^{1/2} \exp[-mv_l^2/2k_{\mathbf{B}}T],\tag{20.17}$$

which is the same as Eq. (19.73).

**Example Problem 20.1.** Find the distribution function for the speed *v*⊥ for motion perpendicular to the *z*-axis.

**Solution 20.1.** First, we calculate the distribution function for velocity **v**⊥ perpendicular to the *z*-axis by integrating *M*(**v**) over *vz*, which we no longer care about. This gives

$$M(\mathbf{v}_{\perp}) = \int_{-\infty}^{\infty} M(\mathbf{v}) \, \mathrm{d}v_{l} = \prod_{l=\mathbf{x}, \mathbf{y}} \left(\frac{m}{2\pi k_{\mathrm{B}}T}\right)^{1/2} \exp[-mv_{l}^{2}/2k_{\mathrm{B}}T]. \tag{20.18}$$

Then we go to polar coordinates so that *vx* = *v*⊥ cos φ and *vy* = *v*⊥ sin φ to obtain

$$M(\mathbf{v}_{\perp}) \, \mathrm{d}v_{\mathbf{x}} \, \mathrm{d}v_{\mathbf{y}} = \left(\frac{m}{2\pi k_{\mathrm{B}}T}\right) \exp[-mv_{\perp}^{2}/2k_{\mathrm{B}}T] \, \mathrm{d}\phi \, v_{\perp} \, \mathrm{d}v_{\perp}.\tag{20.19}$$

Next we integrate on φ from 0 to 2π to get the speed distribution function

$$
\check{M}(v_\perp) = \left(\frac{m}{k_\text{B}T}\right) \exp[-mv_\perp^2/2k_\text{B}T] \, v_\perp. \tag{20.20}
$$

Thus the average speed for motion perpendicular to the *z*-axis is

$$\langle v_{\perp} \rangle = \int_{0}^{\infty} \breve{M}(v_{\perp}) v_{\perp} \, \mathbf{d}v_{\perp} = \int_{0}^{\infty} \left( \frac{m}{k_{\rm B}T} \right) \exp[-mv_{\perp}^{2}/2k_{\rm B}T] \, v_{\perp}^{2} \, \mathbf{d}v_{\perp} = \left( \frac{\pi k_{\rm B}T}{2m} \right)^{1/2}. \tag{20.21}$$

We can also evaluate the partition function *Z*∗ C by substitution of Eq. [(20.11)](#page-358-1) into Eq. [(20.7)](#page-358-2). The integral over **q** just gives a factor of *V N* and the integral over **p** can be performed in Cartesian coordinates, resulting in

$$Z_{\mathbb{C}}^{*} = \frac{V^{N}}{h^{3N}\mathcal{N}!} \left[ \int \exp[-\beta p^{2}/(2m)] \,\mathrm{d}p \right]^{3N} = \frac{V^{N}}{h^{3N}\mathcal{N}!} \left(2\pi \,mk_{\mathbb{B}}T\right)^{3N/2}.\tag{20.22}$$

To evaluate ln *Z*∗ C, we use Stirling's approximation for ln *N* ! to obtain

<span id="page-360-0"></span>
$$
\ln Z_{\rm C}^{*} = \mathcal{N} \ln(V/\mathcal{N}) + \mathcal{N} \ln n_{\rm Q} + \mathcal{N},
\tag{20.23}
$$

where the quantum concentration

<span id="page-360-1"></span>
$$m_{\rm Q} = \left(\frac{2\pi mk_{\rm B}T}{h^2}\right)^{3/2} = \left(\frac{mk_{\rm B}T}{2\pi\hbar^2}\right)^{3/2}.\tag{20.24}$$

Equations [(20.23)](#page-360-0) and [(20.24)](#page-360-1) are the same as Eqs. (19.57) and (19.60) derived from quantum statistical mechanics in the high temperature limit. For high temperatures, the resulting thermodynamic functions are therefore the same as derived in Chapter 19.

### 20.1.1 Effusion of an Ideal Classical Gas

The slow leaking of a gas through a small hole in a box containing the gas is a process known as **effusion**. The hole is assumed to be so small that the gas inside the box can be assumed to be practically in equilibrium at each instant of time, as described by the Maxwell-Boltzmann velocity distribution function *M*(**v**) given by Eq. [(20.16)](#page-359-0). For convenience, we treat a monatomic gas and assume that the hole has an area *a* in a plane perpendicular to the *z*-axis. Let *J* be the flux of gas atoms that exit the hole; *J* has units of atoms/(area time) so that *Ja* d*t* is the number of atoms that effuse (exit the box) in an infinitesimal time d*t*. These atoms can have any values of *vx* and *vy* but they must have *vz* > 0. In an infinitesimal time d*t*, atoms in a rectangular parallelepiped of volume *avz* d*t* will exit. Thus if *n* is the number density of the gas, the flux will be given by

$$J = n \int_{-\infty}^{\infty} \mathbf{d}v_{\mathcal{X}} \int_{-\infty}^{\infty} \mathbf{d}v_{\mathcal{Y}} \int_{0}^{\infty} \mathbf{d}v_{\mathcal{Z}} \, v_{\mathcal{Z}}M(\mathbf{v}). \tag{20.25}$$

We now transform to spherical coordinates for which the volume element is *v* 2 sin θ dϕ dθ d*v* and also write *vz* = *v* cos θ. This gives

$$J = n \int_0^{2\pi} \mathbf{d}\varphi \int_0^\infty \mathbf{d}v \, v^2 \int_0^{\pi/2} \mathbf{d}\theta \, v \cos\theta \sin\theta M(\mathbf{v}). \tag{20.26}$$

Since *M*(**v**) depends only on *v* 2 and is therefore independent of θ and ϕ, the trigonometric integrals give factors of 2π and 1/2. We therefore obtain

$$J = n\pi \int_0^\infty \mathbf{d}v \, v^3 M(\mathbf{v}) = \frac{n}{4} \int_0^\infty \mathbf{d}v \, v \, 4\pi \, v^2 M(\mathbf{v}) = \frac{n}{4} \int_0^\infty \mathbf{d}v \, v \tilde{M}(v),\tag{20.27}$$

*Chapter 20* • Classical Canonical Ensemble 341

*J* = *n*π - ∞ 0 d*v v* 3*M*(**v**) = *n* 4 - ∞ 0 d*v v* 4π*v* 2*M*(**v**) = *n* 4 - ∞ 0 d*v vM*˜ (*v*), (20.27) where *M*˜ (*v*) = 4π*v* 2*M*(**v**) is the speed distribution function given by Eq. (19.75). We readily compute *J* = *n*(*k*B*T*/2π*m*)1/2. This result could have been obtained more easily by just evaluating Eq. (20.25) in Cartesian coordinates, but the weighting of the speed in

$$p = n \int_{-\infty}^{\infty} \mathbf{d}v_{\mathcal{X}} \int_{-\infty}^{\infty} \mathbf{d}v_{\mathcal{Y}} \int_{0}^{\infty} \mathbf{d}v_{\mathcal{Z}}v_{\mathcal{U}}2mv_{\mathcal{Z}}M(\mathbf{v}).\tag{20.28}$$

Instead of effusing, each gas atom that strikes an area *a* of a closed box will rebound and

0

but it must be true on average in order to maintain equilibrium.

−∞

0

−∞

$$p = n \int_0^{2\pi} \mathrm{d}\rho \int_0^{\infty} \mathrm{d}v \, v^2 \int_0^{\pi/2} \mathrm{d}\theta \, 2mv^2 \cos^2\theta \sin\theta M(\mathbf{v}).\tag{20.29}$$
 

**Thorfoora**

$$p = \frac{4\pi n}{3} \int_0^\infty \mathrm{d}v \, mv^4 M(\mathbf{v}) = \frac{n}{3} \int_0^\infty \mathrm{d}v \, mv^2 \tilde{M}(v) = nk_\mathrm{B}T. \tag{20.30}$$

Therefore,

*p* = 4π*n* 3 - ∞ d*v mv* 4*M*(**v**) = *n* 3 - ∞ d*v mv* 2*M*˜ (*v*) = *nk*B*T*. (20.30)

average energy (3/2)*k*B*T* per atom of gas in the box. This arises because there is a preference for

lational partition function and an internal partition function (see Section 21.3 for details), the

0

0

0 0

$$J_{\mathbb{E}} = n \int_{-\infty}^{\infty} \mathrm{d}v_{\mathbb{X}} \int_{-\infty}^{\infty} \mathrm{d}v_{\mathbb{Y}} \int_{0}^{\infty} \mathrm{d}v_{\mathbb{Z}} \, v_{\mathbb{Z}}(1/2)mv^2M(\mathbf{v}). \tag{20.31}$$

**Solution 20.2.** Each atom will carry an energy (1/2)*mv*2 so

$$J_{\rm E} = \frac{n}{4} \int_0^\infty \mathrm{d}v \,(1/2)mv^2 v \tilde{M}(v) = 2k_{\rm B}T \, n(k_{\rm B}T/2\pi \, m)^{1/2}.\tag{20.32}$$

*J*E = *n* 4 - ∞ 0 d*v*(1/2)*mv* 2*vM*˜ (*v*) = 2*k*B*T n*(*k*B*T*/2π*m*) 1/2. (20.32) We note that the average energy per effused atom is *J*E/*J* = 2*k*B*T*, which is greater than the

the faster atoms to effuse. **Example Problem 20.3.** How would the fluxes *J* and *J*E for effusion be modified if instead of

a monatomic gas we have a molecular gas? **Solution 20.3.** As long as the partition function for a molecule can be factored into a trans-

2This assumption appears to attribute special properties to the walls of the box, such as specular reflection,

342 THERMAL PHYSICS

$$J_{\mathrm{E}} = \frac{n}{4} \int_{0}^{\infty} \mathrm{d}v \, v [(1/2)mv^2 + \mu_{\mathrm{int}}] \tilde{M}(v). \tag{20.33}$$

Maxwell-Boltzmann distribution for the velocity will still apply. Therefore, *J* given by Eq. (20.27)

4

0

$$J_{\rm E} = n(2\pi)^{-1/2} 2m(\mathbf{k_{\rm B}}T/m)^{3/2} + \mathcal{J}u_{\rm int}.\tag{20.34}$$

(1/2)*mv*2 with (1/2)*mv*2 + *u*int, where *u*int is the energy per molecule due to internal degrees of freedom. Thus, *J*E = *n* -∞

The crucial difference is that *u*int is independent of *v*, so we obtain simply *J*E = *n*(2π )−1/22*m*(*k*B*T*/*m*) 3/2 + *Ju*int. (20.34)

In this case, the average energy per effused atom is *J*E/*J* = 2*k*B*T* + *u*int and we see that there is no enhancement of the internal energy per molecule, as there is for the kinetic energy.

$$\frac{\mathrm{d}\mathcal{N}}{\mathrm{d}t} = a\mathrm{f}; \quad \frac{\mathrm{d}U}{\mathrm{d}t} = \frac{3}{2}\mathcal{N}k_{\mathrm{B}}\frac{\mathrm{d}T}{\mathrm{d}t} + \frac{3}{2}k_{\mathrm{B}}T\frac{\mathrm{d}\mathcal{N}}{\mathrm{d}t} = a\mathrm{f}_{\mathrm{E}}.\tag{20.35}$$

d*v v*[(1/2)*mv* 2 + *u*int]*M*˜ (*v*). (20.33)

would the number of atoms and the temperature of the gas in the box decay with time due to effusion? **Solution 20.4.** We have d*N* d*t* = *aJ*; d*U* d*t* = 3 2 *N k*B d*T* d*t* + 3 2 *k*B*T* d*N* d*t* = *aJ*E. (20.35)

$$\frac{T}{T_0} = \frac{1}{(1+rt)^2}; \quad \frac{N}{N_0} = \frac{1}{(1+rt)^6},\tag{20.36}$$

<span id="page-362-1"></span>an ordinary differential equation for *N* that can be integrated subject to the initial condition *N* = *N*0. The results are *T* = 1 (1 + *rt*)2 ; *N* = 1 (1 + *rt*)6 , (20.36)

*N*0

where *r* = (*a*/6*V*)(2π )−1/2(*k*B*T*0/*m*)1/2 and *V* is the volume of the box. Of course we need *rt* 1 for the effusion to be slow enough for the quasi-equilibrium assumption to hold.

<span id="page-362-0"></span>*T*0

20.2 Law of D[ulon](#page-362-0)g and Petit

$$\mathcal{H} = \sum_{l} \frac{p_l^2}{2m} + \sum_{l,l} q_l L_l q_l. \tag{20.37}$$

*i* 2*m i*,*j* Here, *m* is the particle mass and the *Lij* are coupling constants. To a first approximation, the energy of a solid, in excess of its equilibrium potential (binding) energy, can be approximated by Eq. (20.37), which is known as a **harmonic Hamiltonian**.

$$Z_{\rm C} = \beta^{-3N} \int \exp\left\{-\left[\sum_{l} \frac{P_l^2}{2m} + \sum_{l,j} Q_l L_{lj} Q_j \right] \right\} \,\mathrm{d}^{3N} P \,\mathrm{d}^{3N} Q. \tag{20.38}$$

⎭

$$U = -\frac{\partial}{\partial \beta} [-3\mathcal{N}\ln\beta + \text{constant}] = 3\mathcal{N}k_B T. \tag{20.39}$$

*Z*C = β−3*N* exp ⎨ ⎣ *P*2 *i* + *QiLijQj* ⎦ ⎬ d3*N P* d3*N Q*. (20.38)

⎩− *i* 2*m i*,*j*

evaluate! Hence Eq. (20.6) becomes

$$\mathbf{C}_{V} = \left(\frac{\partial \mathbf{U}}{\partial T}\right)_{V, \mathcal{N}} = 3Nk_{\mathbf{B}},\tag{20.40}$$

*U* = − ∂ ∂β [−3*N* ln β + constant] = 3*N k*B*T*. (20.39) This amazingly simple result is independent of the mass and the coupling constants! The corresponding heat capacity is therefore *CV* = ∂*U* ∂*T V*,*N* = 3*N k*B, (20.40) which is called the **law of Dulong and Petit**. Of course it is only valid at high temperatures and for a Hamiltonian that is strictly a quadratic function of the momenta and coordinates (i.e., strictly harmonic). It is exactly twice the heat capacity of an ideal gas. It is in agreement with the **equipartition principle**, according to which each translational degree of freedom contributes (1/2)*k*B per particle and each vibrational degree of freedom also contributes (1/2)*k*B per particle. The factor of 3 comes from the dimensionality of space. For one mole of such a solid, *CV* = 3*R* = 5.96 cal/(mol K) ≈ 6 cal/(mol K), a good number to remember. Experimental values of *CV* approach but generally lie a bit below the value

### persist at apparently high temperatures as one approaches the melting point of a solid. See [58, p. 428] for some experimental curves for nobl[e-gas](#page-363-0) [s](#page-363-0)olids.

 *qi* ∂*H* ∂*qj*

 *qi* ∂*H* ∂*pj*

<span id="page-363-2"></span><span id="page-363-0"></span>given by the law of Dulong and Petit, even at very high temperatures, presumably due to anharmonic effects. Moreover, quantum effects, which lower *CV* to zero as *T* → 0, may still

20.3 Averaging Theorem and Equipartition

$$
\left\langle \alpha \imath \frac{\partial \mathcal{H}}{\partial \alpha \jmath} \right\rangle = \delta_{\mathcal{Y}} k_{\mathcal{B}} T,\tag{20.41}
$$

 ω*i* ∂*H* ∂ω*j* = δ*ijk*B*T*, (20.41)

$$
\left\langle q_l \frac{\partial \mathcal{H}}{\partial q_l} \right\rangle = -\left\langle q_l \dot p_l \right\rangle = \delta_{lj} k_B T,\tag{20.42}
$$

<span id="page-363-1"></span>
$$
\left< q_l \frac{\partial \mathcal{H}}{\partial p_j} \right> = \left< q_l \,\dot{q}_l \right> = 0,\tag{20.43}
$$

$$
\left< p_l \frac{\partial \mathcal{H}}{\partial q_l} \right> = -\left< p_l \dot{p}_l \right> = 0,\tag{20.44}
$$

<span id="page-364-0"></span>
$$
\left\langle p_l \frac{\partial \mathcal{H}}{\partial p_l} \right\rangle = \left\langle p_l \,\dot{q}_l \right\rangle = \delta_{lj} k_{\mathcal{B}} T,\tag{20.45}
$$

344 THERMA[L](#page-363-0) [PHYS](#page-363-0)ICS

 ω*i*

line will vanish. This could occur if *H* → ∞ at ω∗

that the potential energy depends only on the coordinates *qi*.

but this is better handled by the virial theorem discussed in Section 20.4.

Therefore,

$$
\left\langle \alpha l \frac{\partial \mathcal{H}}{\partial \alpha_{\parallel}} \right\rangle = \frac{1}{Z_{\mathbb{C}}} \int \alpha l \frac{\partial \mathcal{H}}{\partial \alpha_{\parallel}} \mathbf{e}^{-\beta \mathcal{H}} \, \mathbf{d} \, \omega = -\frac{1}{\beta Z_{\mathbb{C}}} \int \alpha l \frac{\partial \mathbf{e}^{-\beta \mathcal{H}}}{\partial \alpha_{\parallel}} \, \mathbf{d} \alpha
$$

$$
= -\frac{1}{\beta Z_{\mathbb{C}}} \int \left[ \frac{\partial}{\partial \alpha_{\parallel}} \left( \alpha \eta \mathbf{e}^{-\beta \mathcal{H}} \right) - \delta_{\delta} \mathbf{e}^{-\beta \mathcal{H}} \right] \mathbf{d} \alpha
$$

$$
= -\frac{1}{\beta Z_{\mathbb{C}}} \int \alpha \eta \mathbf{e}^{-\beta \mathcal{H}} \Big|_{\alpha_{\parallel}^{\uparrow}}^{\alpha_{\parallel}^{\uparrow\uparrow}} \, \mathbf{d} \alpha^{(0)} + \delta_{\delta} k \mathbf{g} \, T, \tag{20.46}
$$

= − 1 β*Z*C - ∂ [∂ω](#page-363-1)*j* ω*i*e−β*H* − δ*ij*e−β*H* dω = − 1 β*Z*C - ω*i* e−β*H* ω∗∗ *j* ω∗ *j* dω(*j*) + δ*ijk*B*T*, (20.46) where ω∗ *j* and ω∗∗ *j* represent the limits of integration of ω*j* and dω(*j*) denotes the phase space volume element dω with dω*j* missing. Under suitable conditions, the first term on the last

parts makes no sense. For example, in the case of a free particle, *H* is independent3 of all coordinates *qj* so ∂*H*/∂*qj* = 0 and Eq. (20.42) would not h[old.](#page-364-0)

hold. In other cases, however, the integrated term will not vanish or else the integration by

*j* and ω∗∗

$$\mathcal{H} = \sum_{l=1}^{3N} \frac{p_l^2}{2m} + \mathcal{V}(q_1, q_2, \dots, q_{3N}),\tag{20.47}$$

*j* . In such cases, Eq. (20.41) will

**Example Problem 20.5.** Calculate the average kinetic energy for a Hamiltonian of the form *H* = 3*N p*2 *i* + *V*(*q*1, *q*2, ... , *q*3*N* ), (20.47)

*i*=1 2*m* where the first term is the kinetic energy *T* and the second term is the potential energy due to interactions among *N* particles.

$$
\langle \mathcal{T} \rangle = \left\langle \sum_{l=1}^{3N} \frac{p_l^2}{2m} \right\rangle = \frac{3}{2} \mathcal{N} k \mathbf{\&} \mathbf{\&} \mathbf{\;} \mathbf{\;} \tag{20.48}
$$

$$
\text{where}
\mathbf{\;} \quad \text{and} \quad \mathbf{\;} \quad \text{and} \quad \mathbf{\;} \quad \mathbf{\;} \quad \text{and} \quad \mathbf{\;} \quad \mathbf{\;} \quad \mathbf{\;} \quad \mathbf{\;} \quad \mathbf{\;} \quad \mathbf{\;} \quad \mathbf{\;} \quad \mathbf{\;} \quad \mathbf{\;} \quad \mathbf{\;} \quad \mathbf{\;} \quad \dots \tag{20.48}
$$

*T* = *i*=1 *p*2 *i* 2*m* = 3 2 *N k*B*T*. (20.48) Note especially that this result holds not only for an ideal gas but for any system governed by classical statistical mechanics, even when there are interactions among the particles, provided

3For a free particle confined to a box, one could modify *H* to account for forces due to the walls of the box,

<span id="page-365-0"></span>
$$\sum_{l} \alpha_{l} \frac{\partial \mathcal{H}}{\partial \alpha_{l}} = 2\mathcal{H}.\tag{20.49}$$

Appendix F.

$$
\langle \mathcal{H} \rangle = \frac{1}{2} k_{\mathbb{B}} T f_{\mathbb{S}},
\tag{20.50}
$$

to differentiating with respect to λ and then setting λ = 1) gives *i* ω*i* ∂*H* [∂](#page-362-1)ω*i* = 2*H*. (20.49) Thus, *H* = 1 2 *k*B*Tfs*, (20.50) where *f*s is the number of active degrees of freedom, which is equal to the number of nonvanishing terms in the sum in Eq. (20.49). If only the kinetic energy terms contribute, as would be the case if the potential energy were zero, we would have *f*s = 3*N* and the result would be *H* = (3/2)*N k*B*T*, as for the classical ideal gas. If all coordinates and momenta contributed, we would have *f*s = 6*N* , and *H* = 3*N k*B*T*, in agreement with the law of Dulong and Petit in Section 20.2. In the general case, one would have to use a canonical transformation to transform Eq. (20.37) into diagonal form for all generalized coordinates and momenta to see if any terms are missing [8, p. 64]. Mor[eo](#page-365-1)ver, we should eliminate any degrees of freedom that are not activated for quantum mechanical reasons, namely when the corresponding energy levels are so far apart that no excited states are appreciably occupied. For example, consider the degrees of freedom of a diatomic molecule consisting of two point particles. Two point particles would have six degrees of freedom, three translational degrees for each, so one might expect to have *f*s = 6*N* . However, if the particles of the molecule are strongly bound together at some fixed separation 0, the molecule will behave like a rigid rotator. It has three translational

degrees of freedom and it can rotate. Therefore, *f*s = 5*N* and *H* = (5/2)*N k*B*T*, leading to the well-known heat capacity *CV* = (5/2)*N k*B. See Section 21.3 for a more detailed discussion, including the possibility of a vibrational degree of freedom4 if the distance between the particles varies from the constant 0. If the particles are not point particles, one might think of including a rotational degree of freedom that amounts to spinning about the axis connecting the particles. However, the moment of inertia for spinning of actual atoms about the axis that connects their centers is so small that the associated quantum energy levels, which are proportional to its inverse, are very high above the ground state. Therefore, only two rotational degrees of freedom

<span id="page-365-1"></span>are activated at any reasonable temperature. For a detailed analysis, see Section F.8 in

and does not contribute to the heat capacity, so it is seldom mentioned.

<sup>4</sup>It is worth noting that the vibrational zero point energy *h*¯ ω/2 per molecule cannot be avoided, even if *h*¯ω  *k*B*T* so that excited vibrational states are negligible. This, however, just adds a constant *Nh*¯ω/2 to the total energy

346 THERMAL PHYSICS

20.4 Virial Theorem

$$G := \sum_{l=1}^{3N} q_l \, p_l \, . \tag{20.51}$$

classical canonical ensemble. The virial theorem, on the other hand, is based on *time averages* in a classical system. Comparison of these results helps to substantiate that ensemble averages are equivalent to time averages for systems in equilibrium.

$$\frac{\mathrm{d}G}{\mathrm{d}t} = \sum_{l=1}^{3N} \dot{q}_l \, p_l + \sum_{l=1}^{3N} q_l \, \dot{p}_l. \tag{20.52}$$

where *qi* are the canonical coordinates and *pi* are the canonical momenta for a classical

<span id="page-366-0"></span>3*N*

<span id="page-366-1"></span>*Q* := 1

d*G*

$$\overline{Q} \coloneqq \frac{1}{\pi} \int_0^\pi Q(t) \, dt. \tag{20.53}$$

d*t* = *i*=1

$$\frac{\overline{\mathbf{d}G}}{\mathbf{d}t} = \frac{G(\mathbf{r}) - G(\mathbf{0})}{\mathbf{r}}.\tag{20.54}$$

τ 0 Accordingly, the time average of d*[G](#page-366-0)*/d*t* is d*G* d*t* = *G*(τ ) − *G*(0) τ . (20.54)

*i*=1

$$\lim_{\mathbf{r}\to\infty} \frac{\overline{\mathbf{d}G}}{\mathbf{d}t} = \frac{G(\mathbf{r}) - G(\mathbf{0})}{\mathbf{r}} = \mathbf{0}.\tag{20.55}$$

*G*(τ ) − *G*(0) [wil](#page-363-2)l also be bounded, we obtain

virial and allowing the equations to speak for themselves.

averages.

limτ→∞ d*G*

$$\overline{\sum_{l=1}^{3N} \dot{q}_l} \, p_l = -\sum_{l=1}^{3N} q_l \, \dot{p}_l. \tag{20.56}$$

 3*N i*=1 *q*˙*i pi* = − 3*N i*=1 *qi p*˙*i*. (20.56) According to Eq. (20.45), we would have 3*N i*=1 *q*˙*i pi* = 3*N k*B*T* and from Eq. (20.42) we would have 3*N i*=1 *qi p*˙*i*=−3*N k*B*T*. Therefore, Eq. (20.56) is consistent with the results of Section 20.3 for systems in equilibrium if the time averages are replaced by ensemble

<sup>5</sup>Textbooks and other references are quite inconsistent on which quantity is called the virial. Some consider the quantity *G* to be the virial; others consider the right-hand side of Eq. (20.56) or half that quantity or the negative of that quantity to be the virial. We avoid these inconsistencies by not defining any quantity to be the

$$\sum_{l=1}^{3\mathcal{N}} p_l \frac{\partial \mathcal{H}}{\partial p_l} = \sum_{l=1}^{3\mathcal{N}} q_l \frac{\partial \mathcal{H}}{\partial q_l}. \tag{20.57}$$

*Chapter 20* • Classical Canonical Ensemble 347

$$\overline{\mathcal{H}} = \frac{1}{2} \left[ \overline{\sum_{l=1}^{3\mathcal{N}} p_l} \frac{\partial \mathcal{H}}{\partial p_l} + \sum_{l=1}^{3\mathcal{N}} q_l \frac{\partial \mathcal{H}}{\partial q_l} \right]. \tag{20.58}$$

*i*=1 ∂*pi i*=1 ∂*qi* For example, for a Hamiltonian that is homogeneous of degree 2 in all of its coordinates

<span id="page-367-0"></span>and momenta, Eq. (20.49) applies and its time average gives *H* = 1 ⎡ 3*N pi* ∂*H* + 3*N qi* ∂*H* ⎤

$$\sum_{l=1}^{N} m_l \left(\frac{\mathbf{dr}_l}{\mathbf{d}t}\right)^2 = -\sum_{l=1}^{N} m_l \mathbf{r}_l \cdot \frac{\mathbf{d}^2 \mathbf{r}_l}{\mathbf{d}t^2} = -\sum_{l=1}^{N} \mathbf{r}_l \cdot \mathbf{f}_l,\tag{20.59}$$

Equation (20.56) can be interpreted readily if we use Cartesian coordinates and a vector notation, in which [case it](#page-367-0) takes the form

> <span id="page-367-1"></span>= − *N*

> > <span id="page-367-2"></span>*i*=1

$$\overline{\mathcal{T}} = -\frac{1}{2} \overline{\sum_{l=1}^{N} \mathbf{r}_l \cdot \mathbf{f}_l} \tag{20.60}$$

the time a[verage](#page-367-1) of the kinetic energy, namely 2*T* , which yields *T* = −1 *N* **r***i* · **f***i*. (20.60)

$$\mathbf{f}_l = -\nabla l \mathcal{V} \equiv -\frac{\partial \mathcal{V}}{\partial \mathbf{r}_l},\tag{20.61}$$

energy to a total potential *V*(**r**1, **r**2, ... , **r***N* ) from which the force can be derived. If

harmonic motion of a number of oscillators.

Equation (20.60) takes the form

takes the simple form

 *N*

*i*=1 *mi* d**r***i* d*t* 2

form

$$\overline{\mathcal{T}} = \frac{1}{2} \overline{\sum_{l=1}^{N} \mathbf{r}_l \cdot \frac{\partial \mathcal{V}}{\partial \mathbf{r}_l}}. \tag{20.62}$$

*T* = 1 2 *N i*=1 **r***i* · ∂*V* ∂**r***i* . (20.62)

$$
\overline{\mathcal{T}} = \frac{\alpha}{2} \,\overline{\mathcal{V}},\tag{20.63}
$$

*T* = α 2 *V*, (20.63) which relates the average total kinetic energy to the average total potential energy. For the case of a harmonic potential, such as given by Eq. (20.37), we would have α = 2 which would lead to *T* = *V* = *E*/2, where *E* is the constant total energy. This is a well-known result for a simple harmonic oscillator but we see here that it is also true for coupled

<span id="page-368-1"></span>
$$
\overline{\mathcal{T}} = -\frac{1}{2}\overline{\mathcal{V}}.\tag{20.64}
$$

348 THERMAL PHYSICS

$$E = \overline{\mathcal{T}} + \overline{\mathcal{V}} = \overline{\mathcal{T}} - 2\overline{\mathcal{T}} = -\overline{\mathcal{T}} < \mathbf{0}.\tag{20.65}$$

For the case of gravitational forces, we can take α = −1, as shown below, and obtain the often quoted result *T* = −1 2 *V*. (20.64) Then the total energy, which is a constant, would be

<span id="page-368-2"></span>
$$\mathcal{V}(\mathbf{r}_1, \mathbf{r}_2, \dots, \mathbf{r}_N \boldsymbol{\gamma}) = -\frac{1}{2} \sum_{j \neq k} \frac{\mathcal{G}m_j m_k}{|\mathbf{r}_l - \mathbf{r}_k|},\tag{20.66}$$

particles, [bu](#page-368-0)t the result also follows directly from a slightly modified version of the Euler

$$\dot{\mathcal{V}}(\lambda \mathbf{r}_1, \lambda \mathbf{r}_2, \dots, \lambda \mathbf{r}_N) = -\frac{1}{2} \sum_{j \neq k}^{\cdot} \frac{\mathcal{G}m_l m_k}{|\lambda \mathbf{r}_l - \lambda \mathbf{r}_k|} = \frac{1}{|\lambda|} \mathcal{V}(\mathbf{r}_1, \mathbf{r}_2, \dots, \mathbf{r}_N). \tag{20.67}$$

∂ ∂λ *N*

*i*=1

$$\frac{\partial}{\partial \lambda} \sum_{l=1}^{N} \mathcal{V}(\lambda \mathbf{r}_1, \lambda \mathbf{r}_2, \dots, \lambda \mathbf{r}_N) = \sum_{l=1}^{N} \mathbf{r}_l \cdot \frac{\partial \mathcal{V}(\lambda \mathbf{r}_1, \lambda \mathbf{r}_2, \dots, \lambda \mathbf{r}_N)}{\partial(\lambda \mathbf{r}_l)} = -\frac{\lambda}{|\lambda|^3} \mathcal{V}(\mathbf{r}_1, \mathbf{r}_2, \dots, \mathbf{r}_N). \tag{20.68}$$

*j*=*k*

Therefore,6

$$\sum_{l=1}^{\mathcal{N}} \mathbf{r}_l \cdot \frac{\partial \mathcal{V}(\mathbf{r}_1, \mathbf{r}_2, \dots, \mathbf{r}_{\mathcal{N}})}{\partial \mathbf{r}_l} = -\mathcal{V}(\mathbf{r}_1, \mathbf{r}_2, \dots, \mathbf{r}_{\mathcal{N}}),\tag{20.69}$$

= −*V*(**r**1, **r**2, ... , **r***N* ), (20.69)

Setting λ = 1 then gives *N*

<span id="page-368-3"></span>∂*V*(**r**1, **r**2, ... , **r***N* )

### *i*=1 ∂**r***i* which is needed to obtain Eq. (20.64) from Eq. (20.62).

**r***i* ·

<span id="page-368-0"></span>20.5 Virial Coefficients We can use the virial theorem to compute the lowest order correction to [the](#page-368-2) [p](#page-368-2)ressure of a classical monatomic gas that accounts approximately for the effect of pairwise forces

$$\frac{p}{nk_{\rm B}T} = 1 + \sum_{v=2}^{\infty} B_v(T)n^{v-1}.\tag{20.70}$$

*p nk*B*T* = 1 +∞ ν=2

The first virial coefficient is *B*1 = 1 and is seldom mentioned.

6We use |λ| = lim→0 √ λ2 + 2 to take the derivative of 1/|λ| on the right-hand side of Eq. (20.67).

$$\frac{3}{2}\mathcal{N}k_{\rm B}T = -\frac{1}{2}\sum_{l=1}^{\mathcal{N}}\mathbf{r}_{l}\cdot\mathbf{f}_{l}.\tag{20.71}$$

We begin by considering a gas in equilibrium in a box of volume *V* at temperature *T* to which Eqs. (20.48) and (20.60) apply. Combining these equations by equating the time average and the ensemble average gives

$$-\frac{1}{2}\sum_{l=1}^{N}\mathbf{r}_{l}\cdot\mathbf{f}_{l}^{\text{walls}} = p\frac{1}{2}\int_{A}\mathbf{r}\cdot\hat{\mathbf{n}}\,\mathrm{d}A = p\frac{1}{2}\int_{V}\nabla\cdot\mathbf{r}\,\mathrm{d}V = \frac{3}{2}pV.\tag{20.72}$$

Next, we recognize that the forces **f***i* come from the walls of the box and from internal forces due to interparticle interactions. The time average forces due to the walls can be

− 1

 *N*

**r***i* · **f** walls *i* = *p* 1

$$p = nk_{\rm B}T + \frac{1}{3V} \overline{\sum_{l=1}^{N} \mathbf{r}_{l} \cdot \mathbf{f}_{l}^{\rm int}},\tag{20.73}$$

2 *i*=1 2 *A* 2 *V* 2 Thus, Eq. (20.71) becomes

*p* = *nk*B*T* + 1 3*V N i*=1 **r***i* · **f** int *i* , (20.73) where *n* = *N* /*V* is the number density and **f** int *i* are the internal forces due to interparticle

<span id="page-369-1"></span>
$$-\mathbf{r}_{l}\cdot\nabla_{l}\mu - \mathbf{r}_{f}\cdot\nabla_{l}\mu = -\frac{\partial\mu}{\partial r_{l\bar{l}}} \left[\mathbf{r}_{l}\cdot\frac{(\mathbf{r}_{l}-\mathbf{r}_{f})}{r_{l\bar{l}}} + \mathbf{r}_{f}\cdot\frac{(\mathbf{r}_{f}-\mathbf{r}_{l})}{r_{l\bar{l}}}\right] = -r_{l}\frac{\partial\mu(r_{l\bar{l}})}{\partial r_{l\bar{l}}},\tag{20.74}$$

Each pair *i*, *j* of particles contributes

$$\frac{1}{3V}\overline{\sum_{l=1}^{N}\mathbf{r}_{l}\cdot\mathbf{f}_{l}^{\text{int}}} = \frac{N}{3V}\overline{\sum_{j\neq 0}\mathbf{r}_{0}\cdot\mathbf{f}_{j\to 0}^{\text{int}}} = -\frac{N}{6V}\overline{\sum_{j\neq 0}\frac{\partial\mathbf{u}(r_{0j})}{\partial r_{0j}}},\tag{20.75}$$

1 3*V N i*=1 **r***i* · **f** int *i* = *N* 3*V j*=0 **r**0 · **f** int *j*→0 = − *N* 6*V j*=0 *r*0*j* ∂*u*(*r*0*j*) ∂*r*0*j* , (20.75) where **r**0 designates a specific particle and **f** int *j*→0 designates the forces on it due to all other particles *j*. To compute this average, we introduce the **pair distribution function** *g*(*r*) defined such that the average number density of particles at a distance *r* from the center of a particle located at *r* = 0 is *ng*(*r*), where *n* = *N* /*V* is the overall number density. In

0

0

$$\overline{\sum_{j\neq 0} \overline{\rho_{0j} \overline{\rho_{0j}}}} = \int_{V} r \frac{\partial \mathbf{u}(r)}{\partial r} \, \mathbf{n} \mathbf{g}(r) \, \mathbf{d}^3 r = n \int_{0}^{\infty} r \frac{\partial \mathbf{u}(r)}{\partial r} \, 4\pi r^2 \mathbf{g}(r) \, \mathbf{d}r. \tag{20.76}$$
 
$$\text{Mo thomfano find}$$

∂*r*

*j*=0

We therefore find

<span id="page-369-0"></span>∂*r*0*j*

*p*

*V*

interactions.

$$\frac{p}{nk_{\rm B}T} = 1 - \frac{n}{6k_{\rm B}T} \int_{0}^{\infty} r \frac{\partial u(r)}{\partial r} \, 4\pi \, r^{2} \, \mathbf{g}(r) \, \mathrm{d}r. \tag{20.77}$$

*g*(*r*)

<span id="page-370-0"></span>![](_page_370_Figure_1.jpeg)

0.5 1.0

0 1 2 3 4 5 0.0 *r* **FIGURE 20–1** Sketch of the pair distribution function *g*(*r*) versus *r* for *r* measured in units of the atomic diameter. [For](#page-370-0) [a](#page-370-0) [gas](#page-370-0) [of](#page-370-0) [har](#page-370-0)d spheres, the rise at *r* = 1 would be vertical and the first peak would be sharp. The quantity *n*4π*r*2*g*(*r*) is the number of particles in a spherical shell between *r* and *r* + d*r*. It is worth noting that the dependence of the second term in Eq. (20.77) on *T* is more complicated than is apparent because the distribution function *g*(*r*) depends on *T*. At lowest order for a dilute gas, correlations among particles are negligible so *g*(*r*) = exp(−β*u*) is given by the Boltzmann distribution for the pair potential *u*(*r*), with the convention *u*(∞) = 0. Thus, *g*(∞) = 1 and *g*(*r*) ≈ 1 for *r* greater than the range of the potential where *u*(*r*) ≈ 0. More generally, *g*(*r*) = exp(−β*u*) + *ng*1(*r*) + *n*2*g*2(*r*) +··· . Figure 20–1 shows a sketch of *g*(*r*) versus *r*. Typically, *g*(*r*) is zero at *r* = 0 and remains at that value until *r* approaches the atomic diameter; then it rises rapidly to a maximum and undergoes decaying oscillations about the value 1 for a few more atomic diameters, finally decaying to the value 1 for larger *r*. These oscillations are due to short-range order as rings of neighbors, second nearest neighbors, etc. are reached. For a general definition of the [pair d](#page-369-0)istribution function as well as graphs for a hard sphere gas and for argon, see

Ornstein-Zernike equation, see McQuarrie [54, p. 268].

Eq. (20.77) to obtain

- ∞ 0

**Example Problem 20.6.** If the pair distribution function is given to lowest order in *n* by *g*(*r*) = e−β*u*, show that *p* can be expressed in terms of a volume integral of the Mayer function *f*(*r*) =

Pathria and Beale [9, p. 332]. For its connection to the direct correlation function and the

0

e−β*u* − 1. **Solution 20.6.** We note that ∂*f* /∂*r* = −β*g*(*r*)∂*u*/∂*r* and substitute into the second term in

$$\int_0^\infty \frac{\partial \mathbf{u}(r)}{\partial r} \mathbf{g}(r) \, r^3 \, \mathrm{d}r = -\frac{1}{\beta} \int_0^\infty \frac{\partial f}{\partial r} \, r^3 \, \mathrm{d}r = \frac{3}{\beta} \int_0^\infty f \, r^2 \, \mathrm{d}r,\tag{20.78}$$

0

where we have integrated by parts in the last step and noted that *r*3*f*(*r*) vanishes at both *r* = 0 and *r* = ∞. Therefore,

<span id="page-371-0"></span>
$$\frac{p}{mk_{\rm B}T} = 1 - \frac{n}{2} \int_0^\infty f(r) \, 4\pi r^2 \, \mathrm{d}r.\tag{20.79}$$

**Example Problem 20.7.** Calculate *B*2(*r*) for a gas of hard spheres of diameter σ . When two such spheres just touch, their centers are at a distance σ from each other, which can be accounted for by assuming that there is an infinite potential within a radius *r* = σ from the center of a given sphere.

**Solution 20.7.** The relevant functions are shown in the following table:

| Region   | r <σ | σ < r |
|----------|------|-------|
| u(r)     | ∞    | 0     |
| g(r)     | 0    | 1     |
| f<br>(r) | −1   | 0     |

Thus,

$$B_2(T) = -\frac{1}{2} \int_0^\infty f(r) 4\pi r^2 \,\mathrm{d}r = 2\pi \int_0^\sigma r^2 \,\mathrm{d}r = \frac{2\pi}{3} \sigma^3 = 4v_0,\tag{20.80}$$

where *v*0 is the volume of a single hard sphere. In this case, *p* = *nk*B*T*(1 + 4*v*0*n*) ≈ *N k*B*T*/(*V* − 4*N v*0), which has the form of an ideal gas with an excluded volume equal to four times the volume of all the hard spheres.

**Example Problem 20.8.** Calculate *B*2(*r*) for a gas having a potential that is infinite for *r* < σ , has a square well of depth ε for *r* between σ and σ + *a*, and is zero for *r* > σ + *a*.

**Solution 20.8.** The relevant functions are shown in the following table:

| Region   | r <σ | σ< r < σ + a      | σ + a < r |
|----------|------|-------------------|-----------|
| u(r)     | ∞    | −ε                | 0         |
| g(r)     | 0    | exp(βε)           | 1         |
| f<br>(r) | −1   | −<br>exp(βε)<br>1 | 0         |

The integrations are straightforward and result in

$$B_2(T) = \frac{2\pi}{3}\sigma^3 \left[1 - (\mathbf{e}^{\beta\varepsilon} - 1)\frac{(\sigma + a)^3 - \sigma^3}{\sigma^3}\right],\tag{20.81}$$

which agrees with the hard sphere gas for *a* = 0. For βε 1, we can expand the exponential to get the high-temperature result

$$B_2(T) = \frac{2\pi}{3}\sigma^3 \left[1 - \frac{s}{k_B T} \frac{(\sigma + a)^3 - \sigma^3}{\sigma^3}\right]. \tag{20.82}$$

352 THERMAL PHYSICS

$$p + a_0/v^2 = k_\mathbb{B}T/(v - b_0),\tag{20.83}$$

$$\text{where } v = 1/n, a_0 = \varepsilon (2\pi/3)[(\sigma + a)^3 - \sigma^3], \text{and } b_0 = (2\pi/3)\sigma^3.$$

<span id="page-372-0"></span>

$$\mathbf{g}(|\mathbf{r}_2 - \mathbf{r}_1|) \frac{\mathbf{d}^3 r_1}{V} \frac{\mathbf{d}^3 r_2}{V} \tag{20.84}$$

where *v* = 1/*n*, *a*0 = ε(2π/3)[(σ + *a*)3 − σ 3], and *b*0 = (2π/3)σ [3.](#page-369-1) An alternative definition of the pair distribution function is that

$$\frac{1}{3V}\sum_{l=1}^{N}\mathbf{r}_{l}\cdot\mathbf{f}_{l}^{\text{int}} = -\frac{1}{3V}\sum_{\text{pairs}}r_{l}\overline{\frac{\partial u(r_{l})}{\partial r_{l}}}.\tag{20.85}$$

number of particles in d3*r* located at **r**, given that there is a particle at the origin. Thus an

$$-\frac{1}{3V}\sum_{\text{pairs}}r_{\text{l}}\frac{\partial u(r_{\text{l}})}{\partial r_{\text{l}}} = -\frac{N^2}{6V}\int\frac{\mathbf{d}^3r_1}{V}\int\frac{\mathbf{d}^3r_2}{V}\mathbf{g}(|\mathbf{r}_2-\mathbf{r}_1|)r_{12}\frac{\partial u(r_{12})}{\partial r_{12}}.\tag{20.86}$$

The number of pairs is *N* (*[N](#page-372-0)* − 1)/2 ≈ *N* 2/[2](#page-369-0) [so](#page-369-0) ∂*u*(*rij*) d3*r*1 d3*r*2 ∂*u*(*r*12)

$$-\frac{1}{3V}\sum_{\text{pairs}}\overline{r_{\text{lj}}}\frac{\partial\overline{u(r_{\text{lj}})}}{\partial r_{\text{lj}}} = -\frac{N^2}{6V^2}\int\mathbf{d}^3\mathbf{r}\mathbf{g}(\mathbf{r})\mathbf{r}\frac{\partial\overline{u(r)}}{\partial r} = -\frac{n^2}{6}\int_0^\infty r\frac{\partial\overline{u(r)}}{\partial r}4\pi r^2\mathbf{g}(\mathbf{r})\,\mathrm{d}r,\tag{20.87}$$

d3*r*1/*V* = 1 and we are left with

− 1 3*V* pairs *rij* ∂*u*(*rij*) ∂*rij* = − *N* 2 6*V*2 - d3*rg*(*r*)*r* ∂*u*(*r*) ∂*r* = −*n*2 6 - ∞ 0 *r* ∂*u*(*r*) ∂*r* 4π*r*2*g*(*r*) d*r*, (20.87) in agreement with the second term of Eq. (20.77) multiplied by *[nk](#page-368-3)*B*T*. With the use of Eq. (20.84), we can write an expression for the internal energy per

$$\frac{U_{\rm int}}{N} = \frac{\mathcal{N}}{2} \int \frac{\mathbf{d}^3 r_1}{V} \int \frac{\mathbf{d}^3 r_2}{V} \mathbf{u}(\mathbf{r}_{12}) \mathbf{g}(|\mathbf{r}_2 - \mathbf{r}_1|) = \frac{n}{2} \int_0^\infty \mathbf{u}(r) 4\pi r^2 \mathbf{g}(r) \,\mathrm{d}r. \tag{20.88}$$

**Example Problem 20.9.** Beginning with the virial expansion Eq. (20.70) and the fact that one obtains an ideal gas if all *Br* (*T*) = 0 for *r* ≥ 2, determine series expansions for the following: the Helmholtz free energy per particle, *f* ; the entropy per particle,*s*; the internal energy per particle,

2 - ∞ 0

*u*(*r*12)*g*(|**r**2 − **r**1|) = *n*

*u*; the heat capacity (at constant volume) per particle, *c*; and the chemical potential, μ.

**Solution 20.9.** We begin with

*U*int *N* = *N* 2 d3 *r*1 *V* d3*r*2 *V*

$$\mathbf{d}f = -s\,\mathrm{d}T - p\,\mathrm{d}v = -s\,\mathrm{d}T + (p/n^2)\,\mathrm{d}n \tag{20.89}$$

*u*(*r*)4π*r*2*g*(*r*) d*r*. (20.88)

$$f = k \boxtimes T \ln n + w(T) + k \boxtimes T \sum_{r=2}^{\infty} B_{\overline{r}}(T) \frac{n^{r-1}}{r-1},\tag{20.90}$$

*Chapter 20* • Classical Canonical Ensemble 353

$$f = k_{\mathbb{B}}T[\ln(n/n_{\mathbb{Q}}) - 1] + k_{\mathbb{B}}T \sum_{r=2}^{\infty} B_{r}(T) \frac{n^{r-1}}{r-1},\tag{20.91}$$
 
$$f = \begin{array}{ccccc} \dots & \dots & \dots & \dots & \dots & m \end{array}$$

*f* = *k*B*T* ln *n* + *w*(*T*) + *k*B*T r*=2 *Br* (*T*) *r* − 1 , (20.90)

$$s = -\left(\partial f/\partial T\right)_n = k\mathfrak{g}\left[\ln(n_Q/n) + 5/2\right] - k\mathfrak{g}\sum_{r=2}^{\infty} \frac{\mathfrak{d}\{TB_I(T)\}}{\mathrm{d}T} \frac{n^{r-1}}{r-1},\tag{20.92}$$

$$\mu = f + T\mathbf{s} = (3/2)k_{\mathbf{B}}T - k_{\mathbf{B}}T^2 \sum_{r=2}^{\infty} \frac{\mathbf{d}B_{\mathbf{f}}(T)}{\mathbf{d}T} \frac{n^{r-1}}{r-1},\tag{20.93}$$

$$\mathbf{c} = (\partial \boldsymbol{\mu}/\partial \boldsymbol{T})_n = (3/2)k_\mathrm{B} - k_\mathrm{B}T \sum_{r=2}^\infty \frac{\mathbf{d}^2 \mathbf{l}^2 \mathbf{l} \mathbf{T} \mathbf{B}_\mathbf{l}(\boldsymbol{T}) \mathbf{l}}{\mathbf{d}T^2} \frac{\boldsymbol{n}^{r-1}}{r-1},\tag{20.94}$$

<span id="page-373-2"></span>
$$\mu = f + p/n = k_{\rm B} T \ln(n/n_{\rm Q}) + k_{\rm B} T \sum_{r=2}^{\infty} B_{r}(T) \frac{r \, n^{r-1}}{r-1}. \tag{20.95}$$

*c* = (∂*u*/∂*T*)*n* = (3/2)*k*B − *k*B*T r*=2 d*T*2 *r* − 1 μ = *f* + *p*/*n* = *k*B*T* ln(*n*/*n*Q) + *k*B*T* ∞ *r*=[2](#page-371-0) *Br* (*T*) *r nr*−1 *r* − 1 . (20.95)

<span id="page-373-1"></span>[*TBr* (*T*)]

**Example Problem 20.10.** Show that the pressure given by Eq. (20.79) and the particle-particle interaction energy given by Eq. (20.88) are compatible with the *r* = 2 terms in the general

$$-\operatorname{kg}T^{2}\frac{\operatorname{dB}_{2}(T)}{\operatorname{d}T} = \frac{1}{2}\int_{0}^{\infty}u(r)4\pi r^{2}\operatorname{g}(r)\operatorname{d}r.\tag{20.96}$$

requires ∞

$$B_2(T) = -\frac{1}{2} \int_0^\infty f(r) \, 4\pi r^2 \, \mathrm{d}r.\tag{20.97}$$

<span id="page-373-0"></span>, (20.94)

*B*2(*T*) = −1 - ∞ *f* (*r*) 4π*r*2 d*r*. (20.97)

order.

$$\frac{\mathrm{dB}_{2}(T)}{\mathrm{d}T} = -\frac{1}{2} \int_{0}^{\infty} \frac{\partial f(r)}{\partial T} 4\pi r^{2} \,\mathrm{d}r = -\frac{1}{2k_{\mathrm{B}}T^{2}} \int_{0}^{\infty} u(r) \, 4\pi r^{2} \mathrm{g}(r) \,\mathrm{d}r,\tag{20.98}$$

d*B*2(*T*) d*T* = −1 2 -0 ∂*f* (*r*) ∂*T* 4π*r*2 d*r* = − 1 2*k*B*T*2 -0 *u*(*r*) 4π*r*2*g*(*r*) d*r*, (20.98) in agreement with Eq. (20.96). Note that we had to use the explicit form *g*(*r*) = eβ*u*, which gives the correct second-order virial coefficient. More generally, this is only the leading term in an expansion of *g*(*r*) in powers of *n*. Including such terms would lead to virial coefficients of higher

examples.

354 THERMAL PHYSICS 20.6 Use of Canonical Transformations Evaluation of the classical partition function can be facilitated greatly by using canonical

$$q_l = q_l(Q, P); \quad p_l = p_l(Q, P). \tag{20.99}$$

nates. General canonical transformations are discussed in Appendix E. In particular, one transforms from one set of generalized coordinates *q* = *q*1, *q*2, ... , *qN* and their conjugate

transformations to perform the required integrals. Such transformations leave the form

$$Z_{\rm C} = \int \exp[-\beta \, \mathcal{H}(\mathbf{p}, \mathbf{q})] \, \mathrm{d}p \, \mathrm{d}q = \int \exp[-\beta \, \mathcal{K}(\mathbf{P}, \mathbf{Q})] |f| \, \mathrm{d}P \, \mathrm{d}Q,\tag{20.100}$$

<span id="page-374-0"></span>*qi* = *qi*(*Q*, *P*); *pi* = *pi*(*Q*, *P*). (20.99) The corresponding transformation of the partition function would be *Z*C = - exp[−β *[H](#page-374-0)*(**p**, **q**)] d*p* d*q* = - exp[−β *K*(**P**, **Q**)]|*J*| d*P* d*Q*, (20.100) where *K*(**P**, **Q**) is the new Hamiltonian and |*J*| is the absolute value of the Jacobian of the

$$Z_{\mathbb{C}} = \int \exp[-\beta \, \mathcal{H}(\mathbf{p}, \mathbf{q})] \, \mathrm{d}p \, \mathrm{d}q = \int \exp[-\beta \, \mathcal{K}(\mathbf{P}, \mathbf{Q})] \, \mathrm{d}P \, \mathrm{d}Q. \tag{20.101}$$

integral becomes simply *Z*C = - exp[−β *H*(**p**, **q**)] d*p* d*q* = - exp[−β *K*(**P**, **Q**)] d*P* d*Q*. (20.101) The simple form of Eq. (20.101) might seem strange to those accustomed to seeing scale factors such as *r*2 sin θ appearing in Jacobians that arise in transformation of volume integrals from Cartesian to spherical polar coordinates. But for canonical transformations, *both* the coordinates and the momenta transform in just such a way that the corresponding volumes in phase space are the same. Nevertheless, it is frequently the case that familiar scale factors for the coordinate integrals will appear after performing the momentum integrals. Finally, it is sometimes expedient to use transformations

that are not canonical to do the necessary integrals. See the next section for explicit

old and new Hamiltonians are numerically equal at corresponding points.

<sup>7</sup>In Appendix E, we allow these transformations to depend explicitly on time as well, but here we are interested in equilibrium ensembles so we omit explicit dependence on time. Such transformations are called restricted canonical transformations and are treated explicitly in Section E.2. For restricted canonical transformations, the

**Example Problem 20.11.** Compute the classical partition function *Z*∗ C for a single diatomic molecule consisting of point particles having masses *m*1 and *m*2 separated by a fixed distance (no vibrational mode) and having a magnetic moment μB that makes an angle θ with an applied magnetic field *B*. The molecule is confined to a box of volume *V* and its Hamiltonian has the form (which we need to write in terms of canonical momenta)

$$\mathcal{H} = \frac{m_1}{2}\dot{\mathbf{r}}_1^2 + \frac{m_2}{2}\dot{\mathbf{r}}_2^2 - \mu_\mathcal{B}B\cos\theta. \tag{20.102}$$

**Solution 20.11.** We make a canonical transformation to a center of mass coordinate **R** = (*m*1**r**1 + *m*2**r**2)/(*m*1 + *m*2) and a relative coordinate **r** = **r**1 − **r**2 but then an additional transformation of the relative coordinate into spherical polar coordinates with fixed radius *r* = , azimuthal angle ϕ and polar angle θ. The kinetic energy in *H* takes the well-known form

$$\frac{m_1}{2}\dot{\mathbf{r}}_1^2 + \frac{m_2}{2}\dot{\mathbf{r}}_2^2 = \frac{M}{2}\dot{\mathbf{R}}^2 + \frac{\mu_{\text{red}}}{2}[\ell^2\dot{\theta}^2 + \ell^2\sin^2\theta\dot{\varphi}^2],\tag{20.103}$$

where *M* = *m*1 + *m*2 is the total mass and μred = *m*1*m*2/*M* is the reduced mass. The canonical momenta are *Pi* = ∂*H*/∂*R*˙*i* = *MR*˙*i*, *p*θ = ∂*H*/∂θ˙ = μ 2θ˙, and *p*ϕ = ∂*H*/∂ϕ˙ = μ 2 sin2 θ ϕ˙, so the Hamiltonian becomes

$$\mathcal{H} = \sum_{l=1}^{3} \frac{P_l^2}{2M} + \frac{p_\theta^2}{2I} + \frac{p_\varphi^2}{2I\sin^2\theta} - \mu_\mathcal{B}B\cos\theta,\tag{20.104}$$

where *I* = μred 2 is the moment of inertia about the center of mass of the molecule. See Section F.1.1 in Appendix F for an explicit evaluation of *I*. Since the transformation is canonical, the partition function is

$$Z_{\rm C}^{*} = \frac{1}{h^{5}} \int \exp[-\beta \mathcal{H}] \, \mathrm{d}P_{1} \, \mathrm{d}P_{2} \, \mathrm{d}P_{3} \, \mathrm{d}R_{1} \, \mathrm{d}R_{2} \, \mathrm{d}R_{3} \, \mathrm{d}p_{\theta} \, \mathrm{d}\theta_{\theta} \, \mathrm{d}\theta \, \mathrm{d}\varphi. \tag{20.105}$$

The factor of *h*−5, rather than *h*−6, arises because the magnitude of has been assumed to be constant (no vibrational mode). Since exp[−β*H*] factors, we can perform the *R* and *P* integrals immediately to obtain

$$\frac{1}{h^3} \int \exp\left[-\beta \sum_{l=1}^3 \frac{P_l^2}{2M}\right] \operatorname{d}P_1 \operatorname{d}P_2 \operatorname{d}P_3 \operatorname{d}R_1 \operatorname{d}R_2 \operatorname{d}R_3 = Vn_\mathcal{Q},\tag{20.106}$$

where *n*Q = (*Mk*B*T*/2π*h*¯ 2)3/2. The integrals over d*p*θ and d*p*ϕ are well-known Gaussian integrals, resulting in

$$\frac{1}{h} \int \exp\left[-\beta \frac{p_{\theta}^{2}}{2I}\right] \mathrm{d}p_{\theta} = \left(\frac{2\pi I}{h^{2}\beta}\right)^{1/2}; \quad \frac{1}{h} \int \exp\left[-\beta \frac{p_{\psi}^{2}}{2I\sin^{2}\theta}\right] \mathrm{d}p_{\psi} = \sin\theta \left(\frac{2\pi I}{h^{2}\beta}\right)^{1/2}.\tag{20.107}$$

The crucial point to note is that the scale factor sin θ gets trapped inside the remaining θ integral, resulting in

$$Z_{\rm C}^{*} = V \eta_{\rm Q} \left(\frac{2\pi I}{h^{2}\beta}\right) \int \exp[\beta \mu_{\rm B} B \cos \theta] \sin \theta \,\mathrm{d}\theta \,\mathrm{d}\varphi = V \eta_{\rm Q} \left(\frac{2I}{h^{2}\beta}\right) \frac{\sinh(\beta \mu_{\rm B} B)}{\beta \mu_{\rm B} B}.\tag{20.108}$$

356 THERMAL PHYSICS

### We see that the partition function is the product of three factors, *Vn*Q which is the partition function for translation of a structureless ideal gas of molecules having molecular mass *M*, a

factor (2*I*/*h*¯ 2β), which is the partition function for a rigid diatomic molecule rotating about its center of mass, and a factor sinh(βμB*B*)/βμB*B* which is the partition function for a magnetic dipole. 20.7 Rotating Rigid Polyatomic Molecules In the approximation of classical statistical mechanics, we can calculate the partition function by integrating over canonical coordinates and momenta in phase space and dividing by appropriate powers of *h*. Such a partition function should agree with a quantum mechanical result at high temperatures. Rigid rotation of a polyatomic molecule

<span id="page-376-0"></span>
$$\mathcal{H} = \frac{1}{2} (\mathcal{T}_1 \alpha_1^2 + \mathcal{T}_2 \alpha_2^2 + \mathcal{T}_3 \alpha_3^2) = \frac{L_1^2}{2\mathcal{T}_1} + \frac{L_2^2}{2\mathcal{T}_2} + \frac{L_3^2}{2\mathcal{T}_3}.\tag{20.109}$$

<span id="page-376-1"></span>of the molecule can be expressed in terms of three Euler angles, φ, θ, and ψ, where we have adopted the notation and convention of Goldstein [60, p. 107]. As shown in Section F.7, the Hamiltonian can be written in the forms *H* = 1 2 (*I*1ω2 1 + *I*2ω2 2 [+](#page-376-0) *I*3ω2 3) = *L*2 1 2*I*1 + *L*2 2 2*I*2 + *L*2 3 2*I*3 . (20.109)

$$z = \frac{1}{h^3} \int \exp(-\beta \mathcal{H}) \, \mathrm{d}p_\phi \, \mathrm{d}p_\theta \, \mathrm{d}p_\psi \, \mathrm{d}\phi \, \mathrm{d}\theta \, \mathrm{d}\psi. \tag{20.110}$$

be calculated by differentiation and are given explicitly by Eqs. (F.61)–(F.63). Thus *z* = 1 *h*3 - exp(−β*H*) d*p*φ d*p*θ d*p*ψ dφ dθ dψ. (20.110) One could proceed by solving Eqs. (F.61)–(F.63) for *L*1, *L*2, *L*3 and using the results to eliminate these quantities from Eq. (20.109). This results in a very cumbersome expression

$$z = \frac{1}{h^3} \int \exp(-\beta \mathcal{H}) \left| J^{\text{poly}} \right| \, \text{d}L_1 \, \text{d}L_2 \, \text{d}L_3 \, \text{d}\phi \, \text{d}\theta \, \text{d}\psi,\tag{20.111}$$

where

$$|J^{\rm poly}| = \left| \frac{\partial \left( p_{\phi}, p_{\theta}, p_{\psi}, \phi, \theta, \psi \right)}{\partial \left( L_{1}, L_{2}, L_{3}, \phi, \theta, \psi \right)} \right| = \left| \frac{\partial \left( p_{\phi}, p_{\theta}, p_{\psi} \right)}{\partial \left( L_{1}, L_{2}, L_{3} \right)} \right|. \tag{20.112}$$

|*J*poly| = ∂ (*L*1, *L*2, *L*3, φ, θ, ψ ) = ∂ (*L*1, *L*2, *L*3) . (20.112)

*z* = 1

-

$$|\mathcal{J}^{\text{poly}}| = \left| \det \begin{pmatrix} \sin \theta \sin \psi & \sin \theta \cos \psi & \cos \theta \\ \cos \psi & -\sin \psi & 0 \\ 0 & 0 & 1 \end{pmatrix} \right| = |-\sin \theta| = \sin \theta. \tag{20.113}$$

<span id="page-377-1"></span>-

$$z = \frac{1}{h^3} \int \exp(-\beta \mathcal{H}) \sin \theta \,\mathrm{d}L_1 \,\mathrm{d}L_2 \,\mathrm{d}L_3 \,\mathrm{d}\phi \,\mathrm{d}\theta \,\mathrm{d}\psi$$

$$= \frac{8\pi^2}{h^3} \int \exp\left[-\beta \left(\frac{L_1^2}{2\mathcal{Z}_1} + \frac{L_2^2}{2\mathcal{Z}_2} + \frac{L_3^2}{2\mathcal{Z}_3}\right)\right] \,\mathrm{d}L_1 \,\mathrm{d}L_2 \,\mathrm{d}L_3. \tag{20.114}$$

$$\int_{-\infty}^{\infty} \exp[-\beta L_1^2/(2\mathcal{Z}_1)] \, \mathrm{d}L_1 = \left(2\pi \mathcal{Z}_1 \mathrm{k} \mathbb{R}\right)^{1/2}.\tag{20.115}$$

*z* = 1 *h*3

$$z = \pi^{1/2} \left(\frac{2\mathcal{Z}_1 k_\mathsf{B} T}{\hbar^2}\right)^{1/2} \left(\frac{2\mathcal{Z}_2 k_\mathsf{B} T}{\hbar^2}\right)^{1/2} \left(\frac{2\mathcal{Z}_3 k_\mathsf{B} T}{\hbar^2}\right)^{1/2}.\tag{20.116}$$

We are left wit[h](#page-377-0) [t](#page-377-0)he product of three Gaussian integrals of the form - ∞ exp[−β*L*2 1/(2*I*1)] d*L*1 = 2π*I*1*k*B*T* 1/2 . (20.115)

−∞ We therefore obtain 1/2

$$\begin{aligned} \text{minimize } \dots \text{---} & \dots \dots \text{---} \dots \text{---} \dots \text{---} \dots \text{---} \dots \text{---} \dots \text{---} \dots \\ \mathcal{H} &= \frac{\mathcal{Z}}{2} (\boldsymbol{\omega}_1^2 + \boldsymbol{\omega}_2^2) = \frac{\mathcal{Z}}{2} (\sin^2 \theta \dot{\phi}^2 + \dot{\theta}^2) = \frac{1}{2\mathcal{Z}} (\boldsymbol{L}_1^2 + \boldsymbol{L}_2^2). \end{aligned} \tag{20.117}$$

that can also vibrate.

*H* = *I* 2 (ω2 1 + ω2

$$p_{\phi} = \mathcal{Z}\sin^{2}\theta\dot{\phi} = L_{1}\sin\theta\sin\psi + L_{2}\sin\theta\cos\psi\tag{20.118}$$

and

treatment.

$$p_{\theta} = \mathcal{T}\dot{\theta} = L_1 \cos \psi - L_2 \sin \psi. \tag{20.119}$$

Now the only canonical momenta are10

*z*dia = 1 *h*2 -

$$\begin{aligned} \text{r.r.r.}\\ z^{\text{dla}} &= \frac{1}{h^2} \int \exp(-\beta \mathcal{H}) \, \mathrm{d}p_\phi \, \mathrm{d}p_\theta \, \mathrm{d}\phi \, \mathrm{d}\theta = \frac{1}{h^2} \int \exp(-\beta \mathcal{H}) |J^{\text{dla}}| \, \mathrm{d}L_1 \, \mathrm{d}L_2 \, \mathrm{d}\phi \, \mathrm{d}\theta, \\ \text{the magnitude of the Jacobian} \end{aligned} \tag{20.120}$$

Therefore,

where the magnitude of the Jacobian

$$|J^{\rm dila}| = \left| \frac{\partial \left( p_{\phi}, p_{\theta} \right)}{\partial \left( L_1, L_2 \right)} \right| = \sin \theta. \tag{20.121}$$

 ∂ *p*φ, *p*θ 

−β

1 2*I* +

*h*2

<span id="page-377-0"></span>
$$z^{\rm dla} = \frac{4\pi}{h^2} \int \exp\left[-\beta \left(\frac{L_1^2}{2\mathcal{T}} + \frac{L_2^2}{2\mathcal{T}}\right)\right] \mathrm{d}L_1 \,\mathrm{d}L_2. \tag{20.122}$$

8The ranges of the Euler angles are 0 ≤ φ ≤ 2π, 0 ≤ θ ≤ π, and 0 ≤ ψ ≤ 2π. Landau and Lifshitz [7, p. 149]

2 2*I*

give a verbal argument that an integral over three unspecified angles gives a factor of 8π2 and then proceed to integrate over only *L*1, *L*2, *L*3, but no justification in terms of canonical momenta is given. 9As shown in Section F.8 of Appendix F, the quantum states associated with *I*3 have such high energies that

they are not excited at any reasonable temperature. 10Here, we continue to use the same Euler angles as for the polyatomic molecule for the sake of a parallel result

*M*(**L**) =

2π*I*1

$$z^{\text{dla}} = \frac{2\mathcal{T}k_{\text{B}}T}{\hbar^2},\tag{20.123}$$

358 THERMAL PHYSICS

$$\mathcal{H} = \frac{1}{2\mathcal{T}} \left( \frac{p_{\phi}^{2}}{\sin^{2}\theta} + p_{\theta}^{2} \right),\tag{20.124}$$

*h*¯ 2 , (20.123)

in agreement with the high-temperature quantum mechanical result given by Eq. (18.85). In this simple case, the Hamiltonian can be written in terms of the canonical momenta in the form & *p*2

$$M(\mathbf{L}) = \left(\frac{\beta}{2\pi\mathcal{I}_1}\right)^{1/2} \left(\frac{\beta}{2\pi\mathcal{I}_2}\right)^{1/2} \left(\frac{\beta}{2\pi\mathcal{I}_3}\right)^{1/2} \exp\left[-\beta \left(\frac{L_1^2}{2\mathcal{I}_1} + \frac{L_2^2}{2\mathcal{I}_2} + \frac{L_3^2}{2\mathcal{I}_3}\right)\right]. \tag{20.125}$$

On the other hand, when *I*1, *I*2, and *I*3 are all different, there is great simplification in transforming to *L*1, *L*2, *L*3. For example, a normalized probability distribution function for the angular momenta *Li* would be β 1/2 β 1/2 β 1/2 & *L*2 *L*2 *L*2

$$\text{momentum as}$$

$$(L^2) = \int M(\mathbf{L})(L_1^2 + L_2^2 + L_3^2) \, \text{dL}_1 \, \text{dL}_2 \, \text{dL}_3 = \text{kg}T(\mathbb{Z}_1 + \mathbb{Z}_2 + \mathbb{Z}_3). \tag{20.126}$$

cube of infinitesimal volume d*L*1 d*L*2 d*L*3 centered at **L**[. Th](#page-377-1)e average square of the angular momentum is *L*2 = - *M*(**L**)(*L*2 1 + *L*2 2 + *L*2 3) d*L*1 d*L*2 d*L*3 = *k*B*T*(*I*1 + *I*2 + *I*3). (20.126)

$$|J_{\alpha}| = \left| \frac{\vartheta \left( p_{\phi}, p_{\theta}, p_{\psi} \right)}{\vartheta \left( \alpha_{1}, \alpha_{2}, \alpha_{3} \right)} \right| = \mathcal{Z}_{1} \mathcal{Z}_{2} \mathcal{Z}_{3} \sin \theta. \tag{20.127}$$

*I*3ω2 3

partition function Eq. (20.110) by means of the Jacobian |*J*ω| = ∂ *p*φ, *p*θ , *p*ψ ∂ (ω1,ω2,ω3) = *I*1*I*2*I*3 sin θ. (20.127)

1/2

exp −β & *I*1ω2 1

$$M^*(\omega) = \left(\frac{\beta \mathcal{Z}_1}{2\pi}\right)^{1/2} \left(\frac{\beta \mathcal{Z}_2}{2\pi}\right)^{1/2} \left(\frac{\beta \mathcal{Z}_3}{2\pi}\right)^{1/2} \exp\left[-\beta \left(\frac{\mathcal{Z}_1 a_1^2}{2} + \frac{\mathcal{Z}_2 a_2^2}{2} + \frac{\mathcal{Z}_3 a_3^2}{2}\right)\right]. \tag{20.128}$$

*M*∗(*ω*) = β*I*1 1/2 β*I*2 1/2 β*I*3

inertia.

This leads to an average value

$$
\langle \omega^2 \rangle = \int M^*(\omega) (\omega_1^2 + \omega_2^2 + \omega_3^2) \, \mathrm{d}\omega_1 \, \mathrm{d}\omega_2 \, \mathrm{d}\omega_3 = k_\mathrm{B} T \left( \frac{1}{\mathcal{Z}_1} + \frac{1}{\mathcal{Z}_2} + \frac{1}{\mathcal{Z}_3} \right). \tag{20.129}
$$

*I*2ω2 2

ω2 = -*M*∗(*ω*)(ω2 1 + ω2 2 + ω2 3) dω1 dω2 dω3 = *k*B*T* 1 *I*1 + 1 *I*2 + 1 *I*3 . (20.129) It is interesting and physically reasonable that average values of the squares of the principal angular velocities are inversely proportional to their respective moments of

21 Grand Canonical Ensemble In Chapter 19, we derived the canonical ensemble by starting with the microcan[on](#page-379-0)ical

ensemble. The microcanonical ensemble applies to an isolated system which therefore has a fixed energy; on the other hand, the canonical ensemble applies to a system that has a fixed temperature. The derivation is accomplished by considering the system of interest to be a subsystem of a total system that is isolated and to which the microcanonical ensemble applies. The remainder of the total system, exclusive of the system of interest, acts as a heat reservoir whose temperature is imposed on the system of interest. In the present chapter, we introduce the grand canonical ensemble (GCE) which applies to a system having a fixed temperature and a fixed chemical potential, but not a fixed energy or a fixed number of particles. Other extensive parameters of the system, which we take to be only the volume *V* in the development that follows, are fixed.1 Our system of interest is again considered to be a subsystem of a total system that is isolated and therefore has a fixed energy and a fixed number of particles. In this case, the remainder of the total system, exclusive of the system of interest, acts as both a heat reservoir and

a particle reservoir for the system of interest. Thus, it imposes its temperature and its chemical potential on the system of interest. But the system of interest will have an average energy, *U*, and an average number of particles, -*N* , which together with its volume *V* will be sufficient for its thermodynamic description. By using the GCE for which the number of particles is not specified, we gain the flexibility to treat systems that have quantum mechanical constraints on the number of particles that can occupy a quantum state. We shall use it to treat ideal Fermi and Bose gases whose wave functions must be antisymmetric or symmetric, respectively, when its identical particles are interchanged. For such quantum ideal gases, the grand canonical partition function factors, which is not the case for the canonical partition function. The classical ideal gas will be shown to be a limiting case of either a Fermi gas or a Bose gas. Thus the approximations used to treat the classical ideal gas by means of the canonical ensemble with the Gibbs correction factor *N* ! can be clarified. Accordingly we treat a classical i[deal gas of molecules having inter](http://dx.doi.org/10.1016/B978-0-12-803304-3.00021-1)nal structure. Dilute systems for which the constituents can be regarded as independent subsystems can also be treated by a grand canonical partition function that factors. We shall illustrate its use to treat adsorption

<span id="page-379-0"></span>from a gas that imposes its chemical potential on a surface having dilute adsorption

particles.

<sup>1</sup>These are usually the parameters that allow the system to do work. A system without a volume might have an area or a length that is relevant. A system could also have a fixed number of sites that can be occupied by

### <span id="page-380-1"></span>360 THERMAL PHYSICS

sites. Finally, we use the same methodology as used to derive the GCE to develop a pressure ensemble that we illustrate by treating point defects in crystals under conditions of constant temperature and pressure. 21.1 Derivation from Microcanonical Ensemble We derive the GCE from the microcanonical ensemble by generalization of the second derivation of the canonical ensemble given in Section 19.1.2. For an alternative treatment based on the evaluation of an integral by the method of steepest descent, see Schrödinger

[99, p. 41]. We consider a total isolated system (subscript "T") having a fixed energy *E*T and a fixed number of particles *N*T. We regard the total system to consist of a reservoir *R* and a system *I* of interest. The system *I* may, itself, be very large. We consider a situation in which the system *I* is in a quantum state having a specific number of particles *Ns* and quantum states *Ers*(*V*) ≡ *Er* (*Ns*, *V*), where its volume *V* is fixed. For simplicity of notation, we will suppress the argument *V* in the development that follows. When the system of interest is in a specific quantum state, the energy of the reservoir

<span id="page-380-0"></span>
$$\dot{\boldsymbol{\Omega}}_{\rm T}^{\rm IS} = \dot{\boldsymbol{\Omega}}_{\rm R} (\boldsymbol{E}_{\rm T} - \boldsymbol{\mathcal{E}}_{\rm r3}, \boldsymbol{\mathcal{N}_{\rm T}} - \boldsymbol{\mathcal{N}_{\rm S}}) \boldsymbol{\Omega} (\boldsymbol{\mathcal{E}}_{\rm t3}, \boldsymbol{\mathcal{N}_{\rm S}}) = \boldsymbol{\Omega}_{\rm R} (\boldsymbol{E}_{\rm T} - \boldsymbol{\mathcal{E}}_{\rm r3}, \boldsymbol{\mathcal{N}_{\rm T}} - \boldsymbol{\mathcal{N}_{\rm S}}), \tag{21.1}$$

*Ers*, *N*T − *Ns*). This is also equal to the multiplicity function of the total system because the system of interest is in a definite quantum state, so its multiplicity function is -(*Ers*, *Ns*) = 1. Symbolically,

$$P_{\rm T3} = \frac{\Omega_{\rm T}^{\rm IS}}{\Omega_{\rm T}(E_{\rm T}, \mathcal{N}_{\rm T})} = \frac{\Omega_{\rm R}(E_{\rm T} - \mathcal{E}_{\rm T3}, N_{\rm T} - \mathcal{N}_{\rm S})}{\Omega_{\rm T}(E_{\rm T}, \mathcal{N}_{\rm T})} = \frac{\exp[\mathcal{S}_{\rm R}(E_{\rm T} - \mathcal{E}_{\rm R}, N_{\rm T} - \mathcal{N}_{\rm S})/k_{\rm B}]}{\exp[\mathcal{S}_{\rm T}(E_{\rm T}, \mathcal{N}_{\rm T})/k_{\rm B}]},\tag{21.21}$$

this definite quantu[m sta](#page-380-0)te is therefore *Prs* = *rs* T T(*E*T, *N*T) = -R(*E*T − *Ers*, *N*T − *Ns*) T(*E*T, *N*T) = exp[*S*R(*E*T − *Ers*, *N*T − *Ns*)/*k*B]

$$S_{\Gamma}(E_{\Gamma}, \mathcal{N}_{\Gamma}) = S_{\mathbb{R}}(E_{\Gamma} - U, \mathcal{N}_{\Gamma} - \langle \mathcal{N} \rangle) + S(U, \langle \mathcal{N} \rangle),\tag{21.3}$$

we have *S*T(*E*T, *N*T) = *S*R(*E*T − *U*, *N*T − -*N* ) + *S*(*U*,-*N* ), (21.3) where *U* = -*E* is the average internal energy of the system of interest and -*N* is its average

$$P_{\rm IN} = \frac{\exp[-S(U, \langle \mathcal{N} \rangle)/k_{\rm B}] \exp[S_{\rm R}(E_{\rm T} - \mathcal{E}_{\rm r3}, N_{\rm T} - \mathcal{N}_{\rm S})/k_{\rm B}]}{\exp[S_{\rm R}(E_{\rm T} - U, \mathcal{N}_{\rm T} - \langle \mathcal{N} \rangle)/k_{\rm B}]}.\tag{21.4}$$
 We write

*N* )/*k*B] . (21.4)

We write

-

$$\mathrm{S_R} \left[ E_{\mathrm{T}} - \mathcal{E}_{\mathrm{T}3}, N_{\mathrm{T}} - \mathcal{N}_{\mathrm{S}} \right] = \mathrm{S_R} \left[ (E_{\mathrm{T}} - U) + (U - \mathcal{E}_{\mathrm{R}}), (N_{\mathrm{T}} - \langle \mathcal{N} \rangle) + (\langle \mathcal{N} \rangle - \mathcal{N}_{\mathrm{S}}) \right] \tag{21.5}$$

*S*R [*E*T − *Ers*, *N*T − *Ns*] = *S*R [(*E*T − *U*) + (*U* − *Ers*),(*N*T − -*N* ) + (-*N* − *Ns*)] (21.5) and then expand on the basis that |*U* − *Ers*|/|*E*T − *U*| 1 and |-*N* − *Ns*|/|*N*T − -*N* | 1 to obtain

exp[*S*R(*E*T − *U*, *N*T − -

$$\mathcal{S}_{\mathbb{R}}(E_{\Gamma} - \mathcal{E}_{\mathbb{R}^3}N_{\Gamma} - N_3) = \mathcal{S}_{\mathbb{R}}(E_{\Gamma} - U, N_{\Gamma} - \langle \mathcal{N} \rangle) + \frac{U - \mathcal{E}_{\mathbb{R}^3}}{T_{\mathbb{R}}} - \frac{\mu_{\mathbb{R}}}{T_{\mathbb{R}}}(\langle \mathcal{N} \rangle - \mathcal{N}_3) + \dotsb \ . \tag{21.6}$$

$$P_{\rm IN} = \exp[\left(U - T\mathbb{k}S - \mu \mathbb{k}\langle \mathcal{N} \rangle\right)/(k \boxtimes T \mathbb{k})] \exp[-\mathcal{E}_{\rm IN}/(k \boxtimes T \mathbb{k})] \exp[\mu \mathbb{k} \mathcal{N}_{\mathbb{S}}/(k \boxtimes T \mathbb{k})].\tag{21.7}$$

*T*R

*Chapter 21* • Grand Canonical Ensemble 361

*T*R

$$K := U - T\mathcal{S} - \mu \langle \mathcal{N} \rangle = F - \mu \langle \mathcal{N} \rangle,\tag{21.8}$$

Substitution into Eq. (21.4) yields

$$P_{l3} = \exp(\beta \mathcal{K}) \exp(-\beta \mathcal{E}_{l3}) \exp(\beta \mu \mathcal{N}_{\mathfrak{d}}),\tag{21.9}$$

Dropping the subscripts on *T*R and μR and defining the Kramers potential (also known as the grand potential),

*K* := *U* − *TS* − μ-*N* = *F* − μ-*N* , (21.8) Equation (21.7) can be written in the form *Prs* = exp(β*K*) exp(−β*Ers*) exp(βμ*Ns*), (21.9)

where β = 1/(*k*B*T*) as usual. The quantity exp(−β*Ers*) exp(βμ*Ns*) is referred to as a **Gibbs factor** by Kittel and Kroemer [6], by analogy to a Boltzmann factor. At constant *T* andμ, we see that the ratio of the probabilities of any two states is equal to

$$1 = \exp(\beta K) \sum_{n} \exp(-\beta \mathcal{E}_{n}) \exp(\beta \mu \mathcal{N}_{\mathfrak{s}}).\tag{21.10}$$

If we sum the probabilities *Prs* over all values of *Ers* and *Ns* (which Kittel and Kroemer [6] call "all states and numbers," abbreviated by "ASN"), Eq. (21.9) yields

<span id="page-381-2"></span><span id="page-381-0"></span>
$$\mathcal{Z} := \sum_{rs} \exp(-\beta \mathcal{E}_{rs}) \exp(\beta \mu \mathcal{N}_s) = \exp(-\beta K). \tag{21.11}$$

This allows us to define a grand partition function (also known as [the Gi](#page-381-0)bbs sum [6] over ASN), *Z* := - exp(−β*Ers*) exp(βμ*Ns*) = exp(−β*K*). (21.11)

$$P_{l3} = \frac{\exp(-\beta \mathcal{E}_{l3}) \exp(\beta \mu \mathcal{N}_l)}{Z},\tag{21.12}$$

the canonical partition function *Z*. The probabilities can be written in the form

which is similar in form to Eq. (19.6).

<span id="page-381-1"></span>*rs*

factors.

Eq. (21.14).

*Prs* = exp(−β*Ers*) exp(βμ*Ns*) *Z* , (21.12)

$$\mathcal{K} = -k_{\rm B} T \ln \mathcal{Z} \tag{21.13}$$

[In](#page-381-1) [ord](#page-381-1)er to recover the thermodynamic functions, we write Eq. (21.11) in the form *K* = −*k*B*T* ln *Z* (21.13)

d*K* = −*S* d*T* − *p* d*V* − -

$$\mathbf{d}\mathcal{K} = -\mathbf{S}\,\mathrm{d}T - p\,\mathrm{d}V - \langle \mathcal{N} \rangle \,\mathrm{d}\mu. \tag{21.14}$$

*N* dμ. (21.14)

<sup>2</sup>In dealing with the canonical ensemble, to which *F* is related, we regard the number of particles *N* to be specified; however, for the GCE, we relate *K* to the average number of particles -*N* . In thermodynamics, we can ignore the distinction between *N* and -*N* , but for the GCE, this distinction must be made, so we write -*N* in

system, one usually regards -

<span id="page-382-2"></span>
$$S = -\left(\frac{\partial K}{\partial T}\right)_{V,\mu}; \quad p = -\left(\frac{\partial K}{\partial V}\right)_{T,\mu}; \quad \langle \mathcal{N} \rangle = -\left(\frac{\partial K}{\partial \mu}\right)_{T,V}.\tag{21.15}$$

362 THERMAL PHYSICS

Thus we have3 *S* = −∂*K* ∂*T* ; *p* = −∂*K* ; -*N* =−∂*K* ∂μ . (21.15)

$$U = K - T\left(\frac{\partial K}{\partial T}\right)_{V,\mu} - \mu \left(\frac{\partial K}{\partial \mu}\right)_{T,V}.\tag{21.16}$$

specify -*N* and solve for μ, but since μ is contained in a transcendental equation, this can

*V*,μ

$$U = k_{\rm B} T^2 \left( \frac{\partial \ln \mathcal{Z}}{\partial T} \right)_{V, \mu} + k_{\rm B} T \mu \left( \frac{\partial \ln \mathcal{Z}}{\partial \mu} \right)_{T, V} = - \left( \frac{\partial \ln \mathcal{Z}}{\partial \mathcal{\beta}} \right)_{V, \mu} + \frac{\mu}{\beta} \left( \frac{\partial \ln \mathcal{Z}}{\partial \mu} \right)_{\beta, V}. \tag{21.17}$$

*U* = *K* − *T* ∂*K* ∂*T* [−](#page-381-0) μ ∂*K* ∂μ . (21.16)

*V*,μ *T*,*V* Substitution of Eq. (21.13) into Eq. (21.16) then leads to

- *U* = *k*B*T*2 ∂ ln *Z* ∂*T V*,μ + *k*B*T*μ ∂ ln *Z* ∂μ *T*,*V* = −∂ ln *Z* ∂β *V*,μ + μ β ∂ ln *Z* ∂μ β,*V* . (21.17)

$$\mathcal{Z} = \sum_{s} \exp(\beta \mu \mathcal{N}_{s}) \sum_{r} \exp(-\beta \mathcal{E}_{t3}) = \sum_{s} \exp(\beta \mu \mathcal{N}_{s}) Z_{\mathcal{N}_{t}},\tag{21.18}$$

are in order:

the distinction is irrelevant.

*Z* = -

<span id="page-382-1"></span>*s*

exp(βμ*Ns*)

*s* λ*Ns*

*r*

-

*r*

<span id="page-382-0"></span>

$$Z_{\mathcal{N}_l} := \sum_{I} \exp(-\beta \mathcal{E}_{I3})\tag{21.19}$$

where, according to Eq. (19.5),

- *ZNs* := - *r* exp(−β*Ers*) (21.19) is the canonical partition function for a system having exactly *Ns* particles. **2.** We need to specify clearly the variable set on which *Z* and *K* depend. Until now, as

$$
\lambda := \exp(\beta \mu) \tag{21.20}
$$

λ*NsZNs* (21.21)

**activity** λ := exp(βμ) (21.20)

*Ns*

$$\mathcal{Z} = \sum_{s} \lambda^{N_{\ell}} \sum_{r} \exp(-\beta \mathcal{E}_{\ell 3}) = \sum_{\mathcal{N}_{\ell}} \lambda^{N_{\ell}} Z \mathcal{N}_{\ell} \tag{21.21}$$

3Strictly speaking, *S* is an average entropy and *p* is an average pressure, but we have omitted the averaging brackets because they were absent in Eq. (21.14) which is of thermodynamic origin. In the thermodynamic limit,

$$Z_{\mathcal{N}_{\delta}} = \left. \frac{1}{\mathcal{N}_{\delta}!} \left( \frac{\partial}{\partial \lambda} \right)^{\mathcal{N}_{\delta}} \mathcal{Z} \right|_{\lambda=0}. \tag{21.22}$$

*Chapter 21* • Grand Canonical Ensemble 363

$$P_{l3} = \frac{\lambda^{\mathcal{N}_l} \exp(-\beta \mathcal{E}_{l3})}{\mathcal{Z}}.\tag{21.23}$$

- means of the formula *ZNs* = 1 *Ns*! ∂ ∂λ*Ns Z* λ=0 . (21.22) Then the probabilities can be written in the form
<span id="page-383-0"></span>
$$\frac{\sqrt{\langle (\mathcal{N}_{\mathcal{S}} - \langle \mathcal{N} \rangle)^2 \rangle}}{\langle \mathcal{N} \rangle} \sim \frac{1}{\sqrt{\langle \mathcal{N} \rangle}} \tag{21.24}$$

**3.** In the expression for *Z*, it is often convenient to [run th](#page-382-0)e sum formally from *Ns* = 0 to *Ns* = ∞ which would require a reservoir of infinite size. This does not give rise to a problem because we are interested in systems with finite -*N* and we shall see that the

- important values of *Ns* are those near -*N* because -(*Ns* − -*N* )2 *N* ∼ 1 √-
-

*V*,μ =

∂ ln *Z*

$$\text{Concent margin across energy} \left(\omega_1 \mathbf{\hat{z}} - \mathbf{\hat{o}}\right) = \mathbf{\hat{z}} \cdot \mathbf{\hat{z}} \text{mean Eq. (2.125a) can be written in two form}$$

$$Z = \mathbf{I} + \sum_{\mathcal{N}_l} \lambda^{\mathcal{N}_l} Z_{\mathcal{N}_l}.\tag{21.25}$$

**4.** The state with *Ns* = 0 is known as the **vacuum state**. We regard it to be a nondegenerate state having zero energy, *Z*(*Ns* = 0) = 1. Then Eq. (21.18) can be written in the form *Z* = 1 +- λ*NsZNs* . (21.25)

### All other energies are to be measured relative to the vacuum state. Thi[s conv](#page-382-1)ention is consistent with representation of many particle states by means of occupation

numbers of orbitals, which are quantum states of single particles (see Eq. (21.63)). 21.1.1 Kramers Function

*Ns*

$$q(\beta, V, \lambda) := \ln Z,\tag{21.26}$$

terms of the Kramers dimensionless function4 *q*(β, *V*, λ) := ln *Z*, (21.26)

$$
\left(\frac{\partial \ln \mathcal{Z}}{\partial \beta}\right)_{V,\mu} = \left(\frac{\partial q}{\partial \beta}\right)_{V,\lambda} + \lambda \mu \left(\frac{\partial q}{\partial \lambda}\right)_{V,\beta} \tag{21.27}
$$

and

and

$$
\left(\frac{\partial \ln \mathcal{Z}}{\partial \mu}\right)_{V,\beta} = \lambda \beta \left(\frac{\partial q}{\partial \lambda}\right)_{V,\beta}.\tag{21.28}
$$

(21.27)

*V*,β *V*,β 4The Kramers potential (grand potential) *K* is related to the dimensionless Kramers function *q* by the equation *K* = − *k*B*Tq*, but the variables on which they are usually regarded to depend are different.

364 THERMAL PHYSICS

<span id="page-384-0"></span>
$$U = -\left(\frac{\partial q}{\partial \beta}\right)_{V,\lambda}.\tag{21.29}$$

<span id="page-384-2"></span><span id="page-384-1"></span>
$$
\langle \mathcal{N} \rangle = k_{\rm B} T \left( \frac{\partial \ln \mathcal{Z}}{\partial \mu} \right)_{V, \beta} = \lambda \left( \frac{\partial q}{\partial \lambda} \right)_{V, \beta} \tag{21.30}
$$

Thus Eq. (21.17) becomes

$$p = k_{\rm B} T \left( \frac{\partial \ln Z}{\partial V} \right)_{\beta, \mu} = \frac{1}{\beta} \left( \frac{\partial q}{\partial V} \right)_{\beta, \lambda}. \tag{21.31}$$

Similar convers[ion](#page-384-0) [of](#page-384-0) the d[erivativ](#page-384-1)es in Eq. (21.15) gives ∂*q*

-

$$\mathbf{d}\boldsymbol{q} = -U\,\mathbf{d}\boldsymbol{\beta} + \beta p\,\mathbf{d}V + \frac{\langle \boldsymbol{\mathcal{N}} \rangle}{\lambda} \,\mathbf{d}\lambda.\tag{21.32}$$

and *p* [=](#page-384-1) *k*B*T* ∂ ln *Z* ∂*V* β,μ = 1 β ∂*q* ∂*V* β,λ . (21.31) These results can be summarized in terms of the differential d*q* = −*U* dβ + β*p* d*V* + -*N*

λ dλ. (21.32) Note that Eqs. (21.29) and (21.30) could have been obtained directly from definitions of

$$q = \ln\left[\sum_{\mathcal{N}_l} \lambda^{\mathcal{N}_l} Z_{\mathcal{N}_l}\right].\tag{21.33}$$

form of Eq. (21.21) for *q*, namely ⎡ ⎤

$$U_{\mathcal{N}_i} = -\frac{1}{Z_{\mathcal{N}_i}} \left( \frac{\partial Z_{\mathcal{N}_i}}{\partial \mathcal{\beta}} \right)_{V_{\mathcal{N}_i}}.\tag{21.34}$$

ensemble is

Thus Eq. (21.29) takes the form

similar form

values of *Ns*.

$$U = \frac{\sum_{\mathcal{N}_s} \lambda^{\mathcal{N}_s} Z_{\mathcal{N}_s} U_{\mathcal{N}_s}}{\sum_{\mathcal{N}_s} \lambda^{\mathcal{N}_s} Z_{\mathcal{N}_s}},\tag{21.35}$$

*U* = *Ns* λ*NsZNsUNs Ns* λ*NsZNs* , (21.35)

$$
\langle \mathcal{N} \rangle = \frac{\sum_{\mathcal{N}_s} \lambda^{\mathcal{N}_s} Z_{\mathcal{N}_s} \mathcal{N}_s}{\sum_{\mathcal{N}_s} \lambda^{\mathcal{N}_s} Z_{\mathcal{N}_s}}. \tag{21.36}
$$

-*N* = *Ns* λ*NsZNsNs Ns* λ*NsZNs* . (21.36) In fact, Eqs. (21.35) and (21.36) follow directly from the probabilities given by Eq. (21.12). The reader is invited to show that the pressure is a similar weighted average of the pressures, calculated from the canonical ensemble, for systems having definite

<span id="page-385-1"></span>
$$K = -pV,\tag{21.37}$$

<span id="page-385-0"></span>
$$q = \frac{pV}{k_{\rm B}T}.\tag{21.38}$$

The pressure can also be rel[ated d](#page-385-0)irectly to t[he](#page-384-2) *q* function by an algebraic equation. The only extensive variable on which *K* depends is *V*, so its Euler equation is just

*K* = −*pV*, (21.37)

<span id="page-385-2"></span>
$$
\left(\frac{\partial q}{\partial V}\right)_{\beta,\lambda} = \frac{q}{V},\tag{21.39}
$$

Both *K* and *q* are extensive variables that depend on β, λ, and *V*, but β and λ are intensive,

which is consistent with *U* = *TS* − *pV* + μ-

$$
\ln q = \ln V + \ln q_0(\beta, \lambda). \tag{21.40}
$$

 ∂*q* ∂*V* β,λ = *[q](#page-385-0) V* , (21.39)

$$
\eta = Vq_0(\beta, \lambda),
\tag{21.41}
$$

ln *q* = ln *V* + ln *q*0(β, λ). (21.40)

*r*,*s*

*r*,*s*

-

$$p = k_{\mathbb{B}} T q_{\mathbb{B}}(\beta, \lambda), \tag{21.42}$$

*q* = *Vq*0(β, λ), [(21.41](#page-385-1)) [which](#page-385-2) is proportional to *V*. Comparison with Eq. (21.38) shows that

*p* = *k*B*Tq*0(β, λ), (21.42) so the intensive variable *p* can be expressed in terms of only the intensive variables β and λ, or equivalently *T* and μ, independent of *V* as expected. It sometimes happens that the GCE is used to treat systems that do not contain the volume *V* as a variable, in which case *Z*, and therefore *q* and *K*, are independent of *V*. Examples of such systems would be identical spins or harmonic oscillators, fixed in position and distinguishable by virtue of their position, as in a rigid solid, or a set of adsorption sites on a surface. In such cases, equations such as Eqs. (21.31) and (21.37)– (21.42) are not applicable. Formally, such systems have zero pressure or equivalents to pressure that can be defined in spaces of lower dimensionality. As long as these systems

λ

β

$$U = \sum_{r,s} P_{\rm IS} \mathcal{E}_{\rm IS} = -\left(\frac{\partial q}{\partial \beta}\right)_{\lambda} \tag{21.43}$$
 
$$\text{and}$$

(21.43)

and

$$
\langle \mathcal{N} \rangle = \sum_{r,s} P_{rs} \mathcal{N}_{\mathcal{S}} = \lambda \left( \frac{\partial q}{\partial \lambda} \right)_{\beta} \,. \tag{21.44}
$$

$$S = -k\mathfrak{g}\sum_{rs} P_{rs}\ln P_{rs}.\tag{21.45}$$

*N* so

366 THERMAL PHYSICS

$$-\sum_{\mathsf{T}\mathsf{S}} P_{\mathsf{T}\mathsf{S}} \ln P_{\mathsf{T}\mathsf{S}} = -\sum_{\mathsf{T}\mathsf{S}} P_{\mathsf{T}\mathsf{S}} [-q - \beta \mathcal{E}_{\mathsf{T}\mathsf{S}} + \mathcal{N}_{\mathsf{S}} \ln \lambda] = q + \beta U - \langle \mathcal{N} \rangle \ln \lambda.$$

*S* = −*k*B

-

*rs*

**Solution 21.1.** Whether or not there is dependence on *V*, we have *K* = *U* − *TS* − μ-

### *S*/*k*B = *q* + β*U* − -*N* ln λ. But

−*rs Prs* ln *Prs* = −*rs Prs*[−*q* − β*Ers* + *Ns* ln λ] = *q* + β*U* − -*N* ln λ. The entrop[y takes t](#page-382-2)he same form as Eq. (21.45) in any ensemble. 21.1.2 Particle Number Dispersion In Section 19.5, we showed for the canonical ensemble that there was dispersion of the

internal energy for a system held at constant temperature. This is also true for the GCE; however, for the GCE, the chemical potential is held constant and equal to that of a reservoir. Therefore, for a system described by the GCE, there is also dispersion of the

$$
\langle (\Delta \mathcal{N})^2 \rangle := \langle (\mathcal{N} - \langle \mathcal{N} \rangle)^2 \rangle = \langle \mathcal{N}^2 \rangle - \langle \mathcal{N} \rangle^2,\tag{21.46}
$$

*Prs* ln *Prs*. (21.45)

given by Eq. (21.15). We can quantify this dispersion of particle number by calculating its second moment

$$
\langle \mathcal{N}^2 \rangle = \sum_{\mathbf{rs}} \mathcal{N}_{\mathbf{s}}^2 P_{\mathbf{rs}, \mathbf{}} \tag{21.47}
$$

where

$$\frac{\partial^2 \mathcal{Z}}{\partial \mu^2} = \beta^2 \sum_{l3} \mathcal{N}_s^2 \exp(-\beta \mathcal{E}_{l3}) \exp(\beta \mu \mathcal{N}_3),\tag{21.48}$$

<span id="page-386-0"></span>

relative to its average value, namely

agreement with Eq. (21.24), we have

-(*N* )

∂2*Z*

∂μ2 = β2 -

-

 -

-

*rs*

1

1

∂2*Z*

2 := -

$$
\langle \mathcal{N}^2 \rangle = \frac{1}{\beta^2} \frac{1}{\mathcal{Z}} \left( \frac{\partial^2 \mathcal{Z}}{\partial \mu^2} \right)_{\beta, V} . \tag{21.49}
$$

. (21.49)

which yields

Therefore,

$$\langle (\Delta \boldsymbol{N})^2 \rangle = \frac{1}{\beta^2} \frac{1}{\mathcal{Z}} \frac{\partial^2 \mathcal{Z}}{\partial \mu^2} - \frac{1}{\beta^2} \frac{1}{\mathcal{Z}^2} \left( \frac{\partial \mathcal{Z}}{\partial \mu} \right)^2 = \frac{1}{\beta^2} \frac{\partial^2 \ln \mathcal{Z}}{\partial \mu^2} = \frac{1}{\beta} \left( \frac{\partial \langle \boldsymbol{N} \rangle}{\partial \mu} \right)_{\beta, V}. \tag{21.50}$$
 
$$\rho_{\text{universe}} \text{ the orbital load side of } \mathbb{D}-\langle \boldsymbol{0}1.50 \rangle \text{ is } \mathcal{O}(\langle \boldsymbol{N} \rangle). \text{ The fourth-order } \langle \boldsymbol{N} \rangle \text{ is } \mathcal{O}(\langle \boldsymbol{N} \rangle).$$

-(*N* ) 2 = β2 *Z* ∂μ2 − 1 β2 *Z*2 ∂μ 2 β2 ∂μ2 = 1 β ∂μ β,*V* . (21.50) Since μ and β are intensive, the right-hand side of Eq. (21.50) is *O*(-*N* ). Therefore, in

$$\frac{\sqrt{\langle (\Delta \mathcal{N})^2 \rangle}}{\langle \mathcal{N} \rangle} = O\left(\frac{1}{\sqrt{\langle \mathcal{N} \rangle}}\right). \tag{21.51}$$

-

β

-

$$\frac{\sqrt{\langle (\Delta \mathcal{N})^2 \rangle}}{\langle \mathcal{N} \rangle} = \frac{1}{\sqrt{\langle \mathcal{N} \rangle}}. \tag{21.52}$$

*Chapter 21* • Grand Canonical Ensemble 367

For an ideal gas, Eq. (19.66) applies,5 so ∂-*N* /∂μ= β-*N* and we have exactly 

$$
\left(\frac{\partial\mu}{\partial v}\right)_{\beta} = v \left(\frac{\partial p}{\partial v}\right)_{\beta} = -1/\kappa\mathbf{\dot{r}}.\tag{21.53}
$$

small.

Therefore,

 ∂*v*/∂*p* 

$$\left(\frac{\partial \langle \mathcal{N} \rangle}{\partial \mu} \right)_{\beta, V} = \left(\frac{\partial (V/v)}{\partial \mu} \right)_{\beta, V} = -\frac{V}{v^2} \left(\frac{\partial v}{\partial \mu} \right)_{\beta} = \frac{\langle \mathcal{N} \rangle}{v} \kappa_{\mathcal{T}}.\tag{21.54}$$

∂μ ∂*v* = *v* ∂*p*

> ∂-*N*

β , where *v* := *V*/-

<span id="page-387-0"></span>
$$\frac{\sqrt{\langle (\Delta \mathcal{N})^2 \rangle}}{\langle \mathcal{N} \rangle} = \sqrt{\frac{k_{\text{B}} T \kappa_{\text{T}}}{v \langle \mathcal{N} \rangle}}\tag{21.55}$$
 
$$(11) \text{ For an ideal gas } v = 1/\text{n and } k_{\text{T}} T/(\text{no}) = 1 \text{, so Eq. (21.55)}$$

= −1/κT. [(21.53)](#page-387-0)

∂μ β,*V* = ∂μ β,*V v* 2 β *v* κT. (21.54) Substitution into Eq. (21.50) leads to -(*N* )2 *N* = *k*B*T*κT *N* (21.55)

*v*-

### in agreement with Eq. (21.51). For an ideal gas, κT = 1/*p* and *k*B*T*/(*pv*) = 1, so Eq. (21.55) becomes Eq. (21.52). Since *v*-

∂*U*

λ,*V*

Eq. (21.29) we have *U* = -

*N* = *V*, we observe that fluctuations in particle numbers could be large if very small sub-volume of a large volume of gas is observed. 21.1.3 Energy Dispersion

<span id="page-387-1"></span>
$$
\langle E^2 \rangle = \sum_{\mathcal{R}} \mathcal{E}_{\mathcal{R}}^2 P_{\mathcal{R}} = \frac{1}{\mathcal{Z}} \left( \frac{\partial^2 \mathcal{Z}}{\partial \boldsymbol{\beta}^2} \right)_{\boldsymbol{\lambda}, \boldsymbol{V}}.\tag{21.56}
$$

-*E*2 = - *rsPrs* = 1 ∂2*Z* 

> -*N*,*V*

$$
\langle \cdots \rangle \quad \text{(12.57)}
$$

$$
\langle (\Delta E)^2 \rangle = \langle E^2 \rangle - \langle E \rangle^2 = \left( \frac{\partial \ln Z}{\partial \beta^2} \right)_{\lambda, V} = -\left( \frac{\partial U}{\partial \beta} \right)_{\lambda, V} \,. \tag{21.57}
$$

-(*E*) 2=-*E*2−-*E* 2 = ∂ ln *Z* ∂β2 λ,*V* = −∂*U* ∂β λ,*V* . (21.57)

$$
\left(\frac{\partial U}{\partial \beta}\right)_{\lambda, V} = \left(\frac{\partial U}{\partial \beta}\right)_{\langle \mathcal{N} \rangle, V} + \left(\frac{\partial U}{\partial \langle \mathcal{N} \rangle}\right)_{\beta, V} \left(\frac{\partial \langle \mathcal{N} \rangle}{\partial \beta}\right)_{\lambda, V}.\tag{21.58}
$$

λ,*V*

5Equation (19.66) applies to the canonical ensemble, for which the system is regarded as having an exact number of particles *N* , which therefore corresponds to the symbol -*N* of the GCE.

β,*V*

∂-*N*

$$\left(\frac{\partial(\langle N\rangle/\lambda)}{\partial\beta}\right)_{\lambda,V} = -\left(\frac{\partial U}{\partial\lambda}\right)_{\beta,V},\tag{21.59}$$

368 THERMAL PHYSICS

∂*U*

-(*E*)

$$\left(\frac{\partial \langle \mathcal{N} \rangle}{\partial \beta} \right)_{\lambda, V} = -\left(\frac{\partial U}{\partial \ln \lambda} \right)_{\beta, V} = -\frac{1}{\beta} \left(\frac{\partial U}{\partial \mu} \right)_{\beta, V} \,. \tag{21.60}$$

we make use of a Maxwell relation derived from Eq. (21.32), namely

But

$$
\left(\frac{\partial U}{\partial \mu}\right)_{\beta,V} = \left(\frac{\partial U}{\partial \langle \mathcal{N} \rangle}\right)_{\beta,V} \left(\frac{\partial \langle \mathcal{N} \rangle}{\partial \mu}\right)_{\beta,V} = \left(\frac{\partial U}{\partial \langle \mathcal{N} \rangle}\right)_{\beta,V} \beta \langle (\Delta \mathcal{N})^2 \rangle,\tag{21.61}
$$

which becomes ∂-*N* ∂β = − ∂*U* = − 1 ∂*U*

$$\text{Amountил шен мекрь. че излеснос оочини плишау }$$

$$\langle (\Delta E)^2 \rangle = k_\text{B} T^2 C_V + \left\{ \left( \frac{\partial U}{\partial \langle \mathcal{N} \rangle} \right)_{\beta, V} \right\}^2 \langle (\Delta \mathcal{N})^2 \rangle. \tag{21.62}$$

2. (21.62)

ε .

∂μ β,*V* = ∂-*N* β,*V* ∂μ β,*V* = ∂-*N* β,*V* β-(*N* ) 2, (21.61) where Eq. (21.50) has been used in the last step. We therefore obtain finally ∂*U* 2

β,*V*

-(*N* )

∂-*N*

### Equation (21.62) shows that the energy dispersion is the sum of two terms, the first term being the same as for the canonical ensemble and the second term arising from dispersion

2 = *k*B*T*2*CV* +

of the number of particles in the system. 21.2 Ideal Systems: Orbitals and Factorization The GCE can be used to treat the important case of ideal systems of identical particles that can be described in terms of single-particle quantum states called **orbitals**. As defined by Kittel and Kroemer [6, p. 152], an orbital is a term often used by chemists to denote a single-particle quantum state characterized by specification of the quantum numbers of its spatial wave function *and its spin*. A system for which particles interact very weakly can be approximated by an ideal system in which the particles do not interact at all. For a system having *Ns* noninteracting particles, the total wave function can be formed as a sum of products of the wave functions of the orbitals, [8, p. 116], which requires specification of the numbers (called **occupation numbers**) of particles that occupy each orbital. Frequently there is an infinite number of possible orbitals. If the particles are fermions (half integral spin), the total wave function must be antisymmetric under interchange of particles, which requires that each orbital be either unoccupied or occupied by only one particle (the **Pauli exclusion principle**). If the particles are bosons, the total wave function must be symmetric under interchange of particles, which allows each orbital to be unoccupied or multiply-occupied. Classical particles are an approximation to fermions

or bosons in a dilute limit to be discussed below. We denote each orbital by the single symbol ε which denotes its energy *but also carries the information about all of its quantum numbers, including spin.* The number of such orbitals in a quantum state *r* of the whole system having *Ns* particles is denoted by *nrs*

$$\mathcal{E}_{\rm rs} = \sum_{\varepsilon} n_{\varepsilon}^{\rm rs} s,\tag{21.63}$$

where

$$\sum_{\varepsilon} n_{\varepsilon}^{rs} = \mathcal{N}_s,\quad\text{all allowed states }r.\tag{21.64}$$
 
$$r = \dots, \dots, \dots, \dots, \quad c = \dots, \dots, s.\dots, s$$

These occupation numbers, *nrs*

considering. Specifically,

convention *Z*(*Ns* = 0) = 1 used to establish Eq. (21.25).

$$Z = \sum_{s} \lambda^{N_{\vec{s}}} \sum_{r}^{*} \exp\left(-\beta \sum_{\varepsilon} n_{\varepsilon}^{\rm rs} \varepsilon\right) = \sum_{s} \sum_{r}^{*} \prod_{\varepsilon} [\lambda \exp\left(-\beta \varepsilon\right)]^{n_{\vec{s}}^{\rm rs}}.\tag{21.65}$$

- ε *nrs* ε = *Ns*, all allowed states *r*. (21.64) The grand partition function is therefore *Z* = - *s* λ*Ns* -∗ *r* exp −β - ε *nrs* ε ε = - *s* -∗ *r* ε [λ exp (−βε)] *nrs* ε . (21.65) For fixed *Ns*, the allowed values of *nrs* ε are constrained by Eq. (21.64) and also by the constraints for fermions or bosons. The asterisk "∗" on the *r* sum is intended to remind us

$$\mathcal{Z} = \prod_{\varepsilon} \left\{ \sum_{n} \left[ \lambda \exp \left( -\beta \varepsilon \right) \right]^{n} \right\}. \tag{21.66}$$

and the product commute, so we obtain 

<span id="page-389-1"></span><span id="page-389-0"></span>*Z* = ε

$$\mathcal{Z}_{\mathbf{l}}(\boldsymbol{\varepsilon}) \coloneqq \sum_{\mathbf{n}} [\lambda \exp \left( -\beta \boldsymbol{\varepsilon} \right)]^{\mathbf{n}}.\tag{21.67}$$

individual orbitals, each of the form *Z*1(ε) := - *n* [λ exp (−βε)] *n*. (21.67)

$$Z = \prod_{t} Z_1(\mathfrak{s}),\tag{21.68}$$

*Z* [=](#page-383-0) ε *Z*1(ε), (21.68)

so contributions of the orbitals to ln *Z* and physical properties are simply additive. Any restrictions of orbital occupation were already taken into account in computing *Z*1(ε). Alternatively, Eq. (21.68) can be justified on physical grounds, a point of view taken by

Kittel and Kroemer [6, p. 154]. They consider all but one orbital to be part of the reservoir

<sup>6</sup>Here, we have used a shorthand notation *Ers* ≡ *Er* (*Ns*) and *nrs* ε ≡ *nr* ε (*Ns*). For the vacuum state *Ns* = 0, all occupation numbers *nr* ε (*Ns* = 0) = 0, in which case Eq. (21.63) gives *Er* (*Ns* = 0) = 0. This is consistent with the

$$\ln \mathcal{Z} = \sum_{\varepsilon} \ln \mathcal{Z}_1(\varepsilon),\tag{21.69}$$

370 THERMAL PHYSICS with which that orbital interacts, and thus calculate its grand partition function separately. For the entire system, they appeal to additivity over ε of ln *Z*1(ε), so that ln *Z* = - ε ln *Z*1(ε), (21.69)

which is equivalent to Eq. (21.68). In a similar spirit, they also present examples [6, pp. 140- 146] in which the general formula for *Z* is applied to noninteracting subsystems that can be unoccupied or occupied by one or two particles. The resulting partition function is used to calculate the probability of each state. A similar example is presented by Callen [2,

$$\mathcal{Z} = \prod_{v} \mathcal{Z}^{(v)}(\beta, \lambda); \quad \ln \mathcal{Z} = \sum_{v} \ln \mathcal{Z}^{(v)}(\beta, \lambda), \tag{21.70}$$

<span id="page-390-1"></span>We c[an gen](#page-390-1)eralize these examples [as foll](#page-389-0)ows. If *Z*(ν)(β, λ) are the grand partition

$$\mathcal{Z}^{(v)}(\boldsymbol{\beta},\lambda) = \sum_{n} \lambda^{n} \sum_{r} \exp(-\beta \varepsilon_{r\text{fl}}^{(v)}).\tag{21.71}$$

(ν)

*r n* do not have to be

<span id="page-390-0"></span>*Z* = ν *Z*(ν)(β, λ); ln *Z* = ν ln *Z*(ν)(β, λ), (21.70) where *Z*(ν)(β, λ) = - λ*n*- exp(−βε(ν) *r n*). (21.71)

### Each subsystem is in equilibrium with the reservoir and therefore with each other. Note that Eq. (21.71) is more general than Eq. (21.67) because the energies ε

this case happens to equal the number of occupied sites, is

*n*

*r*

multiples of the same quantity ε. 21.2.1 Factorization for Independent Sites In this section, we present several examples of factorization of the grand partition function for cases in which particles can reside on a number *N*tot of noninteracting sites that can be occupied by one or more particles. This would be expected if such sites are sufficiently dilute; they are separated by distances that are large relative to the range of forces applicable to each site. In these examples, we shall suppose for simplicity that the

### chemical potential μ, and hence the activity λ = exp(βμ) is imposed by a classical ideal monatomic gas.

**Example Problem 21.2.** Calculate the probability of adsorption of an ideal gas on *N*tot independent sites that are either unoccupied, with energy zero, or singly occupied with

energy ε1. **Solution 21.2.** The grand partition function for a single site is *Z*(1) = 1 + λ e−βε1 so the total grand partition function is *Z* = (*Z*(1))*N*tot. The average number of adsorbed atoms, which in

$$
\langle \mathcal{N} \rangle = \lambda \frac{\partial q}{\partial \lambda} = \mathcal{N}_{\text{tot}} \frac{\lambda \,\mathbf{e}^{-\beta \varepsilon_1}}{1 + \lambda \,\mathbf{e}^{-\beta \varepsilon_1}} \tag{21.72}
$$

and the average energy is

temperature-dependent pressure

θ

$$U = -\frac{\partial q}{\partial \beta} = \mathcal{N}_{\text{tot}} \frac{\varepsilon_1 \lambda |\mathbf{e}^{-\beta \varepsilon_1}|}{1 + \lambda |\mathbf{e}^{-\beta \varepsilon_1}|}. \tag{21.73}$$

-*N* = λ ∂*q* ∂λ = *N*tot λ e−βε1 1 + λ e−βε1 (21.72)

<span id="page-391-1"></span><span id="page-391-0"></span>
$$\theta = \frac{\lambda \,\mathrm{e}^{-\beta \varepsilon_1}}{1 + \lambda \,\mathrm{e}^{-\beta \varepsilon_1}} = \frac{\lambda \,\mathrm{e}^{-\beta \varepsilon_1}}{\mathcal{Z}^{(1)}}.\tag{21.74}$$

*U* = −∂*q* ∂β = *N*tot 1 + λ e−βε1 . (21.73) Except for the very important factors of λ, Eq. (21.73) resembles the energy for independent twostate systems. In order for the gas to adsorb at low temperatures, we want ε1 < 0. The fraction of occupied sites is θ = -*N* /*N*tot, so θ = λ e−βε1 1 + λ e−βε1 = λ e−βε1

In mea uso\u0ume a\u0un\u0y is uereneve 
$$\lambda = \frac{n}{n_{\mathbb{Q}}(T)} = \frac{p}{n_{\mathbb{Q}}(T)k_{\mathbb{B}}T},\tag{21.75}$$

been deduced entirely from the ratios of the correspo[nding](#page-391-0) terms in *Z*(1) to *Z*(1) itself. From Eq. (19.66), the chemical potential of an ideal gas is μ = *k*B*T* ln(*n*/*n*Q) = *k*B*T* ln(*p*/(*n*Q*k*B*T*)), where *n* is the number density and *n*Q(*T*) = (*mk*B*T*/2π*h*¯ 2)3/2 is the quantum concentration.

$$p_{\mathbb{D}}(T) := n_{\mathbb{Q}}(T)k_{\mathbb{B}}T\,\mathrm{e}^{\beta\varepsilon_{1}} = n_{\mathbb{Q}}(T)k_{\mathbb{B}}T\,\mathrm{e}^{-\beta|\varepsilon_{1}|},\tag{21.76}$$

*n*Q(*T*) = *p n*Q(*T*)*k*B*T* , (21.75)

$$
\theta = \frac{p}{p\mathbf{o} + p}.\tag{21.77}
$$

*p*0(*T*) := *n*Q(*T*)*k*B*T* eβε1 = *n*Q(*T*)*k*B*T* e−β|ε1| for ε1 < 0, which increases with temperature. Then Eq. (21.74) takes the simple form θ = *p p*0 + *p* . (21.77)

![](_page_391_Figure_13.jpeg)

p/p0 p, arbitrary units **FIGURE 21–1** Langmuir adsorption isotherms for the fractional adsorption of an ideal gas on *N*tot independent

sites. The curves on the right correspond to temperatures in the ratios 1:4:8, from left to right.

sites?

function *Z* = [*Z*(1)]

-

372 THERMAL PHYSICS

$$
\mathcal{Z}^{(1)} = \mathbf{l} + \lambda \mathbf{z}(T),\tag{21.78}
$$

**Example Problem 21.3.** Calculate the probability of adsorption of an ideal gas on *N*tot independent sites that are either unoccupied, with energy zero, or singly occupied with partition

$$p_0(T) := n_\mathcal{Q} k_\mathcal{B} T / \mathfrak{z}(T). \tag{21.79}$$

**Solution 21.3.** The grand partition function for a single site is *Z*(1) = 1 + λ*z*(*T*), (21.78)

$$Z_{\mathcal{N}} = \frac{\mathcal{N}_{\text{tot}}!}{\mathcal{N}!(\mathcal{N}_{\text{tot}} - \mathcal{N})!} [\mathbf{z}(T)]^{\mathcal{N}}.\tag{21.80}$$

*N* . (21.80)

The canonical partition function for *N* adsorbed atoms is the coefficient of λ*N* in *Z* = (*Z*(1))*N*tot which is readily found from the binomial theorem to be *ZN* = *N*tot!

[*z*(*T*)]

$$\mu = -k \lg T \frac{\partial \ln Z_{\mathcal{N}}}{\partial \mathcal{N}} = k \lg T \ln \left[ \frac{\mathcal{N}}{\mathcal{N}_{\text{tot}} - \mathcal{N}} \frac{1}{\mathbf{z}(T)} \right] = k \lg T \ln \left[ \frac{\theta}{1 - \theta} \frac{1}{\mathbf{z}(T)} \right]. \tag{21.81}$$

is invited to verify that the chemical potential for such a system is μ = −*k*B*T* ∂ ln*ZN* ∂*N* = *k*B*T* ln *N* 1 = *k*B*T* ln θ 1 

of the *N*tot sites are occupied, but they are distinguishable by virtue of their position. The reader

*z*(*T*)

*N*tot − *N*

Equating this μ to that of a classical ideal gas, Eq. (21.75), gives *p*/*p*0(*T*) = θ/(1 − θ ) with *p*0(*T*) given by Eq. (21.79). Then solving for θ gives the consistent result Eq. (21.77). **Example Problem 21.4.** Calculate the probability of adsorption of a monatomic ideal gas

on *N*tot independent sites that are either unoccupied with energy zero or singly occupied with energy ε1 or doubly occupied with energy ε2. Note that ε2 is not necessarily equal to 2ε1, so atoms on a doubly-occupied site can interact.

$$p_0 = 1/\mathcal{Z}^{(1)}; \quad p_1 = \lambda \operatorname{\mathbf{e}}^{-\beta\varepsilon_1}/\mathcal{Z}^{(1)}; \quad p_2 = \lambda^2 \operatorname{\mathbf{e}}^{-\beta\varepsilon_2}/\mathcal{Z}^{(1)}.\tag{21.82}$$

1 − θ

*z*(*T*)

. (21.81)

*p*0 = 1/*Z*(1) ; *p*1 = λ e−βε1 /*Z*(1) ; *p*2 = λ2 e−βε2 /*Z*(1) . (21.82) The average number of adsorbed gas atoms is therefore -*N* = *N*tot(*p*1 + 2*p*2), where the factor

of 2 enters because of the double occupancy. Alternatively, one can use the total grand partition

$$
\langle \mathcal{N} \rangle = \lambda \frac{\partial q}{\partial \lambda} = \mathcal{N}_{\text{tot}} \frac{\lambda \,\mathbf{e}^{-\beta \varepsilon_1} + 2\lambda^2 \,\mathbf{e}^{-\beta \varepsilon_2}}{1 + \lambda \,\mathbf{e}^{-\beta \varepsilon_1} + \lambda^2 \,\mathbf{e}^{-\beta \varepsilon_2}},
\tag{21.83}
$$

$$U = -\left(\frac{\partial \boldsymbol{q}}{\partial \boldsymbol{\beta}}\right)_{\boldsymbol{\lambda}} = \mathcal{N}_{\text{tot}} \frac{\boldsymbol{\varepsilon}_1 \boldsymbol{\lambda} \,\mathbf{e}^{-\beta \varepsilon_1} + \boldsymbol{\varepsilon}_2 \boldsymbol{\lambda}^2 \,\mathbf{e}^{-\beta \varepsilon_2}}{1 + \boldsymbol{\lambda} \,\mathbf{e}^{-\beta \varepsilon_1} + \boldsymbol{\lambda}^2 \,\mathbf{e}^{-\beta \varepsilon_2}}\tag{21.84}$$

*Chapter 21* • Grand Canonical Ensemble 373

where the factor of 2 occurs automatically, or ε1λ e−βε1 + ε2λ2 e−βε2

*U* = −∂*q* ∂β λ = *N*tot 1 + λ e−βε1 + λ2 e−βε2 (21.84) where there is no such factor of 2.

$$\mathcal{Z}^{(1)} = 1 + \lambda_A \mathbf{e}^{-\beta \varepsilon_A} + \lambda_B \mathbf{e}^{-\beta \varepsilon_B}.\tag{21.85}$$

**Example Problem 21.5.** Calculate the probability of adsorption of either an *A* atom or a *B* atom on *N*tot independent sites that are either unoccupied with energy zero or singly occupied

$$\theta_{A} = \frac{\lambda_{A}\mathbf{e}^{-\beta\varepsilon_{A}}}{1 + \lambda_{A}\mathbf{e}^{-\beta\varepsilon_{A}} + \lambda_{B}\mathbf{e}^{-\beta\varepsilon_{B}}}; \quad \theta_{B} = \frac{\lambda_{B}\mathbf{e}^{-\beta\varepsilon_{B}}}{1 + \lambda_{A}\mathbf{e}^{-\beta\varepsilon_{A}} + \lambda_{B}\mathbf{e}^{-\beta\varepsilon_{B}}},\tag{21.86}$$

In the present case, we have *Z*(1) = 1 + λ*A* e−βε*A* + λ*B* e−βε*B* . (21.85) Thus the fractional occupations are θ*A* = λ*A* e−βε*A* 1 + λ*A* e−βε*A* + λ*B* e−βε*B* ; θ*B* = λ*B* e−βε*B* 1 + λ*A* e−βε*A* + λ*B* e−βε*B* , (21.86)

the chemical potentials of the environment, say ideal gases of *A* and *B*. We see in this case that the *A* and *B* atoms compete for occupancy of the sites. Moreover, a small difference between ε*A* and ε*B* can make an enormous difference between the relative adsorption of *A* and *B* if |βε*i*| 1. For the examples in this section, *Z* = (*Z*(1) )*N*tot , so viewed as a series in powers of λ, the series cuts off after a finite number of terms. For the [first tw](#page-389-0)o examples, the highest power is (λ)*N*tot and for the third example it is (λ)2*N*tot. These cutoffs occur because of the restrictions on maximum occupancy of a site. In terms of the general formula Eq. (21.21), they can be imposed formally by assuming that any state of the entire system having greater occupancy than allowed would have an infinite energy, so its Boltzmann factor

### number of orbitals available for occupation, so the expression for *Z* for those gases

contains all powers of λ, as shown in the next section.

21.2.2 Fermi-Dirac Distribution

would be zero. On the other hand, for ideal Fermi and Bose gases, there are an infinite

and the fraction of unoccupied sites is 1 − θ*A* − θ*B*. We would have to determine λ*A* and λ*B* from

$$Z_1(\varepsilon) := \sum_{n=0,1} \left[ \lambda \exp\left(-\beta\varepsilon\right) \right]^n = 1 + \lambda \exp\left(-\beta\varepsilon\right). \tag{21.87}$$

exp[β(ε − μ)] + 1

*Z*1(ε) := *n*=0,1 [λ exp (−βε)] *n* = 1 + λ exp (−βε). (21.87)

$$f_{\rm FD}(e) := \frac{\lambda \exp\left(-\beta\varepsilon\right)}{1 + \lambda \exp\left(-\beta\varepsilon\right)} = \frac{1}{\lambda^{-1} \exp(\beta\varepsilon) + 1} = \frac{1}{\exp[\beta(\varepsilon - \mu)] + 1},\tag{21.88}$$

374 THERMAL PHYSICS

<span id="page-394-0"></span>
$$
\langle \mathcal{N} \rangle = \sum_{\varepsilon} f \text{fb}(\varepsilon) = (\mathfrak{L}\mathfrak{s} + 1) \sum_{\varepsilon}^{\prime} f \text{fb}(\varepsilon),
\tag{21.89}
$$

*s* and no magnetic field is present, there will be 2*s* + 1 orbitals as compared to orbitals with spin degeneracy ignored. Thus Eq. (21.66) will contain a factor of [*Z*1(ε)] 2*s*+1 for each orbital with spin degeneracy ignored, which will contribute (2*s* + 1)ln *Z*1(ε) to ln *Z*. The total average number of particles in the entire system is therefore 

$$U = \sum_{\varepsilon} \varepsilon f_{\text{FD}}(\varepsilon) = (2s+1) \sum_{\varepsilon}^{\prime} \varepsilon f_{\text{FD}}(\varepsilon). \tag{21.90}$$

usually specified and Eq. (21.89) is used to determine the chemical potential μ, which turns out to be a function of β and -*N* /*V* because the sum will turn out to be proportional

### to *V*. By similar reasoning, the total internal energy is given by

-

<span id="page-394-1"></span>-

ε

ε

*f*BE(ε) = (2*s* + 1)

*U* = - ε ε*f*FD(ε) = (2*s* + 1) ε ε*f*[FD](#page-384-1)(ε). (21.90)

$$\mathcal{Z}_1(\varepsilon) := \sum_{n=0}^{\infty} [\lambda \exp \left( -\beta \varepsilon \right)]^n = \frac{1}{1 - \lambda \exp \left( -\beta \varepsilon \right)},\tag{21.91}$$

For a single orbital of a gas of noninteracting bosons, Eq. (21.67) becomes ∞ *n* = 1

$$f_{\text{RE}(\varepsilon)} := \frac{\lambda \exp\left(-\beta\varepsilon\right)}{1 - \lambda \exp\left(-\beta\varepsilon\right)} = \frac{1}{\lambda^{-1} \exp(\beta\varepsilon) - 1} = \frac{1}{\exp[\beta(\varepsilon - \mu)] - 1},\tag{21.92}$$

occupy that orbital can be deduced by applying Eq. (21.30) to *Z*1(ε) to obtain *f*BE(ε) := λ exp (−βε) 1 − λ exp (−βε) = 1 λ−1 exp(βε) − 1 = 1 exp[β(ε − μ)] − 1 , (21.92) which is known as the **Bose-Einstein distribution** function. We note that *f*BE(ε) differs from *f*FD(ε) only by a sign, but this difference is crucial. For example, *f*FD(ε) ≤ 1 but *f*BE(ε) can be greater than 1, reflecting the possible multiple occupancy of boson orbitals. Moreover, for ε = μ, *f*FD = 1/2, which presents no problem, but *f*BE =∞, which cannot be allowed.7 In the absence of a magnetic field, each energy level has a degeneracy of 2*s* + 1

$$
\langle \mathcal{N} \rangle = \sum_{\varepsilon} f_{\text{RE}}(\varepsilon) = (2\varepsilon + 1) \sum_{\varepsilon}^{\prime} f_{\text{RE}}(\varepsilon) \tag{21.93}
$$

and

*f*BE(ε) (21.93)

have

and

$$U = \sum_{\varepsilon} \varepsilon f_{\rm BE}(\varepsilon) = (2\mathfrak{s} + 1) \sum_{\varepsilon}^{\prime} \varepsilon f_{\rm BE}(\varepsilon). \tag{21.94}$$

ε 7The minimum value of ε − μ can be related to the phenomenon of Bose condensation in the ground state.

ε

<span id="page-395-0"></span>*Chapter 21* • Grand Canonical Ensemble 375 21.2.4 Classical Ideal Gas

$$
\lambda^{-1} \exp(\beta \varepsilon) = \exp[\beta(\varepsilon - \mu)] \gg 1 \tag{21.95}
$$

in the limit of high temperature and low density. In particular, the temperature must be so high (β so small) and the density so low that the ratio of the number of particles to the number of accessible single particle states is v[ery sm](#page-394-0)all. [In oth](#page-394-1)er words, the average number of particles that occupy a single orbital must be small. This will be true for either

$$f_{\rm CL}(\varepsilon) = \exp(\beta \mu) \exp(-\beta \varepsilon). \tag{21.96}$$

λ−1 exp(βε) = exp[β(ε − μ)] 1 (21.95)

$$
\langle \mathcal{N} \rangle = \sum_{\varepsilon} f_{\text{CL}}(\varepsilon) = \exp(\beta \mu) \sum_{\varepsilon} \exp(-\beta \varepsilon),
\tag{21.97}
$$

*f*CL(ε) = exp(βμ) exp(−βε). (21.96)

*f*FD or *f*BE provided that

$$\exp(\beta \mu) = \frac{\langle \mathcal{N} \rangle}{z},\tag{21.98}$$

which yields

$$\varepsilon z = \sum_{\varepsilon} \exp(-\beta \varepsilon) = (2\varepsilon + 1) \sum_{\varepsilon}^{\prime} \exp(-\beta \varepsilon) \tag{21.99}$$

where

-

*N* = -

*z* = -

ε

ε

$$\frac{f_{\rm CL}(\varepsilon)}{\langle \mathcal{N} \rangle} = \frac{\exp(-\beta \varepsilon)}{z}. \tag{21.100}$$

is the canonical partition function for a single particle. Hence, *f*CL(ε) -*N* = exp(−βε) *z* . (21.100)

ε

The left-hand side of Eq. (21.100) is the probability of finding a particle in the orbital (quantum state including spin) corresponding to ε and the right-hand side is the familiar Boltzmann distribution, the same as given by Eq. (18.11). As a further bonus, we can use Eq. (19.56) that applies for particles without spin to

$$
\beta \mu = \ln \left[ \frac{\langle \mathcal{N} \rangle}{V} \frac{1}{n_{\mathcal{Q}}(T)} \right] - \ln(2s+1) \tag{21.101}
$$

βμ = ln *N V n*Q(*T*) − ln(2*s* + 1) (21.101) in agreement with Eq. (19.66) for *s* = 0. The second term in Eq. (21.101) arises because of the spin degeneracy, which has no classical counterpart and which also contributes a term *N k*B ln(2*s* + 1) to the entropy. The above condition λ = exp(βμ) 1 is seen to be equivalent to -*N* /(*Vn*Q) 1, which is true if the actual concentration *n* = -*N* /*V* is small compared with the quantum concentration *n*Q(*T*). This will be true for low density and

$$\ln Z = \ln \prod_{\varepsilon} \left( 1 + \exp[\beta(\mu - \varepsilon)] \right), \tag{21.102}$$

376 THERMAL PHYSICS

whereas for a Bose gas

the distribution function

to obtain

$$\ln \mathcal{Z} = \ln \prod_{\varepsilon} \frac{1}{\{1 - \exp[\beta(\mu - \varepsilon)]\}}.\tag{21.103}$$

system having exactly *N* particles. For a Fermi gas, we have

<span id="page-396-1"></span><span id="page-396-0"></span>
$$\ln \mathcal{Z} = \pm \sum_{\varepsilon} \ln \left\{ 1 \pm \exp[\beta(\mu - \varepsilon)] \right\}. \tag{21.104}$$

ln *Z* = ln ε 1 {1 − exp[β(μ − ε)]} . (21.103)

$$\ln \mathcal{Z} = \sum_{\varepsilon} \exp[\beta(\mu - \varepsilon)] = \lambda \mathcal{Z} = \langle \mathcal{N} \rangle,\tag{21.105}$$

ε

ln *Z* = -

$$\mathcal{Z} = \mathbf{e}^{\lambda z} = \sum_{N=0}^{\infty} \lambda^N \frac{z^N}{N!} . \tag{21.106}$$

ε where Eq. (21.98) has been used in the last step. Therefore,

$$Z_{\mathcal{N}} = \frac{z^{\mathcal{N}}}{\mathcal{N}!} \tag{21.107}$$

<span id="page-396-2"></span>*N*=0 Comparison with Eq. (21.21) shows that *ZN* = *zN*

in agreement with Eq. (19.48). Since ln *Z* = *pV*/(*k*B*T*), we observe that Eq. (21.105) is

### equivalent to the ideal gas law.

ε

21.2.5 F[ermi,](#page-397-0) [Bose,](#page-397-0) and Classical Gases As shown by Pathria [8, p. 134], the main results for ideal Fermi, Bose, and classical gases can be summarized conveniently as follows. One invents a parameter *a* that takes on the

$$f(\varepsilon; a) := \frac{1}{\lambda^{-1} \exp(\beta \varepsilon) + a} = \frac{1}{\exp[\beta(\varepsilon - \mu)] + a} \tag{21.108}$$

*N* ! (21.107)

*f* (ε; *a*) := 1 λ−1 exp(βε) + *a* = 1 exp[β(ε − μ)] + *a* (21.108) encompasses all three results. The three distribution functions are plotted as a function of

ε

$$\ln Z = \frac{1}{a} \sum_{\varepsilon} \ln \left\{ 1 + a \lambda \exp(-\beta \varepsilon) \right\} = \frac{1}{a} \sum_{\varepsilon} \ln \left\{ 1 + a \exp[\beta(\mu - \varepsilon)] \right\} \tag{21.109}$$

<span id="page-397-0"></span>![](_page_397_Figure_1.jpeg)

1 fFD(ε) = f(ε;1)

<span id="page-397-1"></span>0.5

-2 -1 1 2 3 β(ε*−*μ)

$$
\ln \mathcal{Z} = \sum_{t} \lambda \exp(-\beta \varepsilon) = \lambda \mathbf{z},
\tag{21.110}
$$

can be written for the function *q* = ln *Z*. For *a* = ± 1 we obtain Eq. (21.104) but for *a* → 0 the formal limit is

ln *Z* = - ε λ exp(−βε) = λ*z*, (21.110) where *z* is the canonical partition function for a single particle, in agreement with

$$p = \frac{1}{\beta V} q = \frac{1}{\beta V} \frac{1}{a} \sum_{\varepsilon} \ln\left[1 + a\lambda \exp(-\beta\varepsilon)\right]. \tag{21.111}$$

have *p* = 1 β*V q* = 1 β*V* 1 *a* - ε ln 1 + *a*λ exp(−βε) . (21.111)

$$p = \frac{\text{g0}}{\beta (2\pi)^3} \frac{1}{a} \int_0^\infty \ln\left[1 + a\lambda \,\mathbf{e}^{-\beta \epsilon(k)}\right] 4\pi k^2 \,\text{d}k.\tag{21.112}$$

*p* = *g*0 β(2π )3 1 *a* ∞ 0 ln 1 + *a*λ e−βε(*k*) 4π*k*2 d*k*. (21.112)

$$p = \frac{\mathfrak{g}_0}{2a\beta\pi^2} \left\{ \ln \left[ 1 + a\lambda \operatorname{e}^{-\beta\varepsilon(k)} \right] \frac{k^3}{3} \bigg|_{0}^{\infty} - \int_0^{\infty} \frac{k^3}{3} \frac{\operatorname{d}}{\operatorname{dk}} \ln \left[ 1 + a\lambda \operatorname{e}^{-\beta\varepsilon(k)} \right] \operatorname{d}k \right\}.\tag{21.113}$$
 
$$\text{Tho inotopated nostunnihoo and } \mu\alpha \text{ oso leftu with}$$

2*a*βπ2 3 0 0 3

$$p = \frac{\mathfrak{g}_0}{6\pi^2} \int_0^\infty \frac{\lambda \,\mathrm{e}^{-\beta\varepsilon(k)}}{\left[1 + a\lambda \,\mathrm{e}^{-\beta\varepsilon(k)}\right]} k \frac{\mathrm{d}\varepsilon(k)}{\mathrm{d}k} k^2 \,\mathrm{d}k = \frac{\mathfrak{g}_0}{6\pi^2} \int_0^\infty f(\kappa; a) k \frac{\mathrm{d}\varepsilon(k)}{\mathrm{d}k} k^2 \,\mathrm{d}k. \tag{21.114}$$

378 THERMAL PHYSICS

-*N* = λ

∂ ∂λ 1 *a* -

ε

$$
\langle \mathcal{N} \rangle = \lambda \frac{\partial}{\partial \lambda} \frac{1}{a} \sum_{\varepsilon} \ln \left[ 1 + a \lambda \exp(-\beta \varepsilon) \right] = \frac{\mathbf{g} \cdot V}{2\pi^2} \int_0^\infty f(\kappa; a) \, k^2 \, \mathbf{d}k. \tag{21.115}
$$

$$p = \frac{\langle \mathcal{N} \rangle}{3V} \left\langle k \frac{\mathrm{d} \boldsymbol{\varepsilon}(k)}{\mathrm{d}k} \right\rangle,\tag{21.116}$$

Similarly, from Eq. (21.30) we have

where

$$\left\langle k \frac{\mathrm{d}s(k)}{\mathrm{d}k} \right\rangle \equiv \frac{\int_0^\infty f(s; a) \mathrm{d}k \mathrm{d}s(k) / \mathrm{d}k \, \mathrm{l}k^2 \, \mathrm{d}k}{\int_0^\infty f(s; a) k^2 \, \mathrm{d}k} \tag{21.117}$$

Then Eqs. (21.114) and (21.115) can be combined to give *p* = -*N* 3*V k* dε(*k*) d*k* , (21.116)

$$p = \frac{\langle \mathcal{N} \rangle}{3V} s \langle s(k) \rangle = \frac{s}{3} \mu,\tag{21.118}$$

*k* dε(*k*) d*k* ≡ ∞ 0 *f* (ε; *a*)*k*2 d*k* (21.117) is an average value of *k*dε(*k*)/d*k*. In simple cases for which ε(*k*) ∝ *ks* , where *s* is a constant, we have *k*dε(*k*)/d*k* = *s*ε(*k*) which yields *p* = -*N* 3*V s* ε(*k*) = *s* 3 *u*, (21.118)

wh[ere](#page-389-1) *u* = *U*/*V* is the energy density. For a nonrelativistic particle in a box, *s* = 2 and we

### have the result *p* = 2*u*/3. This result is familiar for a classical ideal gas (see Eq. (19.78)), for which ε = (3/2)*k*B*T* and *p* = *N k*B*T*/*V*, but we see that it is also true for an ideal Fermi

gas and an ideal Bose gas. For a particle in a box in the extreme relativistic limit, *s* = 1 and we have the result *p* = *u*/3. 21.2.6 Orbital Populations for Ideal Gases We can apply Eq. (21.30) for -

$$\left(\frac{\partial \mathcal{Z}_1(\varepsilon)}{\partial \mu}\right)_{V,\mathfrak{d},x} = -\left(\frac{\partial \mathcal{Z}_1(\varepsilon)}{\partial \varepsilon}\right)_{V,\mathfrak{d},\mu}.\tag{21.119}$$

the derivatives that follow, we note that

Thus

$$
\langle \mathcal{N} \rangle = \frac{1}{\beta} \frac{\partial \ln \mathcal{Z}}{\partial \mu} = \frac{1}{\beta} \sum_{\varepsilon} \frac{\partial \ln \mathcal{Z}_1(\varepsilon)}{\partial \mu} = -\frac{1}{\beta} \sum_{\varepsilon} \frac{\partial q_{\varepsilon}}{\partial \varepsilon} = \sum_{\varepsilon} \langle n_{\varepsilon} \rangle,\tag{21.120}
$$

-*N* = 1 ∂ ln *Z* ∂μ = 1

where *q*ε := ln *Z*1(ε) and

β

β -

-

ε

ε

∂ ln *Z*1(ε)

β

$$
\langle n_{\varepsilon} \rangle := -\frac{1}{\beta} \left( \frac{\partial q_{\varepsilon}}{\partial \varepsilon} \right)_{V, \beta, \mu} . \tag{21.121}
$$

. (21.121)

*n*ε, (21.120)

-

-

Similarly,

$$
\langle (\Delta \mathcal{N})^2 \rangle = \frac{1}{\beta^2} \frac{\partial^2 \ln \mathcal{Z}}{\partial \mu^2} = \frac{1}{\beta^2} \sum_{\varepsilon} \frac{\partial^2 \ln \mathcal{Z}_1(\varepsilon)}{\partial \mu^2} = \frac{1}{\beta^2} \sum_{\varepsilon} \frac{\partial^2 q_{\varepsilon}}{\partial \varepsilon^2} = \sum_{\varepsilon} \langle (\Delta n_{\varepsilon})^2 \rangle,\tag{21.122}
$$

ε

*V*,β,μ

ε

-

∂*q*ε

$$\langle (\Delta n_{\varepsilon})^2 \rangle := -\frac{1}{\beta} \left( \frac{\partial \langle n_{\varepsilon} \rangle}{\partial \varepsilon} \right)_{V, \beta, \mu} \quad . \tag{21.123}$$

*Chapter 21* • Grand Canonical Ensemble 379

∂*n*ε

$$\langle n_{\ell} \rangle = \frac{1}{\exp[\beta(s-\mu)] \pm 1} \tag{21.124}$$

where

Since -

anu 
$$\frac{\langle \left(\Delta n_{\ell}\right)^{2}\rangle}{\langle n_{\ell}\rangle^{2}} = \exp[\beta(s-\mu)] = \frac{1}{\langle n_{\ell}\rangle} \mp 1. \tag{21.125}$$

by ε. According to Eq. (21.104), we have explicitly8 *n*ε = 1 exp[β(ε − μ)] ± 1 (21.124) and -(*n*ε) 2 *n*ε2 = exp[β(ε − μ)] = 1 *n*ε ∓ 1. (21.125)

For a classical ideal gas, we would have *n*ε 1 so the ∓ 1 in Eq. (21.125) is negligible. This is called a *normal* fluctuation. For fermions, the result is 1/*n*ε − 1 which nearly

$$\mathcal{Z} = \exp(\mathcal{N}) = \sum_{\mathcal{N}=0}^{\infty} \frac{\langle \mathcal{N} \rangle^{\mathcal{N}}}{\mathcal{N}!}. \tag{21.126}$$

seen by returning to Eq. (21.105) from whi[ch we o](#page-397-1)btain *Z* = exp-*N* = -∞ -*N N*

$$P_{\mathcal{N}} = \frac{\langle \mathcal{N} \rangle^{\mathcal{N}}}{\mathcal{N}!} \exp(-\langle \mathcal{N} \rangle),\tag{21.127}$$

*N* th term in this sum divided by *Z*, namely

-

$$
\ln \mathcal{Z}_1(\varepsilon) = \lambda \exp(-\beta \varepsilon) = \langle \mathfrak{n}_{\varepsilon} \rangle \tag{21.128}
$$

which is a Poisson distribution. From Eq. (21.110),

according to Eq. (21.124). Therefore,

which is *above normal* or *extranormal*.

$$\mathcal{Z}_1(\varepsilon) = \mathbf{e}^{\langle n_{\varepsilon} \rangle} = \sum_{n_{\varepsilon}} \frac{\langle n_{\varepsilon} \rangle^{n_{\varepsilon}}}{n_{\varepsilon}!}. \tag{21.129}$$

*Z*1(ε) = e*n*ε = - *n*ε*n*ε *n*ε! . (21.129)

*n*ε The probability of occupation of the orbital ε is therefore *n*ε*n*ε

*n*ε), (21.130)

*pn*ε = *n*ε! exp(−-

which is also a Poisson distribution.

8The upper sign is for fermions and the lower sign is for bosons.

![](_page_400_Picture_1.jpeg)

380 THERMAL PHYSICS **Example Problem 21.6.** Compare the occupation probabilities of orbitals for fermions, bosons, and classical particles and discuss the limit where they become essentially the same.

### Thus, when conditions for a classical gas are valid, there is essentially no double occupancy of orbitals, which explains why the Gibbs correction factor of *N* ! leads to the correct partition function.

**Solution 21.6.** For simplicity, we define γ = λ exp(−βε). For fermions, there are only two probabilities, *p*0 = 1/(1+γ ) and *p*1 = γ /(1+γ ). For bosons, one has *pn* = γ *n*(1−γ ). For classical particles *pn* = γ *n* exp(−γ )/*n*!. The result for classical particles is only valid for γ 1. In that [limit,](#page-395-0) [all](#page-395-0) [three](#page-395-0) [di](#page-395-0)strib[utions](#page-396-2) become approximately *p*0 = 1 − γ , *p*1 = γ , and *pn* = 0,*n* ≥ 1.

21.3 Classical Ideal Gas with Internal Structure

In Sections 21.2.4 and 21.2.5, we treated ideal gases without internal structure, except for spin, which was necessary to distinguish between Fermi and Bose gases and which led to a degeneracy factor of 2*s* + 1. In the present section, we show how to treat gases whose particles are atoms or molecules having internal structure, not only due to nuclear spin but also due to electronic and molecular structure. We return to Eq. (21.105) and expand the notation such that ε → ε*t* + ε*i*, where ε*t* is the

$$\ln \mathcal{Z} = \sum_{t,l} \exp[\beta(\mu - \varepsilon_l - \varepsilon_l)] = \lambda \mathbf{z}_{\text{lift}} \mathbf{z}_l = \langle \mathcal{N} \rangle,\tag{21.131}$$

Thus we obtain

ln *Z* = -

*t*,*i*

$$z_{\rm t} = \sum_{\rm t} \exp(-\beta \varepsilon_{\rm t}) = V n_{\rm Q} \tag{21.132}$$

where the translational partition function is *zt* = -

and the internal partition function is

$$\mathbf{z}_{\text{Int}} = \sum_{l} \exp(-\beta \varepsilon_{l}).\tag{21.133}$$

*z*int = - exp(−βε*i*). (21.133)

*t*

*i*

$$Z = \frac{(\mathbf{z}_{\text{int}} \mathbf{z}_{l})^{N}}{N!}. \tag{21.134}$$

*Z* = (*z*int*zt*)*N N* ! . (21.134)

$$F = -N \text{kg} \, T [\ln(V \text{n}_{\text{Q}}/N) + 1] - N \, \text{kg} \, T \ln z_{\text{int}}.\tag{21.135}$$

*F* = −*N k*B*T*[ln(*Vn*Q/*N* ) + 1] − *N k*B*T* ln *z*int. (21.135)

*Chapter 21* • Grand Canonical Ensemble 381 We see that the effect of the internal structure is additive. In the case that *z*int is only due

$$\mathbf{z}_{\rm int} = \mathbf{z}_{\rm elec} \mathbf{z}_{\rm vib} \mathbf{z}_{\rm nuc} \mathbf{z}_{\rm rot} \tag{21.136}$$

For a gas of molecules or of atoms having structure, one usually assumes that the elec-

Eq. (21.135).

$$
\ln z_{\rm{0tt}} = \ln z_{\rm{elec}} + \ln z_{\rm{vlb}} + \ln z_{\rm{nuc}} + \ln z_{\rm{rot}}.\tag{21.137}
$$

hold because nucleons are more massive and move more slowly than electrons. Therefore, the internal partition function factors to give *z*int = *z*elec*z*vib*z*nuc*z*rot (21.136) so we have ln *z*int = ln*z*elec + ln *z*vib + ln*z*nuc + ln*z*rot. (21.137)

### In other words, the contributions of the internal degrees of freedom are additive. However, in the case of homonuclear molecules (e.g., H2 that we treat later) it is important to

correlate the nuclear and rotational partition functions such that the product *z*nuc*z*rot is replaced by *z*nuc−rot which is based on antisymmetric wave functions for fermions and symmetric ones for bosons.

21.3.1 Monatomic Gas For a monatomic gas, we only have to deal with the nuclear and electronic partition functions. To avoid any ambiguity, we choose the zero of energy to be the nuclear and electronic ground state, as well as zero translational energy. The hyperfine structure due to the nuclear spin has energy splittings that are very small compared to *k*B*T* in most cases of interest, so *z*nuc = 2*I* + 1, where *I* is the nuclear spin.

There is no contribution to the energy and the heat capacity, but the entropy is changed by *N k*B ln(2*I*+1). The free energy and chemical potential are changed by −*N k*B*T* ln(2*I*+1) and −*k*B*T* ln(2*I* + 1), respectively. The value of *z*elec due to the electronic structure depends on the electronic orbital angular momentum *L* and the electronic spin angular momentum *S*. If *L* = *S* = 0, the state is nondegenerate and *z*elect = 1. If *L* =0 but *S* = 0, which is typical of alkali atoms such as

$$\mathbf{z_{\text{left}}} = \sum_{\varepsilon_{\text{left}}} \exp(-\beta \varepsilon_{\text{left}}),\tag{21.138}$$

*z*elect = εelect exp(−βεelect), (21.138) where the sum is over all electronic states, having energies εelect. Usually, only the ground state of degeneracy *g*0*e* and the first excited state of degeneracy *g*1*e* and energy *e* are important because the rest of the states have such high energies that they are practically

*z*elect = *g*0*e* + *g*1*e* exp(−β*e* ). (21.139)

$$\mathbf{z}_{\text{elect}} = \mathbf{g}_{\text{0e}} + \mathbf{g}_{1e} \exp(-\beta \,\Delta_{\text{e}}).\tag{21.139}$$

This leads to contributions to the energy and the heat capacity of the forms

$$U_{\text{elect}} = \mathcal{N} \Delta_{\text{e}} \frac{\mathbf{g}_{1\epsilon} \exp(-\beta \Delta_{\text{e}})}{\mathbf{g}_{0\epsilon} + \mathbf{g}_{1\epsilon} \exp(-\beta \Delta_{\text{e}})} \tag{21.140}$$

and

$$C_{\text{elect}} = \mathcal{N}k_{\text{B}}(\beta \,\Delta_{\ell})^2 \frac{\mathbf{g}_{\text{0e}}\mathbf{g}_{1\ell}\exp(-\beta \,\Delta_{\ell})}{[\mathbf{g}_{\text{0e}} + \mathbf{g}_{1\ell}\exp(-\beta \,\Delta_{\ell})]^2}. \tag{21.141}$$

This electronic heat capacity is zero at low temperatures, passes through a maximum, and then decays again to zero at high temperatures, assuming that no higher energy levels come into play. Contributions to the entropy and the chemical potential are

$$\mathbf{S}_{\text{elect}} = \mathcal{N}k\mathbf{\hat{z}}\ln[\mathbf{g}\mathbf{a}_{\theta} + \mathbf{g}_{1\ell}\exp(-\beta\Delta_{\ell})] + \mathcal{N}k\mathbf{\hat{z}}\beta\Delta_{\ell}\frac{\mathbf{g}_{1\ell}\exp(-\beta\Delta_{\ell})}{\mathbf{g}_{0\ell} + \mathbf{g}_{1\ell}\exp(-\beta\Delta_{\ell})}\tag{21.142}$$

and

$$
\mu_{\text{elect}} = -k_{\text{B}}T \ln[\mathbf{g}_{0e} + \mathbf{g}_{1e} \exp(-\beta \Delta_{e})].\tag{21.143}
$$

For future reference, the entire internal partition function is given approximately by

$$z_{\rm int} = z_{\rm element} z_{\rm nuc} = [\mathbf{g}_{\rm 0} + \mathbf{g}_{\rm le} \exp(-\beta \Delta_{\ell})](2I + 1). \tag{21.144}$$

### 21.3.2 Diatomic Molecular Gas

For diatomic molecules, we take the zero of energy to be the nuclei in their ground states and the atoms to be in their electronic ground states for a completely dissociated molecule, that is, infinite separation of the atoms. Homonuclear diatomic molecules are indistinguishable if rotated 180◦ about their center of mass, thus exchanging identical particles. Therefore, their nuclear and rotational partition functions must be correlated to satisfy requirement of quantum statistics. No such requirements exist for heteronuclear molecules because their nuclei are distinguishable. Therefore, we first treat the simpler case of heteronuclear molecules and then treat homonuclear molecules.

### *Heteronuclear Molecules*

For heteronuclear diatomic molecules *AB*, composed of *A* and *B* atoms, the nuclei remain in their ground states so the nuclear partition function *z*nuc = (2*I*A + 1)(2*I*B + 1) only accounts for degeneracy.

The relevant electronic structure is now that of the molecule. This is usually described in terms of a potential that is strongly repulsive (positively infinite) at short distances of separation, becomes negative reaching the bottom of a potential well at a negative energy ε0*m* = − *D*, and then rises to zero at infinite separation. Usually one needs to consider only the electronic ground state and the first excited state, having energy ε1*m*, because

<span id="page-403-0"></span>
$$z_{\text{elect}} = \exp(\beta D)[\mathbf{g}_{0m} + \mathbf{g}_{1m}\exp(-\beta \Delta_m)],\tag{21.145}$$

*Chapter 21* • Grand Canonical Ensemble 383 occupation of higher molecular electronic states would lead to dissociation. Therefore,

$$
\ln z_{\text{elect}} = \beta D + \ln(\mathbf{g}_{\text{l}m} + \mathbf{g}_{\text{l}m} \exp(-\beta \Delta_{\text{m}})),
\tag{21.146}
$$

*z*elect = exp(β*D*)[*g*0*m* + *g*1*m* exp(−β*m*)], (21.145) where *m* = ε1*m* − ε0*m* is the *separation* between the first excited electronic state and the electronic ground state, and *g*0*m* and *g*1*m* are the respective degeneracies. This expression

resembles Eq. (21.139) for the monatomic gas except for the prefactor exp(β*D*) that arises because of the depth of the potential well. Since ln *z*elect = β*D* + ln[*g*0*m* + *g*1*m* exp(−β*m*)], (21.146) the only contribution of the factor exp(β*D*) is to add an energy −*D* per molecule. The remaining term in Eq. (21.146) makes contributions exactly analogous to those made by

$$z_{\rm vib} = \exp(-\Theta_{\rm V}/2T) \frac{1}{1 - \exp(-\Theta_{\rm V}/T)},\tag{21.147}$$

atoms, giving rise to quantum states that can be approximated by those of a harmonic oscillator with nondegenerate energy levels (1/2 + *n*)*h*¯ ω0, where *n* is zero or a positive integer and ω0 is the angular frequency of vibration. The partition function is

*z*elect for the monatomic case.

<span id="page-403-2"></span><span id="page-403-1"></span>
$$U_{\rm vib} = \mathcal{N}k_{\rm B}\Theta_{\rm V}/2 + \mathcal{N}\frac{k_{\rm B}\Theta_{\rm V}}{\exp(\Theta_{\rm V}/T) - 1}.\tag{21.148}$$

where v := *h*¯ ω/*k*B is a characteristic temperature. The contribution to the total energy is therefore *U*vib = *N k*Bv/2 + *N k*Bv exp(v/*T*) − 1 . (21.148) Here again, the prefactor exp(−v/2*T*) in the partition function just adds a constant energy *k*Bv/2 = *h*¯ ω0/2 per molecule. The cumulative shift in the energy per molecule

$$\mathcal{C}_{\rm vlb} = Nk \mathfrak{g} \frac{(\Theta_{\rm v}/T)^2 \exp(\Theta_{\rm v}/T)}{[\exp(\Theta_{\rm v}/T) - 1]^2}. \tag{21.149}$$

*C*vib = *N k*B (v/*T*)2 exp(v/*T*) [exp(v/*T*) − 1]2 . (21.149) Figure 18–8 depicts a graph of this heat capacity versus temperature. Typical values of this characteristic vibration temperature are v =1000 to 4000 K, which corresponds to an energy of about 0.1-0.3 eV. For *T* v, which is typical, we have *C*vib ≈ 0 and the vibrational mode is said to be "frozen out." For high temperatures, *C*vib ≈ *N k*B and the heat

capacity would be increased by a constant amount. However, the molecule will probably dissociate before one observes the maximum heat capacity due to vibration. Most interesting are the rotational degrees of freedom, for which we will treat the atoms as point particles. Classically, we can think of such a degree of freedom as a rotation of a rigid diatomic molecule about an axis perpendicular to the line joining the atoms and

passing through the center of mass of the molecule. There are two degrees of freedom of

$$
\varepsilon_{\rm rot}(\mathbf{j}) = \mathbf{j}(\mathbf{j} + \mathbf{1})\varepsilon_{\mathbf{0}},\tag{21.150}
$$

384 THERMAL PHYSICS this rotation because we must consider rotations about two perpendicular axes, each also perpendicular to the axis separating the atoms. The quantum energy levels are εrot(*j*) = *j*(*j* + 1)ε0, (21.150) where ε0 =*h*¯ 2/(2*I*) and the moment of inertia *I* =2 0*m*1*m*2/(*m*1 + *m*2) for atoms of masses *m*1 and *m*2 separated by a distance 0. Each energy level has degeneracy 2*j* + 1. This prob-

$$\mathbf{C}_{\rm rot} = \boldsymbol{\aleph} \mathbf{k}_{\rm B}, \quad \text{diatomic molecules, } T \gg \boldsymbol{\Theta}_{\rm I}. \tag{21.151}$$

18–12. We define *r* := ε0/*k*B =*h*¯ 2/(2*I[k](#page-404-0)*B). For *T r* , *C*rot ≈0 and the rotation does not contribute, whereas for *T r* , *C*rot ≈ *N k*B and the rotation contributes (1/2)*k*B per [molecule for each of its two rotational degrees of freedom, consistent with equipartition.](#page-404-1) For most diatomic molecules, *r* is only a few Kelvin degrees [61, p. 92], so the rotational mode is fully excited and the total heat capacity due to rotation is *C*rot = *N k*B, diatomic molecules, *T r* . (21.151) Since typically *r* v, the heat capacity at constant volume for a classical ideal gas composed of diatomic molecules varies with temperature as follows: For temperatures

<span id="page-404-1"></span>high enough to be treated as a classical gas, the heat capacity has the translational value (3/2)*N k*B, rises after a slight overshoot9 to (5/2)*N k*B at temperatures above *r* , and finally rises to (7/2)*N k*B for temperatures above v. This behavior is sketched in Figure

![](_page_404_Figure_6.jpeg)

<span id="page-404-0"></span>log T **FIGURE 21–3** Sketch of the heat capacity *CV* in units of *N k*B of a diatomic molecule as a function of log *T*. The first level at 3/2 at low temperatures *T* < *r* results from translational degrees of freedom. The second level at 5/2 at intermediate temperatures *r* < *T* < v results from translation plus rotation. The final level at 7/2 at high temperatures v < *T* results from translation, rotation, and vibration. Since *r* is typically a few degrees K and v is typically a few thousand degrees K, only the middle value 5/2 is usually observed. This simple picture omits corrections due to the electronic degrees of freedom, which are similar in form to those for a monatomic gas,

9See Section 18.4 for details and a graph.

Eq. (21.142).

C*V*/(*N*kB)

*Chapter 21* • Grand Canonical Ensemble 385 For an excellent and more detailed treatment of heteronuclear diatomic molecules, including data for a number of actual molecules, see McQuerrie [54, p. 91]. *Homonuclear Molecules* The situation for homonuclear molecules, such as hydrogen H2 or deuterium D2 is more

complicated because quantum statistics for fermions and bosons comes into play and requires correlation of *z*nuc and *z*rot to produce a net result *z*nuc−rot that corresponds to a wave function that has the correct symmetry under interchange of the nuclei. In case the nuclei are fermions, as for H2, the Pauli exclusion principle applies so the total wave function must be antisymmetric under interchange of the nuclei. This requires each net spin state of the combined nuclei to be paired with a rotational state that has the correct symmetry. For H2, each nucleus has spin 1/2 so the combined nuclear spin states have spin components |1, |0, and | − 1. The states corresponding to |1 and | − 1 come from |1/2, 1/2 and | − 1/2, −1/2 and are symmetric. Of the states corresponding to |0, one is (|1/2, −1/2+|−1/2, 1/2)/√2 and is symmetric; the other is (|1/2, −1/2−|−1/2, 1/2)/√2

$$z_{\rm rot}(\text{even}) := \sum_{j=0,2,4,\dots} (2j+1) \exp[-\beta j(j+1)\varepsilon_0] \tag{21.152}$$

rotational states and the one antisymmetric spin state with even-*j* rotational states. These rotational partition functions are

$$z_{\rm rot}(\text{odd}) := \sum_{j=1,3,5,\dots} (2j+1) \exp[-\beta j(j+1)\varepsilon_0]. \tag{21.153}$$

and

<span id="page-405-1"></span><span id="page-405-0"></span>
$$z_{\text{nuc}-\text{rot}}(\text{hydrogen}) = 3z_{\text{rot}}(\text{odd}) + z_{\text{rot}}(\text{even}).\tag{21.154}$$

For H2, the combined partition function would be *z*nuc−rot(hydrogen) = 3*z*rot(odd) + *z*rot(even). (21.154)

the smaller weight *I*(2*I* + 1) is called *para*.

$$\stackrel{\cdot}{z_{\text{nuc}\to\text{rot}}}(\text{fermions}) = (I+1)(2I+1)z_{\text{tot}}(\text{odd}) + I(2I+1)z_{\text{tot}}(\text{even}).\tag{21.155}$$

Thus more generally, *z*nuc−rot(fermions) = (*I* + 1)(2*I* + 1)*z*rot(odd) + *I*(2*I* + 1)*z*rot(even). (21.155) For the case of bosons, the total wave function must be symmetric under interchange

$$z_{\rm nuc-rot}(\text{deuterium}) = 6z_{\rm rot}(\text{even}) + 3z_{\rm rot}(\text{odd}).\tag{21.156}$$

10The rotational state that goes with the larger weight (*I* + 1)(2*I* + 1) is called *ortho* and the one that goes with

*z*nuc−rot(deuterium) = 6*z*rot(even) + 3*z*rot(odd). (21.156)

386 THERMAL PHYSICS

<span id="page-406-0"></span>
$$z_{\rm nuc-rot}(\text{bosons}) = (I+1)(2I+1)z_{\rm rot}(\text{even}) + I(2I+1)z_{\rm rot}(\text{odd}).\tag{21.157}$$

$$z_{\rm nuc-rot}(\text{fermions}) = z_{\rm nuc-rot}(\text{bosons}) \approx (2I + 1)^2 T/(2\Theta_I). \tag{21.158}$$

More generally, *z*nuc−rot(bosons) = (*I* + 1)(2*I* + 1)*z*rot(even) + *I*(2*I* + 1)*z*rot([od](#page-405-0)d). [(21](#page-406-0).157)

At high temperatures, *z*rot = *T*/*r* and *z*rot(odd) = *z*rot(even) = *T*/(2*r* ). Thus at high temperatures we have *z*nuc−rot(fermions) = *z*nuc−rot(bosons) ≈ (2*I* + 1) 2*T*/(2*r* ). (21.158)

$$u_{\rm nuc-rot} = -\frac{\partial \ln z_{\rm nuc-rot(hydrogen)} }{\partial \beta} = \frac{3z_{\rm rot(odd)}u_{\rm rot(odd)} + z_{\rm rot(even)}u_{\rm rot(even)}}{3z_{\rm rot(odd)} + z_{\rm rot(even)}},\tag{21.159}$$

At lower temperatures, however, the results for fermions and bosons would differ from one another due to the differences in weightings in Eqs. (21.155) and (21.157). For

where

then be

*u*neq

$$u_{\rm rot}(\text{odd}) = -\partial \ln z_{\rm rot}(\text{odd}) / \partial \beta; \quad u_{\rm rot}(\text{even}) = -\partial z_{\rm rot}(\text{even}) / \partial \beta. \tag{21.160}$$

*u*nuc−rot = −∂ ln *z*nuc−rot(hydrogen) ∂β = 3*z*rot(odd)*u*rot(odd) + *z*rot(even)*u*rot(even) 3*z*rot(odd) + *z*rot(eve[n](#page-406-1)) , (21.159)

<span id="page-406-1"></span>
$$\mathbf{c}_{\rm nuc-rot} = \frac{\partial \mathbf{u}_{\rm nuc-rot}}{\partial T} = -k_{\rm B} \beta^2 \frac{\partial \mathbf{u}_{\rm nuc-rot}}{\partial \beta}. \tag{21.161}$$

*u*rot(odd) = −∂ ln*z*rot(odd)/∂β; *u*rot(even) = −∂*z*rot(even)/∂β. (21.160) The heat capacity per hydrogen molecule would then be

*c*nuc−rot = ∂*u*nuc−rot ∂*T* = −*k*Bβ2 ∂*u*nuc−rot ∂β . (21.161) Similar expressions for *u*nuc−rot and *c*nuc−rot but based on Eq. (21.156) would pertain to deuterium. Ironically, it turns out that the heat capacity given by Eq. (21.161) *does not* lead to agreement with experiments on the heat capacity of hydrogen. The situation for deuterium is similar. This is apparently due to the fact that samples are prepared at room temperature which is well above *r* and they do not re-equilibrate during subsequent experiments at low temperatures [62]. At high temperatures, *zr* (odd) ≈ *z*rot(even), so the contribution to *z*nuc−rot(hydrogen) comes 3/4 from molecules in odd rotational states and 1/4 from molecules in even rotational states. But at low temperatures, *z*rot(odd)/*z*rot(even) ≈ 3 exp(−2*r*/*T*) 1, so *z*nuc−rot(hydrogen) comes almost entirely from molecules in even rotational states. These molecules would be required to have antisymmetric spin states. Thus, when hydrogen is cooled from high to low temperatures, equilibrium would require 3/4 of all molecules to change their spin states from symmetric to antisymmetric. Such a change requires molecules to collide at container walls [61, p. 97] and is an extremely slow process. As a result, the gas behaves like a *nonequilibrium mixture* in which the proportion of rotational states is the same as at high temperature. The observed internal energy per molecule of hydrogen due to rotation would

$$
\mu_{\text{nuc}-\text{rot}}^{\text{neq}}(\text{hydrogen}) = (3/4)\mu_{\text{tot}}(\text{odd}) + (1/4)\mu_{\text{tot}}(\text{even}).\tag{21.162}
$$

$$c_{\rm nucl-rot}^{\rm neq}(\rm hydrogen) = (3/4)c_{\rm rot}(\rm odd) + (1/4)c_{\rm rot}(\rm even),\tag{21.163}$$

$$c_{\rm rot}(\rm odd) = -k_{\rm B} \beta^2 \,\partial\mu_{\rm rot}(\rm odd) / \partial\beta; \quad c_{\rm rot}(\rm even) = -k_{\rm B} \beta^2 \,\partial z_{\rm rot}(\rm even) / \partial\beta. \tag{21.164}$$

$$c_{\rm nuc-rot}^{\rm neq}(\rm deuterium) = (2/3)c_{\rm rot}(\rm even) + (1/3)c_{\rm rot}(\rm odd). \tag{21.165}$$

*c* neq nuc−rot(hydrogen) = (3/4)*c*rot(odd) + (1/4)*c*rot(even), (21.163)

### where *c*rot(odd) = −*k*Bβ2∂*u*rot(odd)/∂β; *c*rot(even) = −*k*Bβ2∂*z*rot(even)/∂β. (21.164)

For deuterium we would have *c* neq nuc−rot(deuterium) = (2/3)*c*rot(even) + (1/3)*c*rot(odd). (21.165) These nonequilibrium val[ues](#page-403-1) [agre](#page-403-1)e wit[h](#page-403-2) [experi](#page-403-2)ment. 21.3.3 Polyatomic Molecular Gas Polyatomic gas molecules come in many varieties. Each atom has a nuclear spin and the molecule has an electronic structure. A molecule consisting of *n* atoms has 3*n* − 5 vibrational degrees of freedom if is a linear molecule (such as CO2) and 3*n* − 6 vibrational

degrees of freedom if it is not a linear molecule (such as CH4 which has C at the center of a regular tetrahedron with H atoms at each corner).11 The vibrational degrees of freedom can sometimes be complex (e.g., torsional modes) but can often be treated as normal modes of vibration, *each* of which leads to contributions to the energy and heat capacity of the forms given by Eqs. (21.148) and (21.149). Generally speaking, one still has *T* v for all of these vibrational modes; they make small contributions but must be taken into account to explain experimentally measured heat capacities. One might also have to take into account a few molecular electronic states. But the main contribution of the internal structure to the heat capacity usually comes from the rotational modes. For linear polyatomic molecules, the rotational modes can be treated in a similar way to diatomic molecules. For polyatomic molecules that are not linear, there is usually considerable simplification because the three principal moments of inertia (see Appendix F), *Ii*, of polyatomic molecules are usually sufficiently large that

$$z_{\rm t0t} = \pi^{1/2} \left(\frac{2\mathcal{Z}_1 \mathbf{k_B} T}{\hbar^2}\right)^{1/2} \left(\frac{2\mathcal{Z}_2 \mathbf{k_B} T}{\hbar^2}\right)^{1/2} \left(\frac{2\mathcal{Z}_3 \mathbf{k_B} T}{\hbar^2}\right)^{1/2}.\tag{21.166}$$

*z*rot = π1/2 2*I*1*k*B*T h*¯ 2 1/2 2*I*2*k*B*T* 1/2 2*I*3*k*B*T* 1/2 . (21.166)

remaining degrees of freedom are generally termed vibrational modes.

$$\mathbf{c}_{\rm rot} = -k_{\rm B} \rho^2 \frac{\partial^2 \ln z_{\rm rot}}{\partial \beta^2} = \frac{3}{2} k_{\rm B} \tag{21.167}$$

*k*B (21.167)

2

∂β2 = 3

<sup>11</sup>In both cases, the total number of degrees of freedom is 3*n* and there are three translational degrees of freedom. A linear molecule has two rotational degrees of freedom and a nonlinear molecule has three. The

$$\mathbf{C}_{V} = \mathcal{N}\frac{3}{2}\mathbf{k_{B}} + \mathcal{N}\sum_{\text{vib}}\mathbf{c}_{\text{vib}} + \mathcal{N}\mathbf{c}_{\text{elect}} + \mathcal{N}\frac{3}{2}\mathbf{k_{B}} = 3\mathcal{N}\mathbf{k_{B}}\quad\text{plus small corrections.}\tag{21.168}$$

388 THERMAL PHYSICS for each molecule. The total heat capacity of a polyatomic gas, to a good approximation, is therefore *CV* = *N* 3 2 *k*B + *N* - vib *c*vib + *N c*elect + *N* 3 2 *k*B = 3*N k*B plus small corrections. (21.168) For molecules that are not heteronuclear, such as CO2 or CH4, one must correct the partition function by dividing by a "symmetry number" σ*r* that is equal to the number of indistinguishable rotational states of the molecule, [54, p. 101], but this does not affect the

heat capacity in the high-temperature approximation used above. It does, however, affect the entropy by an amount −*N k*B ln σ*r* . For example, CO2 is a linear molecule with σ*r* = 2 because of two i[ndistinguisha](#page-380-1)ble rotations of π in orthogonal planes about the carbon atom. For CH4, σ*r* = 12 because of three indistinguishable rotations of 2π/3 about each of

### the four C–H bonds that form a tetrahedron. For a more detailed discussion of polyatomic molecules, see McQuarrie [54, p. 129].

For polyatomic molecules, it is also possible to deduce high-temperature distribution functions for the principal angular momenta, Eq. (20.125), and for the vibrational frequencies about the principal axes, Eq. (20.128).

$$P_{I\mathcal{N}_A\mathcal{N}_B} = \lambda_A^{\mathcal{N}_A} \lambda_B^{\mathcal{N}_B} \exp[-\mathcal{E}_{I\mathcal{N}_A\mathcal{N}_B}]/\mathcal{Z},\tag{21.169}$$

The derivation in Section 21.1 can be generalized in a straightforward way to multicompo-

$$\mathcal{Z} = \sum_{\mathcal{N}_{\rm A}} \sum_{\mathcal{N}_{\rm B}} \sum_{r} \lambda_{\rm A}^{\mathcal{N}_{\rm A}} \lambda_{\rm B}^{\mathcal{N}_{\rm B}} \exp[-\mathcal{E}_{\rm r} \mathbb{M}_{\rm A} \mathbb{M}_{\rm B}].\tag{21.170}$$

where λ*A* = exp(βμ*A*), λ*B* = exp(βμ*B*) and *Z* = - *NA* - *NB* - *r* λ*NA A* λ*NB B* exp[−*ErNANB* ]. (21.170)

$$
\mathcal{Z} = \mathcal{Z}_{\rm A} \mathcal{Z}_{\rm B},
\tag{21.171}
$$

and we have factorization which results in

would become

where

<span id="page-408-0"></span>
$$\mathcal{Z}_A = \sum_{\mathcal{N}_A} \sum_{r_A} \lambda_A^{\mathcal{N}_A} \exp[-\mathcal{E}_{r_A \mathcal{N}_A}]; \quad \mathcal{Z}_B = \sum_{\mathcal{N}_B} \sum_{r_B} \lambda_B^{\mathcal{N}_B} \exp[-\mathcal{E}_{r_B \mathcal{N}_B}]. \tag{21.172}$$

*ZA* = -- *rA* λ*NA A* exp[−*ErANA* ]; *ZB* = -

*NA*

$$P_{rN_A\mathcal{N}_B} = P_{r_A\mathcal{N}_A} P_{r_B\mathcal{N}_B}.\tag{21.173}$$

*B* exp[−*ErBNB* ]. (21.172)

*PrNA*,*NB* = *PrA*,*NA PrB*,*NB* . (21.173) For classical ideal gases, we would have *ZA* = exp(λ*AzA*) and *ZB* = exp(λ*BzB*) so Eq. (21.171)

-

*rB* λ*NB*

$$\mathcal{Z} = \exp(\lambda_A \mathbf{z}_A) \exp(\lambda_B \mathbf{z}_B) = \sum_{\mathcal{N}_A \mathcal{N}_B} \lambda_A^{\mathcal{N}_A} \lambda_B^{\mathcal{N}_B} \frac{\mathbf{z}_A^{\mathcal{N}_A}}{N_A!} \frac{\mathbf{z}_B^{\mathcal{N}_B}}{N_B!}. \tag{21.174}$$

$$Z = \frac{z_A^{N_A}}{N_A!} \frac{z_B^{N_B}}{N_B!}. \tag{21.175}$$

*Chapter 21* • Grand Canonical Ensemble 389

### The coefficient of λ*NA A* λ*NB B* is therefore the canonical partition function for exactly *NA*

-

particles of *A* and *NB* particles of *B*, namely *Z* = *z NA A NA*! *z NB B NB*! . (21.175) 21.5 Pressure Ensemble The pressure ensemble can be obtained by using the same procedure as used to derive the GCE. It applies to a system of interest *I* with a definite number of particles *N* that is held at constant temperature *T* and constant pressure *p*. Thus, the volume *Vs* of the system *I* can

<span id="page-409-0"></span>vary. This is accomplished by putting *I* in contact with a thermal and pressure reservoir *R*. The total system consisting of *I* and *R* is assumed to be isolated and has a fixed energy *E*T and a fixed volume *V*T. The qua[ntum](#page-380-0) states of *I* have energies *Ers* ≡ *Er* (*Vs*, *N* ). Not surprisingly, the pressure ensemble will be associated with the thermodynamic function

$$P_{\rm tr} = \frac{\Omega_{\rm R}(E_{\rm T} - \mathcal{E}_{\rm tr}, V_{\rm T} - V_{\rm s})}{\Omega \rm r(Er, Vr)} = \frac{\exp[S_{\rm R}(E_{\rm T} - \mathcal{E}_{\rm tr}, V_{\rm T} - V_{\rm s})/k_{\rm B}]}{\exp[\rm Sr(Er, Vr)/k_{\rm B}]},\tag{21.176}$$

its multiplicity fu[nction](#page-409-0) will be -(*Ers*, *Vs*) = 1, so the probability of that state will be given by *Prs* = -R(*E*T − *Ers*, *V*T − *Vs*)

<span id="page-409-1"></span>
$$\begin{array}{cccc}\dots & \mathbf{\dot{r}} & \mathbf{\dot{r}} & \mathbf{\dot{r}}\\ \text{Sr}(\text{Er}, V\mathbf{r}) = \text{Sr}(\text{Er} - U, V\mathbf{\dot{r}} - V) + \text{S}(U, V), & & \dots & \end{array} \tag{21.177}$$

<span id="page-409-2"></span>which should be compared to Eq. (21.2). The denominator pertains to an unrestricted equilibrium state, so the entropy of the composite system is additive, *S*T(*E*T, *V*T) = *S*R(*E*T − *U*, *V*T − *V*) + *S*(*U*, *V*)[,](#page-409-1) [(2](#page-409-2)1.177)

$$\mathrm{S_R}\left[E_{\mathrm{T}} - \mathcal{E}_{\mathrm{II}}, V_{\mathrm{T}} - V_{\mathrm{S}}\right] = \mathrm{S_R}\left[\left(E_{\mathrm{T}} - U\right) + \left(U - \mathcal{E}_{\mathrm{II}}\right), \left(V_{\mathrm{T}} - V\right) + \left(V - V_{\mathrm{S}}\right)\right].\tag{21.178}$$

numerator of Eq. (21.176), we write *S*R [*E*T − *Ers*, *V*T − *Vs*] = *S*R [(*E*T − *U*) + (*U* − *Ers*),(*V*T − *V*) + (*V* − *Vs*)] . (21.178)

$$\mathrm{S_R(E_\mathrm{T}-\mathcal{E}_{\mathrm{t}\mathrm{t}},V_\mathrm{T}-V_\mathrm{s}) = \mathrm{S_R}(E_\mathrm{T}-E,V_\mathrm{T}-V) + (U-\mathcal{E}_{\mathrm{t}\mathrm{t}})/T + p(V-V_\mathrm{s})/T,\tag{21.179}$$

*S*R(*E*T − *Ers*, *V*T − *Vs*) = *S*R(*E*T − *E*, *V*T − *V*) + (*U* − *Ers*)/*T* + *p*(*V* − *Vs*)/*T*, (21.179) where higher order terms are neglected. Substitution of Eqs. (21.177) and (21.179) into

$$P_{\rm NS} = \exp[G/k_{\rm B}T] \exp[- (\mathcal{E}_{\rm rs} + pV_{\rm s})/k_{\rm B}T],\tag{21.180}$$

*Prs* = exp[*G*/*k*B*T*] exp[−(*Ers* + *pVs*)/*k*B*T*], (21.180)

where the Gibbs free energy

Eq. (21.176) gives

below.

$$\mathbf{G} = \mathbf{U} - \mathbf{T}\mathbf{S} + p\mathbf{V}.\tag{21.181}$$

<span id="page-410-2"></span>
$$\mathbb{E}\exp[-G/k_{\mathbb{B}}T] = \sum_{r,s} \exp[-(\mathcal{E}_{l3} + pV_{s})/k_{\mathbb{B}}T] \equiv \mathcal{Z}_{p},\tag{21.182}$$

390 THERMAL PHYSICS

$$G = -k_{\rm B} T \ln \mathcal{Z}_p \tag{21.183}$$

Since *Prs* are probabilities, summation12 over all *r* and *s* gives *rs Prs* = 1, so Eq. (21.180) yields

$$\mathbf{d}G(T, p, N) = -\mathbf{S}\,\mathrm{d}T + V\,\mathrm{d}p + \mu\,\mathrm{d}N.\tag{21.184}$$

where *Zp*(*T*, *p*, *N* ) is the partition function for the pressure ensemble. Then *G* = −*k*B*T* ln *Zp* (21.183)

$$
\mu = -\left(\text{kg}\,T/N\right)\ln\,\mathbb{Z}_p,\tag{21.185}
$$

ing that

<span id="page-410-1"></span>d*G*(*T*, *p*, *N*) = −*S* d*T* + *V* d*p* + μd*N* . (21.184)

$$
\lambda_p \coloneqq \exp(-\beta p) \tag{21.186}
$$

μ [= −](#page-382-1)(*k*B*T*/*N* )ln *Zp*, (21.185)

*s*

density function for *Vs*. We use summation here to parallel the treatment of the GCE.

*Zp*(β, λ*p*, *N*) = -

$$\mathcal{Z}_p(\beta, \lambda_p, N) = \sum_s \lambda_p^{V_s} \sum_r \exp(-\beta \mathcal{E}_{t3}) = \sum_s \lambda_p^{V_t} Z(T, V_3, N), \tag{21.187}$$

λ*p* := exp(−β*p*) (21.186) and write [the part](#page-410-0)ition function in the functional form

<span id="page-410-0"></span>
$$q_p(\beta, \lambda_p, N) := \ln \mathcal{Z}_p(\beta, \lambda_p, \mathcal{N}) \tag{21.188}$$

where *Z*(*T*, *Vs*, *N* ) is the canonical partition function for a system having volume *Vs*. Note

λ*p*

∂λ*p*

also given by

example,

$$\mathbf{d}\mathbf{q}_p = -U\,\mathbf{d}\boldsymbol{\beta} + (V/\lambda_p)\,\mathbf{d}\lambda_p - \beta\mu\,\mathbf{d}N.\tag{21.189}$$

whose differential is given by d*qp* = −*U* dβ + (*V*/λ*p*) dλ*p* − βμd*N* . (21.189) Equation (21.189) can be verified by using the chain rule of differentiation to convert

$$U = -\left(\frac{\partial q_p}{\partial \beta}\right)_{\lambda_P \mathcal{N}}.\tag{21.190}$$

*U* = −∂*qp* ∂β λ*p*,*N* . (21.190)

$$
\lambda_P \frac{\partial q_P}{\partial \lambda_P} = \frac{\sum_s \lambda_P^{V_s} V_s \sum_r \exp(-\beta \mathcal{E}_R)}{\sum_s \lambda_P^{V_s} \sum_r \exp(-\beta \mathcal{E}_R)} = \sum_R P_{rs} V_s = \langle V \rangle = V. \tag{21.191}
$$

 *s* λ*Vs p rs* 12To treat *Vs* as a continuous variable, we would need to replace summation by integration with a probability

*Chapter 21* • Grand Canonical Ensemble 391 21.5.1 Vacancies in Monovalent Crystals

As an application of the pressure ensemble, we can calculate the number of **vacancies** on substitutional sites in monovalent crystals having a Bravais lattice. Such vacancies are **point defects** known as **Schottky defects**. They can affect the properties of crystals such as thermal expansion and d[iffusion](#page-410-2) by a vacancy mechanism. For the

$$P_{\rm IN}(\mathcal{N}, \mathcal{N}_{\rm V}) = \frac{1}{\mathcal{Z}_{\rm p}(\mathcal{N}, \mathcal{N}_{\rm V})} \exp[-\beta(\mathcal{E}_{\rm tr} + pV_{\rm s})].\tag{21.192}$$

Girifalco [63, p. 195]. For such a crystal at constant temperature *T* and constant pressure *p* and having *N* ions and *N*v vacancies on specific sites, the probability of being in the quantum state *Ers*

$$\exp[-\beta \mathcal{G} \mathbf{o}(\mathcal{N}, \mathcal{N}_{\mathbb{V}})] = \sum_{r,s} \exp[-\beta(\mathcal{E}_{\mathbb{V}^3} + pV_3)] = \mathcal{Z}_{\mathbb{P}}(\mathcal{N}, \mathcal{N}_{\mathbb{V}}).\tag{21.193}$$

*Zp*(*N* , *N*v) By summing over all values of *r* and *s* as in Eq. (21.182), we can identify a Gibbs free energy *G*0(*N* , *N*v) given by exp[−β*G*0(*N* , *N*v)] = - *r*,*s* exp[−β(*Ers* + *pVs*)] = *Zp*(*N* , *N*v). (21.193)

<span id="page-411-2"></span>
$$S^{\rm conf}(\mathcal{N}, \mathcal{N}_{\rm V}) = k_{\rm B} \ln w(\mathcal{N}, \mathcal{N}_{\rm V}); \quad w(\mathcal{N}, \mathcal{N}_{\rm V}) = \frac{(\mathcal{N} + \mathcal{N}_{\rm V})!}{\mathcal{N}! \mathcal{N}_{\rm V}!}. \tag{21.194}$$

However, since the *N* atoms and *N*v vacancies are on *specific* sites, *G*0(*N* , *N*v) does not account for the configurational entropy

$$\mathbf{G}(\mathcal{N}_{\circ}, \mathcal{N}_{\mathrm{V}}) = \mathbf{G}_{\mathbf{0}}(\mathcal{N}, \mathcal{N}_{\mathrm{V}}) - T\mathbf{S}^{\mathrm{conf}}(\mathcal{N}, \mathcal{N}_{\mathrm{V}}) = \mathbf{G}_{\mathbf{0}}(\mathcal{N}, \mathcal{N}_{\mathrm{V}}) - \mathbf{k}_{\mathrm{B}}T \ln w(\mathcal{N}, \mathcal{N}_{\mathrm{V}}).\tag{21.195}$$

v

We can therefore construct a total Gibbs free energy of the form *G*(*N* , *N*v) = *G*0(*N* , *N*v) − *TS*conf(*N* , *N*v) = *G*0(*N* , *N*v) − *k*B*T* ln *w*(*N* , *N*v). (21.195) The equilibrium number of vacancies *N* eq

$$\mathbf{0} = \frac{\partial \mathbf{G}(\mathcal{N}, \mathcal{N}_{\mathbf{V}})}{\partial \mathcal{N}_{\mathbf{V}}} \Big|_{\mathcal{N}_{\mathbf{V}}^{\mathrm{eq}}} = \mathbf{g}_{\mathbf{V}} + k_{\mathrm{B}} T \ln \left[ \frac{\mathcal{N}_{\mathbf{V}}^{\mathrm{eq}}}{\mathcal{N} + \mathcal{N}_{\mathbf{V}}^{\mathrm{eq}}} \right],\tag{21.196}$$
 where

where

respect to *N*v to obtain

$$\mathbf{g}_{\rm V} := \left. \frac{\partial \mathbf{G}(\mathcal{N}, \mathcal{N}_{\rm V})}{\partial \mathcal{N}_{\rm V}} \right|_{\mathcal{N}_{\rm V}^{\rm eq}} \approx \left. \frac{\partial \mathbf{G}(\mathcal{N}, \mathcal{N}_{\rm V})}{\partial \mathcal{N}_{\rm V}} \right|_{\mathcal{N}_{\rm V} = \mathbf{0}}.\tag{21.197}$$
 
$$\mathbf{g}_{\rm v} := \mathbf{0}, \qquad \mathbf{g}_{\rm v} := \mathbf{0}, \qquad \mathbf{n} := \mathbf{n}.$$

∂*N*v *N*eq v ∂*N*v *N*v=0 . (21.197)

<span id="page-411-0"></span> 

*N* eq v

v

<span id="page-411-1"></span>0 = ∂*G*(*N* , *N*v)

$$\frac{\mathcal{N}_{\rm V}^{\rm eq}}{\mathcal{N} + \mathcal{N}_{\rm V}^{\rm eq}} = \exp[-\mathbf{g}_{\rm V}/k_{\rm B}T]. \tag{21.198}$$

, (21.196)

Eq. (21.195) can be written

<span id="page-412-0"></span>

| FCC crystal           | Cu        | Ni        | Al        |
|-----------------------|-----------|-----------|-----------|
| TM                    | 1358 K    | 1728 K    | 933 K     |
| hv                    | 1.05 eV   | 1.4 eV    | 0.65 eV   |
| sv                    | 0.4 kB    | 1.5 kB    | 0.8 kB    |
| exp(sv/kB)            | 1.5       | 4.5       | 2.2       |
| N eq<br>/N at TM<br>v | 1.9 ×10−4 | 3.6 ×10−4 | 6.8 ×10−4 |
| hb                    | 0.1 eV    | 0.3 eV    | 0.3 eV    |
| sb                    | −         | 2 kB      | 1 kB      |
| N eq<br>d /N at TM    | −         | 8 ×10−7   | 4 ×10−5   |
| fd                    | −         | 0.1%      | 10%       |

*s*v 0.4 *k*B 1.5 *k*B 0.8 *k*B exp(*s*v/*k*B) 1.5 4.5 2.2 *N* eq v /*N* at *T*M 1.9 ×10−4 3.6 ×10−4 6.8 ×10−4 *h*b 0.1 eV 0.[3 eV](#page-411-0) 0.3 eV

*s*b − 2 *k*B 1 *k*B *N* eq d /*N* at *T*M − 8 ×10−7 4 ×10−5 *f*d − 0.1% 10% *Notes*: *f*d given by Eq. (21.208) is the fraction of vacant lattice sites due to divacancies. Data for *h*v , *s*v, *h*b, and *s*b, where *g*b = *h*b − *Ts*b is the binding free energy of a divacancy, are from Girifalco [63, p. 217].

The quantity *g*v is nearly independent of *N* eq v and can be thought of as the Gibbs free energy needed to create a vacancy by moving an atom from a definite substitutional site to the crystal surface. In order of magnitude, we expect *g*v ∼ [1 eV. A](#page-412-0)t room temperature, *k*B*T* ∼ 1/40 eV, so the right-hand side of Eq. (21.198) would be about 4 × 10−18. At *T* = 900 K, it would increase to about 6 × 10−6. Since *N* eq

$$\mathcal{N}_{\rm V}^{\rm eq} = \mathcal{N} \exp(\mathbf{s}_{\rm V}/k\mathbf{s}) \exp(-h_{\rm V}/k\mathbf{s}\,T),\tag{21.199}$$

<span id="page-412-1"></span>con[stant an](#page-411-2)d associated with a single vacancy at a definite location. Then Eq. (21.198) can be written approximately as *N* eq v = *N* exp(*s*v/*k*B) exp(−*h*v/*k*[B](#page-412-1)*T*), (21.199) where *h*v plays the role of an activation energy. Typically the prefactor exp(*s*v/*k*B) ∼ 1

and *N* eq v /*N* ∼ 10−4 near the melting point of a crystal. Table 21–1 gives experimentally determined values of *h*v and *s*v for some FCC metals as well as values of *N* eq v at their melting points. According to Eq. (21.197), *g*v is nearly independent of *N*v in the range of interest where

$$
\Delta G(\mathcal{N}, \mathcal{N}_\mathrm{V}) = \mathbf{g}_\mathrm{V} \mathcal{N}_\mathrm{V} - k_\mathrm{B} T \ln w(\mathcal{N}, \mathcal{N}_\mathrm{V}),
\tag{21.200}
$$

*G*(*N* , *N*v) = *g*v*N*v − *k*B*T* ln*w*(*N* , *N*v), (21.200) where *G*(*N* , *N*v) ≡ *G*(*N* , *N*v) − *G*0(*N* , 0). Equation (21.200) is usually the starting point of a simplified treatment of vacancies and will be used in the next section to explore other

point defects. Nonequilibrium concentrations of vacancies can be obtained by such means as quenching from a higher temperature or irradiation by neutrons. Such concentrations

might last for a long time, depending on the rate of vacancy diffusion and the proximity of

*Chapter 21* • Grand Canonical Ensemble 393

### vacancy sinks such as dislocations and grain boundaries. This can result in the formation of voids. Line defects such as dislocations and area defects such as grain boundaries are

not equilibrium defects because the energy to create them is too large to be offset by configurational entropy. They usual[ly](#page-412-1) [result](#page-412-1) from material preparation, for example, by crystallization, or by mechanical deformation. Prolonged annealing at sufficiently high temperatures can be used to eliminate some line and surface defects but such a process is very slow.

$$
\Delta G(\mathcal{N}_\prime, \mathcal{N}_\prime, \mathcal{N}_\mathbf{d}, \mathcal{N}_\mathbf{l}) = \mathbf{g}_\mathcal{V} \mathcal{N}_\mathbf{V} + \mathbf{g}_\mathbf{d} \mathcal{N}_\mathbf{d} + \mathbf{g}_\mathbf{l} \mathcal{N}_\mathbf{l} - k_\mathbf{B} T \ln \mathcal{W}, \tag{21.201}
$$

In monovalent crystals, vacancies (v), vacancies in adjacent lattice sites called "divacancies" (d) and ions in voids of the substitutional lattice called "interstitials" (i) can be considered as point defects. At equilibrium, all of these are dilute species, so we can proceed with a generalization of Eq. (21.200), resulting in

$$\mathcal{S} = \mathcal{N} + \mathcal{N}_{\text{V}} + 2\mathcal{N}_{\text{d}} - \mathcal{N}_{\text{l}}.\tag{21.202}$$

bonds are needed to form a divacancy than to form two isolated vacancies. Interstitials need to crowd surrounding ions, so we expect *g*i > *g*v, usually leading to interstitials being the most dilute. The number of substitutional lattice sites is *S* = *N* + *N*v + 2*N*d − *N*i. (21.202) The total number of configurations can be expressed as a product of three factors, *W* =*w*d*w*v*w*i, where *w*d is the number of ways that divacancies can be distributed on the sites *S*; *w*v is the number of ways that isolated vacancies can be distributed on the remaining substitutional sites; and *w*i is the number of ways that interstitials can be distributed on *I* interstitial sites. Since we are treating a crystal with a Bravais lattice, we take *I* = α*S*, where α is an integer, for example, 1 for FCC and 3 for BCC. [Exp](#page-413-0)ressions for *w*d, *w*v, and *w*i can be quite complex (see Girifalco [63, p. 214]) if proper counting is done to insure, for example, that vacancies are not adjacent to divacancies. But given that all species are dilute, we can make reasonable approximations immediately. For example, if there are *N*d divacancies, the isolated vacancies can reside on *S* − 2*N*d = *N* + *N*v − *N*i sites, but not next to a divacancy or next to each other. But one makes negligible error by assuming that isolated vacancies are distributed over *N* + *N*v sites, or even over *N* sites. Similarly, if *z* is the number of nearest neighbors of a lattice site, the number of nearest neighbor pairs where a divacancy might reside is *Sz*/2 and some of these could be

<span id="page-413-0"></span>
$$w_{\rm d} \approx \frac{(\mathcal{N}z/2)!}{(\mathcal{N}z/2) - (\mathcal{N}_{\rm d})!\mathcal{N}_{\rm d}!}; \quad w_{\rm V} \approx \frac{(\mathcal{N} + \mathcal{N}_{\rm V})!}{\mathcal{N}\mathcal{N}_{\rm V}!}; \quad w_{\rm l} \approx \frac{(\alpha\mathcal{N})!}{(\alpha\mathcal{N} - \mathcal{N}_{\rm l})!\mathcal{N}_{\rm l}!},\tag{21.203}$$

(α*N* − *N*i)!*N*i!

13In making these approximations, it is important to be sure each quantity has the form of a binomial

(*N z*/2) − (*N*d)!*N*d!

coefficient.

*N* eq

to divacancies is

$$\mathcal{N}_{\rm d}^{\rm eq} \approx \frac{Nz}{2} \exp(-\mathsf{g}_{\rm d}/k_{\rm B}T); \quad \mathcal{N}_{\rm v}^{\rm eq} \approx \mathcal{N}\exp(-\mathsf{g}_{\rm l}/k_{\rm B}T); \quad \mathcal{N}_{\rm l}^{\rm eq} \approx a\mathcal{N}\exp(-\mathsf{g}_{\rm v}/k_{\rm B}T). \tag{21.204}$$

394 THERMAL PHYSICS

which completely decouples different point defects. Then proceeding as with vacancies

$$N_{\rm d}^{\rm eq} = (1/2) \| N \exp(-\mathbf{g}_{\rm V}(\mathbf{k_{B}}T)) \| z \exp(-\mathbf{g}_{\rm V}(\mathbf{k_{B}}T)), \quad \text{no binding energy}, \tag{21.205}$$

*N* eq d ≈ *N z* 2 exp(−*g*d/*k*B*T*); *N* eq v ≈ *N* exp(−*g*i/*k*B*T*); *N* eq i ≈ α*N* exp(−*g*v/*k*B*T*). (21.204) These same results are obtained if the more accurate values of *w*d, *w*v, and *w*i are used, provided that defect numbers are neglected in comparison with *N* in the final results. The most interesting result is for the divacancies. If we had simply *g*d = 2*g*v, we would obtain

<span id="page-414-0"></span>
$$\mathbf{g}_{\rm d} = 2\mathbf{g}_{\rm V} - \mathbf{g}_{\rm b},\tag{21.206}$$

which is simply the equ[ilibrium num](#page-412-0)ber of vacancies times the probability that one of

$$\dot{N}_{\rm d}^{\rm eq} = (\mathbf{z}/2)\mathcal{N}\exp[- (\mathbf{2}_{\rm B} - \mathbf{g_{b}})/k_{\rm B}T] = (\mathbf{z}/2)\mathcal{N}[\exp(-\mathbf{g_{b}}/k_{\rm B}T)]^{2}\exp(\mathbf{g_{b}}/k_{\rm B}T). \tag{21.207}$$

(binding energy) that results from the proximity of adjacent vacancies. Thus one can write *g*d = 2*g*v − *g*b, (21.206) where *g*b = *h*v − *Ts*b > 0 is a binding (free) energy between adjacent vacancies. Then *N* eq d = (*z*/2)*N* exp[−(2*g*v − *g*b)/*k*B*T*] = (*z*/2)*N* [exp(−*g*v/*k*B*T*)] 2 exp(*g*b/*k*B*T*). (21.207) Numbers for *g*b are not very accurate so we give only some estimates of *h*b and *s*b to

$$f_{\rm d} = 2\mathcal{N}_{\rm d}^{\rm eq} / (\mathcal{N}_{\rm v}^{\rm eq} + 2\mathcal{N}_{\rm d}^{\rm eq}).\tag{21.206}$$

recognizing that a divacancy results in two vacant sites, so the fraction [of](#page-414-1) vacant sites due

### *f*d = 2*N* eq d /(*N* eq v + 2*N* eq d ). (21.208)

capable of existing on *N*v− sites.

centers in which localized electrons or holes can exist.

For Ni, *f*d is essentially negligible but for Al it is about 10% at its melting point. 21.5.3 Vacancies and Interstitials in Ionic Crystals Vacancies and interstitials can occur in crystals with ionic bonding but their formation is subject to additional constraints to insure charge neutrality. We shall illustrate these considerations by treating alkali halides, such as NaCl, and silver halides with formulae of

- <span id="page-414-1"></span>the form AgX in which Ag has the oxidation state +1 and *X* is a halogen.14 We consider the following types of point defects:
- **Positive ion vacancy** *N*v+ in number, each being a region of negative charge −*e* and capable of existing on *N*v+ sites. **Negative ion vacancy** *N*v− in number, each being a region of positive charge *e* and

<sup>14</sup>We exclude AgF2 in which Ag has the oxidation state +2. At this stage, we do not treat the possibility of color

*Chapter 21* • Grand Canonical Ensemble 395 **Positive ion interstitial** *N*i+ in number, each being a region of positive charge *e* and capable of existing on *N*i+ sites. **Negative ion interstitial** *N*i− in number, each being a region of negative charge −*e* and capable of existing on *N*i− sites. For the sake of simplicity, we will first treat the case in which only pairs of defects are needed to balance charge because the other two types of defects have values of Gibbs free energy per defect that are much larger. For example, we will only need to consider positive ion vacancies balancing the charge of negative ion vacancies if *g*i+ and *g*i− exceed *g*v+ and *g*v− by amounts that are large compared to *k*B*T*. This will give rise to two types of vacancies, also known as Schottky defects. On the other hand, we will only need to consider positive

ion vacancies balancing the charge of positive ion interstitials if *g*v− and *g*i− exceed *g*v+ and *g*i+ by amounts that are large compared to *k*B*T*. Such vacancy-interstitial pairs are known

$$\mathbf{g}_{\rm V+} \mathcal{N}_{\rm V+} + \mathbf{g}_{\rm V+} \mathcal{N}_{\rm V+} - k_{\rm B} T \ln \mathcal{W}_{\rm V\!V} - \lambda (\mathcal{N}_{\rm V+} - \mathcal{N}_{\rm V-}),\tag{21.209}$$
 ...

but a general methodology that can be used if one needs to consider more than two defect

where

$$\mathcal{W}_{\rm{VV}} = \frac{N^{\rm{v}+}!}{(N^{\rm{v}+} - \mathcal{N}_{\rm{V}+})! \mathcal{N}_{\rm{V}+}!} \frac{N^{\rm{v}-}!}{(N^{\rm{v}-} - \mathcal{N}_{\rm{V}-})! \mathcal{N}_{\rm{V}-}!}. \tag{21.210}$$

typical for alkali halides.

This results in

<span id="page-415-1"></span>
$$\mathcal{N}_{\rm V+}^{\rm eq} = N^{\rm v+} \exp(-\beta \mathbf{g}_{\rm V+} + \lambda); \quad \mathcal{N}_{\rm V-}^{\rm eq} = N^{\rm v-} \exp(-\beta \mathbf{g}_{\rm V-} - \lambda). \tag{21.211}$$

<span id="page-415-2"></span>*g*v+*N*v+ + *g*v+*N*v+ − *k*B*T* ln *W*vv − λ(*[N](#page-415-0)*v+ − *N*v−), (21.209)

(*N*v+ − *N*v+)!*N*v+! (*N*v− − *N*v−)!*N*v−!

$$\mathcal{N}_{\rm V+}^{\rm eq}\mathcal{N}_{\rm V-}^{\rm eq} = N^{\rm v+}N^{\rm v-} \exp\left[-\beta(\mathbf{g}_{\rm V+} + \mathbf{g}_{\rm V-})\right].\tag{21.212}$$

*N* eq These can be multiplied to eliminate λ which yields

$$\mathcal{N}_{\rm V+}^{\rm eq} = \mathcal{N}_{\rm V-}^{\rm eq} = (N^{\rm v+}N^{\rm v-})^{1/2} \exp\left[-\beta(\mathbf{g}_{\rm V+} + \mathbf{g}_{\rm V-})/2\right]. \tag{21.213}$$

But since the constraint requires *N* eq v+ = *N* eq v−, we obtain15 *N* eq v+ = *N* eq v− = (*N*v+*N*v−) 1/2 [exp](#page-415-1) −β(*g*v+ + *g*v−)/2 . (21.213) Equation (21.213) depends only on the ave[rage of](#page-415-2) *g*v+ and *g*v−, so the smaller of the two

<span id="page-415-0"></span>compensates for the larger in establishing the effective activation energy. This case is

$$\mathcal{N}_{\rm V+}^{\rm eq} = \mathcal{N}_{\rm l+}^{\rm eq} = (N^{\rm v+}N^{\rm l+})^{1/2} \exp\left[-\beta(\mathfrak{g}_{\rm V+} + \mathfrak{g}_{\rm l+})/2\right]. \tag{21.214}$$

*N* eq v+ = *N* eq i+ = (*N*v+*N*i+) 1/2 exp −β(*g*v+ + *g*i+)/2 . (21.214) This case typically occurs for silver halides. By replacing + with − in Eq. (21.214), we could get a case in which negative ion vacancies and negative ion interstitials are the dominant

v− in Eq. (21.211) and then solved for exp λ.

point defects. By replacing "v" with "i" in Eq. (21.213), we could get a case in which positive 15Alternatively we could have set *N* eq v+ = *N* eq

$$\mathbf{u}$$

ion interstitials and negative ion interstitials are the dominant point defects, but this case

is not expected to occur because interstitials typically have higher activation energies than vacancies.

<span id="page-416-0"></span>
$$\mathcal{N}_{\mathsf{V+}}^{\mathsf{eq}} = N^{\mathsf{v+}} \exp(-\beta \mathsf{g}_{\mathsf{V+}} + \lambda); \quad \mathcal{N}_{\mathsf{V--}}^{\mathsf{eq}} = N^{\mathsf{v-}} \exp(-\beta \mathsf{g}_{\mathsf{V--}} - \lambda); \quad \mathcal{N}_{\mathsf{l}+}^{\mathsf{eq}} = N^{\mathsf{l}+} \exp(-\beta \mathsf{g}_{\mathsf{l}+} - \lambda). \tag{21.215}$$

order *k*B*T* but *g*v+, *g*v−, *g*i+ *g*i−. Thus, negative ion interstitials can be ignored, so there must

$$\mathcal{N}_{\mathsf{V+}}^{\mathsf{eq}}\mathcal{N}_{\mathsf{V--}}^{\mathsf{eq}} = N^{\mathsf{v}+}N^{\mathsf{v}-}\exp\left[-\beta(\mathsf{g}_{\mathsf{V+}} + \mathsf{g}_{\mathsf{v-}})\right]; \quad \mathcal{N}_{\mathsf{V+}}^{\mathsf{eq}}\mathcal{N}_{\mathsf{I+}}^{\mathsf{eq}} = N^{\mathsf{v}+}N^{\mathsf{l}+}\exp\left[-\beta(\mathsf{g}_{\mathsf{V+}} + \mathsf{g}_{\mathsf{I+}})\right].\tag{21.216}$$

*N*i+) to *G* and minimizing to obtai[n](#page-416-0) *N* eq v+ = *N*v+ exp(−β*g*v+ + λ); *N* eq v− = *N*v− exp(−β*g*v− − λ); *N* eq i+ = *N*i+ exp(−β*g*i+ − λ).

$$\mathcal{N}_{\rm V+}^{\rm eq} = (N^{\rm v+})^{1/2} \exp(-\beta \mathbf{g}_{\rm V+}/2) \left[ N^{\rm v-} \exp(-\beta \mathbf{g}_{\rm V-}) + N^{\rm f+} \exp(-\beta \mathbf{g}_{\rm V+}) \right]^{1/2}. \tag{21.217}$$
 
$$\text{Thon oomhining this result with Eq. (21.216) gives}$$

*N* eq v+*N* eq

Mermin [58, p. 621] for a discussion of these and other defects.

$$\mathcal{N}^{\text{eq}}_{\text{V}-} = \frac{1 \cdot \cdots \cdot \cdots}{\left[N^{\text{v}+}\right]^{1/2} \exp(-\beta \text{g}_{\text{V}} + /2)} N^{\text{v}-} \exp(-\beta \text{g}_{\text{V}} + /2)$$

$$\mathcal{N}^{\text{v}-}_{\text{V}} = \frac{(N^{\text{v}} - \exp(-\beta \text{g}_{\text{V}}) + \mathcal{N}_{\text{I}+} \exp(-\beta \text{g}_{\text{I}+})}{\left[N^{\text{v}} - \exp(-\beta \text{g}_{\text{V}}) + \mathcal{N}_{\text{I}+} \exp(-\beta \text{g}_{\text{V}})\right]^{1/2}} N^{\text{v}-} \exp(-\beta \text{g}_{\text{V}-})}\tag{21.218}$$

Then combining this result with Eq. (21.216) gives

and

us to solve for

*N* eq

$$\mathcal{N}_{\mathsf{l}+}^{\mathrm{eq}} = \frac{(N^{\mathsf{l}+})^{1/2} \exp(-\beta \mathsf{g}_{\mathsf{V}+}/2)}{\left[N^{\mathsf{v}-} \exp(-\beta \mathsf{g}_{\mathsf{V}-}) + \mathcal{N}_{\mathsf{l}+} \exp(-\beta \mathsf{g}_{\mathsf{l}+})\right]^{1/2}} N^{\mathsf{l}+} \exp(-\beta \mathsf{g}_{\mathsf{l}+}). \tag{21.219}$$

*N* eq i+ = (*N*v+) *N*v− exp(−β*g*v−) + *N*i+ exp(−β*g*i+) 1/2 *N*i+ exp(−β*g*i+). (21.219) For ionic crystals, there are many other types of point defects, such as those that arise when a small number of Ca++ ions are substituted for Na+ ions in NaCl, thus stimulating the production of an equal number of Na+ vacancies. Such defects can strongly affect electrical conductivity because of vacancy-assisted diffusion of ions. There is also the possibility of color centers that involve localized electrons and holes that have a large

influence on optical adsorption. The reader is referred to the book by Ashcroft and

1/2 exp(−β*g*v+/2)

![](_page_417_Picture_0.jpeg)

22 Entropy for Any Ensemble Until now we have introduced four ensembles that are used in statistical mechanics: the microcanonical ensemble in Chapter 16, the canonical ensemble in Chapter 19, the grand canonical ensemble in Chapter 21, and the pressure ensemble in Section 21.5 of Chapter 21. The canonical ensemble and the grand canonical ensemble were derived from the microcanonical ensemble, although an alternative derivation of the canonical ensemble was presented. Moreover, in Chapter 15, we introduced the disorder function *D*{*pi*} that gives a precise measure of information based on a set of probabilities {*pi*} that can be used to characterize a system. In the present chapter, we give a definition of the entropy of a system represented by any ensemble used

to define its thermodynamic state statistically. This definition will be based on the methodology of the most probable distribution used in Section 19.1.3 to derive the canonical ensemble. Our definition of entropy will enable us to relate systematically a

### specific thermodynamic function with the logarithm of the partition function for that ensemble.

be satisfied. One such constraint,

the ensemble as having *N A*

<span id="page-417-0"></span>22.1 General Ensemble A general ensemble consists of a very large number *N*ens of immaginary systems, each in some quantum state that we can index by a set of numbers, *i*, *j*, *k*, and a set of probabilities *Pijk* such that a given state will appear *Nijk* = *N*ens*Pijk* times in the ensemble. For the sake of illustration, we have assumed that the states of the ensemble can be characterized by three numbers, but more or less could be used depending on the ensemble. In the case of the ensembles heretofore treated, one number *i* or two numbers *i*, *j* is sufficient. To

$$\sum_{l,l,k} P_{l|k} = 1,\tag{22.1}$$

*k* of *B* particles and eigenstates with energies

- *i*,*j*,*k [Pijk](http://dx.doi.org/10.1016/B978-0-12-803304-3.00022-3)* = 1, (22.1) comes from normalization of the set of probabilities and must always be satisfied. If it is the only constraint, a single state index would suffice. But other constraints might also be relevant. These are best illustrated by example for which we select a grand canonical ensemble with two kinds of particles, say *A* and *B*. Then we would characterize the states of

*j* of *A* particles, *N B*

398 THERMAL PHYSICS

*j* , *N B*

*Eijk* = *Ei*(*N A*

$$\sum_{l,l,k} P_{ljk} \mathcal{E}_{ljk} = \text{constant};\tag{22.2}$$

$$\sum_{l,l,k} P_{ljk} \mathcal{N}_l^A = \text{constant};\tag{22.3}$$

$$\sum_{l,l,k} P_{l|k} \mathcal{N}_k^{\mathbb{B}} = \text{constant}.\tag{22.4}$$

- *i*,*j*,*k Pijk Eijk* = constant; (22.2)

$$\mathcal{W} = \frac{\mathcal{N}_{\rm ens}!}{\prod_{\mathcal{l}\boldsymbol{\mathcal{l}}\boldsymbol{k}\cdot\boldsymbol{\mathcal{l}}\boldsymbol{l}\boldsymbol{k}!}} = \frac{\mathcal{N}_{\rm ens}!}{\prod_{\mathcal{l}\boldsymbol{\mathcal{l}}\boldsymbol{k}} (\mathcal{N}_{\rm ens} P_{\boldsymbol{l}\boldsymbol{\mathcal{l}}\boldsymbol{k}})!}. \tag{22.5}$$

*i*,*j*,*k Pijk N B k* = constant. (22.4) Given such a general ensemble, the number of ways that the ensemble can be

$$S = k_{\rm B} \mathcal{N}_{\rm ens}^{-1} (\ln \mathcal{W})_{\rm max}, \quad \text{subject to constraints,} \tag{22.6}$$

*W* = *N*ens! *ijk Nijk*! = *N*ens! *ijk*(*N*ens*Pijk*)! . (22.5) Then we maximize ln *W* subject to the constraints and assert that the entropy of the system represented by the ensemble is given by

$$
\ln \mathcal{W} = \mathcal{N}_{\text{ens}} \ln \mathcal{N}_{\text{ens}} - \sum_{\text{ijk}} \mathcal{N}_{\text{ens}} P_{\text{ljk}} \ln(\mathcal{N}_{\text{ens}} P_{\text{ljk}}) = -\mathcal{N}_{\text{ens}} \sum_{\text{ljk}} P_{\text{ljk}} \ln P_{\text{ljk}}.\tag{22.7}
$$

identified. Since *N*ens is large, we can use [Stirli](#page-418-0)ng's approximation to evaluate ln *W*, resulting in

d*S* = *T*−1 d-

ensemble, which is how they actually originate.

formed is

<span id="page-418-1"></span><span id="page-418-0"></span>
$$S = -k_{\rm B} \left( \sum_{\langle l|k\rangle} P_{l|k} \ln P_{l|k} \right)_{\rm max}, \quad \text{subject to constraints,} \tag{22.8}$$

Thus ⎛ ⎞

*S* = −*k*B ⎝- *ijk Pijk* ln *Pijk* ⎠ max , subject to constraints, (22.8) where Lagrange multipliers associated with the constraints must still be identified. Referring to Chapter 15, we see that Eq. (22.8) amounts to the maximization of the disorder function, but with the important added information that one must maximize the disorder function subject to the constraints of the ensemble under consideration. Thus, Eq. (22.8) provides a general formula for the entropy of a system represented by any ensemble in terms of maximization of the disorder function. The Lagrange multipliers

$$\mathbf{dS} = T^{-1} \mathbf{d}(E) + (\mathbf{p}/T) \, \mathbf{d}V - (\mu_A/T) \, \mathbf{d} \langle \boldsymbol{\mathcal{N}}^A \rangle - (\mu_B/T) \, \mathbf{d} \langle \boldsymbol{\mathcal{N}}^B \rangle,\tag{22.9}$$

*N B*, (22.9)

*N A* − (μ*B*/*T*) d-

1Instead of the volume, *Eijk* could depend on a whole set of mechanical variables *Y*if the system can do

*E* + (*p*/*T*) d*V* − (μ*A*/*T*) d-

reversible work by means of generalized forces *p*- = − *ijk Pijk* ∂*Eijk*/∂*Y*-. 2These constraints could be multiplied by *N*ens in which case they are conservation laws for the entire

*Chapter 22* • Entropy for Any Ensemble 399

where *T* is the temperature, *p* is the pressure, μ*A* is the chemical potential of *A*, μ*B* is the

*ijk*

$$0 = \frac{\partial}{\partial P_{\rm IXI}} \left\{-\sum_{\rm jlk} P_{\rm jlk} \ln P_{\rm jlk} - \sum_{\rm ljk} P_{\rm ljk} [\alpha + \beta \mathcal{E}_{\rm jlk} + \gamma_{\rm l} \mathcal{N}_{\rm j}^{A} + \gamma_{\rm B} \mathcal{N}_{\rm k}^{B}] \right\}. \tag{22.10}$$

We proceed to carry out this maximization for the example given above. Introducing

*ijk*

⎧

$$-1 - \ln P_{\rm rM} - \mu - \beta \mathcal{E}_{\rm rM} - \gamma_{\rm A} \mathsf{N}_{\rm s}^{A} - \gamma_{\rm B} \mathsf{N}_{\rm t}^{B} = 0,\tag{22.11}$$

*j* + γ*BN B k* ]

⎬ ⎭

. (22.10)

0 = ∂ ∂*Prst* ⎨ ⎩− -*Pijk* ln *Pijk* −-*P[ijk](#page-417-0)*[α + β*Eijk* + γ*AN A*

$$P_{ljk} = \exp\left\{-\omega - 1 - \beta \mathcal{E}_{ljk} - \gamma \mathbb{A} \mathcal{N}_l^A - \gamma \mathbb{A} \mathcal{N}_k^B \right\}. \tag{22.12}$$

− 1 − ln *Prst* − α − β*Erst* − γ*AN A s* − γ*BN B t* = 0, (22.11)

$$P_{l|k} = \mathcal{Z}^{-1} \exp(-\gamma_{l} \mathcal{N}_{l}^{A}) \exp(-\gamma_{l} \mathcal{N}_{k}^{B}) \exp(-\beta \mathcal{E}_{l|k}),\tag{22.13}$$
 
$$P_{l|k} = \mathcal{Z}^{-1} \quad \text{and} \quad \gamma_{l} = \mathcal{Z}^{-1} \quad \text{and} \quad \gamma_{l} = \mathcal{Z}^{-1}$$

*Z* = -

where we have used

-

-

-

*ijk*

*j*

$$\mathcal{Z} = \sum_{\mathbf{j}} \exp(-\gamma_{\mathbf{k}} \mathsf{N}_{\mathbf{j}}^{A_{\mathbf{j}}}) \sum_{\mathbf{k}} \exp(-\gamma_{\mathbf{k}} \mathsf{N}_{\mathbf{k}}^{B_{\mathbf{j}}}) \sum_{\mathbf{l}} \exp(-\beta \mathcal{E}_{\mathbf{l}|\mathbf{k}}).\tag{22.14}$$

*k*

where the grand partition function 

$$\mathrm{dS} = -k_{\mathrm{B}} \sum_{\langle jk\rangle} \left[ 1 + \ln P_{\langle jk\rangle} \right] \mathrm{d}P_{\langle jk\rangle}$$

$$= k_{\mathrm{B}} \sum_{\langle jk\rangle} \left[ \chi_{\mathrm{A}} \mathcal{N}_{f}^{\mathrm{A}} + \chi_{\mathrm{E}} \mathcal{N}_{k}^{\mathrm{B}} + \beta \mathcal{E}_{\langle jk\rangle} \right] \mathrm{d}P_{\langle jk\rangle}.\tag{22.15}$$

d*Pijk*, (22.15)

= *k*B - γ*AN A j* + γ*BN B k* + β*Eijk*

*ijk*

$$
\langle E \rangle = \sum_{\langle jk \rangle} P_{\langle jk \rangle} \mathcal{E}_{\langle jk \rangle}; \quad \mathbf{d} \langle E \rangle = \sum_{\langle jk \rangle} \mathcal{E}_{\langle jk \rangle} \mathbf{d} P_{\langle jk \rangle} + \sum_{\langle jk \rangle} P_{\langle jk \rangle} \frac{\partial \mathcal{E}_{\langle jk \rangle}}{\partial V} \mathbf{d} V; \tag{22.16}
$$

$$
\langle \mathcal{N}^A \rangle = \sum_{ijk} P_{ijk} \mathcal{N}_f^A; \quad \mathbf{d} \langle \mathcal{N}^A \rangle = \sum_{ijk} \mathcal{N}_f^A \, \mathbf{d} P_{ijk}; \tag{22.17}
$$

$$
\langle \mathcal{N}^{B} \rangle = \sum_{ijk} P_{ljk} \mathcal{N}_{k}^{B}; \quad \mathbf{d} \langle \mathcal{N}^{B} \rangle = \sum_{ijk} \mathcal{N}_{k}^{B} \, \mathbf{d} P_{ljk}. \tag{22.18}
$$

*ijk*

$$\mathbf{dS} = k_{\mathbf{B}} \gamma_{A} \mathbf{d} \langle N^{A} \rangle + k_{\mathbf{B}} \gamma_{\mathbf{B}} \mathbf{d} \langle N^{B} \rangle + k_{\mathbf{B}} \beta \,\mathbf{d} \langle E \rangle - \sum_{l \parallel k} P_{l \parallel k} \frac{\partial \mathcal{E}_{l \parallel k}}{\partial V} \,\mathrm{d}V. \tag{22.19}$$

$$\beta = \frac{1}{k \mathbb{B} \, T}; \quad \gamma_A = -\frac{\mu_A}{k \mathbb{B} \, T}; \quad \gamma_B = -\frac{\mu_B}{k \mathbb{B} \, T},\tag{22.20}$$

<span id="page-420-1"></span>∂*Eijk*

Substitution of Eqs. (22.16)–(22.18) into Eq. (22.15) gives

d*S* = *k*Bγ*A* d-

β = 1

-

$$p = -\sum_{\langle l|k\rangle} P_{l|k} \frac{\partial \mathcal{E}_l(\mathcal{N}_f^A, \mathcal{N}_{k^*}^B, V)}{\partial V} \tag{22.21}$$

*k*B*T* ; γ*A* = − μ*A k*B*T* ; γ*B* = − μ*B k*B*T* , (22.20) as well as giving the relation ∂*Ei*(*N A j* , *N B*

$$S = -k\mathbf{B}\sum_{ijk} P_{ijk} \left[ -\gamma\mu\mathcal{N}_f^A - \gamma\mu\mathcal{N}_k^B - \beta\mathcal{E}_{ijk} - \ln\mathcal{Z} \right]$$

$$= \frac{1}{T} \left[ -\mu_A(\mathcal{N}^A) - \mu_B(\mathcal{N}^B) + \langle E \rangle + k_\mathcal{B}T\ln\mathcal{Z} \right].\tag{22.22}$$

<span id="page-420-0"></span>

for the pressure.

$$-k_{\rm B}T\ln Z = \langle E \rangle - TS - \mu_{A}\langle N^{A} \rangle - \mu_{B}\langle N^{B} \rangle \equiv K = -pV,\tag{22.23}$$

= 1 *[T](#page-418-0)* −μ*A*-*N A* − μ*B*-*N B*+-*E* + *k*B*T* ln *Z* . (22.22) Thus −*k*B*T* ln *Z* = -*E* − *TS* − μ*A*-*N A* − μ*B*-*N B* ≡ *K* = −*pV*, (22.23) where the Euler equ[ation](#page-417-0) for -*E* has been used in the last step. The Kramers function *K*

### should be regarded as a function of its natural variables *T*, μ*A*, μ*B*, and *V*, on which this ensemble depends. Equation (22.23) is an easy way of calculating the pressure in terms of

ln *Z*, although Eq. (22.21) reveals its physical origin. 22.1.2 Use of the Entropy Formula

The entropy formula Eq. (22.8) can be used practically by inspection to write down the entropy of any ensemble. For the microcanonical ensemble, there is only one constraint, the normalization of the probabilities Eq. (22.1), for which a single subscript can be used to label the quantum states, all having the same energy. Maximization of the entropy with that constraint shows immediately that all of the *Pi* are equal, specifically *Pi* = 1/, where (*E*, *V*, *N* ) is the (1/)ln(1/) =

number of compatible microstates. Therefore, *S*(*E*, *V*, *N* ) = −*k*B *k*B ln , as we know for that ensemble. For the canonical ensemble, there are two constraints, the normalization and the energy constraint, so *S* = −*k*B −β-*E* − ln *Z*(*T*, *V*, *N* ) = -*E*/*T* + *k*B ln *Z*(*T*, *V*, *N* ), where *Z*(*T*, *V*, *N* ) = *i* exp[−β*Ei*(*V*, *N* )] is the canonical partition function. Thus, the Helmholtz free energy *F*(*T*, *V*, *N* ) = −*k*B*T* ln *Z*. We also find *p* = − *i Pi*∂*Ei*(*V*, *N* )/∂*V* as well as μ = *i Pi*∂*Ei*(*V*, *N* )/∂*N* , as in Section 19.1.3.

For the grand canonical ensemble, we have the results of the previous section.

For the pressure ensemble, which was treated in Section 21.5 by another method, we have the normalization constraint, the energy constraint, and a volume constraint of the form *i*,- *Pi*-*V*- = constant, where *V* is the set of volumes on which the energy eigenstates *Ei*(*V*-, *N* ) depend. The entropy is therefore *S* = −*k*B −β-*E* − β*p*-*V* − ln *Zp*(*T*, *p*, *N* ) = -*E*/*T* + (*p*/*T*)-*V* + *k*B ln *Zp*(*T*, *p*, *N* ), where the partition function

$$Z_{\mathcal{P}}(T, p, \mathcal{N}) = \sum_{\ell} \exp(-\beta p V_{\ell}) \sum_{\ell} \exp\left[-\beta \mathcal{E}_{\ell}(V_{\ell}, \mathcal{N})\right]. \tag{22.24}$$

Thus, the Gibbs free energy *G*(*T*, *p*, *N* ) = −*k*B*T* ln *Zp*. We also have μ = *i*,- *Pi*-∂*Ei* (*V*-, *N* )/∂*N* .

For the sake of illustration, we invent another ensemble for which the normalizing function for the probabilities can be related to a Massieu function of the system. The energies of all of the eigenstates in the ensemble will have the same energy *E*, just as for the microcanonical ensemble, so we have the normalization constraint but no additional energy constraint. But we will allow the members of the ensemble to have a set of volumes, *V* as they did for the pressure ensemble. Thus we will have a volume constraint *i*,- *Pi*-*V*-= constant. The probabilities will be given by

$$P_{l\ell} = \exp(-\gamma V_{\ell}) / \Omega^*,\tag{22.25}$$

where the normalizing function[3](#page-421-0)

$$\mathfrak{Q}^*(E,\boldsymbol{\chi},\boldsymbol{\mathcal{N}}) = \sum_{l,\ell} \exp(-\boldsymbol{\chi}\,V_{\ell}) = \sum_{\ell} \mathfrak{Q}(E,V_{\ell},\boldsymbol{\mathcal{N}}) \exp(-\boldsymbol{\chi}\,V_{\ell}).\tag{22.26}$$

Here, γ is the Lagrange multiplier for the volume constraint and (*E*, *V*-, *N* ) is the number of eigenstates having the given energy *E* and particle number *N* for a state with volume *V*-. The probabilities *Pi* depend on *E*, γ , and *N* , so to find γ we allow it to vary at fixed *E* and *N* . In this case, the differential of the entropy is simply

$$\mathbf{dS} = \sum_{l,\ell} k_{\mathbf{B}} \mathbf{y} \, V_{\ell} \frac{\partial P_{l\ell}}{\partial \mathbf{y}} \, \mathbf{d} \boldsymbol{\chi}. \tag{22.27}$$

For the average volume of the system, we have

$$\mathbf{d}\langle V\rangle = \sum_{l,\ell} P_{l\ell} V_{\ell}; \quad \mathbf{d}\langle V\rangle = \sum_{l,\ell} V_{\ell} \frac{\partial P_{l\ell}}{\partial \chi} \,\mathbf{d}\chi. \tag{22.28}$$

At fixed *E* and *N* , d*S* = (*p*/*T*) d-*V*, so

$$\chi = \mathbf{p}/(\mathbf{k}\boxtimes T). \tag{22.29}$$

<span id="page-421-0"></span><sup>3</sup>This normalizing function is the partition function for this ensemble but we give it a different notation because of its close association with the microcanonical ensemble, as clarified in the next section.

The entropy is therefore

$$S = -k_{\rm B} \left[ -\beta p(V) - \ln \mathcal{Z}(T, p, \mathcal{N}) \right] = (p/T)(V) + k_{\rm B} \ln \mathcal{Q}^*(E, p/T, \mathcal{N}).\tag{22.30}$$

Thus

$$\mathbf{k}_{\rm B} \ln \mathfrak{Q}^*(E, \mathbf{p}/T, \mathcal{N}) = \mathbf{S} - (\mathbf{p}/T)(V) \equiv \mathbf{M}_2(E, \mathbf{p}/V, \mathcal{N}),\tag{22.31}$$

which is a Legendre transform of the entropy, ordinarily called a Massieu function. From the differential of *S*, we find

$$\mathbf{d}M_2(E, \mathbf{p}/V, \mathcal{N}) = (1/T)\,\mathrm{d}E - (V)\,\mathrm{d}(\mathbf{p}/T) - (\mu/T)\,\mathrm{d}\mathcal{N}.\tag{22.32}$$

Thus from the partial derivatives of ∗(*E*, *p*/*T*, *N* ), we are able to compute 1/*T*, −-*V*, and −(μ/*T*).

### 22.2 Summation over Energy Levels

As pointed out by Hill [64, p. 30], the partition function for all of these ensembles can be written as sums over the extensive variables that are needed to characterize the microcanonical ensemble provided that we sum over energy levels (instead of quantum states) with an appropriate degeneracy factor for the energy eigenstates. For a single component system, that factor is (*E*, *V*, *N* ) which is the number of eigenstates having energy *E* for a system with volume *V* and particle number *N* .

For the microcanonical ensemble, there is no summation and one has simply

<span id="page-422-1"></span>
$$\ln \Omega(E, V, \mathcal{N}) = \mathcal{S}(E, V, \mathcal{N}) / k_{\mathcal{B}}.\tag{22.33}$$

For the canonical ensemble,

$$\ln \sum_{E} \Omega(E, V, \mathcal{N}) \exp(-\beta E) = -\beta F(\beta, V, \mathcal{N}).\tag{22.34}$$

For the grand canonical ensemble

$$\ln \sum_{E, \mathcal{N}} \Omega(E, V, \mathcal{N}) \exp(-\beta E + \beta \mu \mathcal{N}) = -\beta K(\beta, V, \mu). \tag{22.35}$$

For the pressure ensemble

<span id="page-422-2"></span>
$$\ln \sum_{E,V} \mathfrak{Q}(E, V, \mathcal{N}) \exp(-\beta E - \beta pV) = -\beta G(\beta, p, \mathcal{N}).\tag{22.36}$$

For the ensemble related to the Massieu function discussed above,

<span id="page-422-0"></span>
$$\ln \sum_{V} \Omega(E, V, \mathcal{N}) \exp(-\beta pV) = M_2(E, p/T, \mathcal{N}) / k_{\mathcal{B}}.\tag{22.37}$$

Note that the form of the right-hand sides of Eq. [(22.37)](#page-422-0) and Eq. [(22.33)](#page-422-1) depend on *E* which is not summed over. In all of these cases, one could use distribution functions for any of the variables that are summed over and then integrate over those variables. This is necessary if *V* is to be treated as a continuous variable in Eqs. [(22.36)](#page-422-2) and [(22.37)](#page-422-0). Every ensemble involves a weighted sum of entropies of a microcanonical ensemble. The extensive variables that are summed over are the ones that have dispersion in the respective ensemble.

This page intentionally left blank

23

# Unified Treatment of Ideal Fermi, Bose, and Classical Gases

In Chapter 21, we introduced the grand canonical ensemble which applies to a system having a fixed temperature and a fixed chemical potential, but not a fixed energy or a fixed number of particles. In Section 21.2.5, we discussed a unified treatment of orbitals of ideal Fermi, Bose, and classical gases for which the grand partition function *Z* factored and could be written formally in the form

$$\mathcal{Z} = \prod_{\varepsilon} \left[ 1 + a \lambda \exp(-\beta \varepsilon) \right]^{1/a},\tag{23.1}$$

where the product is over all orbital[s1](#page-425-0) having energy ε, λ = exp(βμ) is the absolute activity with chemical potential μ, and

$$a = \begin{cases} 1 & \text{fermions} \\ -1 & \text{bosons} \\ 0 & \text{classical} \end{cases} \tag{23.2}$$

This yields

<span id="page-425-3"></span>
$$\ln Z = \frac{1}{a} \sum_{\varepsilon} \ln \left[ 1 + a \lambda \exp(-\beta \varepsilon) \right]. \tag{23.3}$$

The classical case must be interpreted as a limit *a* → 0 to give

<span id="page-425-4"></span>
$$
\lambda \ln \mathcal{Z} = \sum_{\varepsilon} \lambda \exp(-\beta \varepsilon) = \lambda \,\, z,\tag{23.4}
$$

where *z* is the canonical partition function of a single particle. From Eq. (21.32) with *q* = ln *Z*, we obtain

<span id="page-425-1"></span>
$$
\langle \mathcal{N} \rangle = \lambda \left( \frac{\partial \mathcal{q}}{\partial \lambda} \right)_{\beta, V} = \sum_{\varepsilon} f(\varepsilon, a) \tag{23.5}
$$

and

<span id="page-425-2"></span>
$$U = -\left(\frac{\partial \boldsymbol{q}}{\partial \boldsymbol{\beta}}\right)_{\boldsymbol{\lambda}, V} = \sum_{\varepsilon} \varepsilon f(\boldsymbol{\varepsilon}, \boldsymbol{a}),\tag{23.6}$$

<span id="page-425-0"></span>1As explained in Section 21.2, an orbital is a quantum state of a particle specified by all quantum numbers of its spatial wave function and its spin, which we incorporate in the single symbol ε which is also the energy of that state, usually degenerate.

where

$$f(s, a) := \frac{1}{\lambda^{-1} \exp(\beta \varepsilon) + a} = \frac{1}{\exp[\beta(s - \mu)] + a}. \tag{23.7}$$

Note that *f* (ε, *a*) agrees with Eq. (21.88) for *a* = 1 and Eq. (21.92) for *a* = −1. From Eq. (21.38) we also obtain

<span id="page-426-0"></span>
$$\frac{pV}{k_{\rm B}T} = \frac{1}{a} \sum_{\varepsilon} \ln\left[1 + a\lambda \exp(-\beta\varepsilon)\right]. \tag{23.8}$$

### 23.1 Integral Formulae

If the temperature is not too low, the sums in Eqs. [(23.5)](#page-425-1), [(23.6)](#page-425-2), and [(23.8)](#page-426-0) can be converted to integrals because the spacings of the energy levels will be small compared with *k*B*T* and ε will be quasi-continuous. However, conversion to an integral is insufficient for bosons below the condensation temperature, which we discuss in the next chapter. If every state has a degeneracy *g*0 due to spin, then ε = *g*0 ε, where the primed sum is over states with spin degeneracy ignored. For a free particle in a rectangular box of dimensions *H*, *K*, *L*, these states can be expressed in terms of the wave vector **k** given by Eq. (16.51). If one of the integers in that expression, say *nx*, changes by unity, the *x* component of **k** changes by *kx* = 2π/*H*, and similarly the *y* and *z* components change by *ky* = 2π/*K* and *kz* = 2π/*L*. Thus we have

$$
\sum_{\varepsilon} = \text{go} \sum_{\varepsilon}' = \text{go} \sum_{\mathbf{k}} = \text{go} \sum_{k_{\mathbf{k}}} \sum_{k_{\mathbf{y}}} \sum_{k_{\mathbf{z}}} = \text{go} \frac{H \mathbf{K} \mathbf{L}}{(2\pi)^3} \sum_{k_{\mathbf{x}}} \sum_{k_{\mathbf{y}}} \sum_{k_{\mathbf{z}}} \Delta k_{\mathbf{x}} \Delta k_{\mathbf{y}} \Delta k_{\mathbf{z}}.\tag{23.9}
$$

If we apply this to any nearly continuous function *F*(**k**) that does not vary significantly over the **k**-space volume element *kxkykz*, we can replace summation by integration and obtain[2](#page-426-1)

$$\frac{H\mathcal{KL}}{(2\pi)^3} \sum_{k_\mathcal{x}} \sum_{k_\mathcal{y}} \sum_{k_\mathcal{z}} \Delta k_\mathcal{x} \Delta k_\mathcal{y} \Delta k_\mathcal{z} \mathcal{F}(\mathbf{k}) \to \frac{V}{(2\pi)^3} \int \mathbf{d}^3 k \, \mathcal{F}(\mathbf{k}),\tag{23.10}$$

where *HKL* has been replaced by the volume *V*. Furthermore, if *F*(**k**) depends only on the magnitude of **k**, as it would for an integrand of the form *G*(ε(|**k**|)), where ε = *h*¯ 2|**k**| 2/2*m*, we would have

$$\frac{V}{(2\pi)^3} \int \mathrm{d}^3 k \mathcal{G}(\varepsilon(|\mathbf{k}|)) = \frac{V}{(2\pi)^3} 4\pi \int_0^\infty \mathrm{k}^2 \, \mathrm{d}k \, \mathcal{G}(\varepsilon(|\mathbf{k}|)) = \frac{V}{2\pi^2} \int_0^\infty \mathcal{G}(\varepsilon) \, \mathrm{k}^2 \frac{\mathrm{d}k}{\mathrm{d}\varepsilon} \, \mathrm{d}\varepsilon. \tag{23.11}$$

Since (1/2π2)*k*2d*k*/dε = (2/π1/2)(*m*/2π*h*¯ 2)3/2ε1/2, we finally obtain

$$\sum_{\varepsilon} \mathcal{G}(\varepsilon(|\mathbf{k}|)) = \mathbf{g}_0 V n_\mathbf{Q}(T) \frac{1}{\Gamma(3/2)} \int_0^\infty \mathcal{G}(\varepsilon) \, \boldsymbol{\beta}^{3/2} \boldsymbol{\varepsilon}^{1/2} \, \mathrm{d}\varepsilon,\tag{23.12}$$

where *n*Q(*T*) = (*mk*B*T*/2π*h*¯ 2)3/2 is the quantum concentration and the gamma function (3/2) = (1/2)π1/2 has been introduced to unify subsequent notation.

<span id="page-426-1"></span>2This would not be true for thin samples. For instance, if *H* were small, then *kx* would be large.

<span id="page-427-1"></span><span id="page-427-0"></span>
$$n = \text{g}_{\text{0}} n_{\text{Q}}(T) \, h_{\text{3}/2}(\lambda, a) \tag{23.13}$$

written in the forms

freedom so *g*0 = 1.

1 *a*  ∞ 0

$$u_{\rm V} = (3/2)k_{\rm B}T \, \mathbf{g}_{\rm 0} n_{\rm Q}(T) \, h_{5/2}(\lambda, a), \tag{23.14}$$

$$h_v(\lambda, a) := \frac{1}{\Gamma(\nu)} \int_0^\infty \frac{u^{\nu - 1} \, \mathrm{d}u}{\lambda^{-1} \, \mathrm{e}^u + a}. \tag{23.15}$$

and *u*V = (3/2)*k*B*T g*0*n*Q(*T*) *h*5/2(λ, *a*), (23.14) where *n* = *N* /*V* is the average number of particles per unit volume, *u*V = *[U](#page-426-0)*/*V* is the energy per unit volume, and the function *h*ν (λ, *a*) := 1 (ν)  ∞ *u*ν−1 d*u* . (23.15)

0 λ−1 e*u* + *a* Equation (23.13) determines λ, or equivalently the chemical potential μ, as a function of *n* and *T* which can then be substituted into Eq. (23.14) to determine *u*V. For the classical gas,

$$\frac{p}{k\mathbb{B}} = \frac{1}{a}\mathbf{g}_0 n_\mathbb{Q}(T) \frac{1}{\Gamma(3/2)} \int_0^\infty \ln(1 + a\lambda \,\mathbf{e}^{-\mu}) \mu^{1/2} \,\mathrm{d}\mu. \tag{23.16}$$

Before exploring the behavior of the functions *h*ν (λ, *a*), we return to Eq. (23.8) for the pressure and convert the sum to an integral to obtain

<span id="page-427-2"></span>
$$\frac{1}{a} \int_0^\infty \ln(1 + a\lambda \operatorname{e}^{-\mu}) u^{1/2} \operatorname{d}u = \left. \frac{2}{3a} \mu^{3/2} \ln(1 + a\lambda \operatorname{e}^{-\mu}) \right|_0^\infty + \frac{2}{3} \int_0^\infty \frac{\mu^{3/2} \operatorname{d}u}{\lambda^{-1} \operatorname{e}^\mu + a}. \tag{23.17}$$

∞

Then we use *u*1/2 = (2/3)(d/d*u*)*u*3/2 to integrate by parts and obtain

$$p = k_{\rm B} T \text{g}_{\rm B} n_{\rm Q}(T) h_{5/2}(\lambda, a) = (2/3)\mu_{\rm V} \tag{23.18}$$

The integrated part vanishes at both limits and we obtain *p* = *k*B*Tg*0*n*Q(*T*)*h*5/2(λ, *a*) = (2/3)*u*V, (23.18)

*V*,μ

$$
\ln \mathcal{Z} = \text{g}_0 V \text{n}_\text{Q}(T) h_{5/2}(\lambda, a). \tag{23.19}
$$

parts can be used to evaluate the partition function, resulting in

*S k*B

$$K = -k_{\rm B} T \text{g}_{0} V n_{\rm Q}(T) h_{5/2}(\lambda, a) = -(2/3)U = -pV \tag{23.20}$$

Therefore, the Kramers potential is

as expected.

This results in

*K* = −*k*B*Tg*0*Vn*Q(*T*)*h*5/2(λ, *a*) = −(2/3)*U* = −*pV* (23.20)

*S k*B

$$\frac{S}{k_{\text{B}}} = \ln Z - \beta \left(\frac{\partial \ln Z}{\partial \beta}\right)_{V,\mu} \,. \tag{23.21}$$
 This results in

$$\frac{\mathcal{S}}{k_{\rm B}} = (5/2) V \mathbf{g}_0 n_{\rm Q}(T) h_{5/2}(\lambda, a) - \beta V \mathbf{g}_0 n_{\rm Q} \left( \frac{\partial h_{5/2}(\lambda, a)}{\partial \boldsymbol{\beta}} \right)_{V, \mu},\tag{23.22}$$

$$\frac{S}{k_{\rm B}V\mathbf{g}_{0}n_{\rm Q}(T)} = (5/2)h_{5/2}(\lambda, a) - \beta\mu\lambda \frac{\partial h_{5/2}(\lambda, a)}{\partial \lambda}.\tag{23.23}$$

408 THERMAL PHYSICS

$$S = k_{\rm B} V \mathbf{g}_{\rm b} n_{\rm Q}(T) \left[ (5/2) h_{5/2}(\lambda, a) - \ln \lambda \, h_{3/2}(\lambda, a) \right]. \tag{23.24}$$

*S k*B*Vg*0*n*Q(*T*) = (5/2)*h*5/2(λ, *a*) − βμλ ∂*h*5/2(λ, *a*) ∂λ . (23.23)

In the next section, we will show that λ∂*h*5/2(λ, *a*)/∂λ = *h*3/2(λ, *a*). Then noting that βμ = ln λ, we obtain

(5/2)*h*5/2(λ, *a*) − ln λ *h*3/2(λ, *a*)

### Alternatively we could compute the entropy from *S*/*k*B = β(*U* − *K* − μ*N* ), which leads to the same answer.

*S* = *k*B*Vg*0*n*Q(*T*)

λ

λ

For fermions, we will have to examine λ > 1 separately.

<span id="page-428-0"></span>

Thus, it remains to determine the behavior of the functions *h*ν (λ, *a*) which we take up in the next section.

$$
\lambda \frac{\partial h_{\boldsymbol{v}}(\lambda, \boldsymbol{a})}{\partial \lambda} = h_{\boldsymbol{v}-1}(\lambda, \boldsymbol{a}); \quad \boldsymbol{v} > 1. \tag{23.25}
$$

. (23.24)

23.2 The Functions *h*ν(λ, *a*)

We first derive the relation

$$
\lambda \frac{\partial h_{\nu}(\lambda, a)}{\partial \lambda} = \lambda \frac{\partial}{\partial \lambda} \frac{1}{\Gamma(\nu)} \int_{0}^{\infty} \frac{u^{\nu - 1} \, \mathrm{d}u}{\lambda^{-1} \, \mathrm{e}^{u} + a} \tag{23.26}
$$

We begin with

$$
\lambda \frac{\partial}{\partial \lambda} \frac{1}{\lambda^{-1} \mathbf{e}^{\mu} + a} = -\frac{\partial}{\partial \mu} \frac{1}{\lambda^{-1} \mathbf{e}^{\mu} + a}. \tag{23.27}
$$

and note that

$$\lambda \frac{\partial h_{\nu}(\lambda, a)}{\partial \lambda} = -\frac{1}{\Gamma(\nu)} \frac{u^{\nu - 1}}{\lambda^{-1} \mathbf{e}^{u} + a} \Big|_{0}^{\infty} + \frac{\nu - 1}{\Gamma(\nu)} \int_{0}^{\infty} \frac{u^{\nu - 2} \, \mathrm{d}u}{\lambda^{-1} \mathbf{e}^{u} + a}. \tag{23.28}$$

λ ∂*h*ν (λ, *a*) ∂λ = − 1 (ν) *u*ν−1 λ−1 e*u* + *a* ∞ 0 + ν − 1 (ν)  ∞ 0 *u*ν−2 d*u* λ−1 e*u* + *a* . (23.28)

The integrated term vanishes at both limits provided that ν > 1. In the second term, we use (ν) = (ν − 1)(ν − 1), resulting in Eq. (23.25). For 0 ≤ λ < 1, we can obtain series expansions for *h*ν(λ, *a*). Since λ = eβμ and βμ is real, we certainly have λ ≥ 0. Returning to Eqs. (23.5) and (23.7), we see that*f* (ε, *a*) must be finite and positive for all values of ε. If we examine the ground state ε = 0 for bosons, we see that *f* (0, −1) = λ/(1 − λ), which means that λ < 1, or equivalently μ < 0. For fermions, *f* (0, 1) = λ/(1 + λ) so no such restriction exists and 0 ≤ λ < ∞. Therefore, our series expansion will cover the range of 0 ≤ λ < 1 but we will have to examine λ = 1 carefully.

$$h_{\boldsymbol{\nu}}(\lambda, a) = \frac{1}{\Gamma(\boldsymbol{\nu})} \int_0^\infty \frac{u^{\boldsymbol{\nu} - 1} \lambda \operatorname{e}^{-u} \operatorname{d}u}{1 + a\lambda \operatorname{e}^{-u}} = \frac{1}{\Gamma(\boldsymbol{\nu})} \left(\frac{1}{-a}\right) \sum_{n=1}^\infty (-a\lambda)^n \int_0^\infty u^{\boldsymbol{\nu} - 1} \operatorname{e}^{-nu} \operatorname{d}u$$

$$= \frac{1}{\Gamma(\boldsymbol{\nu})} \left(\frac{1}{-a}\right) \sum_{n=1}^\infty \frac{(-a\lambda)^n}{n^v} \int_0^\infty v^{v-1} \operatorname{e}^{-v} \operatorname{d}v = \left(\frac{1}{-a}\right) \sum_{n=1}^\infty \frac{(-a\lambda)^n}{n^v}.\tag{23.29}$$

 1 −*a*

From Eq. (23.15) we obtain

$$\mathbf{g}_{\boldsymbol{\nu}}(\boldsymbol{\lambda}) := h_{\boldsymbol{\nu}}(\boldsymbol{\lambda}, -1) = \boldsymbol{\lambda} + \frac{\boldsymbol{\lambda}^2}{2^{\boldsymbol{\nu}}} + \frac{\boldsymbol{\lambda}^3}{3^{\boldsymbol{\nu}}} + \dots = \sum_{n=1}^{\infty} \frac{\boldsymbol{\lambda}^n}{n^{\boldsymbol{\nu}}} \tag{23.30}$$

∞

(−*a*λ)*n*

*n*ν . (23.29)

= 1 (ν) 1

*h*ν (λ, *a*) = 1

only quote the first few terms [8, p. 510]:

0

−*a*

∞

*g*ν (λ) := *h*ν (λ, −1) = λ +

$$f_{\boldsymbol{v}}(\lambda) := h_{\boldsymbol{v}}(\lambda, 1) = \lambda - \frac{\lambda^2}{2^{\boldsymbol{v}}} + \frac{\lambda^3}{3^{\boldsymbol{v}}} + \dots = \sum_{n=1}^{\infty} \frac{\lambda^n}{n^{\boldsymbol{v}}} (-1)^{n+1}. \tag{23.31}$$
 
$$\text{so } h_{\boldsymbol{v}}(\boldsymbol{\cdot}, 0) \quad \text{y for } \boldsymbol{\cdot}, \dots \text{ 0.os mentioned nonvariacoly}$$

2ν + *n*=1 *n*ν (23.30)

 ∞ 0

*v*ν−1 e−*v* d*v* =

and for fermions,

(−*a*λ)*n n*ν

$$h_{\mathbb{V}}(1, -1) = \mathbb{g}_{\mathbb{V}}(1) = 1 + \frac{1}{2^{\mathbb{v}}} + \frac{1}{3^{\mathbb{v}}} + \dots = \sum_{n=1}^{\infty} \frac{1}{n^{\mathbb{v}}} = \zeta(\mathbb{v}),\tag{23.32}$$

For classical particles, *h*ν(λ, 0) = λ for ν > 0 as mentioned previously. The value λ = 1 must be handled wit[h care.](#page-428-0) It turns out that

For bosons,

$$\zeta(\nu) := \sum_{k=1}^{\infty} k^{-\nu}, \quad \Re \nu > 1,\tag{23.33}$$

where ζ (ν) := ∞ *k*=1 *k*−ν , ν > 1, (23.33) is [the](#page-430-0) [Riemann](#page-430-0) zeta function. For ν = 1, this is the well-known harmonic series and

$$h_{\boldsymbol{v}}(1,1) = f_{\boldsymbol{v}}(1) = 1 - \frac{1}{2^{\boldsymbol{v}}} + \frac{1}{3^{\boldsymbol{v}}} + \dots = \sum_{n=1}^{\infty} \frac{1}{n^{\boldsymbol{v}}} (-1)^{n+1},\tag{23.34}$$

*h*ν (1, 1) = *f*ν (1) = 1 − 1 2ν + 1 3ν +··· = ∞ *n*=1 1 *n*ν (−1) *n*+1, (23.34)

which is an alternating series with terms of decreasing size for positive ν. In fact, *f*ν (1) = (1 − 21−ν )ζ (ν) for ν > 1, as the reader may verify by writing out the series.

Figure 23–1 shows some plots of *h*ν(λ, *a*) as a function of λ, including values of λ > 1 which we have not yet discussed for fermions. For fermions and λ > 1, one can either compute the integrals for *h*ν (λ, 1) = *f*ν (λ) numerically or resort to an asymptotic expansion that is valid for large λ. This expansion, known as the **Sommerfeld expansion** [65], is actually a series in (ln λ)−1 = (βμ)−1 = *k*B*T*/μ and is useful at high temperatures to treat degenerate Fermi gases. For now we

<span id="page-430-0"></span>![](_page_430_Figure_1.jpeg)

1 1.5 hν(λ,a)h5/2(λ,*−*1) h3/2(λ,1) h5/2(λ,1)

$$f_{\boldsymbol{\nu}}(\boldsymbol{\lambda}) \sim \frac{(\boldsymbol{\ln}\boldsymbol{\lambda})^{\boldsymbol{\nu}}}{\Gamma(\boldsymbol{\nu}+1)} \left[ 1 + \boldsymbol{\nu}(\boldsymbol{\nu}-1) \frac{\pi^2}{6} \left( \frac{1}{\ln \boldsymbol{\lambda}} \right)^2 + \boldsymbol{\nu}(\boldsymbol{\nu}-1)(\boldsymbol{\nu}-2)(\boldsymbol{\nu}-3) \frac{7\pi^4}{360} \left( \frac{1}{\ln \boldsymbol{\lambda}} \right)^4 + \dotsb \right]. \tag{23.35}$$

plots merge for λ 1 which is the classical limit. The upper two curves are for bosons and the lower two are for fermions. The middle line is for the classical case *a* = 0.

+ ν(ν − 1)(ν − 2)(ν − 3)

### In Chapter 25, we shall examine a related expansion in more detail to treat the free-

electron model of metals. 23.3 Virial Expansions for Ideal Fermi and Bose Gases

 1

∞

We digress briefly to discuss so-called virial expansions which are series expansions for

<span id="page-430-1"></span>1 + ν(ν − 1)

π2 [6](#page-427-2)

 1 ln λ 2

0.5

$$\mathbf{y} := \frac{p}{\mathbf{g}_0 n_{\mathbf{Q}} k_{\mathbf{B}} T} = h \mathbf{\bar{s}}_{7} \boldsymbol{\omega}(\lambda, \mathbf{a}) = \left(\frac{1}{-a}\right) \sum_{n=1}^{\infty} \frac{(-a\lambda)^n}{n^{5/2}} \tag{23.36}$$

(−*a*λ)*n*

(−*a*λ)*n*

7π4 360 1 ln λ 4 +···

. (23.35)

*y* := *p*

so Eq. (23.38) becomes simply

and Eq. (23.13) becomes

*f*ν (λ) ∼ (ln λ)ν

(ν + [1](#page-427-1))

<span id="page-430-2"></span>
$$\mathbf{x} := \frac{n}{\mathbf{g}_0 n_{\mathbf{Q}}} = h_{\mathbf{3}/2}(\lambda, a) = \left(\frac{1}{-a}\right) \sum_{n=1}^{\infty} \frac{(-a\lambda)^n}{n^{3/2}}.\tag{23.37}$$
 
$$\text{Eq. (23.37) we obtain}$$

*x* := *n g*0*n*Q = *h*3/2(λ, *a*) = 1 −*a*

*y*

$$\frac{y}{x} = \frac{p}{nk_{\rm B}T} = \frac{h_{5/2}(\lambda, a)}{h_{3/2}(\lambda, a)}.\tag{23.38}$$

*n*3/2 . (23.37)

*x* = *p nk*B*T* = *h*5/2(λ, *a*) *h*3/2(λ, *a*) . (23.38) For a given value of *a*, *p*/(*nk*B*T*) depends only on λ and hence only on *x*. We can then invert the series in Eq. (23.37) by successive approximations and obtain a series expansion for *p*/(*nk*B*T*) in terms of *x*. For the classical case, *a* = 0, we have *h*5/2(λ, 0) = *h*3/2(λ, 0) = λ,

$$\frac{p}{mk\mathbb{B}T} = 1.\tag{23.39}$$

*p*

4

accurate to within about 1% for fermions and about 5% for bosons even up to λ = 1.

p/(nkBT)

plotting routine. Amazingly, the deviations from linearity are only a few percent.

$$\mathbf{y} = \lambda - a\lambda^2/2^{5/2} + \cdots \tag{23.40}$$

and

*nk*B*T* = 1. (23.39)

This turns out to be the leading term for *a* = 0 for sufficiently small λ. We illustrate the expansion procedure by calculating the next term in the series. For the Fermi and Bose gases, we have, to order λ2, the expressions *y* = λ − *a*λ2/25/2 +··· (23.40)

<span id="page-431-0"></span>
$$\frac{p}{\infty} = \frac{p}{nk_{\text{B}}T} = 1 - ax\left(-\frac{1}{4\sqrt{2}}\right) + \dots = 1 - ax(-0.17678) + \dots \dots \tag{23.42}$$

To lowest order, we have λ = *x* which we substitute into the second-order term in Eq. (23.41) to obtain λ = *x* + *ax*2/23/2 + ··· . Substitution into Eq. (23.40) gives *y* = *x* + *ax*2/23/2 − *ax*2/25/2 ··· so to this order we have *y x* = *p nk*B*T* = 1 − *ax* − 1 √2 +···= 1 − *ax*(−0.17678) +··· . (23.42)

$$\frac{p}{nk_{\rm B}T} = \sum_{\ell=1}^{\infty} (-a)^{\ell-1} a_{\ell} \, x^{\ell-1},\tag{23.43}$$

<span id="page-431-1"></span>and a negative correction for bosons. This iteration process can be carried out to higher order and results in a virial expansion of the form (see [8, p. 160]) *p nk*B*T* = ∞ =1 (−*a*) −1*a x*−1, (23.43) √2) = −0.17678, *a*3 =

where the first few virial coefficients are *a*1 = 1, *a*2 = −1/(4 −[2/(9 √3) − 1/8]=−0.00330, and *a*4 = −[3/32 + 5/(32√2) − 1/(2 √6)]=−0.00011. It turns out that the higher order terms in the series are not very important and Eq. (23.42) is

![](_page_431_Figure_13.jpeg)

0.5 **FIGURE 23–2** Plot of *p*/(*nk*B*T*) versus *x* = *n*/(*g*0*n*Q) for ideal Fermi and Bose gases up to values that correspond to λ = 1. This plot was constructed by evaluation of the functions *h*ν (λ, *a*) numerically and then using a parametric

412 THERMAL PHYSICS

### the functions *h*ν(λ, *a*) numerically as functions of λ and then using the parametric p[lotting](#page-427-1) routine in MathematicaR . The plot agrees extremely well with the series expansion up to

we have

Eq. (23.13) to obtain

0 = 3

*Vk*B 1

<span id="page-432-0"></span>*n*/(*g*0*n*Q) = 0.5. By using values of λ > 1 it can be extended to larger values than shown for fermions and deviates only slightly from a straight line. Therefore, Eq. (23.42) suffices approximately over a considerable range of *x*. We shall see later that Bose condensation sets in very near to λ = 1, in agreement with the limited range of the plot for bosons.

$$\mathbf{C}_{V} = \frac{15}{4} V \mathbf{k}_{\mathbf{B}} \mathbf{g}_{0} n_{\mathbf{Q}} h_{5/2}(\lambda, a) + \frac{3}{2} V \mathbf{k}_{\mathbf{B}} T \mathbf{g}_{0} n_{\mathbf{Q}} \frac{\partial h_{5/2}(\lambda, a)}{\partial \lambda} \left(\frac{\partial \lambda}{\partial T}\right)_{V, \langle \mathcal{N} \rangle},\tag{23.44}$$

We can compute the heat capacity at constant volume by partial differentiation of the internal energy *U* [with](#page-428-0) [re](#page-428-0)spect to *T* with *V* and *N* held constant. From Eq. (23.14)

$$0 = \frac{3}{2} V \mathbf{k}_{\rm B} \frac{1}{T} \mathbf{g}_{0} n_{\rm Q} h_{3/2}(\lambda, a) + V \mathbf{k}_{\rm B} T \mathbf{g}_{0} n_{\rm Q} \frac{\partial h_{3/2}(\lambda, a)}{\partial \lambda} \left(\frac{\partial \lambda}{\partial T}\right)_{V, \langle \lambda \rangle} \,. \tag{23.45}$$

where we have recalled that *n*Q ∝ *T*3/2. To calculate (∂λ/∂*T*)*V*,*N* we differentiate

$$\left(\frac{\partial\lambda}{\partial T}\right)_{V,\langle\lambda\rangle} = -\frac{3}{2}\frac{\lambda}{T}\frac{h_{3/2}(\lambda,a)}{h_{1/2}(\lambda,a)}.\tag{23.46}$$

2 *V*,*N* Then after using Eq. (23.25) we solve for the required derivative to obtain

<span id="page-432-1"></span>
$$C_V = \frac{3}{2} V k_{\rm B} \mathbf{g}_0 n_{\rm Q} \left\{ \frac{5}{2} h_{5/2}(\lambda, a) - \frac{3}{2} \frac{\left[ h_{3/2}(\lambda, a) \right]^2}{h_{1/2}(\lambda, a)} \right\}. \tag{23.47}$$

By substituting into Eq. (23.44) and again using Eq. (23.25), we obtain

*CV* = 3 2

$$C_V = \frac{3}{2} \langle \mathcal{N} \rangle k_\mathcal{B} \left\{ \frac{5}{2} \frac{h_{5/2}(\lambda, a)}{h_{3/2}(\lambda, a)} - \frac{3}{2} \frac{h_{3/2}(\lambda, a)}{h_{1/2}(\lambda, a)} \right\}. \tag{23.48}$$

*CV* = 3 2 *N k*B 5 2 *h*5/2(λ, *a*) *h*3/2(λ, *a*) − 3 2 *h*3/2(λ, *a*) *h*1/2(λ, *a*) . (23.48)

We caution, however, that Eqs. (23.4), (23.13), and (23.48) are not valid for bosons for temperatures below the Bose condensation temperature that we treat in the next chapter.

24 Bose Condensation An ideal Bose fluid is one composed of noninteracting bosons, which are particles having integral spin *s* = 0, 1, 2, ... and orbitals ε. The partition function for a single orbital is

given by Eq. (21.91) and the average number of particles occupying that orbital is given by Eq. (21.92). The average number of particles in the system is given by Eq. (21.93) but ordinarily this number is specified and Eq. (21.93) is used to find the absolute activity λ or, equivalently, the chemical potential μ. If we take the lowest energy state to be ε = 0, we see for systems having a finite number of bosons that λ < 1 (μ must be negative) to prevent *f*BE(ε) from becoming infinite. In Chapter 23, we gave a unified treatment of ideal Fermi, Bose, and classical gases. This treatment is applicable to bosons, for which *a* < 1, provided that the temperature is above the so-called condensation temperature *T*c, a critical temperature to be defined in

the next section. For *T* < *T*c, λ becomes very nearly equal to one and many of the results in Chapter 23 for bosons require modification. In some cases, it will no longer be possible

to the excited states.

which we now write in the form

$$f_{\text{BE}}(\varepsilon) := f(\varepsilon, -1) = \frac{1}{\lambda^{-1} \exp(\beta \varepsilon) - 1} = \frac{1}{\exp[\beta(\varepsilon - \mu)] - 1};\tag{24.1}$$

$$\mathbf{g}_{\nu}(\boldsymbol{\varepsilon}) := h_{\nu}(\boldsymbol{\varepsilon}, -1) = \frac{1}{\Gamma(\nu)} \int_{0}^{\infty} \frac{\boldsymbol{u}^{\nu - 1} \, \mathrm{d} \boldsymbol{u}}{\lambda^{-1} \, \mathrm{e}^{\boldsymbol{u}} - 1} \,. \tag{24.2}$$

<span id="page-433-0"></span>*f*BE(ε) := *f* (ε, −1) = 1 λ−1 exp(βε) − 1 = 1 exp[β(ε − μ)] − 1 ; (24.1) *g*ν (ε) := *h*ν (ε, −1) = 1 (ν) - ∞ 0 *u*ν−1 d*u* λ−1 e*u* − 1 . (24.2)

Hereafter in this chapter, we will also write *N* instead of *N* with the understanding

the function *g*3/2(λ) which is plotted in Figure 24–1. We see that *g*3/2(λ) is a monotonically

### that the average number of particles will be specified and λ (or equivalently μ) will be determined consistently as a function of particle density and temperature.

24.1 Bosons at Low Temperatures

$$\mathcal{N} = V \mathbf{g}_{\mathbf{0}} n_{\mathbf{Q}}(T) \mathbf{g}_{3/2}(\lambda),\tag{24.3}$$

*N* = *Vg*0*n*Q(*T*)*g*3/2(λ), (24.3) where we have written *n*Q(*T*) for the quantum concentration to emphasize its dependence on temperature. Here, *g*0 = 2*s* + 1 accounts for degeneracy due to spin *s* that must be an integer for bosons. The problem with this equation becomes evident when we examine

<span id="page-434-2"></span><span id="page-434-0"></span>0.5

particles

the ground state.

![](_page_434_Figure_1.jpeg)

1 1.5 gν(λ) 1.34149

ν = 5/2

0.2 0.4 [0.6](#page-434-0) 0.8 1 λ

$$\mathcal{N} = \mathsf{Vg}_{\mathsf{0}} \mathsf{n}_{\mathsf{Q}}(T) \mathsf{g}_{\mathsf{3}/2}(1). \tag{24.4}$$

increasing function of λ which has its maximum value at λ = 1, namely *g*3/2(1) = 2.61238. Inserting this value int[o Eq.](#page-433-0) (24.3) gives

$$n = \text{g}_0 \left(\frac{mk_\text{B}T_\text{c}}{2\pi\hbar^2}\right)^{3/2} \text{g}_{3/2}(\text{l}).\tag{24.5}$$

for a given value of *n* = *N* /*V*, there exists a critical temperature *T*c below which all particles cannot be accommodated. This temperature satisfies

*n* = *g*0 *mk*B*T*c 2π*h*¯ 2 3/2 *g*3/2(1). (24.5) This presents a problem because we must accommodate all particles, even at low temperatures! For *T* < *T*c, Eq. (24.3) cannot be correct and must be modified.

<span id="page-434-1"></span>
$$\mathcal{N} = \sum_{\epsilon} \frac{1}{\lambda^{-1} \exp(\beta \varepsilon) - 1}. \tag{24.6}$$

the form *N* = [1](#page-434-1) λ−1 exp(βε) − 1 . [(24.6)](#page-434-0)

$$\mathcal{N}\mathbf{\hat{o}} = \mathbf{g}\mathbf{\hat{o}}\frac{1}{\lambda^{-1} - 1} = \mathbf{g}\mathbf{\hat{o}}\frac{\lambda}{1 - \lambda}.\tag{24.7}$$

*N*0 = *g*0 1 λ−1 − 1 = *g*0 λ 1 − λ . (24.7) As λ → 1 this term becomes infinite, so for λ very slightly less than 1 it cannot be ignored. If the sum in Eq. (24.7) were converted to an integral, as was done to obtain Eq. (24.4), that integral would be unaffected by leaving out a single point, so it would not properly include the nearly singular term given by Eq. (24.7). Thus, the right-hand side of Eq. (24.4) accounts only for the number *N*e of particles in the excited states. This is no problem for *T* > *T*c but for *T* < *T*c we must account explicitly for particles that have "condensed" into

<span id="page-435-1"></span>*N* = *N*0 + *N*e = *g*0

<span id="page-435-0"></span>
$$\mathcal{N} = \mathcal{N}_0 + \mathcal{N}_\mathbf{e} = \mathbf{g}_0 \frac{\lambda}{1 - \lambda} + V \mathbf{g}_0 n_\mathbf{Q}(T) \mathbf{g}_{3/2}(1); \quad T < T_\mathbf{c}. \tag{24.8}$$

<span id="page-435-3"></span>λ

<span id="page-435-2"></span>
$$m_{\mathbf{e}} \coloneqq \frac{\mathcal{N}_{\mathbf{e}}}{V} = \mathbf{g} \alpha_{\mathbf{Q}}(T) \mathbf{g} \mathbf{g} / 2(1) = \mathbf{g} \mathbf{0} \left(\frac{mk_{\mathbf{B}}T}{2\pi\hbar^2}\right)^{3/2} \mathbf{g} / 2(1); \quad T < T_{\mathbf{C}}.\tag{24.9}$$

Accordingly, we replace Eq. (24.4) by

$$
\lambda = \left[1 + \frac{\mathbf{g}_0}{\mathcal{N}_0}\right]^{-1}.\tag{24.10}
$$

*n*e := *N*e *V* = *g*0*n*Q(*T*)*g*3/2(1) = *g*0 *mk*B*T* 2π*[h](#page-434-2)*¯ 2 3/2 *g*3/2(1); *T* < *T*c. (24.9) Solving Eq. (24.7) for λ gives λ = 1 + *g*0 *N*0 −1 . (24.10) There appears at first to be an inconsistency between Eqs. (24.5) and (24.7) for the

$$
\lambda = \left[1 + \frac{\text{g0}}{10^{-6}\mathcal{N}}\right]^{-1} \approx 1 - \frac{\text{g0}}{10^{-6}\mathcal{N}} \approx 1\tag{24.11}
$$

<span id="page-435-4"></span>Eq. (24.7)! This turns out to be a false argument because *N*0 is never zero, but can still be negligible with respect to *N* . All we need for Eq. (24.5) to hold for determination of *T*c is *N*0 *N* . For example, suppose that *N*0 = 10−6*N* . Then Eq. (24.10) becomes λ = 1 + *g*0 10−6*N* −1 ≈ 1 − *g*0 10−6*N* [≈](#page-435-1) 1 (24.11)

$$
\mu \approx -\text{kp}\,T\frac{\text{g}\,0}{10^{-6}\,\text{N}},\tag{24.12}
$$

λ = 1 in *g*3/2(λ) while letting it be a variable extremely close to 1 in Eqs. (24.7) and (24.8). In terms of the chemical potential, Eq. (24.11) would become μ ≈ −*k*B*T g*0 10−6*N* , (24.12) which means that the chemical potential is negative and very slightly less than zero.1 If

*N*0 accounted for all of *N* , equations of the form of Eqs. (24.11) and (24.12) would hold but without the factor of 10−6. Then λ would be even closer to 1 and μ would be even closer to 0.

*n*e = *n*

*n*0 = *n*

*T*

*T*c

$$n_{\text{e}} = n \left(\frac{T}{T_{\text{c}}}\right)^{3/2} \tag{24.13}$$
 and

(24.13)

the ground state energy ε0.

and

ground state by *n*0 := *N*0/*V*, we obtain

$$m_0 = n \left[ 1 - \left( \frac{T}{T_\odot} \right)^{3/2} \right]. \tag{24.14}$$

1The ground state energy has been set equal to 0 for convenience. Otherwise, μ would be slightly less than

416 THERMAL PHYSICS

![](_page_436_Figure_1.jpeg)

0.4 0.6

0.5 1 1.5 2 T/Tc **FIGURE 24–2** Plots of the fraction of condensate, *n*0/*n* associated with the ground state, and of the normal fluid,

# The concentrations (number densities) *n*e and *n*0 are represented graphically in

*n*e/*n* associated with the excited states, as a function of *T*/*T*c according to Eqs. (24.13) and (24.14).

0.2

0.8

1

Figure 24–2. For an exact treatment that agrees with the present results in the thermodynamic limit, see Pathria and Beale [9, Appendix F].

$$
\ln \mathcal{Z}_0 = -\mathbf{g}_0 \ln(1 - \lambda). \tag{24.15}
$$

To determine the thermodynamic functions for *T* ≤ *T*c, we return to the sum in Eq. (23.3)

pressure

2Note that −(∂*K*0/∂μ)*T*,*V* = λ

 

∂ ln *Z*0/∂λ

$$K_0 = \mathbf{g}_0 k_B T \ln(1 - \lambda) \tag{24.16}$$

ln *Z*0 = −*g*0 ln(1 − λ). (24.15) This term contributes an amount

$$K = K_0 + k_\mathrm{B} T \mathsf{V} \mathsf{g}_\mathrm{0} n_\mathrm{Q}(T) \frac{1}{\Gamma(3/2)} \int_0^\infty \ln(1 - \lambda \, \mathrm{e}^{-\mu}) u^{1/2} \, \mathrm{d}u. \tag{24.17}$$

1 -∞

$$K = K_0 - k_\mathrm{B} T \mathrm{Vg_0} n_\mathrm{Q}(T) \mathrm{g_{5/2}}(\lambda). \tag{24.18}$$

After integration by parts, as in Eq. (23.17), this becomes *K* = *K*0 − *k*B*TVg*0*n*Q(*T*)*g*5/2(λ). (24.18) Fortunately, *K*0 is negligible except for computation of *N* , which we have already

β,*V* = *g*0λ/(1 − λ) = *N*0 in agreement with Eq. (24.7).

$$p_0 = -\frac{k_\mathrm{B}T}{V} \mathrm{g_0} \ln(1 - \lambda) \tag{24.19}$$

*V g*0 ln(1 − λ) (24.19)

$$p = k_{\rm B} T \mathbf{g}_0 n_{\rm Q}(T) \mathbf{g}_{5/2}(\lambda). \tag{24.20}$$

<span id="page-437-2"></span>
$$p_0 = \frac{k_\mathrm{B}T}{V} \mathbf{g}_0 \ln\left[ (\mathcal{N}_0/\mathbf{g}_0) + 1 \right]. \tag{24.21}$$

over and above the pressure given by Eq. (23.18) for bosons, namely

$$p = \mathbf{g}_0 n_\mathbf{Q}(T) k_\mathbf{B} T \mathbf{g}_{5/2}(\lambda); \quad T > T_\odot \tag{24.22}$$

<span id="page-437-1"></span>
$$p = \mathbf{g_0} n_\mathbf{Q}(T) k_\mathbf{B} T \mathbf{g_{5/2}}(1); \quad T \le T_\mathbf{c}. \tag{24.23}$$

Since *V* ∝ *N* , this term is of the order of *N* −1 ln *N* and should be neglected in the thermodynamic limit of large *N* . Thus we have

*p* = *g*0*n*Q(*T*)*k*B*Tg*5/2(λ); *T* > *T*c (24.22) and

<span id="page-437-0"></span>
$$p = nk_\mathrm{B}T\frac{\mathbf{g}_{5/2}(\lambda)}{\mathbf{g}_{3/2}(\lambda)};\quad T > T_\mathrm{c.} \tag{24.24}$$

Note espe[cially](#page-437-0) [t](#page-437-0)hat Eq. (24.23) shows that *p* depends only on *T*, independent of *n*. Care must therefore be taken in expressing the pressure i[n term](#page-437-1)s of *n* because Eq. (24.3)

and the second term gives

$$p = \left(\frac{T}{T_{\mathbb{C}}}\right)^{3/2} nk \mathbb{B} \, T \frac{\mathbf{g}_{5/2}(1)}{\mathbf{g}_{3/2}(1)} = n_{\mathbb{C}} k \mathbf{g}_{}^{\mathbf{T}} \frac{\mathbf{g}_{5/2}(1)}{\mathbf{g}_{3/2}(1)}; \quad T \le T_{\mathbb{C}}.\tag{24.25}$$

but *p* = *T T*c 3/2 *nk*B*T g*5/2(1) *g*3/2(1) = *n*e*k*B*T g*5/2(1) *g*3/2(1) ; *T* ≤ *T*c. (24.25)

Equation (24.25) shows that *the condensate makes no contribution to the pressure*. Those bosons in the ground state, the so-called condensate, exert no pressure. As written, Eq. (24.25) appears to depend on *n*, thus contradicting Eq. (24.23), but it must be recalled that *T*3/2 c is proportional to *n*, so *n* actually cancels in Eq. (24.25) (see Eq. (24.9)). Similar considerations pertain to the internal energy and the entropy, although the calculations are more complicated because one must first take derivatives. For the internal energy, the situation is quite simple because the ground state has zero energy so the

$$
\mathfrak{q} = \mathfrak{q}\mathfrak{q} + \mathrm{V\mathfrak{g}n}\mathfrak{n}_{\mathbb{Q}}(T)\mathfrak{g}\mathfrak{z}_{/2}(\lambda),
\tag{24.26}
$$

*q* = ln *Z* = −β*K* which leads to *q* = *q*0 + *Vg*0*n*Q(*T*)*g*5/2(λ), (24.26)

$$U = \frac{3}{2} k_{\mathbb{B}} T \mathbb{V} \mathbb{g}_0 n_{\mathbb{Q}}(T) \mathbb{g}_{5/2}(\lambda) \tag{24.27}$$

*U* = 3 2 *k*B*TVg*0*n*Q(*T*)*g*5/2(λ) (24.27)

2

$$u_V = \frac{3}{2} n k_B T \frac{\mathbf{g}_{5/2}(\lambda)}{\mathbf{g}_{3/2}(\lambda)}; \quad T > T_\mathbb{C} \tag{24.28}$$

but

<span id="page-438-2"></span>
$$n\nu = \left(\frac{T}{T_{\mathbb{C}}}\right)^{3/2} \frac{3}{2} n k \mathbb{B} T \frac{\mathbf{g}_{5/2}(1)}{\mathbf{g}_{3/2}(1)} = \frac{3}{2} n_{\mathsf{e}} k \eta_{\mathsf{B}} T \frac{\mathbf{g}_{5/2}(1)}{\mathbf{g}_{3/2}(1)}; \quad T \le T_{\mathbb{C}}.\tag{24.29}$$

418 THERMAL PHYSICS

$$\mathbf{S}_{\mathbf{0}} = -\left(\frac{\partial K_{\mathbf{0}}}{\partial T}\right)_{\mu, V} = -\mathbf{g}_{\mathbf{0}} k_{\mathbf{B}} \left[ \ln(1 - \lambda) + \frac{\lambda \ln \lambda}{1 - \lambda} \right]. \tag{24.30}$$

We see that the *condensate makes no contribution to the internal energy* for *T* < *T*c. It

 *T T*c

*S*0 = *k*B*g*0

<span id="page-438-0"></span>*u*V =

$$\mathbf{S}_{0} = k_{\rm B} \mathbf{g}_{0} \left\{ \ln \left[ (\mathcal{N}_{0}/\mathbf{g}_{0}) + 1 \right] + (\mathcal{N}_{0}/\mathbf{g}_{0}) \ln \left[ 1 + (\mathbf{g}_{0}/\mathcal{N}_{0}) \right] \right\}. \tag{24.31}$$

*S*0 = −∂*K*0 ∂*T* μ,*V* = −*g*0*k*B ln(1 − λ) + λ ln λ 1 − λ . (24.30) In view of Eq. (24.10), this becomes

<span id="page-438-5"></span>
$$\mathbf{S} = k_{\rm B} V \mathbf{g}_{\rm 0} n_{\rm Q}(T) \left[ (5/2) \mathbf{g}_{5/2}(\lambda) - \ln \lambda \, \mathbf{g}_{3/2}(\lambda) \right],\tag{24.32}$$

Pr[ovi](#page-438-1)ded that *N*0 is any reasonable fraction of *N* , we have *g*0/*N*0 1 in which case (*N*0/*g*0)ln[1 + (*g*0/*N*0)] ≈ 1; the remaining term in Eq. (24.31) is of order ln *N* and is also negligible in the thermodynamic limit. Thus,

<span id="page-438-4"></span>
$$\text{sv} = k_{\text{B}} n \left[ \frac{5}{2} \frac{\text{g}_{5/2}(\lambda)}{\text{g}_{3/2}(\lambda)} - \ln \lambda \right]; \quad T > T_{\text{C}}, \tag{24.33}$$

in agreement with Eq. (23.24). This result can also be expressed in terms of the number density, resulting in an entropy density

<span id="page-438-3"></span>
$$\mathrm{s}_{\mathrm{V}} = \left(\frac{T}{T_{\mathrm{C}}}\right)^{3/2} n k_{\mathrm{B}} \frac{5}{2} \frac{\mathrm{g} \,\mathrm{s}/2}{\mathrm{g} \,\mathrm{s}/2} (1) = n_{\mathrm{e}} k_{\mathrm{B}} \frac{5}{2} \frac{\mathrm{g} \,\mathrm{s}/2}{\mathrm{g} \,\mathrm{s}/2} (1) ; \quad T \le T_{\mathrm{c}}.\tag{24.34}$$

but3

*s*V = *T T*c 3/2 *nk*B 5 2 *g*5/2(1) *g*3/2(1) = *n*e*k*B 5 2 *g*5/2(1) *g*3/2(1) ; *T* ≤ *T*c. [(24](#page-438-2).34)

$$\mathbf{C}_{V} = \frac{3}{2} \mathcal{N} k_{\rm B} \left\{ \frac{5}{2} \frac{\mathbf{g}_{5/2}(\lambda)}{\mathbf{g}_{3/2}(\lambda)} - \frac{3}{2} \frac{\mathbf{g}_{3/2}(\lambda)}{\mathbf{g}_{1/2}(\lambda)} \right\}; \quad T > T_{\rm C}. \tag{24.35}$$

<span id="page-438-1"></span>*CV* = 3 2 *N k*B 5 2 *g*5/2(λ) *g*3/2(λ) − 3 2 *g*3/2(λ) *g*1/2(λ) ; *T* > *T*c. (24.35) It would be wrong, however, to use Eq. (23.47) (or Eq. (23.48) which is derived from it) for *T* ≤ *T*c because Eq. (23.47) is based on a temperature derivative of Eq. (23.13) which is

4

*g*3/2(1)

$$C_V = \left(\frac{T}{T_\mathbb{C}}\right)^{3/2} N k_\mathbb{B} \frac{15}{4} \frac{\mathfrak{g}_{5/2}(1)}{\mathfrak{g}_{3/2}(1)} = \mathcal{N}_\mathfrak{e} k_\mathbb{B} \frac{15}{4} \frac{\mathfrak{g}_{5/2}(1)}{\mathfrak{g}_{3/2}(1)}; \quad T \le T_\mathbb{C}. \tag{24.36}$$

3Note that the term in ln λ → 0 for λ → 1.

*T*c

4

![](_page_439_Figure_1.jpeg)

[0.5](#page-438-3) 1 CV/(*N*kB)

0.5 1 1.5 2

T/Tc **FIGURE 24–3** Heat capacity *CV* /(*N k*B) of an ideal Bose fluid as a function of *T*/*T*c. For *T* → ∞, *CV* /(*N k*B) = 3/2, the value for a classical ideal gas. The curve resembles the letter and the peak of the curve, which is about 28% higher than the classical value, occurs at the lambda point where *T* = *T*c. The heat capacity of He4 displays a similar behavior, although it is not an ideal Bose fluid. Since *g*1/2(1) = ∞, Eq. (24.35) for *T* = *T*c yields the same result as Eq. (24.36), so *CV* is continuous at *T*c. On the other hand, its slope is discontinuous at *T*c, as illustrated in Figure 24–3. The *CV* versus *T* curve resembles the letter . Since the peak of the curve corresponds to the condensation temperature, the corresponding transition in liquid He4

is said to occur at the "**lambda point**," even though He4 atoms have attractive forces and are only crudely approximated by an ideal Bose gas. Evaluated at the number density of liquid He4, *T*c ≈ 3 K; however, the **lambda transition** in liquid He4 takes place at about 2.17 K. Equations (24.25), (24.29), and (24.34) show explicitly that the bosons that are "condensed" in th[e groun](#page-437-0)d [state](#page-438-2) do no[t contr](#page-438-4)ibute to t[he pre](#page-439-0)ssure, the internal energy, or the entropy. This suggests that below *T*c the ideal Bose fluid [behave](#page-435-3)s like a mixture of two "phases," the **inactive condensate** associated with the ground state and a **normal fluid** associated with the excited states. As the temperature is lowered from *T*c to *T* = 0, it is as if

there is a "phase transition" from the normal fluid to the condensate. For a brief discussion of liquid helium as well as superfluidity, see Kittel and Kroemer [6, p. 20] and Pathria and

Beale [9, p. 108,215].

Eq. (24.12) for further detail.

<span id="page-439-0"></span>
$$\mathcal{N}\mu = \mathcal{U} - \mathcal{TS} + \mathcal{p}V.\tag{24.37}$$

[From](#page-435-4) [th](#page-435-4)e Euler equation, one has *N* μ = *U* − *TS* + *pV*. (24.37)

$$\mu = -k_{\rm B} T \ln \left( 1 + \frac{\mathbf{g}_0}{\mathcal{N}_0} \right),\tag{24.38}$$
 
$$\varepsilon_1, \dots, \varepsilon_{n-1}, \dots, \varepsilon_{n-1}, \varepsilon_n, \dots, \varepsilon_{n-1}, \dots, \varepsilon_{n-1}, \varepsilon_n, \dots, \varepsilon_{n-1}, \dots, \varepsilon_n, \varepsilon_n, \dots, \varepsilon_{n-1}, \dots, \varepsilon_{n-1}, \varepsilon_n, \dots, \varepsilon_{n-1}, \dots, \varepsilon_{n-1}, \dots, \varepsilon_n$$

μ = −*k*B*T* ln *N*0 , (24.38) which is negative and very close to zero because *g*0 is of order 1 and *N*0 is of order *N* , even if it is negligible in comparison to *N* , say 10−6*N* . See the argument in connection with

$$H = U + pV = U + (2/3)U = (5/3)U \tag{24.39}$$

<span id="page-440-1"></span>420 THERMAL PHYSICS

<span id="page-440-0"></span> *g*5/2(λ)

$$\mathbf{C}_{\mathcal{P}} = \frac{5}{2} \mathcal{N} k_{\mathbf{B}} \left\{ \frac{\mathbf{g}_{5/2}(\lambda)}{\mathbf{g}_{3/2}(\lambda)} + \frac{\mathbf{g}_{3/2}(\lambda)\mathbf{g}_{5/2}'(\lambda) - \mathbf{g}_{5/2}(\lambda)\mathbf{g}_{3/2}'(\lambda)}{[\mathbf{g}_{3/2}(\lambda)]^2} T \left(\frac{\partial \lambda}{\partial T}\right)_{\mathcal{N},p} \right\},\tag{24.40}$$

enthalpy *H* at constant *N* and *p*. First of all, we have *H* = *U* + *pV* = *U* + (2/3)*U* = (5/3)*U* (24.39)

$$\left(\frac{\partial\lambda}{\partial T}\right)_{\mathcal{N},p} = -\frac{5}{2T} \frac{\mathbf{g}_{5/2}(\lambda)}{\mathbf{g}_{5/2}'(\lambda)}.\tag{24.41}$$

*Cp* = 5 2 *N k*B *g*3/2(λ) + [*g*3/2(λ)]2 *T* ∂*T N*,*p* , (24.40) where the prime[s deno](#page-438-3)te derivatives. Differentiation of Eq. (24.22) holding *p* constant then

$$\mathbf{C}_{p} = \frac{5}{2} N k_{\rm B} \left\{ \frac{5}{2} \frac{[\mathbf{g}_{5/2}(\lambda)]^2}{[\mathbf{g}_{3/2}(\lambda)]^2} \frac{\mathbf{g}_{1/2}(\lambda)}{\mathbf{g}_{3/2}(\lambda)} - \frac{3}{2} \frac{\mathbf{g}_{5/2}(\lambda)}{\mathbf{g}_{3/2}(\lambda)} \right\}; \quad T > T_{\rm C}. \tag{24.42}$$

We recall that *g* 5/2(λ) = λ−1*g*3/2(λ) and *g*

*Cp* = 5

<span id="page-440-2"></span>*N k*B 5

Eq. [(24.41)](#page-435-3) into Eq. (24.40) leads to

$$\frac{C_p}{C_V} = \frac{5}{3} \frac{\mathbf{g}_{5/2}(\lambda)\mathbf{g}_{1/2}(\lambda)}{[\mathbf{g}_{3/2}(\lambda)]^2}; \quad T > T_\odot. \tag{24.43}$$

$$\mathbf{g}_{1/2} = \begin{bmatrix} \ddots & \ddots & \ddots & \ddots & \ddots & \ddots & \ddots & \cdots \end{bmatrix}$$

3/2(λ) = λ−1*g*1/2(λ). Then substitution of

2 2 [*g*3/2(λ)]2 2 Dividing by Eq. (24.35) then yields *Cp CV* = 5 3 *g*5/2(λ)*g*1/2(λ) [*g*3/2(λ)]2 ; *T* > *T*c. (24.43)

$$\frac{C_p}{C_V} = 1 + \frac{4}{9} \frac{C_V}{\mathcal{N}k_\text{B}} \frac{\mathbf{g}_{1/2}(\lambda)}{\mathbf{g}_{3/2}(\lambda)},\tag{24.44}$$

rewritten in the form

which leads to

leads to

$$\frac{C_p - C_V}{\mathcal{N}k_\mathbb{B}} = \frac{4}{9} \left( \frac{C_V}{\mathcal{N}k_\mathbb{B}} \right)^2 \frac{\mathbf{g}_{1/2}(\boldsymbol{\lambda})}{\mathbf{g}_{3/2}(\boldsymbol{\lambda})}.\tag{24.45}$$

*Cp* − *CV* = 4 *CV* 2 *g*1/2(λ)

*Cp CV*

*N k*B 9 *N k*B *g*3/2(λ). (24.45) Equation (24.45) shows that *Cp* > *CV* as expected. For *T* ≤ *T*c, we see from Eq. (24.25) that *p* depends only on *T*. So in the approximation λ = 1 inherent in this equation, constant *p* demands constant *T*. On the other hand, the energy *U* and the enthalpy *H* = *U* + *pV* = (5/3)*U* = (5/2)*pV* depend on both *T* and *V* or, alternatively, on both *p* and *V*. Therefore, at constant *p* and *T*, *H* can change linearly with *V*. In other words, at constant *p* one can add or subtract heat from the system by changing *V* and the system remains at constant *T*. The system therefore behaves as if it has

an infinite heat capacity *Cp*. The same conclusion would be reached if we relate the heat

$$
\mathcal{N}\mathbf{0} = \mathcal{N} - V\mathbf{g}_0 \left(\frac{mk_\mathbf{B}T}{2\pi\hbar^2}\right)^{3/2} \mathbf{g}_{3/2}(\mathbf{I}).\tag{24.46}
$$

*Q* = *T S* to a change in the entropy *S*, since by Eq. (24.34) we see that *S* is also proportional to *V* at constant *T*. In any event, when heat is added to the system at constant *p* and *T*, the amount of condensate *N*0 changes. This becomes more evident if we use Eq. (24.5) to

$$V_{\rm c} = \frac{\mathcal{N}}{\text{gog}_{3/2}(1)} \left(\frac{2\pi\hbar^2}{mk_{\rm B}T}\right)^{3/2}.\tag{24.47}$$

. (24.47)

When heat is added to the system by increasing *V* at constant *p* and *T*, we see that *N*0 decreases linearly with *V* until *N*0 = 0, at which point the system will have a critical volume *V*c

3/2

 2π*h*¯ 2 *mk*B*T*

### *g*0*g*3/2(1) For *V* > *V*c at the same *T*, the fluid will be entirely in the gaseous state in which virtually

rewrite Eq. (24.14) in the explicit form

all of the bosons are accommodated in the excited states. See Section 24.3 for a related discussion. 24.3 Condensate Region

### Except in the preceding section, we have regarded t[he volu](#page-441-0)me *V* to be fixed and focused our discussion on temperature *T* relative to the critical temperature *T*c. But *T*c actually

24.3.1 In the *v*, *T* Plane

depends on *V*, so in this section we take a broader approach.

*V*c = *N*

<span id="page-441-1"></span><span id="page-441-0"></span>
$$\frac{1}{v} = \mathbf{g}_0 n_\mathbf{Q}(T) \mathbf{g}_{3/2}(\mathbf{l}),\tag{24.48}$$

We return to Eq. (24.4) which we now write in the form

$$\frac{1}{vT^{3/2}} = \mathbf{g} (mk\mathbf{g}/2\pi\hbar^2)^{3/2} \mathbf{g}_{3/2}(1) =: C^*,\tag{24.49}$$

1 *vT*3/2 = *g*0(*mk*B/2π*h*¯ 2) 3/2*g*3/2(1) =: *C*∗, (24.49)

$$vT^{3/2} < 1/C^*, \quad \text{condensate region},\tag{24.50}$$

*vT*3/2 < 1/*C*∗, condensate region, (24.50) depicted in Figure 24–4 where the population in the ground state is so large that it must be taken explicitly into account. This zone is bounded from above by the curve *vT*3/2 = 1/*C*∗ which can be solved to give either a critical temperature *T*c(*v*) = (1/*C*∗)2/3(1/*v*)2/3 as a

function of *v* or a critical volume per particle *v*c(*T*) = (1/*C*∗)(1/*T*)3/2 as a function of *T*.

422 THERMAL PHYSICS

![](_page_442_Figure_1.jpeg)

T

v **FIGURE 24–4** Condensate region (shaded) *vT*3/2 < 1/*C*∗ for a Bose fluid in arbitrary units. The dotted line is an isobar (*p* = constant) th[at depe](#page-437-2)nds onl[y on](#page-441-0) *T* in the condensate zone and asymptotes the dashed line *T* = *pv*/*k* for a classical ideal gas at high temperatures and large volumes.

$$\tilde{v} = \mathbf{g}_0 (m/2\pi\hbar^2)^{3/2}; \quad \tilde{t} = \mathbf{k}_\mathbf{B} T; \quad \tilde{p} = \mathbf{g}_0^{-1} (m/2\pi\hbar^2)^{-3/2},\tag{24.51}$$

region but in the normal region it follows a curved path that may be obtained by eliminating λ between Eqs. (24.22) and (24.48), which cannot be done analytically. This

$$
\tilde{v}^{-1}\tilde{t}^{-3/2} = \mathbf{g}_{7/2}(\lambda); \quad \tilde{\mathbf{p}}\tilde{t}^{-5/2} = \mathbf{g}_{7/2}(\lambda). \tag{24.52}
$$

*v*˜ = *g*0(*m*/2π*h*¯ 2) 3/2; *t*˜ = *k*B*T*; *p*˜ = *g*−1 0 (*m*/2π*h*¯ 2) −3/2, (24.51)

$$\tilde{v} = \left[\frac{\mathfrak{g}_{5/2}(\lambda)}{\tilde{p}}\right]^{3/5} \left[\frac{1}{\mathfrak{g}_{3/2}(\lambda)}\right]; \quad \tilde{t} = \left[\frac{\tilde{p}}{\mathfrak{g}_{5/2}(\lambda)}\right]^{2/5} \tag{24.53}$$

Then an isobar may be plotted from the parametric equations *v*˜ = *g*5/2(λ) *p*˜ 3/5 1 *g*3/2(λ) ; *t*˜ = *p*˜ *g*5/2(λ)2/5 (24.53) by choosing some constant value of *p*˜ and letting λ range from very small values to 1.

$$\frac{\tilde{p}\tilde{v}}{\tilde{t}} = \frac{\mathbf{g}_{5/2}(\lambda)}{\mathbf{g}_{3/2}(\lambda)} \to 1 \text{ as } \lambda \to 0,\tag{24.54}$$

*p*˜ *v*˜ *t*˜ = *g*5/2(λ) *g*3/2(λ) → 1 as λ → 0, (24.54)

which is the classical ideal gas law that is approached asymptotically far from the conden-

sate region.

24.3.2 In the *v*, *p* Plane

$$p = k_{\mathbb{B}} C^* \mathfrak{g}_{5/2}(1) T^{5/2} / \mathfrak{g}_{3/2}(1), \quad \text{condensate region}, \tag{24.55}$$

<span id="page-443-1"></span>![](_page_443_Figure_1.jpeg)

[p](#page-441-1)

<span id="page-443-0"></span>v **FIGURE 24–5** Condensate region (shaded) *pv* 5/3 < [con](#page-443-0)stant given by Eq. [(24.56)](#page-443-1) [for](#page-443-1) [an](#page-443-1) [id](#page-443-1)eal Bose fluid in arbitrary

$$pv^{5/3} < \frac{2\pi\hbar^2}{m} \frac{\text{g}_{5/2}(\text{l})}{[\text{g}_{3/2}(\text{l})]^{5/3}} \frac{1}{\text{g}_0^{2/3}}, \quad \text{condensate region.} \tag{24.56}$$

we can combine it with Eq. (24.50) to rewrite the condensate region in the form *pv* 5/3 <

*k*B(*C*∗)−2/3*g*5/2(1)/*g*3/2(1) or explicitly *pv* 5/3 < 2π*h*¯ 2 *m g*5/2(1) [*g*3/2(1)]5/3 1 *g* 2/3 0 , condensate region. (24.56)

$$
\tilde{v} = \tilde{t}^{-3/2} \left[ \mathbf{g}_{3/2}(\lambda) \right]^{-1}; \quad \tilde{p} = \tilde{t}^{5/2} \mathbf{g}_{5/2}(\lambda). \tag{24.57}
$$

horizontal line at some value of *p*. Outside the condensate region, we can make a parametric plot of an isotherm b[y](#page-438-5) [using](#page-438-5) Eq. (24.52) and solving for *v*˜ and *p*˜, resulting in *v*˜ = *t*˜−3/2 *g*3/2(λ)−1 ; *p*˜ = *t*˜5/2*g*5/2(λ). (24.57)

### condensate region is bounded by *p*˜ *v*˜ 5/2 = *g*5/2(1) region such an isotherm asymptotes the hyperbola *p*˜ *v*˜ = *t*˜ for a classical ideal gas.

Then Eq. (24.3) shows that

24.3.3 Isentropic Tran[sform](#page-443-2)atio[n](#page-443-3) In a reversible adiabatic transformation, the number of particles *N* and the entropy *S* must

[−](#page-437-2)5/3

<span id="page-443-3"></span><span id="page-443-2"></span> *g*3/2(1)

$$vT^{3/2} = \text{constant},\tag{24.58}$$

. Far from the condensate

*vT*3/2 = constant, (24.58)

Then for some fixed value of *t*˜, we let λ range from small values to 1. In these variables, the

$$p/T^{5/2} = \text{constant.}\tag{24.59}$$

*p*/*T*5/2 = constant. (24.59)

$$pv^{5/3} = \text{constant.}\tag{24.60}$$

ratio is only equal to 5/3 in the classical limit.

region is an isentrope.

$$pv/T = \text{constant},\tag{24.61}$$

424 THERMAL PHYSICS

Furthermore, *pv*/*T* = constant, (24.61) which can be obtained by multiplying Eq. (24.58) by Eq. (24.59). These equations resemble the equations for an isentropic transformation of a classical monatomic ideal gas for

which the exponent 5/3 = *Cp*/*CV* , but Eq. (24.43) for the ideal Bose gas shows that this

For an isentropic transformation for *T* ≤ *T*c, Eq. (24.32) for λ = 1 yields Eq. (24.58) whereas Eq. (24.23) for λ = 1 yields Eq. (24.59), so Eqs. (24.60) and (24.61) are still valid. Comparison of Eq. (24.58) with Eq. (24.49) shows that the boundary of the condensate

![](_page_445_Picture_0.jpeg)

25 Degenerate Fermi Gas In this chapter, we examine in more detail the behavior of an ideal Fermi gas. Even for temperatures near absolute zero, the Pauli exclusion principle forces fermions into high energy states, and the gas is said to be degenerate. Consequently, raising the temperature causes only a small change in occupation of even higher energy states. This gives rise to a heat capacity that is much smaller than for a classical gas. This and other phenomena are illustrated for a simple model of a metal in which the valence electrons are treated as an ideal Fermi gas. In the presence of a magnetic field, the two spin states of each electron have different energies which gives rise to weak magnetic behavior known as Pauli paramagnetism. The magnetic field also affects the nonspin states, which gives rise to weak Landau diamagnetism. If sufficiently heated, some electrons can overcome an energy barrier and leave the metal, a phenomenon known as thermionic emission. If an external electric field is applied, this energy barrier can be reduced and thermionic emission can be enhanced. Electron emission can also be enhanced by radiation, the photoelectric effect. Finally, we examine semiconductors that have densities of single electron quantum states separated by a forbidden region of energy known as a band gap. Such states pertain to an electron in an effective periodic potential that accounts approximately for interactions with the lattice. With increase of temperature, some electrons can be excited to states above that band gap, resulting in an overall increase in electron mobility and enhanced

### <span id="page-445-0"></span>electrical conductivity. Adding small amounts of impurities to such a metal, a process known as doping, can cause major changes in the way electrons are thermally excited in

semiconductors. 25.1 Ideal Fermi Gas at Low Temperatures

$$0 \le \frac{1}{\lambda^{-1} \mathbf{e}^{\beta e} + 1} = \frac{1}{\exp[\beta(e-\mu)] + 1} \le 1. \tag{25.1}$$

0 ≤ 1 λ−1 eβε + 1 = 1 [ex](http://dx.doi.org/10.1016/B978-0-12-803304-3.00025-9)p[β(ε − μ)] + 1 ≤ 1. (25.1) For an ideal Bose gas, the corresponding average occupancy becomes infinite for ε = 0 as λ → 1. However, for fermions, λ = eβμ can be any positive number, so 0 ≤ λ ≤ ∞. In particular, one does not have to take the ground state into account explicitly, so conversion from a sum to an integral presents no problem. Therefore, for fermions, there is no critical

temperature, such as the condensation temperature *T*c for bosons.

by the bounded quantity

<span id="page-446-0"></span>
$$n = \mathbf{g}_0 n_\mathbf{Q}(T) f_{\mathbf{3}/2}(\lambda),\tag{25.2}$$

426 THERMAL PHYSICS At all temperatures (see Section 23.1 and Eq. (23.13) with *f*ν (λ) = *h*ν(λ, 1)), the particle density *n* = *N* /*V* can be writte[n in t](#page-446-0)he form *n* = *g*0*n*Q(*T*)*f*3/2(λ), (25.2)

which can be regarded as an implicit equation for μ(*n*, *T*), with *n* specified. In particular, the function *f*3/2(λ) is not bounded as λ→∞. As we shall see later,

$$\mathcal{N} = \text{g0} \sum_{\varepsilon}^{\prime} \frac{1}{\exp[\beta(\varepsilon - \mu)] + 1},\tag{25.3}$$

εF ≡ μ(*n*, 0). This same *T* = 0 limit may be explored in an elementary way by returning to the sum (see Eq. (21.89)) that led to Eq. (25.2), namely *N* = *g*0 - 1 exp[β(ε − μ)] + 1 , (25.3)

$$\lim_{\beta \to \infty} \frac{1}{\exp[\beta(s-\mu)]+1} = \begin{cases} 1 & \text{if } s < s_{\text{F}}\\ 0 & \text{if } s > s_{\text{F}} \end{cases} \tag{25.4}$$

*T* →0, β →∞, so μ→εF that depends only on *n*. Thus, *f*FD(ε) becomes a step function of the form

$$\mathcal{N} = \mathbf{g}_0 \sum_{c < c\mathbf{p}}' \mathbf{1}.\tag{25.5}$$

So for *T* = 0, Eq. (25.3) takes the simple form *N* = *g*0 - ε<εF 1. (25.5) For the free particle and periodic boundary conditions, we know that ε =*h*¯ 2*k*2/2*m* and that

$$\mathcal{N} = \text{g}_0 \frac{V}{(2\pi)^3} \int_0^{k\text{yr}} 4\pi k^2 \,\text{d}k = \text{g}_0 \frac{V}{(2\pi)^3} \frac{4}{3} \pi k_\text{F}^3,\tag{25.6}$$

*N* = *g*0 *V k*F 4π*k*2 d*k* = *g*0 *V* 4 π*k*3 F, (25.6)

*k*F = (6π2*n*/*g*0)

<span id="page-446-2"></span>(2π )3

0

<span id="page-446-1"></span>lim β→∞ 1

$$k_{\rm F} = (6\pi^2 n/\mathfrak{g}_0)^{1/3} \tag{25.7}$$

sum in Eq. (25.5) to obtain

and

$$\varepsilon_{\rm F} = \frac{\hbar^2}{2m} (6\pi^2 n / \text{g}_0)^{2/3}. \tag{25.8}$$

1/3 (25.7)

εF = *h*¯ 2 2*m* (6π2*n*/*g*0) 2/3. (25.8) At *T* = 0 the energy is also easy to calculate because one can include a factor of ε in the

<span id="page-447-1"></span>
$$\mathcal{U}U_0 = \mathbf{g}_0 \sum_{\varepsilon < \varepsilon \mathbb{F}}' \varepsilon = \mathbf{g}_0 \frac{\hbar^2}{2m} \frac{V}{(2\pi)^3} \int_0^{k_{\text{F}}} 4\pi \, k^4 \, \mathbf{d}k = \frac{3}{5} \mathcal{N} \varepsilon_{\text{F}}.\tag{25.9}$$

<span id="page-447-0"></span>
$$p_0 = \frac{2}{5} n s_{\rm F}.\tag{25.10}$$

*U*0 = *g*0 ε<εF ε = *g*0 *h*¯ 2 2*m V* (2π )3 *k*F 0 4π*k*4 d*k* = 3 5 *N* εF. (25.9) According to Eq. (23.18), the pressur[e](#page-447-0) [is](#page-447-0) [tw](#page-447-0)o-thirds of the energy density at all temperatures, so the pressure at *T* = 0 is given by *p*0 = 2 5 *n*εF. (25.10)

$$T\mathbf{\hat{r}} := \frac{\varepsilon_{\mathbf{F}}}{k_{\mathbf{B}}} = \frac{\hbar^2}{2mk_{\mathbf{B}}} (6\pi^2 n/\mathfrak{g}\mathfrak{g})^{2/3} . \tag{25.11}$$

occupation of high energy states results in a cumulative energy given by Eq. (25.9) and a

corresponding pressure given by Eq. (25.10). One can also define a **Fermi temperature** = *h*¯ 2 (6π2*n*/*g*0) 2/3. (25.11)

*T*F := εF *k*B 2*mk*B This may be rewritten in the form *n* = *g*0 *mk*B*T*F 2π*h*¯ 2 3/2 4 3π1/2 , (25.12)

which greatly resembles Eq. (24.5) for the critical temperature *T*c of an ideal Bose gas. We emphasize, however, that *T*F is *not* a critical temperature but rather a temperature that characterizes the degree to which fermions at *T* = 0 are forced into excited states by the Pauli exclusion principle. A word about the relative magnitudes of *T*F and *T*c is relevant. If we consider fermions or bosons that have comparable number densities and masses, say the masses of He3 (a fermion with half integral spin) and He4 (a boson with integral spin), the mag[nitud](#page-446-1)es of *T*F [an](#page-447-1)d *T*c will be comparable. As we saw previously, *T*c was typically a few K degrees at the density of He4 near the lambda transition. But electrons are fermions and the electron mass is about 1836 times smaller than the mass of a proton. Therefore, for free electron gases in metals at their usual densities, *T*F is typically 50,000 K degrees. In such cases, one has *T T*F for any temperature of interest. We shall see that a Fermi gas at temperature *T* > 0 but *T T*F displays characteristics very similar to a Fermi gas at *T* = 0 except a small fraction ∼ *T*/*T*F of electrons is now in excited states. Consequently, a Fermi gas

<span id="page-447-2"></span>at *T T*F is usually referred to as a **degenerate Fermi gas**. Equivalent conditions for a degenerate Fermi gas are therefore βμ 1, λ 1, or *n*/*n*Q(*T*) 1. Before leaving this section, it is worth pointing out that the integrals in Eqs. (25.6) and (25.9) could equally well have been written as integrals over ε by expressing *k* = 2*m*ε/*h*¯ 2

$$\mathbf{g}(\varepsilon) := \frac{\mathbf{G}(\varepsilon)}{V} \coloneqq \frac{\mathbf{g}_0}{2} \frac{m}{\hbar^2 \pi^2} \left(\frac{2m}{\hbar^2}\right)^{1/2} \varepsilon^{1/2} = \frac{3}{2} \frac{n}{\varepsilon_\mathcal{F}} \left(\frac{\varepsilon}{\varepsilon_\mathcal{F}}\right)^{1/2}. \tag{25.13}$$

$$m = \int_0^{\varepsilon_{\rm F}} \mathbf{g}(\varepsilon) \, \mathrm{d}\varepsilon \tag{25.14}$$

428 THERMAL PHYSICS

$$
\hbar\nu(T=0) = \int_0^{\epsilon_\text{F}} \mathbf{g}(\varepsilon)\varepsilon \,d\varepsilon = \frac{3}{5}\hbar\varepsilon_\text{F}.\tag{25.15}
$$

*g*(ε) dε (25.14)

### 0 and the energy density

*g*(ε) dε is the number of states per unit volume in that same interval. Then

*n* = εF

*u*V(*T* = 0) = εF 0 *g*(ε)ε dε = 3 5 *n*εF. (25.15) 25.2 Free Electron Model of a Metal As an example of an ideal Fermi gas with spin *s* = 1/2, we treat the free electron model of a metal. According to this model, each atom contributes *z*v valence electrons to a sea of electrons that are shared by the remaining ion cores. Interactions among the valence electrons as well as intera[ctions](#page-445-0) with the ion cores are treated only on average. Specifically, one assumes that each valence electron experiences an *effective potential* that is constant (and set equal to zero for convenience) within the metal. The potential outside the metal is assumed to be sufficiently large that the electrons are confined to the volume *V* of the metal. Thus, each valence electron behaves as if it were free but confined to a box of

volume *V*. We shall see that the valence electrons constitute a very dense gas, typically 1000-10,000 times more dense than a classical gas, so quantum effects are important. Even though the free electron model is quite naive, it works rather well for some elements, especially the alkali metals. The quantum statistics of such an electron gas are governed by the Fermi-Dirac distribution function Eq. (25.1). Quantitative details for *k*B*T* εF are handled by a series expansion in *k*B*T*/μ due to Sommerfeld. We shall see that μ depends very weakly on *T*, so ultimately results for μ and *u*V can be expressed as a series expansion in *k*B*T*/εF = *T*/*T*F.

This free electron model of a metal was the first to explain why an electron gas in a metal contributes only a small fraction of the heat capacity that it would if it were a classical gas. We estimate the number density of an electron gas in a metal. Consider a simple cubic

$$n \sim \frac{1}{a^3} \sim \frac{1}{(2.5 \times 10^{-8} \,\text{cm})^3} \sim 6.4 \times 10^{22} \,\text{cm}^{-3}.\tag{25.16}$$

*n* ∼ 1 *a*3 ∼ 1 (2.5 × 10−8 cm)3 ∼ 6.4 × 1022 cm−3. (25.16) This should be compared to the number density *nc* of a classical ideal gas at standard

$$n_c \sim \frac{6.02 \times 10^{23}}{22.4 \times 10^3 \,\text{cm}^3} \sim 2.7 \times 10^{19} \,\text{cm}^{-3}.\tag{25.17}$$

*Chapter 25* • Degenerate Fermi Gas 429 We see that the electron gas has a number density that is about 1000 times that of a classical gas. For *T* = 273 K, we find the quantum concentration *n*Q = (*mk*B*T*/2π*h*¯ 2)3/2 ∼ 1.1 × 1019 cm−3 for electrons and 2.4 × 1024 cm−3 for hydrogen. Thus, *n n*Q for electrons, which are expected to behave like a dense quantum gas; however, for hydrogen *n n*Q so it behaves like a classical gas. For *n* ∼ 6.4 × 1022 cm−3, we have *k*F ∼ 1.1 × 108 cm−1 which corresponds to a Fermi wavelength λF = 2π/*k*F ∼ 5.7 × 10−8 cm which is comparable to the lattice constant *a*. T[he Ferm](#page-447-2)i energy εF ∼ 7.7×10−12 erg ∼ 4.4 eV, which corresponds to a Fermi temperature *T*F = εF/*k*B ∼ 51, 000 K. These numerical estimates are

typical values; for actual values for given materials, see table 2.1 of Ashcroft and Mermin [58, p. 28]. In any case, it is important to recognize that for temperatures *T* of practical interest for metals, one has *T T*F, so only a small fraction ∼ *k*B*T*/εF = *T*/*T*F of the free electrons are thermally activated with respect to their energy levels for *T* = 0. This thermal

activation is governed by the Fermi-Dirac distribution function, as discussed in the

### <span id="page-449-2"></span>For now, we shall assume that no magnetic field is present, so each state corresponding to a given value of **k** is twofold degenerate because of spin. This degeneracy has already

been incorporated in *g*(ε) given by Eq. (25.13) with *g*0 = 2.

$$f_{\rm FD}(\varepsilon) = \frac{1}{\exp[(\varepsilon - \mu)/k_B T] + 1},\tag{25.18}$$

The population of electronic orbitals for *T* > 0 is governed by the Fermi-Dirac distribution function (see Eq. (21.88)), *f*FD(ε) = 1 exp[(ε − μ)/*k*B*T*] + 1 , (25.18)

$$n = \int_0^\infty \mathbf{g}(\varepsilon) f_{\rm FD}(\varepsilon) \, d\varepsilon. \tag{25.19}$$

*n* = ∞

The internal energy density is given by

next section.

<span id="page-449-1"></span><span id="page-449-0"></span>
$$
\mu_{\rm V} = \int_0^\infty \varepsilon \,\mathbf{g}(\varepsilon) f_{\rm FD}(\varepsilon) \,\mathrm{d}\varepsilon.\tag{25.20}
$$

*u*V = ∞ 0 ε *g*(ε)*f*FD(ε) dε. (25.20) Equations of the forms of Eqs. (25.19) and (25.20) would hold even if *g*(ε) were for a more

general model in which the valence electrons were subject to an effective single-electron potential due to a crystal lattice. As *T* →0, Eq. (25.4) shows that *f*FD(ε) is a step function as depicted in Figure 25–1. For *T* > 0 but still *T T*F, the corners of the step function become rounded

as also shown in Figure 25–1. In three dimensions, the value of μ becomes slightly less than

430 THERMAL PHYSICS

![](_page_450_Figure_1.jpeg)

[0.4](#page-449-0) 0.6 0.8 fFD(ε)

0.5 1 1.5 2 ε/μ

**FIGURE 25–1** Plots of the Fermi-Dirac distribution function as a function of ε/μ for *T* = 0 (step function) and *T* > 0 but *T T*F (curve). Note that μ also depends on *T* but is practically equal to εF (see Eq. (25.35)). Thus μ/*k*B*T* 1,

### but μ/(*k*B*T*) = 30 was chosen for the sake of illustration.

25.3.1 Sommerfeld Expansion

0.2

εF in order to satisfy Eq. (25.19), for reasons to be discussed later. We note that *f*FD(μ) = 1/2 for any *T* > 0.

$$I := \int_0^\infty w(\varepsilon) f(\varepsilon) \,\mathrm{d}\varepsilon,\tag{25.21}$$

In order to treat Eqs. (25.19) and (25.20) in the general case of *T* > 0 but still *T T*F, we

*I* :=

0

0

*H*(ε) =

$$H(\varepsilon) = \int_0^{\varepsilon} \mathbf{u}\eta(\eta) \, \mathbf{d}\eta,\tag{25.22}$$

<span id="page-450-0"></span>where *w*(ε) is either *g*(ε) or ε *g*(ε). We define an auxiliary function

*I* =

$$\frac{\mathbf{d}H(\varepsilon)}{\mathbf{d}\varepsilon} = \boldsymbol{w}(\varepsilon). \tag{25.23}$$

which has the properties *H*(0) = 0 and

$$I = \int_0^\infty \frac{\mathrm{d}H(\varepsilon)}{\mathrm{d}\varepsilon} f(\varepsilon) \, \mathrm{d}\varepsilon = H(\varepsilon) f(\varepsilon) \Big|_0^\infty + \int_0^\infty H(\varepsilon) \left( -\frac{\mathrm{d}f(\varepsilon)}{\mathrm{d}\varepsilon} \right) \, \mathrm{d}\varepsilon. \tag{25.24}$$

*I* = ∞ 0 d*H*(ε) dε *f* (ε) dε = *H*(ε)*f* (ε) ∞ 0 + ∞ 0 *H*(ε) −d*f* (ε) dε dε. (25.24) The first term on the right-hand side of Eq. (25.24) vanishes because of the properties of *H*(ε) at the lower limit and *f* (ε) at the upper limit. The function −d*f* /dε is highly peaked near ε = μ and nearly 0 elsewhere because of the shape of *f* (ε). In fact, as *T* → 0 it tends toward a Dirac delta function, δ(ε − μ), which is the formal derivative of a unit step function. We therefore realize that *H*(ε) is only important in the vicinity of ε = μ, so we

expand it in a power series near μ.

$$I = \int_{-\mu/\text{kg}\,T}^{\infty} H(\mu + \text{xk}_{\text{B}}T) \left(-\frac{\text{df}}{\text{dx}}\right) \,\text{d}x,\tag{25.25}$$

$$-\frac{\mathbf{d}f}{\mathbf{dx}} = -\frac{\mathbf{d}}{\mathbf{dx}}\frac{1}{\mathbf{e}^{\mathbf{x}}+1} = \frac{\mathbf{e}^{\mathbf{x}}}{(\mathbf{e}^{\mathbf{x}}+1)^2} = \frac{1}{4}\frac{1}{\cosh^2(\mathbf{x}/2)},\tag{25.26}$$

$$H(\mathbf{x}k_{\rm B}T+\mu) = H(\mu) + H'(\mu)\mathbf{x}k_{\rm B}T + \frac{1}{2!}H''(\mu)(\mathbf{x}k_{\rm B}T)^2 + \cdots,\tag{25.27}$$

where − d*f* d*x* = − d d*x* 1 e*x* + 1 = e*x* (e*x* + 1)2 = 1 4 1 cosh2(*x*/2) , (25.26) which is an even function of *x*. Then we expand *H* in a Taylor series [1](#page-449-0)

$$I = H(\mu) + \frac{\pi^2}{6} \boldsymbol{\mu}^\prime(\boldsymbol{\mu}) (\boldsymbol{k} \otimes \boldsymbol{T})^2 + \cdots,\tag{25.28}$$

substitute Eq. (25.27) into Eq. (25.25) and perform the integrals over *x*. The lower limit in Eq. (25.25) is essentially −∞, so integrals over odd powers of *x* are negligible to an excellent

(μ)(*k*B*T*)

(μ)(*k*B*T*)

*w*

$$n = \int_0^\mu \mathbf{g}(\eta) \, \mathbf{d}\eta + \frac{\pi^2}{6} \mathbf{g}'(\mu) (k_B T)^2 + \cdots;\tag{25.29}$$

<span id="page-451-0"></span>2 [+··](#page-451-0)· , (25.28)

2 +··· ; (25.29)

6 (μ) = *H*(μ). Equations (25.[19](#page-451-1)) and (25.20) therefore become μ *g*(η) dη + π2

0 6 *g u*V = μ 0 η*g*(η) dη + π2 6 [μ*g*(μ)] (*k*B*T*) 2 +··· . (25.30)

$$n = \int_0^{\varepsilon_{\rm F}} \mathbf{g}(\eta) \, \mathrm{d}\eta + \mathbf{g}(\varepsilon_{\rm F}) (\mu - \varepsilon_{\rm F}) + \frac{\pi^2}{6} \mathbf{g}'(\varepsilon_{\rm F}) (k_{\rm B} T)^2 + \cdots \tag{25.31}$$

is small compared to εF and expand again to obtain2

it at μ = εF.

resulting in

where we have used *w*

<span id="page-451-2"></span>*n* =

μ − εF = −π2

6 *g* (εF) *g*(εF)

<span id="page-451-3"></span>
$$\mathbf{M}_{\rm V} = \int_{0}^{\varepsilon_{\rm F}} \eta \mathbf{g}(\eta) \, \mathbf{d}\eta + \varepsilon_{\rm F} \mathbf{g}(\varepsilon_{\rm F}) (\mu - \varepsilon_{\rm F}) + \frac{\pi^2}{6} [\varepsilon_{\rm F} \mathbf{g}(\varepsilon_{\rm F})]' (k_{\rm B} T)^2 + \cdots \,\tag{25.32}$$

and *u*V = εF 0 η*g*(η) dη + εF*g*(εF)(μ − εF) + π2 6 [εF*g*(εF)] (*k*B*T*) 2 +··· . (25.32)

<span id="page-451-1"></span>
$$
\mu - \varepsilon_{\rm F} = -\frac{\pi^2}{6} \frac{\mathbf{g}'(\varepsilon_{\rm F})}{\mathbf{g}(\varepsilon_{\rm F})} (k_{\rm B} T)^2 + \cdots \ . \tag{25.33}
$$

2 +··· . (25.33)

1See Eq. (23.35) for additional terms. See Ashcroft and Mermin [58, appendix C] or Pathria [8, appendix E] for

(*k*B*T*)

details and even higher order terms of the expansion. 2Consistent to second order in *k*B*T*/εF, we do not need to expand the second-order term but simply evaluate *u*V =

<span id="page-452-0"></span> εF 0

$$\mu_{\rm V} = \int_{0}^{\varepsilon_{\rm F}} \eta \mathbf{g}(\eta) \, \mathrm{d}\eta + \frac{\pi^{2}}{6} \mathbf{g}(\varepsilon_{\rm F}) (k_{\rm B} T)^{2} + \cdots \, , \tag{25.34}$$

432 THERMAL PHYSICS

Equation (25.33) shows that the chemical potential shifts from εF by a small amount in a direction of opposite sign to *g* (εF). Substitution of Eq. (25.33) into Eq. (25.32) gives

<span id="page-452-1"></span>
$$
\mu = \varepsilon_{\rm F} - \frac{\pi^2}{12} \varepsilon_{\rm F} \left( \frac{k_{\rm B} T}{\varepsilon_{\rm F}} \right)^2 + \dotsb; \tag{25.35}
$$

which depends only on the value of *g* (not its derivative) at the Fermi energy. The first term in Eq. (25.34) is just the value of *u*V at *T* = 0 given by Eq. (25.9). For the free electron model, for which *g*[(ε)](#page-449-2) is given by Eq. (25.13), Eqs. (25.33) and

(25.34) become μ = εF − π2 12 εF *k*B*T* 2 +··· ; (25.35)

εF *u*V = 3 εF*n* + π2 (*k*B*T*)2 *n* +··· . (25.36)

$$f_{\rm FD} = \frac{1}{2} - \frac{1}{2}\tanh[\beta(\mathfrak{s} - \mu)/2]. \tag{25.37}$$

Fermi energy εF except at *T* = 0. The shift in chemical potential relative to the Fermi energy can be understood by noting that the Fermi-Dirac function given by Eq. (25.18) can be written in the form. *f*FD = 1 2 − 1 2 tanh[β(ε − μ)/2]. (25.37) Thus for *T* > 0 but *T T*F, the increase in the probability of occupancy with ε>μ is exactly equal to the decrease in the probability of occupancy with ε<μ. But because *g*(ε) ∝ ε1/2, this ch[ange i](#page-452-0)n probabilities would result in a greater *number* of electrons having ε>μ with respect to the *number* lost from ε<μ. Thus, μ must decrease slightly from εF in order to conserve the total number of electrons. The analytical result Eq. (25.33) shows that the shift from εF has the same sign as *g* (εF). In two dimensions, *g*(εF) is a

### to exponential order for εF/*k*B*T* 1. In one dimension, *g*(ε) ∝ ε−1/2, so μ is slightly larger than εF.

25.3.2 Heat Capacity

constant, so μ = εF+*k*B*T* ln[1−exp(−εF/*k*B*T*)]; thus there is no shift in chemical potential

$$\text{v}\sqrt{} = \frac{3}{2}nk_{\text{B}}\frac{\pi^2}{3}\frac{k\text{g }T}{\text{s}\text{F}} + \dotsb. \tag{25.38}$$

*c*V = 3 2 *nk*B π2 3 *k*B*T* εF +··· . (25.38) We observe that *c*V depends linearly on *T* and is reduced from the heat capacity, 3*nk*B/2, of a classical ideal gas by the small factor (π2/3)(*k*B*T*/εF). This factor arises because the Pauli exclusion principle forces the electrons to occupy energy levels up to εF at *T* = 0. Therefore, only a small fraction ∼ *k*B*T*/εF of electrons are thermally activated for *T* = 0 and each of these will have energy ∼ (*k*B*T*) above εF. They will therefore lead to a heat capacity *c*V ∼ 2*nk*B(*k*B*T*/εF), in agreement with Eq. (25.38) except for a numerical factor.

$$
\Delta \mathbf{v} = \begin{cases}
\, \text{AT} + \text{BT}^3, & \text{electronic conductor,} \\
\, \text{BT}^3, & \text{insulator,}
\end{cases}
\qquad \text{at low } T,\tag{25.39}
$$

<span id="page-453-1"></span>At high *T*, the electronic heat capacity given by Eq. (25.38) is quite small compared with

where *A* and *B* are constants.

<span id="page-453-0"></span>**k**

25.4 Pauli Paramagnetism

### the heat capacity ∼ 3*nk*B due to lattice vibrations,3 but at sufficiently low *T* it dominates the heat capacity due to lattice vibrations, which is proportional to *T*3. Thus at low *T*, we have a dependence of heat capacity on temperature of the form

*c*V = *AT* + *BT*3, electronic conductor, *BT*3, insulator, at low *T*, (25.39)

$$\frac{\hbar^2 k^2}{2m} - \mu^* \mathcal{B}, \quad \text{spin up;}$$

$$\frac{\hbar^2 k^2}{2m} + \mu^* \mathcal{B}, \quad \text{spin down,} \tag{25.40}$$

sets of states having energies:

$$\mathcal{N} = \sum_{\mathbf{k}} \left[ \frac{1}{\exp[\beta(\hbar^2 k^2 / 2m - \mu^* B - \mu)] + 1} + \frac{1}{\exp[\beta(\hbar^2 k^2 / 2m + \mu^* B - \mu)] + 1} \right],\tag{25.41}$$

2*m* where μ∗ is the magnetic moment, taken to be positive. For *N* electrons, we have *N* = - 1 exp[β(*h*¯ 2*k*2/2*m* − μ∗*B* − μ)] + 1 + 1 exp[β(*h*¯ 2*k*2/2*m* + μ∗*B* − μ)] + 1 , (25.41)

$$\mathcal{N} = \frac{V}{(2\pi)^3} \left[ \int_0^{[(\epsilon\mathbf{r} + \mu^*B)2m/\hbar^2]^{1/2}} 4\pi \,\mathbf{k}^2 \,\mathrm{d}\mathbf{k} + \int_0^{[(\epsilon\mathbf{r} - \mu^*B)2m/\hbar^2]^{1/2}} 4\pi \,\mathbf{k}^2 \,\mathrm{d}\mathbf{k} \right]. \tag{25.42}$$

presence of the magnetic field. The sums can then be converted to integrals and we obtain 1/2 1/2

$$n = \frac{1}{6\pi^2} \left(\frac{2m}{\hbar^2}\right)^{3/2} \left[ (\varepsilon_\mathrm{F} + \mu^* B)^{3/2} + (\varepsilon_\mathrm{F} - \mu^* B)^{3/2} \right]. \tag{25.43}$$

*n* = 1 2*m*

For *B* = 0, Eq. (25.43) yields

0

6π2

3π2

*h*¯ 2

per unit volume. For the monovalent alkali metals, these number densities would be the same.

F

*h*¯ 2

3/2

*N* = *V* (2π )3

$$\varepsilon_{\rm F0} \equiv \varepsilon_{\rm F}(B=0) = \frac{\hbar^2}{2m} (3\pi^2 n)^{2/3},\tag{25.44}$$

εF0 ≡ εF(*B* = 0) = *h*¯ 2 2*m* (3π2*n*) 2/3, (25.44)

$$n = \frac{1}{3\pi^2} \left(\frac{2m}{\hbar^2}\right)^{3/2} \varepsilon_{\rm F}^{3/2} \left[1 + \frac{3}{8} \left(\frac{\mu^* \mathcal{B}}{\varepsilon_{\rm F}}\right)^2 + \dotsb\right].\tag{25.45}$$

3For lattice vibrations, *n* would be the number of lattice sites per unit volume, not the number of electrons

εF

8

$$\varepsilon_{\rm F} = \varepsilon_{\rm F0} \left[ 1 - \frac{1}{4} \left( \frac{\mu^* B}{\varepsilon_{\rm F0}} \right)^2 + \dotsb \right]. \tag{25.46}$$

434 THERMAL PHYSICS

Then by substitution of Eq. (25.44) to eliminate *n* and expansion in *B* we find εF = εF0 1 − 1 4 μ∗*B* εF0 2 +···  . (25.46)

$$m_{\rm V} = \frac{1}{6\pi^2} \left(\frac{2m}{\hbar^2}\right)^{3/2} \left[ (\varepsilon_{\rm F} + \mu^* B)^{3/2} \mu^* - (\varepsilon_{\rm F} - \mu^* B)^{3/2} \mu^* \right]. \tag{25.47}$$

The magnetization *m*V (magnetic moment per unit volume) at *T* = 0 can now be calculated easily by recognizing that the two terms in Eq. (25.43) come from spin up and

$$m_{\rm V} = \frac{3}{2} n(\mu^*)^2 \frac{1}{\varepsilon_{\rm F}} \text{R}.\tag{25.48}$$

*m*V = 1 6π2 2*m h*¯ 2 3/2 (εF + μ∗*B*) 3/2μ∗ − (εF − μ∗*B*) 3/2μ∗ . (25.47)

$$\chi_0 = \frac{\partial m_V}{\partial B} = \frac{3}{2} n(\mu^*)^2 \frac{1}{\varepsilon_F}.\tag{25.49}$$

*m*V = 3 2 *n*(μ∗) 2 1 εF *B*. (25.48) The corresponding susceptibility per unit volume is therefore

<span id="page-454-1"></span><span id="page-454-0"></span>
$$\chi_{\infty} = \frac{1}{V} \frac{\partial \mathcal{M}}{\partial B} = n(\mu^*)^2 \frac{1}{k_B T}. \tag{25.50}$$

For high temperatures, the corresponding result for a spin 1/2 paramagnet can be calculated from Eq. (19.125) with μB = μ∗, *g* = 2 and *J* = 1/2, resulting in χ∞ = 1 ∂*M* ∂*B* = *n*(μ∗) 2 1

−μ∗ to obtain

*V k*B*T* . (25.50) Thus the elect[ron ga](#page-454-0)s has a susce[ptibili](#page-446-0)ty that is smaller by a factor of (3/2)(*k*B*T*/εF), similar to the situation for the heat capacity. This weak paramagnetism is known as **Pauli**

$$n = n_{\mathbb{Q}}(T)[f_{3/2}(\lambda_{+}) + f_{3/2}(\lambda_{-})],\tag{25.51}$$

integrals, which leads to

obtain

**paramagnetism**.

$$
\lambda_{\pm} = \exp[\beta(\mu \pm \mu^* B)] = \lambda \exp(\pm \beta \mu^* B). \tag{25.52}
$$

where λ± = exp[β(μ ± μ∗*B*)] = λ exp(±βμ∗*B*). (25.52)

$$K = -k_{\rm B} T \text{\!\!\!V\!n_{\rm Q}(T)} \text{\!\!\!f}_{5/2}(\lambda_{+}) + f_{5/2}(\lambda_{-}) \text{\!\!\! }. \tag{25.53}$$

*K* = −*k*B*TVn*Q(*T*)[*f*5/2(λ+) + *f*5/2(λ−)]. (25.53) To obtain the magnetic moment *M*, we note that *K* = *F* − μ*N* and then use Eq. (19.96) to

d*K* = −*S* d*T* − *p* d*V* − *M*d*B* − *N* dμ (25.54)

$$\mathbf{d}K = -\mathbf{S}\mathbf{d}T - p\mathbf{d}V - \mathcal{M}\mathbf{d}B - \mathcal{N}\mathbf{d}\mu \tag{25.54}$$

temperatures.

answer at low temperatures,

$$\mathcal{M} = -\left(\frac{\partial K}{\partial B}\right)_{T,V,\mu}.\tag{25.55}$$

$$m_{\rm V} = n_{\rm Q}(T) [f_{3/2}(\lambda_{+}) - f_{3/2}(\lambda_{-})] \mu^{*}.\tag{25.56}$$

from which

$$\begin{split} \chi &= n_{\rm Q}(T) \| f_{1/2}(\lambda_{+}) + f_{1/2}(\lambda_{-}) \| \beta(\mu^{*})^{2} \\ &\quad + n_{\rm Q}(T) \| f_{1/2}(\lambda_{+}) - f_{1/2}(\lambda_{-}) \| \mu^{*} \beta \left( \frac{\partial \mu}{\partial B} \right)_{T, V, \mathcal{N}} . \end{split} \tag{25.57}$$

To compute the susceptibility χ per unit volume, we need to take the derivative of *m*V with

$$
\left(\frac{\partial\mu}{\partial B}\right)_{T,V,\mathcal{N}} = -\mu^* \frac{[\text{f}_{1/2}(\lambda_+) - \text{f}_{1/2}(\lambda_-)]}{[\text{f}_{1/2}(\lambda_+) + \text{f}_{1/2}(\lambda_-)]}.\tag{25.58}
$$

+ *n*[Q](#page-454-0)(*T*)[*f*1/2(λ+) − *f*1/2(λ−)]μ∗β ∂μ ∂*B T*,*V*,*N* . (25.57) From Eq. (25.51) we compute the required derivative

<span id="page-455-0"></span>
$$\chi = 2n_{\mathcal{Q}}(T)\beta(\mu^*)^2 f_{1/2}(\lambda). \tag{25.59}$$

This results in a rather complicated expression for χ, but unless we are interested in the

<span id="page-455-1"></span>[∂μ](#page-455-0) ∂*B* 

*T*,*V*,*N*

$$n = 2n_{\mathbb{Q}}(T)f_{\mathbb{S}/2}(\lambda). \tag{25.60}$$

χ = 2*n*Q(*T*)β(μ∗) 2*f*1/2(λ). (25.59) In this sa[me](#page-455-0) *B* = 0 limit, Eq. (25.51) becomes

*n* = 2*n*Q(*T*)*f*3/2(λ). (25.60) Together, Eqs. (25.59) and (25.60) allow determination of χ and μ in the *B* = 0 limit at all

$$\chi = n\beta(\mu^*)^2 \frac{f_{1/2}(\lambda)}{f_{3/2}(\lambda)} = n(\mu^*)^2 \frac{3}{2\mu} \left[ 1 - \frac{\pi^2}{6} \left( \frac{k\mathfrak{g}\,T}{\mu} \right)^2 + \cdots \right]. \tag{25.61}$$

χ = *n*β(μ∗) 2 *f*1/2(λ) *f*3/2(λ) = *n*(μ∗) 2 3 2μ 1 − π2 6 *k*B*T* μ 2 +···  . (25.61)

$$\chi = n(\mu^*)^2 \frac{3}{2} \frac{1}{\varepsilon_\mathrm{F}} \left[ 1 - \frac{\pi^2}{12} \left( \frac{k_\mathrm{B}T}{\varepsilon_\mathrm{F}} \right)^2 + \cdots \right],\tag{25.62}$$
 
$$\text{which agrees with Eq. (25.49) at } T = 0.$$

χ = *n*(μ∗) 2 3 2 1 εF 1 − π2

εF which agrees with Eq. (25.49) at *T* = 0. At high temperatures, *T T*F, if attainable for some spin 1/2 ideal Fermi gas, we would

$$\chi = n(\mu^*)^2 \beta \left[ 1 - \frac{\lambda}{2^{3/2}} + \dotsb \right]. \tag{25.63}$$

, (25.62)

te[mperature res](#page-453-1)ult

$$\chi = n(\mu^*)^2 \beta \left[ 1 - \frac{n}{2^{5/2} n_{\mathcal{Q}}(T)} + \dotsb \right]. \tag{25.64}$$

. (25.64)

436 THERMAL PHYSICS It is then sufficient to estimate (see Eq. (21.101)) λ = *n*/(2*n*Q(*T*)) and thus obtain the high

### χ = *n*(μ∗) 2β 1 − *n* 25/2*n*Q(*T*) +···

Although we have calculated χ only for spin 1/2 particles, the same technique would work for any half integral spin *s*, in which case one would have 2*s* + 1 different λ*i* to deal with. 25.5 Landa[u](#page-456-0) Diamagnetism In Section 25.4, we treated Pauli paramagnetism that results from the splitting of electron spin states in a magnetic field. It turns out that a magnetic field can also influence the

orbital states, which gives rise to a diamagnetic effect in which the magnetic moment opposes the applied field. In other words, the magnetic susceptibility for diamagnetism is negativ[e.](#page-456-1) We shall see that Landau diamagnetism gives rise to a susceptibility that is −1/3 the susceptibility for Pauli paramagnetism, provided that the effective orbital magnetic moment is equal to that for spin. For a magnetic field applied along the *z*-axis, the velocity in the *z*-direction of a classical particle of charge *e* is unaffected but its velocity in the *x*- and *y*-directions is affected by the Lorentz force4 which acts perpendicular to *z* with magnitude *Bev*⊥/*c*. Thus, such a classical charged particle would move in a spiral of radius *R* = *mv*⊥*c*/*eB*. Setting *v*⊥ = *R*ω,

$$
\varepsilon = \frac{e\hbar B}{mc} \left( j + \frac{1}{2} \right) + \frac{\hbar^2 k_z^2}{2m},
\tag{25.65}
$$

namely,5

-

-

(2π )2

*ky*

*kx*

<span id="page-456-0"></span>ε = *ehB*¯ *mc j* + 1 2 + *h*¯ 2*k*2 *z* 2*m* , (25.65) where *j* = 0, 1, 2, ... . The energy levels associated with the quantum number *j* are strongly degenerate, which can be understood by relating them to a coale[scence of s](#page-453-1)tates associated with free

<span id="page-456-1"></span>
$$
\sum_{k_\mathcal{X}} \sum_{k_\mathcal{Y}} \rightarrow \frac{L_\mathcal{X} L_\mathcal{Y}}{(2\pi)^2} \int 2\pi k_\perp \,\mathrm{d}k_\perp = \frac{L_\mathcal{X} L_\mathcal{Y}}{(2\pi)^2} \int 2\pi k_\perp \frac{\mathrm{d}k_\perp}{\mathrm{d}\varepsilon_\perp} \mathrm{d}\varepsilon_\perp = \frac{L_\mathcal{X} L_\mathcal{Y}}{h^2} 2\pi m \int \mathrm{d}\varepsilon_\perp,\tag{25.66}
$$

*h*2 2π*m*

dε⊥, (25.66)

obtained by mapping the *x*, *y* motion onto the problem for a harmonic oscillator.

(2π )2

2π*k*⊥

dε⊥

<sup>4</sup>For SI units, set *c* =1 in this and subsequent formulas in this section. 5The quantity *eh*¯ /*mc* is twice the Bohr magneton μB = *eh*¯ /2*mc* that we introduced in Section 19.6.2. Except for possible corrections for effective masses, μB = μ∗ as used in Section 25.4. The given energy levels can be

$$
\int \mathrm{d}\varepsilon_{\perp} = \sum_{j} \Delta \varepsilon_{j} = \sum_{j} \frac{e \hbar B}{mc},
\tag{25.67}
$$

*Chapter 25* • Degenerate Fermi Gas 437

$$\frac{L_{\chi}L_{\mathcal{Y}}}{h^{2}}\,2\pi\,m\frac{e\hbar B}{mc} = L_{\chi}L_{\mathcal{Y}}\frac{eB}{hc}.\tag{25.68}$$

perpendicular to *z*. If we then make the correspondence dε⊥ = - ε*j* = - *ehB*¯ *mc* , (25.67)

*j j*

<span id="page-457-2"></span>*LxLy*

$$\ln \mathcal{Z} = \text{g}_0 \sum_{t}^{'} \ln(1 + \lambda \,\text{e}^{-\beta t}),\tag{25.69}$$

This degeneracy, exclusive of spin, turns out to be correct based on a detailed solution of the proble[m](#page-457-0) [66, p. 424]. We proceed to compute the grand partition function ln *Z* = *g*0 - ε ln(1 + λ e−βε), (25.69) where the factor of *g*0 = 2 is due to spin degeneracy. In fact, the spin states are not

degenerate in the presence of *B* as we know from our treatment of Pauli paramagnetism in

**Euler-Maclaurin sum formula**

-∞

*j*=0

separately.6

Eq. (25.52).

where we have used ε⊥ = *h*¯ 2*k*2

$$\ln Z = \text{g}_0 \frac{V}{2\pi} \frac{eB}{\hbar c} \int_{-\infty}^{\infty} \text{d}k_2 \sum_{j=0}^{\infty} \ln(1 + \lambda \,\text{e}^{-\beta c}),\tag{25.70}$$

We therefore obtain ln *Z* = *g*0 *V* 2π *eB hc* ∞ −∞ d*kz* -∞ *j*=0 ln(1 + λ e−βε), (25.70) where we have replaced the sum over *kz* with an integral over *kz* and a factor of *Lz*/2π as usual, recognizing that the volume *V* = *LxLyLz*. For *ehB*¯ /*mc k*B*T*, which we assume

$$\sum_{j=0}^{\infty} \mathbf{g}(j + \frac{1}{2}) = \int_0^{\infty} \mathbf{g}(\mathbf{x}) \, d\mathbf{x} + \frac{1}{24} \mathbf{g}'(\mathbf{0}) + \cdots,\tag{25.71}$$

<span id="page-457-0"></span>-∞ *g*(*j* + 1 2 ) = ∞ *[g](#page-457-1)*(*x*) d*x* + 1 24*g* (0) +··· , (25.71)

*j*=0 0 that is derived in Appendix H, Eq. (H.25), to obtain the first term that depends on *B*. Thus, ln(1 + λ e−βε) = ∞ 0 d*x* ln 1 + λ exp −β *ehB*¯ *mc x* − β *h*¯ 2*k*2 *z* 2*m* − 1 24β *ehB*¯ 1 +··· . (25.72)

<span id="page-457-1"></span>*z* /2*m*) + 1

6The decomposition represented later by Eq. (25.72) would still be valid if λ were replaced by λ± given by

λ−1 exp(β*h*¯ 2*k*2

*mc*

= *mc ehB*¯ *h*¯ 2 *m*

$$\frac{mc}{e\hbar B} \int_0^\infty \mathrm{d}y \ln\left[1 + \lambda \exp\left(-\beta y - \beta \frac{\hbar^2 k_z^2}{2m}\right)\right]$$

$$= \frac{mc}{e\hbar B} \frac{\hbar^2}{m} \int_0^\infty k_\perp \,\mathrm{d}k_\perp \ln\left[1 + \lambda \exp\left(-\beta \frac{\hbar^2 (k_\perp^2 + k_z^2)}{2m}\right)\right]$$

$$= \frac{mc}{e\hbar B} \frac{\hbar^2}{m} \frac{1}{2\pi} \int_0^\infty \mathrm{d}k_\parallel \int_0^\infty \mathrm{d}k_\parallel \ln\left[1 + \lambda \exp\left(-\beta \frac{\hbar^2 (k_\perp^2 + k_y^2 + k_z^2)}{2m}\right)\right].\tag{25.73}$$

*mc ehB*¯ ∞ 0 d*y* ln 1 + λ exp −β*y* − β *h*¯ 2*k*2 *z* 2*m* 

$$\ln Z_0 = \text{g}_0 \frac{V}{(2\pi)^3} \int \text{d}^3 k \ln[1 + \lambda \exp(-\beta \hbar^2 k^2 / 2m)],\tag{25.74}$$

= *mc ehB*¯ *h*¯ 2 *m* 1 2π ∞ 0 d*kx* ∞ 0 d*ky* ln 1 + λ exp −β *h*¯ 2(*k*2 *x* + *k*2 *y* + *k*2 *z* ) 2*m*  . (25.73) Therefore, the contribution of Eqs. (25.70)–(25.73) is

$$\begin{split} \ln \mathcal{Z}_{\mathsf{B}} &= -\frac{\beta}{24} \frac{\mathsf{g}_{\mathsf{0}} V}{(2\pi)^{2}} \frac{\mathsf{e}^{2} B^{2}}{mc^{2}} \int_{-\infty}^{\infty} \mathrm{d}k_{\mathsf{2}} \frac{1}{\lambda^{-1} \exp(\beta \hbar^{2} k_{\mathsf{2}}^{2}/2m) + 1} \\ &= -\frac{1}{6} \frac{\mathsf{g}_{\mathsf{0}} V \mathsf{h}_{\mathsf{Q}}(T)}{(\mathsf{k} \mathsf{p} T)^{2}} (\mu^{*} \mathsf{B})^{2} f_{1/2}(\lambda), \end{split} \tag{25.75}$$

netism. The contribution of that term to Eq. (25.70) is ln *Z*B = − β 24 *g*0*V* (2π )2 e2*B*2 *mc*2 ∞ −∞ d*kz* 1 λ−1 exp(β*h*¯ 2*k*2 *z* /2*m*) + 1

$$m\mathbf{v} = \frac{k_{\rm B}T}{V} \left(\frac{\partial \ln \mathcal{Z}_{\rm B}}{\partial \mathbf{B}}\right)_{V,\mu} = -\frac{1}{3} \frac{\mathbf{g} \rho n_{\rm Q}(T)}{k_{\rm B}T} (\mu^*)^2 B \mathbf{f}_{1/2}(\lambda) = -\frac{n(\mu^*)^2}{3k_{\rm B}T} \frac{f_{1/2}(\lambda)}{f_{3/2}(\lambda)} B \tag{25.76}$$

the me[tal](#page-455-1) [can](#page-455-1) be taken as the electron mass. The magnetization is *m*V = *k*B*T* ∂ ln *Z*B = −1 *g*0*n*Q(*T*) 2*Bf*1/2(λ) = −*n*(μ∗)2 *f*1/2(λ)

$$\chi = \frac{k_{\rm B}T}{V} \left( \frac{\partial \ln \mathcal{Z}_{\rm B}}{\partial B} \right)_{V,\mu} = -\frac{1}{3} \frac{\mathbf{g}_{\rm B} n_{\rm Q}(T)}{k_{\rm B}T} (\mu^*)^2 f_{\rm I/2}(\lambda) = -\frac{n(\mu^*)^2}{3k_{\rm B}T} \frac{f_{\rm I/2}(\lambda)}{f_{\rm I/2}(\lambda)}.\tag{25.77}$$

therefore χ = *k*B*T V* ∂ ln *Z*B ∂*B V*,μ = −1 3 *g*0*n*Q(*T*) *k*B*T* (μ∗) 2*f*1/2(λ) = −*n*(μ∗)2 3*k*B*T f*1/2(λ) *f*3/2(λ). (25.77) This diamagnetic susceptibility is −1/3 of the Pauli paramagnetic susceptibility given

by Eq. (25.61), provided of course that the values of μ∗ are the same (no eff[ective](#page-446-2) mass

corrections).

**Example Problem 25.1.** What is the total zero-field susceptibility for *T T*F due to Pauli paramagnetism and Landau diamagnetism if there are effective mass corrections *m* → *m*eff for the translational energies *h*¯ 2*k*2/2*m*eff for both, and also a correction for the magnetic moment

for Landau diamagnetism? **Solution 25.1.** For Pauli paramagnetism, we assume that μ∗ = μB, the Bohr magneton. For the Landau diamagnetism, we need μ∗ = *r*μB, where *r* = *m*/*m*eff. According to Eq. (25.8), the

Fermi energy depends on mass, so we should use *r*εF in place of εF. In view of Eq. (25.62), we

$$\chi_{\rm tot} = \left(1 - \frac{r^2}{3}\right) \frac{3}{2} \frac{n(\mu_{\rm B})^2}{r \varepsilon_{\rm F}} \left[1 - \frac{\pi^2}{12} \left(\frac{k_{\rm B}T}{r \varepsilon_{\rm F}}\right)^2 + \cdots \right]. \tag{25.78}$$

*Chapter 25* • Degenerate Fermi Gas 439

### have the low temperature result

χtot = 1 − *r*2 3 3 2 *n*(μB)2 *r*εF 1 − π2 12 *k*B*T r*εF 2 +···  . (25.78) 25.6 Thermionic Emission If a metal is [hea](#page-459-0)ted, electrons can acquire sufficient energy to escape, a process known as thermionic emission. The process is somewhat similar to effusion, treated for a classical gas in Section 20.1.1, except for effusion one calculates the slow rate of escape through a small hole in a cavity. For thermionic emission, one considers the possibility that electrons moving in a given direction, say the *z*-direction, can overcome a potential energy barrier *W*∗ that keeps the otherwise free electrons in the metal to begin with. We measure *W*∗ from the zero of energy used for free electrons inside the metal. We can think of *W*∗ as being made up of two parts, a positive part *W*0 that would be necessary to remove an electron very far from the metal in the absence of surface relaxation effects, and another positive part *Ws* due to surface relaxation that accounts for a layer of surface dipoles (called the double layer).7 What we actually calculate is the flux *J* through an imaginary small window of area *a* perpendicular to the *z*-direction, recognizing, however, that the electrons can

escape in all directions. Moreover, we assume that the rate of escape is so slow that the system remains in quasi-equilibrium. We also assume that electrons are continuously supplied to the metal by a suitable electrical circuit so that the metal remains electrically neutral. Since we know that electrons in a metal obey Fermi-Dirac statistics, they fill energy levels up to the Fermi energy εF even at *T* = 0. Therefore, we anticipate that they start out with an energetic boost of approximately εF so that they only have a barrier *W* = *W*∗ − εF

<span id="page-459-0"></span>to overcome. This turns out approximately to be the case, and follows naturally from a

-

-

*V* -

the metal.

Mermin [58, p. 354].

$$J = \frac{2}{V} \sum_{k_{\mathcal{I}}} \sum_{k_{\mathcal{I}}} \sum_{k_{\mathcal{Z}} > k_{\mathcal{Z}}^{\prime}} \frac{1}{\exp\left\{\beta \| (\hbar^2 k^2 / 2m) - \mu \| \right\} + 1} \frac{\hbar k_{\mathcal{Z}}}{m},\tag{25.79}$$

*m* , (25.79)

*kx ky kz*>*k*∗ *z* 7Surface relaxation can be quite complicated and the value of the potential experienced by an electron outside a metal can depend on surface condition and surface charges that depend on surface orientation. To remove this complication in the case where all surfaces are not equivalent, one considers the electron to be removed from the metal only to a point sufficiently far outside the double layer that the electron no longer experiences any changes due to the presence of the double layer but not so far away as to be influenced by fields external to the metal, for example due to surface charges. For a more comprehensive discussion see Ashcroft and

exp {β[(*h*¯ 2*k*2/2*m*) − μ]} + 1

*J* = 4π

smaller flux of charge8

<span id="page-460-1"></span>∞

<span id="page-460-0"></span>*W*∗

440 THERMAL PHYSICS

$$J = \frac{2}{(2\pi)^3} \int_{-\infty}^{\infty} \mathrm{d}k_x \int_{-\infty}^{\infty} \mathrm{d}k_y \int_{k_z^a}^{\infty} \mathrm{d}k_z \frac{1}{\exp\left(\beta \|(\hbar^2 k^2 / 2m) - \mu\|\right) + 1} \frac{\hbar k_z}{m}.\tag{25.80}$$

where *k*∗ *z* = (2*mW*∗/*h*¯ 2)1/2 is assumed to be the threshold value of *kz* needed for escape. The quantity *hk*¯ *z*/*m* plays the role of velocity in the *z*-direction and the remainder of the expression is the number density of eligible electrons. The factor of 2 is due to

$$J = \frac{4\pi}{mh^3} \int_0^\infty p' \,\mathrm{d}p' \int_{p_2^*}^\infty p_2 \,\mathrm{d}p_2 \frac{1}{\exp\left[\beta l(p'^2/2m) + (p_2^2/2m) - \mu\right] + 1},\tag{25.81}$$

*J* = 2 (2π )3 −∞ d*kx* −∞ d*ky k*∗ *z* d*kz* exp {β[(*h*¯ 2*k*2/2*m*) − μ]} + 1 *m* . (25.80) We then pass to cylindrical coordinates *hk*¯ *x* = *p* cos ϕ, *hk*¯ *y* = *p* sin ϕ, and *hk*¯ *z* = *pz* and do

$$J = \frac{4\pi mk_{\rm B}T}{h^3} \int_{W^*}^{\infty} d\varepsilon_2 \ln(1 + \exp[-\beta(\varepsilon_2 - \mu)]).\tag{25.82}$$

*mh*3 0 *p*∗ *z* exp {β[(*p*2/2*m*) + (*p*2 *z*/2*m*) − μ]} + 1 where *p*∗ *z* = (2*mW*∗)1/2. We perform the int[egral](#page-452-1) [o](#page-452-1)ver *p* and change variables to ε*z* = *p*2 *z*/2*m* to obtain

$$J = \frac{4\pi mk_{\rm B}T}{h^3} \int_{W^*}^{\infty} \mathrm{d}\varepsilon_2 \exp[-\beta(\varepsilon_2 - \mu)] = \frac{4\pi m(k_{\rm B}T)^2}{h^3} \exp[-\beta(W^* - \mu)].\tag{25.83}$$

To proceed, we make the approximation that *W*∗−μ *k*B*T* which means that exp[−β(ε*z*− μ)] 1 in the range of integration. We can therefore expand the logarithm to obtain *J* = 4π*mk*B*T h*3 ∞ dε*z* exp[−β(ε*z* − μ)] = 4π*m*(*k*B*T*)2 *h*3 exp[−β(*W*∗ − μ)]. (25.83)

$$J_{\rm q} = |\mathbf{e}| \frac{4\pi m (k_{\rm B} T)^2}{h^3} \exp(-\beta \mathcal{W}),\tag{25.84}$$

electron to get the magnitude of the flux of charge *J*q = |*e*| 4π*m*(*k*B*T*)2 *h*3 exp(−β*W*), (25.84) where *W* = *W*∗ − εF is the work function of the metal, introduced previously. This result is

known as the **Richardson-Dushman equation** and is supported by experiment if reduced by a transmission coefficient that accounts for the surface condition of the metal and the simplifying assumptions that have been made about the barrier for escape. As anticipated, the energy barrier *W*∗ is reduced to *W* = *W*∗ − εF since at *T* = 0, the electrons already occupy energy levels up to εF. If the electron gas had behaved like a

$$J_{\mathbf{q}}^{\text{class}} = |\mathbf{e}| \left(\frac{k_{\text{B}}T}{2\pi m}\right)^{1/2} \exp(-\beta W^{*})\tag{25.85}$$

*J*class q = |*e*| 2π*m* exp(−β*W*∗) (25.85)

free electrons in metals at any reasonable temperature because of their high density and the small electron mass.

with a higher activation energy *W*∗ and a prefactor proportional to *T*1/2 instead of *T*2. 8We write this formula only for the sake of comparison, recognizing that it is not true because *n*/*n*Q(*T*) 1 for

*Chapter 25* • Degenerate Fermi Gas 441 25.6.1 Schottky Effect An electric field of strength *E* at the surface of a metal and directed toward the metal is known to enhance thermionic emission. This is known as the **Schottky effect**, which is reasonable to expect because an electron outside the metal, having a negative charge, would experience a force in the opposite direction of the field. If *z* measures distance outside the metal, the electrical potential due to the electric field is *Ez* and the potential energy of an electron at distance *z* due to the field is −*eEz*, all relative to the energy *W*0. But an electron at distance *z* outside the metal creates an electric field of its own that must be

$$\int_{z}^{\infty} -e^{2}/(2z)^{2} \,\mathrm{d}z = -e^{2}/(4z),\tag{25.86}$$

to this image charge (really the induced surface charge) will be −*e*2/(2*z*)2, so the electron will be attracted to[ward](#page-460-0) [t](#page-460-0)he metal. The potential energy felt by the electron due to this image effect will be ∞ *z* −*e*2/(2*z*) 2 d*z* = −e2/(4*z*), (25.86)

$$\mathcal{W}_{\rm E} = \mathcal{W}^* - e(e\mathcal{E})^{1/2} - s_{\rm F} = \mathcal{W} - e(e\mathcal{E})^{1/2} \tag{25.87}$$

has a maximum at *z* = (*eE*)1/2/2 where its value is −*e*(*eE*)1/2. The barrier for escape to far distances from the surface at which the electric field is applied therefore be[comes](#page-460-0) *W*0 + *Ws* − *e*(*eE*) 1/2 = *W*∗ − *e*(*eE*) 1/2, resulting in an effective work function *W*E = *W*∗ − *e*(*eE*) 1/2 − εF = *W* − *e*(*eE*) 1/2 (25.87)

### instead of *W* in Eq. (25.84). In SI units, −*e*(*eE*)1/2 → −*e*(*eE*/4π0)1/2 = (1.44×10−9*E*)1/2 [eV](#page-460-1), where *E* is measured in V/m. To reduce *W* by even 0.1 eV would require a large field,

*h*3

*W*∗−*h*ν

which now becomes

penetration of *E* into the metal.

*E* ∼ 7 × 106 V/m. Typically, *W* is 2-4 eV. 25.6.2 Photoelectric Effect If photons of monochromatic light of frequency ν enter a metal, they can collide with electrons and reduce the barrier for emission from *W*∗ to *W*∗ − *h*ν. If *h*ν *W*∗, Eq. (25.84) will apply with *W* replaced by *W* − *h*μ, analogous to the small reduction in the effective work function caused by an applied electric field. But in the case of sufficiently energetic

$$J = \frac{4\pi mk_{\rm B}T}{h^3} \int_{W^*-hv}^{\infty} \mathrm{d}\varepsilon_2 \ln(1 + \exp[-\beta(\varepsilon_2 - \mu)]).\tag{25.88}$$

dε*z* ln{1 + exp[−β(ε*z* − μ)]}. (25.88)

<sup>9</sup>Recall that we ignored the effect of surface charges and external fields in the result that led to the work function *W*. The presence of the field *E* itself also requires a positive surface charge on the metal to prevent

$$J = \frac{4\pi m (k_{\rm B}T)^2}{h^3} \int_0^\infty \mathrm{d}u \ln(1 + \exp[\beta(h\nu - \mathcal{W}^* + \mu) - \mu]).\tag{25.89}$$

$$J = \frac{4\pi m(k_B T)^2}{h^3} \int_0^\infty \mathrm{d}u \ln(1 + \exp[\beta h(\nu - \nu_0) - \mu]).\tag{25.90}$$

We substitute ε*z* = *uk*B*T* + *W*∗ − *h*ν to obtain

and integrate by parts to obtain

$$
\lambda_{\nu} \coloneqq \exp[\beta h(\nu - \nu \emptyset)] \tag{25.91}
$$

Then approximating *W*∗ − μ ≈ *W*∗ − εF = *W* and defining ν0 := *W*/*h*, we obtain

*J* = 4π*m*(*k*B*T*)2 *h*3

$$\int_0^\infty \mathrm{d}u \ln[1 + \lambda_\nu \,\mathrm{e}^{-u}] = \int_0^\infty \mathrm{d}u \frac{u}{\lambda_\nu^{-1} \,\mathrm{e}^u + 1} = f_2(\lambda_\nu),\tag{25.92}$$

We introduce the notation

 ∞ 0

$$J = \frac{4\pi m(k_{\rm B}T)^2}{h^3} f_2(\lambda_v). \tag{25.93}$$

 ∞ 0 d*u* ln[1 + λν e−*u*] = ∞ 0 d*u u* λ−1 ν e*u* + 1 = *f*2(λν ), (25.92) where *f*2(λν) = *h*2(λμ, 1) is given by Eq. (23.15). We therefore have *J* = 4π*m*(*k*B*T*)2 *h*3 *f*2(λν ). (25.93)

$$J_{\rm sat} = \frac{2\pi m}{h}(\upsilon - \upsilon_0)^2\tag{25.94}$$

[2](#page-463-0) (25.94)

asymptotic form (see Eq. (23.35)) *f*2(λν ) ∼ ln(λν)2/2 = β2*h*2(ν − ν0)2, so *J* saturates at a

### *J*sat = 2π*m*

val[ue](#page-447-2)

that is independent of temperature. 25.7 Semiconductors In this section, we treat the statistical mechanics of semiconductors based on single particle states (orbitals) of an electron in an effective periodic potential due to interaction with a crystal lattice. Thus the density of states is no longer given by the free electron result,

<span id="page-462-0"></span>*h* (ν − ν0)

$$\mathbf{g}(\boldsymbol{\varepsilon}) = \begin{cases} \mathbf{g}_{\boldsymbol{\nu}}(\boldsymbol{\varepsilon}) & \text{for } \mathbf{0} \le \boldsymbol{\varepsilon} \le \boldsymbol{\varepsilon}_{\text{V}} \\ \mathbf{0} & \text{for } \boldsymbol{\varepsilon}_{\text{V}} < \boldsymbol{\varepsilon} < \boldsymbol{\varepsilon}_{\text{C}} = \boldsymbol{\varepsilon}_{\text{V}} + \boldsymbol{\varepsilon}_{\text{g}} \\ \mathbf{g}_{\boldsymbol{\varepsilon}}(\boldsymbol{\varepsilon}) & \text{for } \boldsymbol{\varepsilon}_{\text{C}} < \boldsymbol{\varepsilon}. \end{cases} \tag{25.95}$$

⎪⎪⎩ *g*c(ε) for εc < ε. The region of width εg = εc − εv, where *g*(ε) = 0 is known as a **band gap** that separates the

**valence band** *g*v(ε) from the **conduction band** *g*c(ε). We consider a material for which the valence band is completely full and the conduction band is completely empty at *T* = 0. In this condition, each electron is in a definite

state and cannot move in response to an applied electric field, so the material will behave

<span id="page-463-0"></span>![](_page_463_Figure_1.jpeg)

g(ε) gv(ε) gc(ε) εg

εv εc ε **FIGURE 25–2** Sketch of density of states *g*(ε) given by Eq. (25.95) versus electron energy ε for a simple semiconductor. The size εg of the band gap is exaggerated for the sake of illustration. as an insulator. For *T* > 0, some electrons will be excited into the conduction band, leaving unoccupied states called **holes** in the valence band. Under these conditions, electrons in both the valence and conduction bands can move in response to an electric field and the material can conduct electricity. Provided that εg *k*B*T*, only a small number of electrons will be excited to the conduction band. For *T* = 300 K, we have *k*B*T* = 0.026 eV. If εg ≥ 10 eV, hardly any electrons will be excited into the conduction band and the material will be a good insulator. However, if εg ∼ 1 eV or less, there will be a significant number of electrons excited to the conduction band, accompanied by a dramatic increase in electrical conductivity at *T* = 300 K. Such a material is called an **i[ntrinsi](#page-462-0)c semiconductor**. Certain **dopants**, which are foreign atoms of very low concentrations, can be substituted for host atoms in the material and can greatly modify this behavior. Dopants referred to as **donors** can lead to a greatly enhanced number of electrons in the conduction band

### band. Strongly doped materials are called **extrinsic semiconductors**. We first treat the intrinsic cas[e and th](#page-465-0)en show how dopants can be accounted for.

25.7.1 Intrinsic Semiconductors

*N*

0

<span id="page-463-1"></span>whereas so-called **acceptors** can lead to a greatly enhanced number of holes in the valence

$$\frac{\mathcal{N}}{V} = \int_{0}^{v_{V}} \mathbf{g}_{V}(\boldsymbol{\varepsilon}) \, \mathrm{d}\boldsymbol{\varepsilon}; \quad T = \mathbf{0},\tag{25.96}$$

*N V* = εv 0 *g*v(ε) dε; *T* = 0, (25.96) where *N* is the number of valence electrons. This will be true if the Fermi energy εF is at εv or anywhere else within the band gap because there are no states in the gap. By extrapolation from *T* > 0, we will see later that εF is located near the middle of the band

εc

$$\frac{\mathcal{N}}{V} = \int_0^{\varepsilon_{\mathbb{R}}} \mathbf{g}_{\mathbb{V}}(\varepsilon) \frac{1}{\mathbf{e}^{\beta(\varepsilon-\mu)} + 1} d\varepsilon + \int_{\varepsilon_{\mathbb{C}}}^{\infty} \mathbf{g}_{\mathbb{C}}(\varepsilon) \frac{1}{\mathbf{e}^{\beta(\varepsilon-\mu)} + 1} d\varepsilon. \tag{25.97}$$

<span id="page-464-2"></span>*[n](#page-464-1)* =

<span id="page-464-3"></span><span id="page-464-0"></span>
$$-\int_{0}^{\varepsilon_{\rm{V}}} \mathbf{g}_{\mathbf{V}}(\varepsilon) \frac{1}{1 + \mathbf{e}^{-\beta(\varepsilon - \mu)}} \, \mathrm{d}\varepsilon + \int_{\varepsilon_{\rm{C}}}^{\infty} \mathbf{g}_{\mathbf{f}}(\varepsilon) \frac{1}{\mathbf{e}^{\beta(\varepsilon - \mu)} + 1} \, \mathrm{d}\varepsilon = \mathbf{0}.\tag{25.98}$$

444 THERMAL PHYSICS

$$n = \int_{\varepsilon_{\mathbb{C}}}^{\infty} \mathbf{g}_{\mathbf{c}}(\varepsilon) \frac{1}{\mathbf{e}^{\beta(\varepsilon-\mu)} + 1} \, \mathrm{d}\varepsilon \approx \int_{\varepsilon_{\mathbb{C}}}^{\infty} \mathbf{g}_{\mathbf{c}}(\varepsilon) \mathbf{e}^{-\beta(\varepsilon-\mu)} \, \mathrm{d}\varepsilon,\tag{25.99}$$

− εv 0 *g*v(ε) 1 1 + e−β(ε−μ) dε + ∞ εc *g*c(ε) 1 eβ(ε−μ) + 1 dε = 0. (25.98) The second term in Eq. (25.97) is the concentration of electrons in the conduction band, namely,

<span id="page-464-1"></span>
$$p = \int_0^{\varepsilon_V} \mathbf{g}_{\mathbf{V}}(\varepsilon) \frac{1}{1 + \mathbf{e}^{-\beta(\varepsilon - \mu)}} \, \mathrm{d}\varepsilon \approx \int_0^{\varepsilon_V} \mathbf{g}_{\mathbf{V}}(\varepsilon) \mathbf{e}^{-\beta(\mu - \varepsilon)} \, \mathrm{d}\varepsilon,\tag{25.100}$$

wher[e](#page-469-0) [the](#page-469-0) [se](#page-469-0)cond [approx](#page-469-1)imate form follows, provided that ε − μ *k*B*T* in the range of integration, wh[ich](#page-464-0) [we](#page-464-0) assume for now to be the case. Similarly, the negative of the first term in Eq. (25.98) is defined to be the concentration *p* of **holes**, which are hypothetical *positive* charge carriers in the valence band. Thus *p* = εv 0 *g*v(ε) 1 1 + e−β(ε−μ) dε ≈ εv 0 *g*v(ε)e−β(μ−ε) dε, (25.100) where now μ − ε *k*B*T* in this range [of inte](#page-464-2)gration. When the appro[ximate](#page-464-0) forms in

Eqs. (25.99) and (25.100) are valid, which will be the case if εg *k*B*T* and μ remai[ns near](#page-464-3)

$$pn = \left[\int_{0}^{\varepsilon_{\mathrm{V}}} \mathbf{g}_{\mathrm{V}}(\varepsilon) \mathbf{e}^{\beta \varepsilon} \, \mathrm{d}s \right] \left[\int_{\varepsilon_{\mathrm{E}}}^{\infty} \mathbf{g}_{\mathrm{C}}(\varepsilon) \mathbf{e}^{-\beta \varepsilon} \, \mathrm{d}s \right],\tag{25.101}$$

overall charge neutrality. By using the approximate forms for *n* and *p*, we see that *pn* = εv 0 *g*v(ε)eβε dε ∞ εc *g*c(ε)e−βε dε , (25.101) which is independent of μ. Equation (25.101) is independent of Eq. (25.98) provided that *n* and *p* are given by the approximate forms on the right-hand sides of Eqs. (25.99)

and (25.100), respectively, and is known as the **law of mass action**. 10 In the degenerate case, *pn* is given by Eq. (25.134) of Section 25.7.3, where we also treat doped extrinsic

<span id="page-464-4"></span>
$$n = \mathbf{e}^{-\beta c_{\mathcal{E}}} \mathbf{e}^{\beta \mu} \int_{0}^{\infty} \mathbf{g}_{\mathcal{E}} (\nu + \varepsilon_{\mathcal{E}}) \mathbf{e}^{-\beta w} \, \mathrm{d}w \tag{25.102}$$

and

semiconductors.

ε = εv [−](#page-464-3) *w* [wh](#page-469-2)[ich](#page-464-1)[r](#page-464-1)[esults in](#page-469-2)

25.7.3 and Kittel and Kroemer [6, p. 365] for details.

$$p = \mathbf{e}^{\beta \epsilon_{\rm V}} \mathbf{e}^{-\beta \mu} \int_{0}^{\epsilon_{\rm V}} \mathbf{g}_{\rm V}(\varepsilon_{\rm V} - \nu) \mathbf{e}^{-\beta \mu} \, \mathrm{d}w. \tag{25.103}$$

*g*v(εv − *w*)e−β*w* d*w*. (25.103)

10This is by analogy to a gaseous chemical reaction of the form AB = A + B; in the present case, we would think of an electron-hole pair dissociating into an electron and a hole. In the event that the approximate forms of Eqs. (25.99) and (25.100) do not hold, as is the case for degenerate semiconductors that result from high doping levels, modification is required because the full Fermi-Dirac distribution function must be used. See Section

0

*Chapter 25* • Degenerate Fermi Gas 445

<span id="page-465-5"></span>
$$\mathbf{g}_{\rm c}(\boldsymbol{w} + \boldsymbol{\varepsilon}_{\rm c}) = 2 \frac{2}{\pi^{1/2}} \left( \frac{m_{\rm h}}{2\pi \hbar^2} \right)^{3/2} w^{1/2}; \quad \mathbf{g}_{\rm v}(\boldsymbol{\varepsilon}_{\rm v} - \boldsymbol{w}) = 2 \frac{2}{\pi^{1/2}} \left( \frac{m_{\rm p}}{2\pi \hbar^2} \right)^{3/2} w^{1/2}. \tag{25.104}$$
 
$$\text{Thon now obtain}$$

semiconductor physics, according to which these densities of state near the band gap can

*g*c(*w* + εc) = 2

2 π1/2

<span id="page-465-4"></span><span id="page-465-0"></span>*mnk*B*T*

be confused with the Fermi energy, which is the value of μ at *T* = 0.

3/2

$$n = n^* \mathbf{e}^{-\beta(\epsilon_\ell - \mu)}; \quad p = p^* \mathbf{e}^{-\beta(\mu - \epsilon_\ell)},\tag{25.105}$$

would be

where

<span id="page-465-3"></span><span id="page-465-1"></span>
$$n^* = 2\left(\frac{m_n k_\mathrm{B} T}{2\pi \hbar^2}\right)^{3/2}; \quad p^* = 2\left(\frac{m_p k_\mathrm{B} T}{2\pi \hbar^2}\right)^{3/2}.\tag{25.106}$$

Then we obtain *n* = *n*∗e−β(εc[−](#page-464-0)μ); *p* = *p*∗e−β(μ−εv) [,](#page-465-1) (25.105)

$$pm = p^* n^* \mathbf{e}^{-\beta \varepsilon_{\mathbf{g}}}.\tag{25.107}$$

*n*∗ = 2 2π*h*¯ [2](#page-465-2) ; *p*∗ = 2 2π*h*¯ 2 . (25.106) We note that *n*∗ and *p*∗ each have the form of a quantum concentration of an ideal gas

$$
\mu_{\rm l} = \frac{\varepsilon_{\rm v} + \varepsilon_{\rm c}}{2} + \frac{k_{\rm B}T}{2} \ln\left(\frac{p^*}{n^*}\right) = \varepsilon_{\rm v} + \frac{1}{2}\varepsilon_{\rm g} + \frac{3k_{\rm B}T}{4} \ln\left(\frac{m_{\rm p}}{m_{\rm n}}\right),
\tag{25.108}
$$

For an intrinsic semiconductor, Eq. (25.98) requires *p*i = *n*i, where we have added the subscript "i" to denote the intrinsic case. Then from Eq. (25.105) we obtain μi = εv + εc 2 + *k*B*T* 2 ln*p*∗ *n*∗ = εv + 1 2 εg + 3*k*B*T* 4 ln*mp mn* , (25.108) which locates the chemical potential11 very near the middle of the band gap. If *mn* = *mp*,

$$n_{\!\!\!\!/} = p_{\!\!\!\!/} = \left(p^* n^*\right)^{1/2} \mathbf{e}^{-\beta \epsilon_{\emptyset}/2}.\tag{25.109}$$

taking the square root of Eq. [(25.107](#page-465-4)), we find the individual concentrations

<span id="page-465-2"></span>*n*i = *p*i = *p*∗*n*∗1/2 e−βεg/2. (25.109) **Example Problem 25.2.** For silicon, εg = 1.14 eV and at *T* = 300 K one has *k*B*T* = 0.0259 eV, *p*∗ = 1.1 × 1019 cm−3, and *n*∗ = 2.7 × 1019 cm−3. Silicon is diamond cubic with a cube edge of *a* = 3.57 × 10−8 cm; there are eight atoms in each cube and each has a valence of 4. Calculate

*n*i and compare with the total valence electron concentration *N* /*V*. Then calculate μi − εv and compare with the middle of the band gap. **Solution 25.2.** From Eq. (25.109) we calculate *p*∗*n*∗1/2 = 1.7 × 1019 cm−3 and also exp(−βεg/2) = 2.77 × 10−10. Thus *n*i = *p*i = 4.8 × 109 cm−3. Since *N* /*V* = 32/*a*3 = 7.0 ×

1023 cm−3, the ratio of *n*i to *N* /*V* is 6.8×10−15. We first calculate (*k*B*T*/2)ln(*p*∗/*n*∗) = −0.012 eV 11In the semiconductor literature, the chemical potential μ is usually called the Fermi level, which should not 446 THERMAL PHYSICS

25.7.2 Semiconductors with Dopants

whereas εg/2 = 0.57 eV. Thus, μi − εv = 0.56 eV, about 2% lower than the middle of the band gap.

$$n - p = \Delta,\tag{25.110}$$

As mentio[ned abo](#page-465-4)ve, dopants known as donors and acceptors can be substituted for host atoms to affect the carrier concentrations of electrons in the conduction band and holes

$$pn = n_1^2,\tag{25.111}$$

*n* − *p* = , (25.110)

*pn* = *n*2

$$n - \frac{n_{\parallel}^2}{n} = \Delta,\tag{25.112}$$

Problem 25.3 below for more detail.

*n* =

$$n = \sqrt{n_{\text{l}}^2 + (\Delta/2)^2} + \Delta/2; \quad p = \sqrt{n_{\text{l}}^2 + (\Delta/2)^2} - \Delta/2. \tag{25.113}$$

i , (25.111)

*n* [=](#page-464-3) , (25.112) which can be solved to yield

<span id="page-466-1"></span><span id="page-466-0"></span>
$$n \approx (\Delta + |\Delta|)/2 + n_{\parallel}^2/|\Delta|; \quad p \approx (-\Delta + |\Delta|)/2 + n_{\parallel}^2/|\Delta|,\tag{25.114}$$

For (
/2)2 *n*2 i , the semiconductor is said to be extrinsic (dominated by dopants) and

*n* ≈ ( + | |)/2 [+](#page-466-0) *n*2 i /| |; *p* ≈ (− + | |)/2 + *n*2 i /| |, (25.114)

$$n = m_{\!\!\!\!/} \mathbf{e}^{\beta(\mu-\mu_{\!\!\!/})}; \quad p = m_{\!\!\!\!/} \mathbf{e}^{-\beta(\mu-\mu_{\!\!\!/})} \tag{25.115}$$

By using the a[pproximate fo](#page-467-0)rms in Eqs. (25.99) and (25.100), we can write

be replaced by

$$
\Delta/2 = n_{\rm l} \sinh[\beta(\mu - \mu_{\rm l})].\tag{25.116}
$$

from wh[ich](#page-469-3) /2 = *n*i sinh[β(μ − μi)]. (25.116)

$$|\Delta/2| \ll \eta_1 \sinh[\beta \varepsilon_{\rm g}/2],\tag{25.117}$$

|/2| *n*i sinh[βεg/2], (25.117) but this still allows |/2*n*i| to be fairly large. In the extrinsic limit, μ approaches either εc or εv, shown in Figure 25–3, depending on the sign of | |. If | | becomes comparable to *p*∗ or *n*∗, the chemical potential shifts so far from the center of the band gap that the approximate forms of Eqs. (25.99) and (25.100) are no longer valid. See the Example

![](_page_467_Figure_1.jpeg)

<span id="page-467-0"></span>Conduction band

εd εc

εv Valence band εa εg **FIGURE 25–3** [Schematic diagram of the valence and conduction bands with acceptor levels at](#page-467-0) εa just above the valence band (which lies below εv), and donor levels at εd just below the conduction band (which lies above εc). We now proceed to calculate . A donor12 provides one more valence electron than a host atom, and this extra electron can possibly be added to the pool of electrons that are subject, to a first approximation, to the effective periodic potential. However, if the extra electron is not localized near the donor site, the core of the donor atom, which consists of its nucleus and other bound electrons, would appear to have a net positive charge (relative to the host atoms). By analogy with the hydrogen atom, but in a medium with a greatly altered dielectric constant, a donor can be regarded as a localized defect that has a weakly bound state at an energy εd that is slightly below εc, as illustrated in Figure 25–3. We assume that the number of donors is *N*d *N* , where *N* is still the number of valence electrons for the intrinsic case. Since these defects are quite dilute, they can be treated by means of the grand canonical ensemble in which the bulk of the system imposes a chemical potential μ, corresponding to an absolute activity λ = eβμ. There

$$\mathcal{N}_{\rm d} \frac{2\lambda \mathbf{e}^{-\beta \varepsilon_{\rm d}}}{1 + 2\lambda \mathbf{e}^{-\beta \varepsilon_{\rm d}}} = \mathcal{N}_{\rm d} \frac{1}{(1/2)\mathbf{e}^{\beta(\varepsilon_{\rm d} - \mu)} + 1} \approx \mathcal{N}_{\rm d} 2\mathbf{e}^{-\beta(\varepsilon_{\rm d} - \mu)} \ll \mathcal{N}_{\rm d}.\tag{25.118}$$

a localized electron is *N*d 2λe−βεd 1 + 2λe−βεd = *N*d 1 (1/2)eβ(εd−μ) + 1 ≈ *N*d2e−β(εd−μ) *N*d, (25.118)

$$\mathcal{N}_{\mathbf{d}}^{+} \equiv \mathcal{N}_{\mathbf{d}} \frac{1}{1 + 2\lambda \mathbf{e}^{-\beta \varepsilon_{\mathbf{d}}}} = \mathcal{N}_{\mathbf{d}} \frac{1}{1 + 2\mathbf{e}^{-\beta(\varepsilon_{\mathbf{d}} - \mu)}} \approx \mathcal{N}_{\mathbf{d}} (1 - 2\mathbf{e}^{-\beta(\varepsilon_{\mathbf{d}} - \mu)}) \sim \mathcal{N}_{\mathbf{d}}.\tag{25.119}$$

*N* + d ≡ *N*d 1 1 + 2λe−βεd = *N*d 1 1 + 2e−β(εd−μ) ≈ *N*d(1 − 2e−β(εd−μ)) ∼ *N*d. (25.119)

In other words, if there are *N*d donors, practically all of them will donate an electron to the bands, provided that the given restrictions on μ are valid. An acceptor13 provides one less electron than a host atom. Its core therefore appears

to have a net negative charge unless a hole is bound to the acceptor site. A hole bound 12For example, one could dope silicon with the donor phosphorus. For the host silicon, each Si atom, atomic number 14, provides four valence electrons (3*s*23*p*2). Each donor atom P, atomic number 15, that is substituted

for Si provides five valence electrons (3*s*23*p*3). 13If the host atom is Si, each acceptor atom Al, atomic number 13, that is substituted for Si provides three valence electrons (3*s*23*p*).

448 THERMAL PHYSICS to an acceptor site essentially means that an electron is rejected from the site. If a hole is

$$\mathcal{N}_{\mathbf{a}}^{-} \equiv \mathcal{N}_{\mathbf{a}} \frac{\lambda \mathbf{e}^{-\beta \varepsilon_{\mathbf{a}}}}{2 + \lambda \mathbf{e}^{-\beta \varepsilon_{\mathbf{a}}}} = \mathcal{N}_{\mathbf{a}} \frac{1}{2 \mathbf{e}^{\beta(\varepsilon_{\mathbf{a}} - \mu)} + 1} \approx \mathcal{N}_{\mathbf{4}} (1 - 2 \mathbf{e}^{-\beta(\mu - \varepsilon_{\mathbf{a}})}) \sim \mathcal{N}_{\mathbf{a}},\tag{25.120}$$

a bond. If a hole is bound to an acceptor site, an electron of either spin has left the site,

$$\mathcal{N}_{\mathbf{a}} \frac{2}{2 + \lambda \mathbf{e}^{-\beta \varepsilon_{\mathbf{a}}}} = \mathcal{N}_{\mathbf{a}} \frac{1}{1 + (1/2)\mathbf{e}^{\beta(\mu - \varepsilon_{\mathbf{a}})}} \approx \mathcal{N}_{\mathbf{a}} (\mathbf{e}^{-\beta(\mu - \varepsilon_{\mathbf{a}})}) \ll \mathcal{N}_{\mathbf{a}}.\tag{25.121}$$

*N* − a ≡ *N*a λe−βεa 2 + λe−βεa = *N*a 1 2eβ(εa−μ) + 1 ≈ *N*a(1 − 2e−β(μ−εa) ) ∼ *N*a, (25.120)

and the number of acceptor sites that are not occupied by a valence electron is

<span id="page-468-0"></span>*V*

*n*+

*n* + *n*−

$$\begin{aligned} \text{(Electrons in bands)} &= \text{(Valence electrons if all sites were host atoms)}\\ &+ \text{(Electrons freeed from donor)}\\ &- \text{(Electrons bound to acceptor)}. \end{aligned} \tag{25.122}$$

We can now establish the following balance for electrons: (Electrons in bands) = (Valence electrons i[f all site](#page-463-1)s were host atoms)

$$\begin{split} \int_{0}^{\varepsilon_{\text{V}}} \mathsf{g}_{\text{V}}(\varepsilon) \frac{1}{\mathsf{e}^{\beta(\varepsilon-\mu)} + 1} \, \mathrm{d}\varepsilon + \int_{\varepsilon_{\text{E}}}^{\infty} \mathsf{g}_{\text{E}}(\varepsilon) \frac{1}{\mathsf{e}^{\beta(\varepsilon-\mu)} + 1} \, \mathrm{d}\varepsilon \\ = \frac{N}{V} + \frac{N_{\text{d}}}{V} \frac{1}{1 + 2\mathsf{e}^{-\beta(\varepsilon_{\text{d}}-\mu)}} - \frac{N_{\text{d}}}{V} \frac{1}{2\mathsf{e}^{\beta(\varepsilon_{\text{d}}-\mu)} + 1}. \end{split} \tag{25.123}$$

 εv 0 *g*v(ε) 1 eβ(ε−μ) + 1 dε + εc *g*c(ε) 1 eβ(ε−μ) + 1 dε = *N V* + *N*d 1 1 + 2e−β(εd−μ) − *N*a 1 . (25.123)

$$
\Delta = n - p = n_{\rm d}^{+} - n_{\rm u}^{-}, \tag{25.124}
$$

given by Eqs. (25.99) and (25.100) [to](#page-468-0) [obtai](#page-468-0)n

where

namely,

$$n_{\rm d}^{+} = \frac{N_{\rm d}^{+}}{V} = n_{\rm d} \frac{1}{1 + 2\mathbf{e}^{-\beta(\varepsilon_{\rm d} - \mu)}};\tag{25.125}$$

$$n_{\mathbf{a}}^{-} = \frac{\mathcal{N}_{\mathbf{a}}^{-}}{V} = n_{\mathbf{a}} \frac{1}{2\mathbf{e}^{\beta(\varepsilon_{\mathbf{a}}-\mu)} + 1}. \tag{25.126}$$

*n*− a = *N* − a *V* = *n*a 1 2eβ(εa−μ) + 1 . (25.126) The quantity on the right-hand side of Eq. (25.124) is called the **net ionized donor concentration**. We note that Eq. (25.124) is just a statement of overall charge neutrality,

$$n + n_{\mathbf{a}}^{-} = p + n_{\mathbf{d}}^{+}.\tag{25.127}$$

d . (25.127)

<span id="page-469-3"></span>If is not too large, we will have μ ∼ μi ∼ εv + εg/2 which gives approximately = *n*d − *n*a to lowest order. See Kittel and Kroemer [6, p. 371] for an interesting graphical solution for μ [und](#page-465-1)er conditions of rather large for which μ becomes comparable to εd.

$$
\varepsilon_{\mathbb{C}} - \mu = k \mathbb{B} \operatorname{Tr} \ln(\mathfrak{n}^*/\Delta). \tag{25.128}
$$

*Chapter 25* [• Deg](#page-466-1)enerate Fermi Gas 449

<span id="page-469-0"></span>the breakdown of the approximation that leads to the second form of Eq. (25.99). Evaluate μ under conditions for which becomes sufficiently large that μ enters the conduction band. Then examine the same problem except for negative but of large magnitude. **Solution 25.3.** From Eq. (25.105) with *n* = we have

$$n = n^* \frac{1}{\Gamma(3/2)} \int_0^\infty \frac{u^{1/2}}{\lambda_\text{c}^{-1} \mathbf{e}^u + 1} \, \text{d}u = n^* f_{3/2}(\lambda_\text{c}), \tag{25.129}$$

exp[β(ε − μ)] will no longer be large in the range of integration. Thus, Eq. (25.105) is no longer valid. From the first form of Eq. (25.99) and with *g*c(ε) given by Eq. (25.104), we obtain *n* = *n*∗ 1 (3/2) ∞ 0 *u*1/2 λ−1 c e*u* + 1 d*u* = *n*∗*f*3/2(λc), (25.129)

<span id="page-469-1"></span>
$$
\mu - \varepsilon_{\rm 0} = \frac{\hbar^2}{2m_n} \left( 3\pi^2 \Delta \right)^{2/3} . \tag{25.130}
$$

3/2/(5/2) to obtain

large and we can use the asymptotic form *f*3/2(λc) = [β(μ − εc)] μ − εc = *h*¯ 2 2*mn* 3π2 2/3 . (25.130)

$$p = p^* \frac{1}{\Gamma(3/2)} \int_0^\infty \frac{u^{1/2}}{\lambda_\text{V}^{-1} \mathbf{e}^\mu + 1} \, \text{d}\mu = p^* f_{3/2}(\lambda_\text{V}) \tag{25.131}$$

*p* = *p*∗ 1 ∞ *u*1/2 d*u* = *p*∗*f*3/2(λv) (2[5.131)](#page-469-1)

$$
\varepsilon_{\rm V} - \mu = \frac{\hbar^2}{2m_p} \left( 3\pi^2 |\Delta| \right)^{2/3} . \tag{25.132}
$$

. (25.132)

(3/2)

εv − μ = *h*¯ 2

2*mp* 3π2| |

<span id="page-469-2"></span>limit of the integral),

into Eq. (25.124) gives

25.7.3 Degenerate Semiconductors Substitution of the more general expressions for *n* and *p* given by Eqs. (25.129) and (25.131)

2/3

replace Eq. (25.107) by

such as the Joyce-Dixon approximation [6, p. 366].

<span id="page-470-0"></span>
$$n^* f_{3/2}(\lambda_\mathbf{c}) - p^* f_{3/2}(\lambda_\mathbf{v}) = \frac{n_\mathbf{d}}{2\lambda_\mathbf{c} + 1} - \frac{n_\mathbf{a}}{2\lambda_\mathbf{v} + 1},\tag{25.133}$$

450 THERMAL PHYSICS *n*∗*f*3/2(λc) − *p*∗*f*3/2(λv) = *n*d 2λc + 1 − *n*a 2λv + 1 , (25.133) where λc = exp[β(μ−εc)] and λv = exp[β(εv−[μ)](#page-468-0)]. Since λvλc = exp(−βεg) < 1, Eq. (25.133)

$$pm = p^* n^* f_{\mathbb{Z}/\mathbb{Z}}(\lambda_\mathbb{V}) f_{\mathbb{Z}/\mathbb{Z}}(\lambda_\mathbb{C}) \tag{25.134}$$

*f*3/2(λc) ≈ λc and *f*3/2(λv) ≈ λv. Then one recovers the cases treated that are based on the approximate expressions on the right-hand side of Eqs. (25.99) and (25.100). If the doping is such that *either* λc or λv is not small, the semiconductor is said to be degenerate and the

*pn* = *p*∗*n*∗*f*3/2(λv)*f*3/2(λc) (25.134)

*f*3/2 functions associated with the dominant carrier must be used. Alternatively, one could

and then solve simultaneously with Eq. (25.124) by means of power series expansions,

26 Quantum Statistics In this chapter, we discuss several formal aspects of the statistical mechanics of quantum systems. Two types of averaging arise. The first type pertains to the intrinsically statistical nature of quantum mechanics itself and is present even when the system is in a pure quantum state |ψ(*t*) with wave function ψ(**r**,*t*) = **r**|ψ(*t*)-. The second type of averaging pertains to averages over many quantum states related to an ensemble used to represent a system for which complete information about its quantum state is not known. Such an ensemble might be used to represent a system in a state of thermodynamic equilibrium under some constraints, for example, near isolation or contact with a temperature reservoir. To treat such systems, it is convenient to introduce a statistical operator ρˆ that is known as the **density operator**. In terms of ρˆ, we shall see that the expectation value of some obs[er](#page-471-0)vable having operator ˆ *f* can be written in

### tation and also leads to approximation methods for problems that cannot be solved exactly.

assumed to be normalized, so

Schrödinger representation).

the form of a trace, tr(ˆ

26.1 Pure States

of the system. This allows us to express results in a manner independent of represen-

*f* ρ)ˆ , which is invariant if calculated for any complete set of states

$$
\langle \psi(t) | \psi(t) \rangle = \int \psi^*(\mathbf{r}, t) \psi(\mathbf{r}, t) \, d\mathbf{r} = 1. \tag{26.1}
$$

ψ (*t*)|ψ (*t*)- = - ψ∗(**r**,*t*)ψ (**r**,*t*) d**r** = 1. (26.1)

<span id="page-471-0"></span>
$$
\langle \hat{f} \rangle = \langle \psi(t) | \hat{f} | \psi(t) \rangle = \int \psi^*(\mathbf{r}, t) \hat{f}(\mathbf{r}) \psi(\mathbf{r}, t) \, \mathrm{d}\mathbf{r}, \tag{26.2}
$$

*f*-=ψ (*t*)|ˆ *f* |ψ (*t*)- = ψ∗(**r**,*t*)ˆ *f* (**r**)ψ (**r**,*t*) d**r**, (26.2) where ˆ *f* (**r**) is the corresponding operator (in general, a differential operator in the

<sup>1</sup>Here, the vector **r** denotes the coordinates of the entire system; for a system composed of *N* particles, **r** would have 3*N* components. The function ψ(**r**,*t*) is also assumed to carry information about nonclassical variables

452 THERMAL PHYSICS

$$
\hat{1} = \sum_{f} |f\rangle\langle f|.\tag{26.3}
$$

in which ˆ

|*f* -

Thus

$$
\langle \hat{f} \rangle = \langle \psi(t) | \hat{f} | \psi(t) \rangle = \sum_{f, f'} \langle \psi(t) | f' \rangle \langle f' | \hat{f} | \psi(t) \rangle = \sum_{f} | \langle f | \psi(t) \rangle |^2 f. \tag{26.4}
$$

unit operator 1 can be expressed in the form ˆ 2

$$|\psi(t)\rangle = \sum_{f} |f\rangle \langle f|\psi(t)\rangle. \tag{26.5}$$

|2*f* . (26.4)

*f*-=ψ (*t*)|ˆ *f* |ψ (*t*)- = ψ (*t*)|*f f* |ˆ *f* |*f f* |ψ (*t*)- = |*f* |ψ (*t*)-

*f* -

shows that tr(ρ)ˆ = 1. Alternatively, Eq. (26.10) shows that

integrate over the continuous spectrum if relevant.

= tr(ρˆˆ

<span id="page-472-0"></span>*f*

<span id="page-472-1"></span>
$$
\langle f \rangle = \sum_{f, f'} \langle f | \psi(t) \rangle \langle \psi(t) | f' \rangle \langle f' | \hat{f} | f \rangle = \sum_{f} \langle f | \hat{\rho} \hat{f} | f \rangle = \text{tr}(\hat{\rho} \hat{f}),
\tag{26.6}
$$

|ψ (*t*)-

The quantities *f* |ψ(*t*)-

$$
\hat{\rho} := |\psi(\mathbf{t})\rangle\langle\psi(\mathbf{t})|\tag{26.7}
$$

*f*- = *f* ,*f f* |ψ (*t*)ψ (*t*)|*f f* |ˆ *f* |*f* - = *f f* | ˆρ ˆ *f* |*f* - = tr(ρˆˆ *f* ), (26.6)

$$
\hat{\rho}\hat{\rho} = |\psi(t)\rangle\langle\psi(t)|\psi(t)\rangle\langle\psi(t)| = |\psi(t)\rangle\langle\psi(t)| = \hat{\rho}.\tag{26.8}
$$

is the **density operator** for the pure state |ψ(*t*)-. It is a **projection operator** onto the state |ψ(*t*)-, so ρˆρˆ = |ψ (*t*)ψ (*t*)|ψ (*t*)ψ (*t*)|=|ψ (*t*)ψ (*t*)|= ˆρ. (26.8)

$$
\langle \hat{f} \rangle = \text{tr}(\hat{\rho}\hat{f}) = \text{tr}(\hat{\!\!\hat{f}}\hat{\!\!\/}) = \sum_{n} \langle \phi_{n} | \hat{\!\!\/} \hat{\!\!\/} \hat{\!\!\/} | \phi_{n} \rangle \tag{26.9}
$$

*n* ρ*nn* = 1.

properties of the trace, we have

or in matrix form

$$
\langle f \rangle = \sum_{m,n} f_{nm} \rho_{mn},
\tag{26.10}
$$

*f*- = *m*,*n fnm*ρ*mn*, (26.10) where *fnm* = φ*n*|ˆ *f* |φ*m* and ρ*mn* = φ*m*|ψ(*t*)ψ(*t*)|φ*n*- = ρ∗ *nm*. The quantities ρ*mn* are the elements of the **density matrix** ρ, which is the matrix representation of the density operator, in this case for a pure state. By setting ˆ *f* equal to the unit operator, Eq. (26.9)

<sup>2</sup>It is possible to have a continuous spectrum of states as well as discrete states in which case the closure relation requires both integration over the complete spectrum as well as summation over the continuous spectrum (see Dirac [67, p. 37]). Schiff [57, p. 156] uses the symbol S*f* instead of a summation sign to indicate this process. For simplicity we use only the summation sign with the implicit understanding that one must also

*Chapter 26* • Quantum Statistics 453 26.2 Statistical States

$$
\langle f \rangle = \sum_{l} p_l \langle \psi_l(t) | \hat{f} | \psi_l(t) \rangle. \tag{26.11}
$$

**state**, also known as a **mixed state**. For convenience, we take the set of states |ψ*i*(*t*)- to be mutually orthonormal, although not necessarily complete. From the results of the preceding section, the average value in a statistical state of some observable represented by the operator ˆ *f* is therefore = *pi* ψ*i*(*t*)|ˆ

$$
\langle f \rangle = \sum_{l,n} p_l \langle \psi_l(t) | \hat{f} | \phi_n \rangle \langle \phi_n | \psi_l(t) \rangle = \sum_{l,n} p_l \langle \phi_n | \psi_l(t) \rangle \langle \psi_l(t) | \hat{f} | \phi_n \rangle = \text{tr}(\hat{\rho}^S \hat{f}), \tag{26.12}
$$

as a weighted average over the quantum states *i* = 1, 2, ..., each with probability *pi*, that make up the statistical state. By employing any complete set of states φ*n* for which the unit

*pi* ψ*i*(*t*)|ˆ

*f* |φ*n*-

|ψ*i*(*t*)-

<span id="page-473-2"></span><span id="page-473-0"></span>φ*n*|ψ*i*(*t*)-

ρˆ

*n* |φ*n*-

the system is in some pure state |ψ(*t*)-

*pi* of being in the pure state |ψ*i*(*t*)-

$$\hat{\rho}^S = \sum_l |\psi_l(t)\rangle p_l \langle \psi_l(t)|\tag{26.13}$$

*i*,*n i*,*n* where the Hermitian operator

$$
\langle f \rangle = \sum_{l,f} p_l f |\langle f \rangle \psi_l(t)\rangle|^2,\tag{26.14}
$$

to be eigenstates |*f* of ˆ *f* with eigenvalues *f* , we obtain *f*- = *i*,*f pi f* |*f* |ψ*i*(*t*)-|2, (26.14) which illustrates that two averaging processes are involved. One is quantum mechanical

<span id="page-473-1"></span>averaging with weighting factors |*f* |ψ*i*(*t*)-|2 given by the squares of the wave func-

=

*i*

*pi* 

*pi*ψ*i*(*t*)||φ*n*-

tr((ρˆ *S*)

$$\text{tr}(\hat{\rho}^S) = \sum_n \langle \phi_n | \sum_l | \psi_l(t) \rangle p_l \langle \psi_l(t) | | \phi_n \rangle = \sum_l p_l \sum_n \langle \psi_l(t) | \phi_n \rangle \langle \phi_n | \psi_l(t) \rangle = 1. \tag{26.15}$$

ψ*i*(*t*)|φ*n*-

tr(ρˆ *S*) =

*n* φ*n*| 

that state.

Moreover,

operator is

*f*-=

$$\langle \boldsymbol{\phi}^{\rm S} \rangle^2 = \sum_{l} |\psi_l(\mathbf{t})\rangle p_l \langle \psi_l(\mathbf{t})| \sum_{j} |\psi_j(\mathbf{t})\rangle p_j \langle \psi_j(\mathbf{t})| = \sum_{l} |\psi_l(\mathbf{t})\rangle p_l^2 \langle \psi_l(\mathbf{t})|.\tag{26.16}$$

φ*n*|ψ*i*(*t*)-

(ρˆ *S*) *i j i i* ψ*i*(*t*)|. (26.16) Since Eq. (26.8) holds for a pure state, Eq. (26.16) show that ρˆ*S* represents a pure state only

$$\text{tr}((\hat{\rho}^S)^2) = \sum_l p_l^2 \le 1,\tag{26.17}$$

= 1. (26.15)

Explicitly,

$$
\langle f \rangle = \text{tr}(\hat{\rho}^S \hat{f}) = \text{tr}(\hat{f}\hat{\rho}^S) = \sum_n \langle \phi_n | \hat{f} \hat{\rho}^S | \phi_n \rangle = \sum_{m,n} f_{nm} \rho_{mn}^S,\tag{26.18}
$$

454 THERMAL PHYSICS

with the equality holding only for a pure state. For an arbitrary basis |φ*n* we would have *f*- = tr(ρˆ *S* ˆ *f* ) = tr(ˆ *f* ρˆ *S*) = *n* φ*n*|ˆ *f* ρˆ *S*|φ*n*- = *m*,*n fnm*ρ*S mn*, (26.18)

where ρ*S mn* = *i* φ*m*|ψ*i*(*t*)*pi*ψ*i*(*t*)|φ*n*- = (ρ*S nm*)∗. 26.3 Random Phases and External Influence

$$|\Psi^{\mu}(t)\rangle = \sum_{j} \sqrt{p_j} \exp(i\omega_j) |\psi_j(t)\rangle,\tag{26.19}$$

R.B. Griffiths. The first rationalization is based o[n](#page-473-2) [the](#page-473-2) [a](#page-473-2)ssumption of random phases, for example, see

$$|\Psi^{\mathfrak{a}}(t)\rangle\langle\Psi^{\mathfrak{a}}(t)| = \sum_{j,k} \sqrt{p_j p_k} \exp[i(\alpha_j - \alpha_k)] |\psi_j(t)\rangle\langle\psi_k(t)|.\tag{26.20}$$

where the α*j* are a set of phases. Normalization requires *i pi* = 1. The projection operator for such a state is |α(*t*)α(*t*)| = *pjpk* exp[*i*(α*j* − α*k*)]|ψ*j*(*t*)ψ*k*(*t*)|. (26.20)

$$\begin{split} \overline{|\Psi^{a}(t)\rangle\langle\Psi^{a}(t)|} &= \sum_{j,k} \sqrt{p_{j}p_{k}} \overline{\exp[i(\alpha_{j}-\alpha_{k})]} \, |\psi_{f}(t)\rangle\langle\psi_{k}(t)| \\ &= \sum_{j,k} \sqrt{p_{j}p_{k}} \, \delta_{j\mathbf{k}} \, |\psi_{f}(t)\rangle\langle\psi_{k}(t)| = \sum_{j} p_{j} |\psi_{f}(t)\rangle\langle\psi_{f}(t)|. \end{split} \tag{26.21}$$

*j*,*k* = *j*,*k pjpk* δ*jk* |ψ*j*(*t*)ψ*k*(*t*)| = *j pj*|ψ*j*(*t*)ψ*j*(*t*)|. (26.21)

$$|\Psi^{\epsilon}(t)\rangle = \sum_{j} |\epsilon_{j}\rangle \otimes \exp(i\omega_{j})\sqrt{p_{j}}|\psi_{j}(t)\rangle,\tag{26.22}$$

, resulting in

of the form | (*t*)- = *j* |*j*- ⊗ exp(*i*α*j*) *pj* |ψ*j*(*t*)-, (26.22) where ⊗ represents the outer product of the subspace spanned by an orthonormal set

$$|\Psi^{\ell}(t)\rangle\langle\Psi^{\ell}(t)| = \sum_{j,k} |\epsilon_{j}\rangle\langle\epsilon_{k}| \otimes \exp[i(a_{j}-a_{k})] \sqrt{p_{j}p_{k}} \,|\,\psi_{f}(t)\rangle\langle\psi_{k}(t)|.\tag{26.23}$$

*j*,*k* A density operator for the system of interest of the form of Eq. (26.13) can be obtained by taking the expectation value, and hence the trace, of this total projection operator with

respect to any complete set of orthonormal *external* states |φ -

$$\text{tr}_{\epsilon}\left(|\Psi^{\ell}(t)\rangle\langle\Psi^{\ell}(t)|\right) = \sum_{j,k}\sum_{\phi_{\ell}}\langle\phi_{\ell}|\epsilon_{j}\rangle\langle\epsilon_{k}|\phi_{\ell}\rangle\exp[i(\alpha_{j}-\alpha_{k})]\sqrt{p_{j}p_{k}}\,|\psi_{j}(t)\rangle\langle\phi_{k}(t)|$$

$$=\sum_{j,k}(\epsilon_{k}|\epsilon_{j})\exp[i(\alpha_{j}-\alpha_{k})]\sqrt{p_{j}p_{k}}\,|\psi_{j}(t)\rangle\langle\phi_{k}(t)|$$

$$=\sum_{j,k}p_{j}|\psi_{j}(t)\rangle\langle\phi_{j}(t)|.\tag{26.24}$$

φ*j*(*t*)|. (26.24)

tr (| (*t*)- (*t*)|) = *j*,*k* φ φ |*jk*|φ exp[*i*(α*j* − α*k*)] *pjpk* |ψ*j*(*t*)φ*k*(*t*)| = *j*,*k k*|*j* exp[*i*(α*j* − α*k*)] *pjpk* |ψ*j*(*t*)φ*k*(*t*)|

### *j* Either of these rationalizations demonstrates that the statistical operator describes a

=

*pj*|ψ*j*(*t*)-

*ih*¯ d

quantum mechanical system for which there is incomplete information. The phases of the associated quantum states are unknown but one can still average over those quantum states by knowledge of their probabilities.

$$i\hbar\frac{d}{dt}|\psi_l(t)\rangle = \hat{\mathcal{H}}|\psi_l(t)\rangle\tag{26.25}$$

One can calculate the time evolution of the statistical density operator by recognizing that the probabilities *pi* are independent of time and making use of the evolution equations for

> *ih*¯ d d*t*

operator for a pure state |ψ*i*(*t*)-

= *i* 

26.4 Time Evolution

the states |ψ*i*(*t*)-

$$-i\hbar \frac{\mathbf{d}}{\mathbf{d}t} \langle \psi_l(t) | = \langle \psi_l(t) | \hat{\mathcal{H}}, \tag{26.26}$$

d*t* and its Hermitian conjugate

*pi*ψ*i*(*t*)|−|ψ*i*(*t*)-

if *pi* = 1 and *pj* = 0 for *j* = *i*.

$$\begin{split} i\hbar \frac{\mathbf{d}}{\mathbf{d}t} \hat{\boldsymbol{\beta}}^{S} &= \frac{\mathbf{d}}{\mathbf{d}t} \sum_{l} |\psi_{l}(t)\rangle p_{l} \langle \psi_{l}(t)| \\ &= \sum_{l} \left[ \left( i\hbar \frac{\mathbf{d}}{\mathbf{d}t} |\psi_{l}(t)\rangle \right) p_{l} \langle \psi_{l}(t)| + |\psi_{l}(t)\rangle p_{l} \left( i\hbar \frac{\mathbf{d}}{\mathbf{d}t} \langle \psi_{l}(t)| \right) \right] \\ &= \sum_{l} \left[ \hat{\mathcal{H}} |\psi_{l}(t)\rangle p_{l} \langle \psi_{l}(t)| - |\psi_{l}(t)\rangle p_{l} \langle \psi_{l}(t)| \hat{\mathcal{H}} \right]. \end{split} \tag{26.27}$$

opposite sign.

Thus3

$$i\hbar\frac{d}{dt}\hat{\rho}^S = \hat{\mathcal{H}}\hat{\rho}^S - \hat{\rho}^S\hat{\mathcal{H}} \equiv \left[\hat{\mathcal{H}}, \hat{\rho}^S\right],\tag{26.28}$$

. (26.27)

*ih*¯ d d*t* ρˆ *S* = *H*ˆ ρˆ *S* − ˆρ*SH*ˆ ≡ *H*ˆ, ρˆ *S* , (26.28) where the latter expression is a commutator. Equation (26.28) also applies to the density

<sup>3</sup>Here, the operator ρˆ*S* is in the Schrödinger representation. The result in Eq. (26.28) should not be confused with the time derivative of an operator in the Heisenberg representation, which contains a commutator with

<span id="page-476-0"></span>
$$\left[\hat{\mathcal{H}}, \hat{\rho}^{\mathbb{S}}\right] = \mathbf{0},\tag{26.29}$$

456 THERMAL PHYSICS If ρˆ*S* is the *statistical operator for an equilibrium state*, we need dρˆ*S*/d*t* = 0 in which case *H*ˆ, ρˆ *S* = 0, (26.29)

that is, ρˆ*S* commutes with the Hamiltonian. Equation (26.28) is the quantum mechanical analog of the classical Liouville equation (Eq. (17.9)) for an equilibrium ensemble for

$$\frac{\mathbf{d}}{\mathbf{d}t}\langle\mathbf{f}\rangle = \frac{\mathbf{d}}{\mathbf{d}t}\mathrm{tr}(\hat{\boldsymbol{\rho}}^{S}\hat{\boldsymbol{f}}) = \mathrm{tr}\left(\frac{\mathbf{d}\hat{\boldsymbol{\rho}}^{S}\hat{\boldsymbol{f}}}{\mathbf{d}t}\hat{\boldsymbol{f}}\right) + \mathrm{tr}\left(\hat{\boldsymbol{\rho}}^{S}\frac{\partial\hat{\boldsymbol{f}}}{\partial t}\right) = \frac{1}{\overline{\boldsymbol{\eta}}}\mathrm{tr}\left(\left[\hat{\boldsymbol{\mathcal{H}}},\hat{\boldsymbol{\rho}}^{S}\right]\hat{\boldsymbol{f}}\right) + \mathrm{tr}\left(\hat{\boldsymbol{\rho}}^{S}\frac{\partial\hat{\boldsymbol{f}}}{\partial t}\right).\tag{26.30}$$

is Eq. (17.11), namely the vanishing of the Poisson bracket {ρ, *H*}. The time derivative of the average value *f* of some observable may be computed in a similar way as follows:4

### d d*t f*- = d d*t* tr(ρˆ *S* ˆ *f* ) = tr dρˆ*S* d*t* ˆ *f* + tr ρˆ *S* ∂ ˆ *f* ∂*t* = 1 *ih*¯ tr *H*ˆ, ρˆ *S* ˆ *f* + tr ρˆ *S* ∂ ˆ *f* ∂*t* . (26.30)

information about number operators.

use a partial derivative for its time rate of change.

If the observable is explicitly independent of time, ∂ ˆ *f* /∂*t* = 0, and for an equilibrium state Eq. (26.29) applies, so d*f* -/d*t* = 0, as expected. 26.5 Density Operators for Specific Ensembles In this section, we present the statistical density operators for the three main ensembles, microcanonical, canonical, and grand canonical, employed in statistical thermodynamics. These ensembles pertain to equilibrium states, so Eq. (26.29) applies and can be satisfied by choosing ρˆ*S* to be a function of a Hamiltonian *H*ˆ that is independent of time. ρˆ*S* can therefore be expressed in terms of a set of probabilities and the *stationary* eigenstates |*En*-

 of *H*ˆ. It is for this reason that we only had to deal with the stationary eigenstates of *H*ˆ in our previous description of statistical mechanics, beginning with the microcanonical ensemble. For brevity of notation we drop the superscript *S* in the rest of this section, but bear in mind that we are dealing with a *statistical operator for a system in equilibrium*. The results can therefore be expressed easily in the energy representation where the matrix representations of *H*ˆ, and therefore also ρ(ˆ *H*ˆ), are diagonal. Specifically, we employ a complete set of orthonormal stationary eigenstates |*En* that satisfy *H*ˆ|*En*- = *En*|*En*-. Note especially that *n* labels states, not energies, so there can be many values of *n* for a given energy in the case of degeneracy. For the case of the grand canonical ensemble, we will employ states that are also eigenstates of the number operator *N*ˆ . See Appendix I for more

<sup>4</sup>The operator ˆ *f* is in the Schrödinger representation so its only dependence on time is explicit; we therefore

*Chapter 26* • Quantum Statistics 457 26.5.1 Microcanonical Ensemble The microcanonical ensemble applies in principle to an isolated system having constant total energy *E*. We recognize, however, that a truly isolated system is an impossibil-

<span id="page-477-0"></span>
$$
\hat{\rho} = \sum_{n} |E_{n}\rangle p_{n} \langle E_{n}| = \sum_{n=1}^{\Omega} |E_{n}\rangle \frac{1}{\Omega} \langle E_{n}|; \quad p_{n} = \begin{cases} 1/\Omega & \text{for } E - \Delta E \le E_{\hbar} \le E \\ 0 & \text{otherwise.} \end{cases} \tag{26.31}
$$

to *E*. Within this range, the number of quantum states of the system is represented

$$\mathbf{S} = -k_{\mathbf{B}} \text{tr}(\hat{\rho} \ln \hat{\rho}),\tag{26.32}$$

ρˆ = *n* |*EnpnEn*| = *n*=1 |*En*- [1](#page-477-0) *En*|; *pn* = 1/ for *E* − *E* ≤ *En* ≤ *E*. 0 otherwise. (26.31) The entropy is given by *S* = *k*B ln . In terms of ρˆ, it can be calculated from the formula *S* = −*k*Btr(ρˆ lnρ)ˆ , (26.32) where the function ln ρˆ is to be understood as the operator whose eigenvalues, in a representation where ρˆ is diagonal, are equal to the logarithm of the eigenvalues of ρˆ. The quantity −tr(ρˆ ln ρ)ˆ in Eq. (26.32) is just the expectation value of − ln ρˆ in the statistical

$$-\text{tr}(\hat{\rho}\ln\hat{\rho}) = -\sum_{m} \langle \phi_{m}|\sum_{n=1}^{\Omega} |E_{n}\rangle \frac{\text{ln}(1/\Omega)}{\Omega} \langle E_{n}| |\phi_{m}\rangle$$

$$=\sum_{n=1}^{\Omega} \sum_{m} \langle E_{n}|\phi_{m}\rangle \langle \phi_{m}|E_{n}\rangle \frac{\text{ln}\,\Omega}{\Omega} = \sum_{n=1}^{\Omega} \langle E_{n}|E_{n}\rangle \frac{\text{ln}\,\Omega}{\Omega} = \ln\Omega. \tag{26.33}$$

*En*|*En*-

ln

= ln . (26.33)

### = *n*=1 *m En*|φ*m*φ*m*|*En*-

the form

states |φ*m*-

in the form

26.5.2 Canonical Ensemble The canonical ensemble pertains to a system in contact with a heat reservoir that maintains the system at temperature *T*. The corresponding probabilities in the energy representation are just *Pn* = exp(−β*En*)/*Z*, where β = 1/(*k*B*T*) and *Z* = 

*n*=1

ln = 

$$\hat{\rho} = \sum_{n} |E_{n}| \frac{\exp(-\beta E_{n})}{Z} \\ \langle E_{\hbar}| = \frac{\exp(-\beta \hat{\mathcal{H}})}{Z} = \frac{\exp(-\beta \hat{\mathcal{H}})}{\text{tr}\left[\exp(-\beta \hat{\mathcal{H}})\right]}. \tag{26.34}$$

*n* tr exp(−β*H*ˆ) In this case, the sum is over all energy states, a complete set. From the last form of Eq. (26.34), it is obvious that tr ρˆ = 1. In this case, Eq. (26.32) leads to the familiar formula

458 THERMAL PHYSICS

states |*NsErs*-

having operator ˆ

*r*,*s Prs* ln *Prs* as expected.

*S* = −*k*B

$$\text{S/}k_{\text{B}} = -\text{tr}(\hat{\rho}\ln\hat{\rho}) = -\sum_{m} \langle \phi_{m}|\sum_{n}|E_{n}\rangle P_{n}\ln P_{n}\langle E_{n}||\phi_{m}\rangle = -\sum_{n} P_{n}\ln P_{n},\tag{26.35}$$

$$\langle U = \langle \hat{\mathcal{H}} \rangle = \text{tr}(\hat{\rho}\hat{\mathcal{H}}) = \frac{\text{tr}\left[\hat{\mathcal{H}}\exp(-\beta\hat{\mathcal{H}})\right]}{\text{tr}\left[\exp(-\beta\hat{\mathcal{H}})\right]}.\tag{26.36}$$

*S*/*k*B = −tr(ρˆ lnρ)ˆ = − *m* φ*m*| *n* |*En*-*Pn* ln*PnEn*||φ*m*-=− *n Pn* ln *Pn*, (26.35) where *Pn* are the probabilities of occupation of the states. Of course the expectation value of the energy itself is the internal energy

$$U = \frac{\sum_{n} E_n \exp(-\beta E_n)}{\sum_{m} \exp(-\beta E_m)}. \tag{26.37}$$

### calculated, at least approximately, in any convenient representation. If the eigenvalues are known, then we retrieve the familiar result

*U* = *H*ˆ-

*U* = *n En* exp(−β*En*) *m* exp(−β*Em*) . (26.37) 26.5.3 Grand Canonical Ensemble

If the eigenvalues of *H*ˆ cannot be calculated, the last expression in Eq. (26.36) can be

$$
\hat{\mathcal{H}}|\mathcal{N}_{3}\mathcal{E}_{t3}\rangle = \mathcal{E}_{t3}|\mathcal{N}_{3}\mathcal{E}_{t3}\rangle; \quad \hat{\mathcal{N}}|\mathcal{N}_{3}\mathcal{E}_{t3}\rangle = \mathcal{N}_{3}|\mathcal{N}_{3}\mathcal{E}_{t3}\rangle. \tag{26.38}
$$

ensemble will be diagonal in a set of states that are simultaneous eigenfunctions of the number operator *N*ˆ and the Hamiltonian operator *H*ˆ for a system having *N* particles. Such

$$\hat{\rho} = \sum_{\mathbf{r}, \mathbf{s}} |\mathcal{N}_{\mathbf{s}} \mathcal{E}_{\mathbf{t}\mathbf{s}}\rangle P_{\mathcal{N}} \langle \mathcal{N}_{\mathbf{s}} \mathcal{E}_{\mathbf{t}\mathbf{s}}| = \sum_{\mathbf{r}, \mathbf{s}} |\mathcal{N}_{\mathbf{s}} \mathcal{E}_{\mathbf{t}\mathbf{s}}\rangle \frac{\exp[-\beta(\mathcal{E}_{\mathbf{t}} - \mu \mathcal{N}_{\mathbf{s}})]}{\mathcal{Z}} \langle \mathcal{N}_{\mathbf{s}} \mathcal{E}_{\mathbf{t}\mathbf{s}}|$$

$$= \frac{\exp[-\beta(\hat{\mathcal{H}} - \mu \hat{\mathcal{N}})]}{\mathcal{Z}} = \frac{\exp[-\beta(\hat{\mathcal{H}} - \mu \hat{\mathcal{N}})]}{\text{tr}\left[\exp[-\beta(\hat{\mathcal{H}} - \mu \hat{\mathcal{N}})]\right]},\tag{26.39}$$

= exp[−β(*H*ˆ − μ*N*ˆ )] *Z* = exp[−β(*H*ˆ − μ*N*ˆ )]

$$\mathcal{Z} = \sum_{\mathfrak{s}} \exp(\beta \mu \mathcal{N}_{\mathfrak{s}}) \sum_{r} \exp(-\beta \mathcal{E}_{\mathfrak{N}}) = \sum_{\mathfrak{s}} \lambda^{\mathcal{N}_{\mathfrak{s}}} \sum_{r} \exp(-\beta \mathcal{E}_{\mathfrak{N}}).\tag{26.40}$$

*Z* = *s* exp(βμ*Ns*) *r* exp(−β*Ers*) = *s* λ*Ns r* exp(−β*Ers*). (26.40)

$$
\langle f \rangle = (1/Z) \text{tr} \left[ \hat{f} \exp[-\beta(\hat{\mathcal{H}} - \mu \hat{\mathcal{N}})] \right] = \frac{\sum_{\mathcal{N}} \lambda^{\mathcal{N}}(\mathbf{f})_{\mathcal{N}} Z_{\mathcal{N}}}{\sum_{\mathcal{N}} \lambda^{\mathcal{N}} Z_{\mathcal{N}}},\tag{26.41}
$$

*f*- = (1/*Z*)tr ˆ *f* exp[−β(*H*ˆ − μ*N*ˆ )] = *N N* λ*N ZN* , (26.41) where *ZN* is the canonical partition function for a system of *N* particles and *f* -*N* is the canonical average of ˆ *f* for that system. From Eq. (26.32), the entropy is just

26.6 Examples of the Density Matrix For the canonical ensemble, we calculate the matrix elements of the equilibrium statistical

$$
\psi_{\mathbf{k}}(\mathbf{r}) = V^{-1/2} \exp(i\mathbf{k} \cdot \mathbf{r}),
\tag{26.42}
$$

*Chapter 26* • Quantum Statistics 459

26.6.1 Single Free Particle

$$
\hat{\mathcal{H}}\psi\mathbf{k} = s\mathbf{k}\psi\mathbf{k}\tag{26.43}
$$

, the relevant matrix

periodic boundary conditions. The wave function is ψ**k**(**r**) = *V* −1/2 exp(*i***k** · **r**), (26.42) which satisfies *H*ˆ ψ**k** = ε**k**ψ**k** (26.43) with ε**k** = *h*¯ 2*k*2/(2*m*). Here, *H*ˆ = *p*ˆ 2/2*m*, where *p*ˆ = (*h*¯ /*i*)∇ is the momentum operator. For periodic boundary conditions, ψ**k** is also an eigenfunction of the momentum operator

, for which ψ**k**(**r**) = **r**|ε**k**-

$$
\langle \varepsilon_{\mathbf{k}} | \exp(-\beta \hat{\mathcal{H}}) | \varepsilon_{\mathbf{k}'} \rangle = \exp(-\beta \varepsilon_{\mathbf{k}}) \,\delta_{\mathbf{k} \mathbf{k}'}.\tag{26.44}
$$

and zero). In terms of the eigenstates |ε**k**-

Thus

elements are

could also be written

$$\operatorname{tr}(\exp(-\beta\hat{\mathcal{H}})) = \sum_{\mathbf{k}} \exp(-\beta\varepsilon_{\mathbf{k}}) \approx \frac{V}{(2\pi)^3} \int \operatorname{d}^3 k \, \exp[-\beta\hbar^2 k^2/(2m)]$$

$$= \frac{V}{(2\pi)^3} \left[ \left(\frac{2m}{\beta\hbar^2}\right)^{1/2} \int_{-\infty}^{\infty} \operatorname{d}x \, \exp(-x^2) \right]^3 = V/\lambda_{\Gamma}^3. \tag{26.45}$$

<span id="page-479-0"></span>3

= *V* 2*m* 1/2 -∞

(2π )3

-= (λ3

$$\frac{1}{\lambda_{\Gamma}^{3}} = \left(\frac{m}{2\pi\hbar^{2}\beta}\right)^{3/2} = n_{\rm Q},\tag{26.46}$$

1 λ3 T = *m* 2π*h*¯ 2β 3/2 = *n*Q, (26.46)

$$
\langle \varepsilon_{\mathbf{k}} | \hat{\boldsymbol{\beta}} | \varepsilon_{\mathbf{k}'} \rangle = (\lambda_{\mathbf{I}}^3 / V) \exp(-\beta \varepsilon_{\mathbf{k}}) \delta_{\mathbf{k} \mathbf{k}'}.\tag{26.47}
$$

ε**k**| ˆρ|ε**k**- = (λ3 T/*V*) exp(−βε**k**)δ**kk** . (26.47) Since these energy eigenstates are also eigenstates of the momentum operator, Eq. (26.47)

$$
\langle \mathbf{k} | \hat{\rho} | \mathbf{k}' \rangle = (\lambda_\mathrm{T}^3 / V) \exp[-\beta \hbar^2 k^2 / (2m)] \delta_\mathbf{kk'}.\tag{26.48}
$$

T/*V*) exp[−β*h*¯ 2*k*2/(2*m*)]δ**kk** . (26.48)

We proceed to calculate the matrix elements of ρˆ in the coordinate representation |**r**- where it is not diagonal. Thus

$$
\langle \mathbf{r} | \hat{\rho} | \mathbf{r}' \rangle = \sum_{\mathbf{k} \mathbf{k}'} \langle \mathbf{r} | \mathbf{k} \rangle \langle \mathbf{k} | \hat{\rho} | \mathbf{k}' \rangle \langle \mathbf{k}' | \mathbf{r}' \rangle = \frac{\lambda_\mathrm{T}^3}{V^2} \sum_\mathbf{k} \exp[-\beta \hbar^2 k^2 / (2m)] \exp[i\mathbf{k} \cdot (\mathbf{r} - \mathbf{r}')]
$$

$$
\approx \frac{\lambda_\mathrm{T}^3}{V^2} \frac{V}{(2\pi)^3} \int \mathrm{d}^3 k \exp[-\beta \hbar^2 k^2 / (2m)] \exp[i\mathbf{k} \cdot (\mathbf{r} - \mathbf{r}')] \tag{26.49}
$$

$$
= \frac{\lambda_\mathrm{T}^3}{(2\pi)^3 V} \exp[-m|\mathbf{r} - \mathbf{r}'|^2 / (2\beta \hbar^2)] \int \mathrm{d}^3 k \exp[-(\beta \hbar^2 / 2m)|\mathbf{k} - i(m/\beta \hbar^2)(\mathbf{r} - \mathbf{r}')|^2]
$$

$$
= \frac{\lambda_\mathrm{T}^3}{(2\pi)^3 V} \exp[-m|\mathbf{r} - \mathbf{r}'|^2 / (2\beta \hbar^2)] \left(\frac{2\pi m}{\beta \hbar^2}\right)^{3/2}, \tag{26.50}
$$

where we have completed the square in the argument of the exponential to get a Gaussian integral. In terms of λT, this result can be written simply as

$$
\langle \mathbf{r} | \hat{\rho} | \mathbf{r}' \rangle = \frac{1}{V} \exp[-\pi \left( |\mathbf{r} - \mathbf{r}'| / \lambda_\Gamma \right)^2]. \tag{26.51}
$$

The diagonal element**r**| ˆρ|**r**- = 1/*V* is independent of **r** and shows that there is a uniform probability density of finding the particle anywhere in the box, as would be expected for periodic boundary conditions. Of course trρˆ = *V* **r**| ˆρ|**r**d3*r* = *V*/*V* = 1.

One could also treat this problem with boundary conditions for which the wave function vanishes on the sides of the box. In that case, ψε**k** = (8/*V*)1/2 sin(*kxx*) sin(*kyy*) sin(*kzz*), with **k** now given by Eq. (16.52). In that case, ε**k** = *h*¯ 2*k*2/2*m*, but ψε**k** is no longer an eigenfunction of the momentum operator **p**ˆ. As expected, **r**| ˆρ|**r** goes to zero on the sides of the box and increases to a maximum at the center of the box. For λT much smaller than any edge length of the box, **r**| ˆρ|**r**- ≈ 1/*V* except within a distance of order λT near the walls of the box.

### 26.6.2 One-Dimensional Harmonic Oscillator

For a harmonic oscillator in one dimension, *x*, the energies are given by ε*n* = *h*¯ ω(*n* + 1/2) and the partition function *z* = exp(−β*h*¯ ω/2)/[1 − exp(−β*h*¯ ω)]. Thus the probabilities are

$$p_n = \exp(-\beta \varepsilon_n)/z = \exp(-n\beta\hbar\omega)[1 - \exp(\beta\hbar\omega)],\tag{26.52}$$

independent of the zero point energy. The density operator is therefore

$$
\hat{\rho} = \sum_{n=0}^{\infty} |n\rangle p_n \langle n|. \tag{26.53}
$$

The expectation value of *x*2 is given by

$$
\langle \mathbf{x}^2 \rangle = \text{tr}(\hat{\rho}\hat{\mathbf{x}}^2) = \sum_{n=0}^{\infty} p_n \langle n|\hat{\mathbf{x}}^2|n\rangle. \tag{26.54}
$$

$$
\hat{\alpha}^2 = \frac{\hbar}{m\omega} \left( a^\dagger a + \frac{1}{2} + \frac{aa + a^\dagger a^\dagger}{2} \right). \tag{26.55}
$$

*Chapter 26* • Quantum Statistics 461

$$\langle \mathbf{x}^2 \rangle = \sum_{n=0}^{\infty} p_n \hbar (n + 1/2) / (m\omega) = \sum_{n=0}^{\infty} p_n \varepsilon_\hbar / (m\omega^2) = \langle \mathbf{H} \rangle / (m\omega^2). \tag{26.56}$$

*x*ˆ 2 = *h*¯ *m*ω *a*†*a* + 2 + 2 . (26.55) The operators *aa* and *a*†*a*† have no diagonal elements, so *n*|*x*ˆ2|*n*- = *h*¯ (*n* + 1/2)/(*m*ω). Therefore, *x*2- = ∞ *pnh*¯ (*n* + 1/2)/(*m*ω) = ∞ *pn*ε*n*/(*m*ω2) = *H*-/(*m*ω2). (26.56)

*n*=0 *n*=0 Here, *H*- = *h*¯ ω[1/2 + (exp(β*h*¯ ω) − 1)−1] is the average energy. Thus the average potential energy is (1/2)*m*ω2*x*2- = (1/2)*H*just as for the time average of the potential energy

### of a classical harmonic oscillator. The average of the kinetic energy is therefore *H*-(1/2)*H*- = (1/2)*H*-, the same as the time average of the kinetic energy of a classical

ρˆ = |χ-

<span id="page-481-1"></span>26.6.3 Spin 1/2 Particle

harmonic oscillator. See Pathria [8, pp. 113-115] for a representation of this density matrix in the *x* representation, where it is also shown that *x*| ˆρ|*x*follows a Gaussian distribution.

<span id="page-481-0"></span>
$$\mathbf{c}_1|\chi\rangle = \mathbf{c}_1|\alpha\rangle + \mathbf{c}_2|\beta\rangle,\tag{26.57}$$

−

In the previous examples[, we ha](#page-481-0)ve not included spin, so we proceed here to treat electrons having spin 1/2. We will begin by treating a pure state and then proceed to discuss a statistical state. We represent the pure state by |χ- = *c*1|α- [+](#page-481-1) *c*2|β-, (26.57)

$$
\hat{\rho} = |\chi\rangle\langle\chi| = |\mathbf{c}\rangle^2 |\alpha\rangle\langle\alpha| + \mathbf{c}_1 \mathbf{c}_2^* |\alpha\rangle\langle\beta| + \mathbf{c}_1^* \mathbf{c}_2 |\beta\rangle\langle\alpha| + |\mathbf{c}_2|^2 |\beta\rangle\langle\beta|.\tag{26.58}
$$

and *c*1 and *c*2 are complex numbers. |χ is assumed to be normalized, so |*c*1| The density operator is the projection operator

$$\chi = \begin{pmatrix} c_1 \\ c_2 \end{pmatrix} = c_1 \begin{pmatrix} 1 \\ 0 \end{pmatrix} + c_2 \begin{pmatrix} 0 \\ 1 \end{pmatrix} \equiv c_1 \alpha + c_2 \beta,\tag{26.59}$$

χ = *c*1 = *c*1 1 + *c*2 0 ≡ *c*1α + *c*2β, (26.59)

ρ = χχ† =

σ*x* =

$$\rho = \chi \chi^{\dagger} = \begin{pmatrix} c_1 \\ c_2 \end{pmatrix} (c_1^* \ c_2^*) = \begin{pmatrix} |c_1|^2 & c_1 c_2^* \\ c_1^* c_2 & |c_2|^2 \end{pmatrix},\tag{26.60}$$
 
$$\text{which is Hermitian.}$$

, (26.60)

*c*2 *c*∗ 1*c*2 |*c*2| which is Hermitian.

2) =

$$
\sigma_{\mathcal{X}} = \begin{pmatrix} \mathbf{0} & 1 \\ 1 & \mathbf{0} \end{pmatrix}; \quad \sigma_{\mathcal{Y}} = \begin{pmatrix} \mathbf{0} & -i \\ i & \mathbf{0} \end{pmatrix}; \quad \sigma_{\mathcal{Z}} = \begin{pmatrix} 1 & \mathbf{0} \\ \mathbf{0} & -1 \end{pmatrix}. \tag{26.61}
$$

2

2

<span id="page-482-0"></span>
$$
\sigma_{\mathcal{X}}\sigma_{\mathcal{Y}} = -\sigma_{\mathcal{Y}}\sigma_{\mathcal{X}} = \mathrm{i}\sigma_{\mathcal{Z}}; \quad \sigma_{\mathcal{Y}}\sigma_{\mathcal{Z}} = -\sigma_{\mathcal{Z}}\sigma_{\mathcal{Y}} = \mathrm{i}\sigma_{\mathcal{X}}; \quad \sigma_{\mathcal{Z}}\sigma_{\mathcal{X}} = -\sigma_{\mathcal{X}}\sigma_{\mathcal{Z}} = \mathrm{i}\sigma_{\mathcal{Y}}; \quad \sigma_{\mathcal{X}}\sigma_{\mathcal{Y}} = -\sigma_{\mathcal{X}}\sigma_{\mathcal{Y}} = \mathrm{i}\sigma_{\mathcal{Y}}; \quad \sigma_{\mathcal{X}}\sigma_{\mathcal{Y}} = \mathrm{i}\sigma_{\mathcal{Y}} = -\sigma_{\mathcal{Y}}\sigma_{\mathcal{Y}} = \mathrm{i}\sigma_{\mathcal{Y}}
$$

$$
\sigma_x^2 = \sigma_y^2 = \sigma_z^2 = E \equiv \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}; \quad \text{tr } \sigma_\lambda = \text{tr } \sigma_\mathcal{V} = \text{tr } \sigma_\mathcal{Z} = 0. \tag{26.62}
$$

These have the properties σ*x*σ*y* = −σ*y*σ*x* = *i*σ*z*; σ*y*σ*z* = −σ*z*σ*y* = *i*σ*x*; σ*z*σ*x* = −σ*x*σ*z* = *i*σ*y*; σ2 *x* = σ2 *y* = σ2 *z* = *E* ≡ 1 0 0 1 ; tr σ*x* = tr σ*y* = tr σ*z* = 0. (26.62) The Pauli spin matrices can be related to fermion operators that *anticommute*, as developed in Section I.3 of Appendix I.

$$
\rho = (1/2)[E + \mathbf{P} \cdot \boldsymbol{\sigma}],\tag{26.63}
$$

the expectation value of σ*x* transforms like a vector [69, pp. 261-270]. In this s[ense,](#page-482-0) *σ* is

*Px* = *c*∗

notation is therefore

1*c*2 + *c*1*c*∗

2 = 2(*c*∗

$$P_X = \mathbf{c}_1^* \mathbf{c}_2 + \mathbf{c}_1 \mathbf{c}_2^* = 2\Re(\mathbf{c}_1^* \mathbf{c}_2), \quad P_Y = (\mathbf{c}_1^* \mathbf{c}_2 - \mathbf{c}_1 \mathbf{c}_2^*)/\mathbf{i} = 2\Im(\mathbf{c}_1^* \mathbf{c}_2) \quad P_Z = |\mathbf{c}_1|^2 - |\mathbf{c}_2|^2,\tag{26.64}$$

results in ρ = (1/2)[*E* + **P** · *σ*], (26.63) where

$$
\langle \sigma_{\mathbf{x}} \rangle = \text{tr} \, (\sigma_{\mathbf{x}} \rho) = (1/2) P_{\mathbf{x}} \text{tr} \, (\sigma_{\mathbf{x}}^2) = P_{\mathbf{x}}, \tag{26.65}
$$

which may be verified as follows. First, take the trace of Eq. (26.63) and recognize that tr ρ = 1, tr *E* = 2 and tr *σ* = 0, which verifies the term (1/2)*E*. Then multiply Eq. (26.63) by σ*x* and take the trace to obtain σ*x*- = tr (σ*x*ρ) = (1/2)*Px* tr (σ2 *x* ) = *Px*, (26.65) where Eq. (26.62) has been used. By using the explicit form Eq. (26.60) for ρ, we can

$$
\langle \boldsymbol{\sigma} \rangle = \mathbf{P}.\tag{26.66}
$$

result *σ*- = **P**. (26.66) It also turns out that **P** is a unit vector, which is known as the **polarization vector** for the pure state χ under consideration. This can be seen readily by writing *c*1 = |*c*1|*ei*γ1 and

way for the *y* and *z* components, we verify the expressions for *Py* and *Pz* and obtain the

$$P_\chi^2 + P_\chi^2 + P_z^2 = 4|\mathbf{c}_1|^2|\mathbf{c}_2|^2 + (|\mathbf{c}_1|^2 - |\mathbf{c}_2|^2)^2 = (|\mathbf{c}_1|^2 + |\mathbf{c}_2|^2)^2 = 1. \tag{26.67}$$

*P*2 *x* + *P*2 *y* + *P*2 *z* = 4|*c*1| 2|*c*2| 2 + (|*c*1| 2 − |*c*2| 2) 2 = (|*c*1| 2 + |*c*2| 2) 2 = 1. (26.67) We are now in a position to relate to the magnetic moment of an electron which has spin (1/2). We associate the "spin up" state α with the spin component (1/2) and the "spin down" state β with the spin component −(1/2). For simplicity, we approximate the *g*factor for spin (approximately 2.0023) by 2, so the magnetic moment for spin up would be −2μB(1/2) = −μB, where μB = *eh*¯ /(2*mc*) > 0 is the Bohr magneton and the minus sign results from the negative charge of the electron. The magnetic moment operator in matrix

$$
\mu = -\mu_{\rm B}\sigma \tag{26.68}
$$

operator.

where |α-

ing density matrix

the magnetic field.

α| and |β-

$$
\mathcal{H} = -\boldsymbol{\mu} \cdot \mathbf{B} = \mu_{\rm B} \boldsymbol{\sigma} \cdot \mathbf{B}.\tag{26.69}
$$

*Chapter 26* • Quantum Statistics 463 *μ* = −μB*σ* (26.68) and the Hamiltonian is5

$$
\rho \chi = \chi = (1/2)[\chi + \mathbf{P} \cdot \sigma \,\,\chi] \tag{26.70}
$$

More insight can be gained by noting that ρ given by Eq. (26.60) has eigenvalues λ = 1 and λ = 0. Moreover, χ is a normalized eigenvector of ρ corresponding to λ = 1, unique except for an overall phase factor. An eigenvector of ρ that corresponds to λ = 0 must be perpendicular to χ and can be taken to be χ⊥ = *c*∗

$$
\rho \chi_{\perp} = 0 = (1/2) \| \chi_{\perp} + \mathbf{P} \cdot \boldsymbol{\sigma} \chi_{\perp} \|,\tag{26.71}
$$

ρχ = χ = (1/2)[χ + **P** · *σ* χ] (26.70) from which we deduce that **P**·*σ* χ = χ, so χ is also an eigenvector of **P**·*σ* with eigenvector 1. Similarly, operating on χ⊥ gives ρχ⊥ = 0 = (1/2)[χ⊥ + **P** · *σ* χ⊥], (26.71) so **P**·*σ* χ⊥ = −χ⊥. This is equivalent to saying that χ⊥ is an eigenstate of the operator

−**P**·*σ* with eigenvalue 1. Therefore, for an axis along **P**, χ corresponds to the "spin up" state and χ⊥ corresponds to the "spin down" state. This shows that the operator **P**·*σ* is the spin operator for the direction **P** that corresponds to σ*z* for our original but arbitrary

$$
\hat{\rho}^S = p_a |\alpha\rangle\langle\alpha| + p_\beta |\beta\rangle\langle\beta|,\tag{26.72}
$$

For a statistical state, all we know are the probabilities *p*α of b[eing](#page-483-0) [in](#page-483-0) the eigenstate |α- and *p*β of being in the eigenstate |β-. The density operator is ρˆ *S* = *p*α|αα| + *p*β |ββ|, (26.72)

<span id="page-483-1"></span><span id="page-483-0"></span>
$$
\rho^S = \begin{pmatrix} p_a & 0 \\ 0 & p_\beta \end{pmatrix} \tag{26.73}
$$

ρ*S* = *p*α 0 (26.73)

value of α will be *p*α and that for β will be *p*β . This is easily verified by taking the

$$
\rho^S = (1/2)[E + (p_a - p_\beta)\sigma_2],\tag{26.74}
$$

is diagonal with elements equal to *p*α and *p*β . We can rewrite Eq. (26.73) in the form ρ*S* = (1/2)[*E* + (*p*α − *p*β)σ*z*], (26.74) which is quite different from ρ for a pure state given by Eq. (26.60) for the case in which |*c*1| 2 = *p*α and |*c*2| 2 = *p*β . For the statistical state and the pure state, the expectation

<sup>5</sup>We often say that the spins tend to line up with the magnetic field, but the low energy state for an electron, due to its negative charge, occurs when its spin is opposite to the magnetic field so its magnetic moment is along

tr(ρˆ|α-

<span id="page-484-0"></span>α|) = α| ˆρ|α-

$$\text{tr}(\hat{\rho}|\alpha\rangle\langle\alpha|) = \langle\alpha|\hat{\rho}|\alpha\rangle + \langle\beta|\hat{\rho}|\alpha\rangle\langle\alpha|\beta\rangle = \langle\alpha|\hat{\rho}|\alpha\rangle = |\mathbf{c}_1|^2 = \mathbf{p}_a.\tag{26.75}$$

464 THERMAL PHYSICS

trace of the density matrix with the respective projection operator. For example, for the pure state

$$
\hat{\rho}_{\chi}^{S} = \mathbf{p}_{\chi}|\chi\rangle\langle\chi| + \mathbf{p}\perp|\chi\perp\rangle\langle\chi\perp|,\tag{26.76}
$$

But at least one of the quantities σ*x*- = *Px* or σ*y*- = *Py* will not be zero for the pure state, exce[pt for](#page-484-0) the special valu[es](#page-483-1) *c*1 = 0 or *c*2 = 0, in which cases both density matrices represent the same pure state. On the other hand, for the statistical state σ*x*-=σ*y*-= 0.

$$
\rho_\chi^S = (1/2)[E + (p_\chi - p_\perp)\mathbf{P} \cdot \sigma]. \tag{26.77}
$$

operator ρˆ *S* χ = *p*χ |χχ| + *p*⊥|χ⊥χ⊥|, (26.76) where *p*χ and *p*⊥ are probabilities. By using Eq. (26.63) for each pure state and recalling that −**P** corresponds to χ⊥, we deduce the corresponding density matrix ρ*S* χ = (1/2)[*E* + (*p*χ − *p*⊥)**P**·*σ*]. (26.77)

<span id="page-484-2"></span><span id="page-484-1"></span>Equation (26.77) resembles Eq. (26.74) but with respect to the **P**-axis, as opposed to our original arbitrary *z*-axis. For **P** not along the *z*-axis, these represent different statistical states except for the special values *p*α = *p*β = *p*χ = *p*⊥ = 1/2, in which case ρ*S* = ρ*S*

$$\text{tr}(\rho^{\mathcal{S}}|\chi\rangle\langle\chi|) = p_a|\mathbf{c}_1^2 + p_\beta|\mathbf{c}_2|^2; \quad \text{tr}(\rho^{\mathcal{S}}|\chi_\perp\rangle\langle\chi_\perp|) = p_a|\mathbf{c}_2|^2 + p_\beta|\mathbf{c}_1|^2,\tag{26.78}$$

There is an interesting relationship for expectation values of χ and χ⊥ for ρ*S* and for α

χ . Thus

and β in ρ*S*

ˆ

$$\text{tr}(\rho_{\mathcal{X}}^{\mathcal{S}}|\alpha\rangle\langle\alpha|) = p_{\mathcal{X}}|c_1^2 + p_{\perp}|c_2|^2; \quad \text{tr}(\rho_{\mathcal{X}}^{\mathcal{S}}|\beta\rangle\langle\beta|) = p_{\mathcal{X}}|c_2|^2 + p_{\perp}|c_1|^2,\tag{26.79}$$

$$\text{s.t. } \text{tr}(\rho_{\mathcal{X}}^{\mathcal{S}}|\alpha\rangle\langle\alpha|) = p_{\mathcal{X}}|c_2|^2 + p_{\perp}|c_1|^2,\tag{26.70}$$

tr(ρ*S*|χ-1 + *p*β |*c*2| χ⊥|) = *p*α|*c*2| which sum to 1 whereas tr(ρ*S* χ |αα|) = *p*χ |*c*2 1 + *p*⊥|*c*2| 2; tr(ρ*S* χ |ββ|) = *p*χ |*c*2| 2 + *p*⊥|*c*1| 2, (26.79)

which also sum to 1. For the isotropic statistical state, each of these probabilities is equal to 1/2. Equations (26.78) and (26.79) are special cases of Eq. (26.11) for which the operator *f* is a projection operator for some pure state. For a magnetic field **B**, which for convenience we can take to be along the *z*-axis, the

$$p_u = e^{-w}/(e^{\mu} + e^{-w}); \quad p_\beta = e^{\mu}/(e^{\mu} + e^{-w})\tag{26.80}$$

energies μB*B* and −μB*B*. For thermal equilibrium, the probabilities would be

with *w* = βμB*B*. Then

$$\begin{cases} \dots \\ \langle \sigma_2 \rangle = (p_a - p_\beta) = (e^{-w} - e^w)/(e^w + e^{-w}) = -\tanh w \end{cases} \tag{26.81}$$

σ*z*- = (*p*α − *p*β ) = (*e*−*w* − *ew*)/(*ew* + *e*−*w*) = −tanh *w* (26.81) and the magnetic moment is μ*z* = −μBσ*z* = μB tanh *w* in the direction of *B*. Of course we could have obtained this last result by elementary methods, so the use of the statistical density matrix for this simple two-state problem is overkill. Nevertheless, in this simple

case, we see in detail the difference between a pure state and a statistical state.

See Schiff [57, p. 382] for a treatment of general spin *s*.

*Chapter 26* • Quantum Statistics 465

$$
\boldsymbol{\rho}^S = \begin{pmatrix} 1/2 & \mathbf{0} \\ \mathbf{0} & 1/2 \end{pmatrix} \tag{26.82}
$$

. (26.83)

 or |β-.

**Example Problem 26.1.** Compare the isotropic statistical state (1/2)|α-

state |φ-

√2)*ei*γ |β-

ρ1 =

= √1/3|α-

−1/3. The value of **P** for |φ⊥-

the overall phase factor) would be

in a gas, they would be indistinguishable.

one could take |φ⊥-

1/2 1/2

(1/

$$\rho_1 = \begin{pmatrix} 1/2 & 1/2 \\ 1/2 & 1/2 \end{pmatrix}; \quad \rho_2 = \begin{pmatrix} 1/2 & -i/2 \\ i/2 & 1/2 \end{pmatrix}; \quad \rho_3 = \begin{pmatrix} 1/2 & e^{-l\gamma}/2 \\ e^{l\gamma}/2 & 1/2 \end{pmatrix}. \tag{26.83}$$

**Solution 26.1.** The respective density matrices are ρ*S* = 1/2 0 0 1/2 (26.82) and

1/2 1/2 *i*/2 1/2 *ei*γ /2 1/2 For all four, the probability of finding the system in |α or |β is 1/2. For the statistical state, *σ* - = 0. For |φ1-, *Px* = 1, *Py* = 1, and *Pz* = 0. For |φ2-, *Px* = 0, *Py* = 1, and *Pz* = 0. And for |φ3-, *Px* = cos γ , *Py* = sin γ , and *Pz* = 0. For the three pure states, the vector **P** is perpendicular to the

; ρ3 =

*z*-axis, but spins in those eigenstates still *have probabilities* of 1/2 of being in either |α-

; ρ2 =

1/2 −*i*/2

$$
\rho^S = \begin{pmatrix} 1/3 & 0 \\ 0 & 2/3 \end{pmatrix}; \quad \rho = \begin{pmatrix} 1/3 & e^{-l\gamma}\sqrt{2/9} \\ e^{l\gamma}\sqrt{2/9} & 2/3 \end{pmatrix}. \tag{26.84}
$$

1/2 *e*−*i*γ /2

perpendicular to |φ and what would be its density matrix? **Solution 26.2.** The respective density matrices are ρ*S* = 1/3 0 0 2/3 ; ρ = 1/3 *e*−*i*γ √2/9 *ei*γ √2/9 2/3 . (26.84) For both, the probability of finding the system in |α is 1/3 and in |β it is 2/3. For the statistical state,σ*x*-=σ*y* - = 0 and σ*z*-√2/3) cos γ , *Py* = (2 √2/3) sin γ , and *Pz* =

$$
\rho_{\perp} = \begin{pmatrix} 2/3 & -e^{-l\gamma}\sqrt{2/9} \\ -e^{l\gamma}\sqrt{2/9} & 1/3 \end{pmatrix}. \tag{26.85}
$$

. (26.85)

ρ⊥ =

= √2/3 *e*−*i*γ |α-

26.7 Indistinguishable Particles Suppose we have a set of identical particles that cannot be distinguished from one another in the sense that interchange of any pair of particles will not lead to a new quantum state.6 We shall refer to such particles as indistinguishable particles. Then quantum mechan-

 2/3 −*e*−*i*γ √2/9 −*ei*γ √2/9 1/3

ical considerations require their quantum states to have certain symmetry properties,

<sup>6</sup>If identical particles were imbedded in a solid, they could be distinguished by their position in the solid, so we would not regard them as indistinguishable. On the other hand, if they shared the same volume as they would

466 THERMAL PHYSICS depending on whether they are bosons (integral spin) or fermions (half integral spin). If

$$
\hat{\mathcal{H}}(\xi_1, \xi_2, \dots, \xi_N) = \sum_{l=1}^{N} \hat{h}(\xi_l),
\tag{26.86}
$$

operators that can be used to c[on](#page-486-0)struct such states. We proceed to illustrate this symmetry requirement for ideal Bose and Fermi gases for which the interaction energies of particles are assumed to be negligible. The Hamiltonian for such a system will be of the form *H*ˆ(ξ1, ξ2, ... , ξ*N* ) = *N h*ˆ(ξ*i*), (26.86)

<span id="page-486-2"></span>
$$
\dot{h}\,u_a(\xi) = \varepsilon_a u_a(\xi), \quad \text{for } \xi = \xi_1, \xi_2, \dots, \tag{26.87}
$$

where ξ*i* represents the coordinates, momenta, and spin of particle *i* and *h*ˆ(ξ ) is the Hamiltonian for a single particle having coordinates ξ, the same function for each particle.

> α

*i*=1

For each particle, we label the eigenstates of a complete set of commuting observables, including *h*ˆ, by a single number7 α, where α = 1, 2, .... Thus, *h u*ˆ α(ξ ) = εα*u*α(ξ ), for ξ = ξ1, ξ2, ... , (26.87) or more succinctly *h*ˆ|α- = εα|α-, where εα is the energy of the state α. Each physically distinct quantum state of a system of *N* bosons or fermions can be described by specifying a set {*n*α} of occupation numbers *n*α (sometimes called

$$\sum_{a} n_{a} = \mathcal{N} \tag{26.88}$$

shall have

|α = 1-

$$\sum_{a} n_{a} \varepsilon_{a} = \mathcal{E},\tag{26.89}$$

<span id="page-486-1"></span>and

sequentially according to some scheme.

a distribution) for each of the states |α-

, *n*2 particles in |α = 2-

<span id="page-486-0"></span> α *n*αεα = *E*, (26.89) where *E* is the total energy. Given a set of occupation numbers {*n*α}, we focus on only the subset of nonzero occupation numbers, *n*α, *n*β , ... , *n*γ , where now α, β, ... , γ represent specific eigenstates

$$\psi_{\{n_a\}}(\xi_1, \xi_2, \dots, \xi_\beta \gamma) = \prod_{l=1}^{n_a} u_\alpha(\xi_l) \prod_{j=n_a+1}^{n_a+n_\beta} u_\beta(\xi_j) \cdots \prod_{k=\mathcal{N}-n_\gamma}^{\mathcal{N}} u_\mathcal{V}(\xi_k), \tag{26.90}$$

*k*=*N*−*n*γ

7Generally, a set of quantum numbers is used to label each state, but we simply renumber these sets

*j*=*n*α+1

*Chapter 26* • Quantum Statistics 467

$$S \coloneqq \frac{1}{\mathcal{N}!} \sum_{\text{all}} P,\tag{26.91}$$
 
$$\text{and} \qquad \left[\begin{array}{c} \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \dots \quad \right]$$

because it specifies which particles are in a given state. We can, however, obtain from it a wave function having the desired symmetry properties by summing over all permutations of the ξ*i* as follows:

$$A \coloneqq \frac{1}{\mathcal{N}!} \sum_{\text{all}} P(-1)^p,\tag{26.92}$$

*N* ! all where the sum is over all permutations and *P* is a permutation operator that permutes the coordinates ξ*i*. For fermions we apply the anti-symmetrization operator *A* := 1 *N* ! all *P*(−1) *p*, (26.92) where the factor (−1)*p* is +1 or −1 according to whether the permutation *p* generated by *P* is even or odd. In applying *A* to ψ(ξ1, ξ2, ... , ξ*N* ) in Eq. (26.90), we see immediately that the result is zero if any *n*α > 1. This follows because one possible permutation would involve an interchange of two particles in the same state, which would produce terms of opposite sign. To get a nonvanishing result for fermions, all of the states

belonging to the subset of nonvanishing occupation numbers must be different and

numbers for the single particle states are 0 and 1, which is equivalent to the Pauli exclusion

<span id="page-487-0"></span>
$$\Psi^{B}_{\{n_{a}\}}(\xi_{1},\xi_{2},\ldots,\xi_{\mathcal{N}}) = \left[\frac{N!}{n_{a}!n_{\beta}!\cdots n_{\mathcal{V}}!}\right]^{1/2} S \prod_{l=1}^{n_{a}} u_{a}(\xi_{l}) \prod_{j=n_{a}+1}^{n_{a}+n_{\beta}} u_{\beta}(\xi_{j}) \cdots \prod_{k=\mathcal{N}-n_{\mathcal{V}}}^{N} u_{\mathcal{V}}(\xi_{k}).\tag{26.93}$$

*B* {*n*α}(ξ1, ξ2, ... , ξ*N* ) = *N* ! *n*α!*n*β!··· *n*γ ! 1/2 *S n*α *i*=1 *u*α(ξ*i*) *n*α +*n*β *j*=*n*α+1 *u*β(ξ*j*)··· *N k*=*N*−*n*γ *u*γ (ξ*k*). (26.93)

$$\Psi_{\{n_a\}}^B(\xi_1, \xi_2, \dots, \xi_N) = \left[\frac{n_a! n_\beta! \cdots n_\gamma!}{N!}\right]^{1/2} \sum_{\text{dis}} P \prod_{l=1}^{n_a} \mu_a(\xi_l) \prod_{j=n_a+1}^{n_a+n_\beta} \mu_\beta(\xi_j) \cdots \prod_{k=\mathcal{N}-n_\gamma}^{N} \mu_\gamma(\xi_k), \quad (26.94)$$

*B* {*n*α}(ξ1, ξ2, ... , ξ*N* ) = *n*α!*n*β!··· *n*γ ! *N* ! 1/2 *P n*α *i*=1 *u*α(ξ*i*) *j*=*n*α+1 *u*β(ξ*j*)··· *k*=*N*−*n*γ *u*γ (ξ*k*), (26.94)

all

dis

have occupation numbers equal to 1. Thus for fermions, the only possible occupation

where now the sum is only over *N* !/(*n*α!*n*β !··· *n*γ !) distinct permutations.

*F*

**fermions**

$$\begin{split} \Psi^{F}_{\left[\hbar_{\mathsf{u}}\right]}(\xi_{1},\xi_{2},\ldots,\xi_{\mathcal{N}}) &= \left[\mathcal{N}!\right]^{1/2} A \, \mathsf{u}_{\alpha}(\xi_{1}) \mathsf{u}_{\beta}(\xi_{2}) \cdots \mathsf{u}_{\mathcal{N}}(\xi_{\mathcal{N}}) \\ &= \left[\frac{1}{\mathcal{N}!}\right]^{1/2} \sum_{\text{all}} P(-1)^{p} \, \mathsf{u}_{\alpha}(\xi_{1}) \mathsf{u}_{\beta}(\xi_{2}) \cdots \mathsf{u}_{\mathcal{N}}(\xi_{\mathcal{N}}). \end{split} \tag{26.95}$$

<span id="page-488-0"></span>

$$\Psi^{F}_{\{\boldsymbol{\mu}_{\boldsymbol{\mu}}\}}(\boldsymbol{\xi}_{1},\boldsymbol{\xi}_{2},\ldots,\boldsymbol{\xi}_{\mathcal{N}}) = \left[\frac{1}{\mathcal{N}!}\right]^{1/2} \begin{bmatrix} u_{\boldsymbol{\mu}}(\boldsymbol{\xi}_{1}) & u_{\boldsymbol{\beta}}(\boldsymbol{\xi}_{1}) & \cdots & u_{\boldsymbol{\gamma}}(\boldsymbol{\xi}_{1}) \\ u_{\boldsymbol{\mu}}(\boldsymbol{\xi}_{2}) & u_{\boldsymbol{\beta}}(\boldsymbol{\xi}_{2}) & \cdots & u_{\boldsymbol{\gamma}}(\boldsymbol{\xi}_{2}) \\ \vdots & \vdots & \vdots & \vdots \\ \boldsymbol{\mu}_{\boldsymbol{\mu}}(\boldsymbol{\xi}_{\mathcal{N}}) & u_{\boldsymbol{\beta}}(\boldsymbol{\xi}_{\mathcal{N}}) & \cdots & u_{\boldsymbol{\gamma}}(\boldsymbol{\xi}_{\mathcal{N}}) \end{bmatrix}.\tag{26.96}$$

Consequently, for fermions, the wave function can be expressed as a Slater determinant:

*F* {*n*α}(ξ1, ξ2, ... , ξ*N* ) = 1 *N* ! 1/2 ⎡ ⎢ ⎢ ⎢ ⎣ *u*α(ξ1) *u*β (ξ1) ··· *u*γ (ξ1) *u*α(ξ2) *u*β (ξ2) ··· *u*γ (ξ2) . . . . . . . . . . . . *u*α(ξ*N* ) *u*β(ξ*N* ) ··· *u*γ (ξ*N* ) ⎤ ⎥ ⎥ ⎥ ⎦ . (26.96) See Appendix I for an alternative way of representing boson and fermion states in Dirac

$$\mathcal{N}!/(\mathfrak{n}_{\mathfrak{a}}!n_{\mathfrak{f}}!\cdots n_{\mathfrak{f}}!), \quad \text{for identical but distinguishable boltzons.} \tag{26.97}$$

crostates is quite different for systems of identical bosons, fermions, or classical particles, which for brevity we will refer to as **'boltzons'** since they are the sort of particle tre[ated by](#page-486-1)

$$W_G = 1/(n_a!n_{\beta}!\cdots n_{\gamma}!), \quad \text{for indistinguishable boltzons.} \tag{26.98}$$

*N* !/(*n*α!*n*β!··· *n*γ !), for identical but distinguishable boltzons. [(26.97](#page-488-0)) For indistinguishable boltzons, this number could be reduced by *N* !, as su[ggested](#page-486-2) by Gibbs, to give a weighting factor *W*G = 1/(*n*α!*n*β!··· *n*γ !), for indistinguishable boltzons. (26.98) This weighting factor *W*G < 1 unless *n*α = *n*β = ··· = *n*γ = 1 (or 0, which means here that the state is not included) in which case *W*G = 1. If the wave functions in Eq. (26.90) were used to represent indistinguishable bosons, they would constitute only one quantum

$$\mathcal{W}_{\mathbb{B}} = 1,\quad \text{for indistinguishable bosons, any } \langle n_u \rangle \text{.}\tag{26.99}$$

different, in which case they would represent only one state represented by Eq. (26.96). Therefore, the weighting factors for any configuration set {*n*α} that satisfies Eq. (26.88) are

$$\mathcal{W}_{\mathbb{F}} = 1,\quad \text{for indistinguishable fermions, } (n_a) = 0, 1. \tag{26.100}$$

and *W*F = 1, for indistinguishable fermions,{*n*α} = 0, 1. (26.100) One might ask under what circumstances systems of indistinguishable boltzons, bosons, and fermions would lead to the same number of quantum states. The answer is: under conditions for which the number of available single particle states is extremely large compared to the total number of particles. A single particle state is deemed to be accessible if its Boltzmann factor exp(−βε) is not negligibly small. Thus there will be a huge number of accessible states at high temperature. Then if the system is also sufficiently dilute, the probability of multiply-occupied states will be extremely small and most states will be either unoccupied or singly occupied. Under these conditions, every significant set of occupation numbers will contain only ones and zeros, so the Gibbs-

boltzon weighting factor *W*G for such a state will be practically unity.

transition in a binary alloy.

σ*i* = ±1. This results in

27 Ising Model

Until now we have confined most of our treatments to systems of weakly interacting particles. A number of new phenomena, generally referred to as cooperative phenomena, arise whenever particles interact. These phenomena often include phase transitions, such

$$\mathcal{H} = -\frac{1}{2} \sum_{l,l} I_l \mathbf{\hat{S}}_l \cdot \mathbf{\hat{S}}_l \tag{27.1}$$

The present chapter is devoted primarily to the study of a model known as the Ising model which is a simple tractable model for a magnetic system. We begin by considering a **spin Hamiltonian** of the form *H* = −1 2 - *i*,*j Jij***S***i* · **Sj**, (27.1) where the quantities **S***i* play the role of spins situated on a lattice, the sums are over all lattice sites, and *Jij* is a coupling constant. Such a spin Hamiltonian is a drastic simplification itself. The spins are actually pseudo-spins that might be combinations of spin and orbital angular momenta. The interaction itself is primarily due to electrostatic energies

$$\mathcal{H} = -\frac{1}{2}f \sum_{l,j}^{mn} \mathbf{S}_l \cdot \mathbf{S}_l. \tag{27.2}$$

<span id="page-489-0"></span>*nn*

*H* = −1 2 *J i*,*j* **S***i* · **S***j*. (27.2) Here, there is just one coupling constant *J* and the sum is only over nearest neighbors.

$$\mathcal{H} = -\frac{1}{2}I\sum_{l,j}^{mn}\sigma_l\sigma_j = -I\sum_{l,j}^{mp}\sigma_l\sigma_j,\tag{27.3}$$

*H* [=](http://dx.doi.org/10.1016/B978-0-12-803304-3.00027-2) [−](http://dx.doi.org/10.1016/B978-0-12-803304-3.00027-2)1 2 *J i*,*j* σ*i*σ*j* = −*J* - *i*,*j* σ*i*σ*j*, (27.3) where the second sum is over nearest-neighbor pairs. This model gives rise to only two energy states for a pair of nearest-neighbor spins, aligned neighbors (1, 1 or −1, −1) with energy −*J* and opposite neighbors (1, −1 or −1, 1) with energy *J*. Despite this drastic simplification, the Ising model still presents some challenging problems, even though it

allows for exact solutions for lattices in one and two spatial dimensions.

470 THERMAL PHYSICS

<span id="page-490-2"></span>
$$\mathcal{H} = -\frac{1}{2} \sum_{l,j} I_{l\bar{\jmath}} \sigma_l \sigma_j - \mu^* \mathcal{B} \sum_l \sigma_l,\tag{27.4}$$

$$J\eta = \begin{cases} J > 0 & \text{if } i \text{ and } j \text{ are nearest neighbors.} \\ 0 & \text{otherwise.} \end{cases} \tag{27.5}$$

form1 *H* = −1 2 - *Jij*σ*i*σ*j* − μ∗*B* - σ*i*, (27.4)

*i*,*j i* where μ∗ > 0 is a magnetic moment (not the chemical potential) and

<span id="page-490-1"></span><span id="page-490-0"></span>
$$
\sigma_l = (\sigma_l - \langle \sigma_l \rangle) + \langle \sigma_l \rangle \tag{27.6}
$$

*Jij* = 0 otherwise. (27.5)

> <span id="page-490-3"></span>−1 [2](#page-490-2)

more evident if we introduce the notation

$$-\frac{1}{2}\sum_{l,j} I_{lj}\sigma_l\sigma_j = \frac{1}{2}\sum_{l,j} I_{lj}\langle\sigma_l|\langle\sigma_j\rangle - \sum_{l,j} I_{lj}\sigma_l\langle\sigma_j|$$

$$-\frac{1}{2}\sum_{l,j} I_{lj}(\sigma_l - \langle\sigma_l|)(\sigma_j - \langle\sigma_l|),\tag{27.7}$$

−1 2 - *i*,*j Jij*σ*i*σ*j* = 1 2 - *i*,*j Jij*σ*i*σ*j* −- *i*,*j Jij*σ*i*σ*j* −1 2 - *Jij*(σ*i* − σ*i*)(σ*j* − σ*j*), (27.7)

$$-\frac{1}{2}\sum_{l,j} I_{lj}\sigma_l\sigma_l = \frac{1}{2}I\mathcal{N}q(\sigma)^2 - Iq(\sigma)\sum_l \sigma_l$$

$$-\frac{1}{2}\sum_{l,j} I_{lj}(\sigma_l - \langle\sigma\rangle)(\sigma_j - \langle\sigma\rangle),\tag{27.8}$$

*i*,*j i* − 1 

2 *i*,*j Jij*(σ*i* − σ)(σ*j* − σ), (27.8) where *N* is the number of lattice sites and *q* is the number of nearest neighbors. The term on the second line of Eq. (27.8) represents correlations between nearest-neighbor spins. This may be seen because its average would vanish if σ*i*σ*j* = σ*i*σ*j*=σ2 for *i* = *j*. This can also be seen because the average of the first two terms is −(1/2)*Jq*σ2 which would not equal the average of the left-hand side unless nearest-neighbor spins were uncorrelated. The second term on the right-hand side resembles the term in Eq. (27.4) that contains the external magnetic field *B*. This becomes

$$B_I := Jq \langle \sigma \rangle / \mu^* \tag{27.9}$$

*BJ* := *Jq*σ/μ∗ (27.9) 1The factor of 1/2 avoids double counting of interactions. The reader is cautioned that Ising Hamiltonians are often written without this factor of 1/2 and sometimes also with a factor of 2. If one sums only over nearestneighbor *pairs*, the factor of 1/2 should be omitted. The sign convention here is that μ∗σ*i* is the magnetic moment for this pseudo-spin.

$$\mathcal{H} = \frac{1}{2}I\mathcal{N}q(\sigma)^2 - \mu^*(\mathcal{B} + \mathcal{B}_l)\sum_l \sigma_l - \frac{1}{2}\sum_{l,j} l_{lj}(\sigma_l - \langle \sigma \rangle)(\sigma_j - \langle \sigma \rangle). \tag{27.10}$$

*Chapter 27* • Ising Model 471

in which case Eq. (27.4) takes the form

<span id="page-491-0"></span>
$$\mathcal{H}_{\rm M} = \frac{1}{2} I \mathcal{N} \boldsymbol{q} (\boldsymbol{\sigma})^2 - \mu^*(\boldsymbol{B} + \boldsymbol{B}_l) \sum_l \sigma_l. \tag{27.11}$$

The quantity *BJ* is seen to play the role of a mean field experienced by a given spin due to the presence of the other spins. The **mean-field approximation**2 consists of ignoring the correlation term, resulting in a mean field Hamiltonian

*H*M = 1 2 *JN q*σ 2 − μ∗(*B* + *BJ*) *i* σ*i*. (27.11) Many books also ignore the first term in Eq. (27.11) because it depends only on average quantities and plays no role in computing the magnetization. Omitting it, however, leads

$$z = \exp[-\beta(1/2)]q(\sigma)^2[2\cosh(\beta\mu^*(B+B))]\tag{27.12}$$

a factor of 1/2 in a somewhat *ad hoc* manner. By using the mean field Hamiltonian given [by](#page-491-0) [Eq.](#page-491-0) (27.11), we obtain a problem for

spin is therefore

*H* = 1 2 *JN q*σ

$$p_{+} = \frac{\exp[\beta \mu^{*} (B + B_{l})]}{2 \cosh[\beta \mu^{*} (B + B_{l})]}; \quad p_{-} = \frac{\exp[-\beta \mu^{*} (B + B_{l})]}{2 \cosh[\beta \mu^{*} (B + B_{l})]} \tag{27.13}$$

and the probabilities are *p*+ = exp[βμ∗(*B* + *BJ*)] [2 co](#page-490-3)sh[βμ∗(*B* + *BJ*)] ; *p*[−](#page-491-2) = exp[−βμ∗(*B* + *BJ*)] 2 cosh[βμ∗(*B* + *BJ*)] (27.13)

$$
\langle \sigma \rangle = p_+ - p_- = \tanh[\beta \mu^* (B + B)) \tag{27.14}
$$

factor in *z*, which came from the first term in Eq. (27.11). The magnetization*M* = *N* μ∗σ, where

defining a dimensionless parameter

<span id="page-491-3"></span><span id="page-491-2"></span>
$$U = \langle \mathcal{H}_{\rm M} \rangle = -\frac{1}{2} J \mathcal{N} q \langle \sigma \rangle^2 - \mu^* \mathcal{N} B \langle \sigma \rangle. \tag{27.15}$$

<span id="page-491-1"></span>and the average energy is3 1

$$
\langle \sigma \rangle = \tanh[\beta \mu^* (\mathcal{B} + Jq \langle \sigma \rangle / \mu^*)], \tag{27.16}
$$

Since *BJ* is given by Eq. (27.9), we see that Eq. (27.14) can be rewritten in the form σ = tanh[βμ∗(*B* + *Jq*σ/μ∗)], (27.16)

$$\mathbf{x} = \beta \mu^*(\mathbf{B} + J\mathbf{q} \langle \sigma \rangle / \mu^*). \tag{27.17}$$

*x* = βμ∗(*B* + *Jq*σ/μ∗). (27.17)

field approximation arises because average quantities appear in the mean field Hamiltonian.

<sup>2</sup>This is also known as the Bragg-Williams or the Weiss molecular field approximation. 3Since *BJ* depends on σ which in turn depends on β and *B*, the formulae *M* = −*N k*B*T*∂ ln *z*/∂*B* and *U* = −∂ ln *z*/∂β will only work if σ is held constant during the differentiation. This inconsistency of the mean

472 THERMAL PHYSICS

![](_page_492_Figure_1.jpeg)

0.5

x

-3 -2 -1 1 2 3

<span id="page-492-1"></span>-0.5

Then

$$
\langle \sigma \rangle = -\frac{\mu^* B}{Jq} + \frac{k_\mathrm{B} T}{Jq} \mathbf{x} \tag{27.18}
$$

of 1.4, 1, and 0.6. There are only solutions for *x* = 0 for *k*B*T*/*Jq* < 1.

negative solutions for all *T* when *B* < 0.

direction opposite to the spontaneous magnetization that occurs in zero field.

$$-\frac{\mu^*B}{Jq} + \frac{k_\text{B}T}{Jq}\mathbf{x} = \tanh\mathbf{x}.\tag{27.19}$$

σ=−μ∗*B Jq* + *Jq x* (27.18) and Eq. (27.16), which is now σ = tanh*x*, becomes − μ∗*B Jq* + *k*B*T Jq x* = tanh *x*. (27.19) Viewed as a function of *x*, the left-hand side of Eq. (27.19) is just a straight line of slope *k*B*T*/*Jq* and intercept −μ∗*B*/*Jq* and the right-hand side is a curve that can be drawn once

$$T_{\mathbf{c}} = q \mathbf{J} / k_{\mathbf{B}} \tag{27.20}$$

are solutions for *x* = 0 provided that *k*B*T*/*Jq* < 1 and [otherwise no](#page-493-0) solutions. This defines a **critical [te](#page-492-0)mperature**

*T*c = *qJ*/*k*B (27.20) below which there is a spontaneous magnetization in the absence of an applied magnetic field. Note that if *x* is a solution, −*x* is also a solution. This degeneracy arises because *B* = 0 so there is no preferred direction for the spontaneous magnetic field. If we started with a

<span id="page-492-0"></span>finite positive field and then let it shrink to zero, we would create a bias for the positive solution. Graphical solutions for *B* > 0 are illustrated in Figure 27–2. We see that positive solutions4 for *x* exist for all values of *k*B*T*/*Jq*, but those for large *T* correspond to small values of *x* and therefore to small values of σ = tanh *x*. Similar considerations lead to

<sup>4</sup>For sufficiently small positive values of *k*B*T*/*Jq*, there can also be negative solutions. These can be shown to correspond to metastable or unstable solutions that represent cases in which a magnetic field is applied in a

<span id="page-493-0"></span>![](_page_493_Figure_1.jpeg)

-3 -2 -1 1 2 3 -0.5 x

-1 **FIGURE 27–2** Graphical solution of Eq. (27.19) for *B* > 0, namely μ∗*B*/*Jq* = 0.5 for the sake of illustration. The curve is tanh *x* and the lines have slopes *k*B*T*/*Jq* of 1.4 and 0.6. There are positive solutions for all values of *k*B*T*/*Jq* but those for large *T* correspond to small values of *x* and therefore to small values of σ = tanh *x*. For *B* < 0, the lines would have a positive intercept and the solutions for *x* would be negative. The foregoing results in the mean field approximation are suggestive but *incorrect*. Indeed, it is possible to solve the Ising model exactly in one dimension and two dimensions and num[erically in th](#page-493-1)ree and higher dimensions. There are also better approximate solutions for all dimensions. The most serious discrepancy occurs in one dimension

$$\frac{k \lg T_{\rm c}}{J} = \frac{2}{\ln(1 + \sqrt{2})} = 2.26919,\tag{27.21}$$

temperatures *T*c > 0 but the numerical values of *k*B*T*c/*J* are different. For instance, the exact two-dimensional solution for a square lattice, due to Onsager, gives *k*B*T*c *J* = 2 ln(1 + √ 2) = 2.26919, (27.21) whereas the mean field approximation gives *k*B*T*c/*J* = 4. Some comparative values of *T*c are given in Table 27–1. We see that the mean field model shows the general trend with dimensionality but is certainly wrong in detail because correlations are neglected. The cluster model of Boethe (see Pathria [8, p. 329]) takes into account the correlations

<span id="page-493-1"></span>
$$\frac{k_{\rm B}T_{\rm c}}{J} = \frac{2}{\ln[q/(q-2)]}.\tag{27.22}$$

*k*B*T*c *J* = 2 ln[*q*/(*q* − 2)] . (27.22)

| Dimensionality | 1 | 2       | 3       | 4       | 5       | 6       | 7       |
|----------------|---|---------|---------|---------|---------|---------|---------|
| Exact          | 0 | 2.26919 |         |         |         |         |         |
| Numerical      |   | 2.26919 | 4.51153 | 6.68003 | 8.77739 | 10.8348 | 12.8690 |
| Boethe         | 0 | 2.88539 | 4.93261 | 6.95212 | 8.96284 | 10.9696 | 12.9743 |
| Mean field     | 2 | 4       | 6       | 8       | 10      | 12      | 14      |

*Note*: Numerical results are from Galam and Mauger [70].

474 THERMAL PHYSICS

transition for any *T* > 0.

function to obtain

![](_page_494_Figure_1.jpeg)

0.2 0.4 0.6 σ

[0.](#page-491-2)2 0.4 [0.6](#page-492-1) 0.8 1 1.2 1.4 1.6 T/Tc

**FIGURE 27–3** Dimensionless magnetization per spin, σ = *M*/*N* μ∗, versus dimensionless temperature *t* = *T*/*T*c for *B* = 0 and *b* = μ∗*B*/*Jq* = 0.05 according to the parametric equations Eq. (27.23). For *B* = 0, the magnetization is zero for *T* > *T*c but for *B* > 0 it extends beyond *T*c.

$$
\langle \sigma \rangle = \tanh x; \quad t = \frac{\tanh x}{x} + \frac{b}{x}, \tag{27.23}
$$

per spin, *M*/*N* μ∗ = σ, as a function of *T*/*T*c [for](#page-494-0) *B* = 0 and *B* > 0. These plots were constructed by writing Eqs. (27.14) and (27.19) in the parametric form σ = tanh *x*; *t* = tanh *x x* + *b x* , (27.23)

where the dimensionless temperature *t* := *T*/*T*c and the dimensionless magnetic field *b* := (μ∗*B*/*Jq*) = (μ∗*B*/*k*B*T*c). For a given value of *b*, one can assign values of the parameter *x* and construct a plot of σ versus *t*. For *b* = 0, we see that σ = 0 for *T* > *T*c but for *b* > 0

$$m = \tanh(m/t) = \frac{\mathbf{e}^{2m/t} - 1}{\mathbf{e}^{2m/t} + 1}.\tag{27.24}$$

follows: For *B* = 0 we can eliminate *x* from Eq. (27.23) to obtain *m* = tanh(*m*/*t*) = e2*m*/*t* − 1 e2*m*/*t* + 1 . (27.24)

3(1 − *t*)

2*p* + 1

$$\frac{1}{t} = \frac{1}{2m} \ln \left( \frac{1+m}{1-m} \right) = \sum_{p=0}^{\infty} \frac{m^{2p}}{2p+1},\tag{27.25}$$

1 *t* = 1 2*m* ln1 + *m* 1 − *m* = *p*=0

$$t = \frac{1}{1 + m^2/3 + m^4/5 + \dotsb} = 1 - m^2/3 - 4m^4/45 + \dotsb,\tag{27.26}$$
 
$$\text{which can be calculated in account volume times.}$$

1 + *m*2/3 + *m*4/5 +··· = 1 − *m*2/3 − 4*m*4/45 +··· , (27.26)

which can be solved to lowest order to give

$$m = \sqrt{3}(1-t)^{1/2}.\tag{27.27}$$

<span id="page-494-0"></span>, (27.25)

*Chapter 27* • Ising Model 475

Equation (27.27) shows how the magnetization rises from zero as *T* decreases slightly from

$$C_V = \frac{\partial U}{\partial T} = -\mathcal{N} \mathcal{J} q(m+b) \frac{\partial m}{\partial T}. \tag{27.28}$$

two dimensions, the correct critical exponent is 1/8 for a square lattice and approximately 0.313 for a simple cubic lattice in three dimensions. As was the case with *T*c itself, the mean

∂*m*

$$m = \tanh\left[\frac{1}{t}(b+m)\right].\tag{27.29}$$

Then

susceptibility

Then\\

$$\frac{\partial m}{\partial T} = \text{sech}^2 \left[ \frac{1}{t} (b+m) \right] \left[ \frac{1}{t} \frac{\partial m}{\partial T} - \frac{1}{t^2 T_\odot} (b+m) \right],\tag{27.30}$$
\\
which we can solve to obtain

*m* = tanh

$$\frac{\partial m}{\partial T} = -\frac{(b+m)(1-m^2)}{t^2 - t(1-m^2)}\frac{1}{T_\mathrm{c}},\tag{27.31}$$

<span id="page-495-0"></span>. (27.29)

∂*m* ∂*T* = sech2 1 *t* (*b* + *m*) *t* ∂*T* − 1 *t*2*T*c (*b* + *m*) , (27.30) which we can solve to obtain

(*b* + *m*)  ∂*m*

$$\frac{C_V}{Nk_\text{B}} = \frac{(b+m)^2(1-m^2)}{t^2 - t(1-m^2)}.\tag{27.32}$$

where we have used sech2 (*b* + *m*)/*t* = 1 − *m*2. Combining Eqs. (27.28) and (27.31) gives *CV* = (*b* + *m*)[2](#page-495-0)(1 − *m*2)

$$t = \frac{\tanh x}{x} + \frac{b}{x}; \quad \frac{C_V}{\mathcal{N}k_{\mathbb{B}}} = \frac{x^2(\tanh x + b)\operatorname{sech}^2 x}{(\tanh x + b) - x\operatorname{sech}^2 x}. \tag{27.33}$$

Eq. (27.23) and obtain, after some algebra, the parametric equations *t* = tanh *x x* + *b x* ; *CV N k*B = *x*2(tanh *x* + *b*) sech2*x* (tanh *x* + *b*) − *x* sech2 *x* . (27.33) Figure 27–4 shows a plot of *CV* /*N k*B versus *T*/*T*c for *B* = 0 and *B* > 0. For *B* = 0 there is a sharp peak at *CV* /*N k*B = 3/2 at *T* = *T*c and zero heat capacity for *T* > *T*c. The height of this peak is not obvious from Eq. (27.32) or (27.33) because the function is discontinuous

$$U/N = -(1/2)lqm^2 = -(3/2)k_{\mathbb{B}}(T_{\mathbb{C}} - T); \quad T \approx T_{\mathbb{C}},\tag{27.34}$$

*U*/*N* = −(1/2)*Jqm*2 = −(3/2)*k*B(*T*c − *T*); *T* ≈ *T*c, (27.34) and then differentiating with respect to *T*. The same technique of implicit differentiation can be used to compute the magnetic

*t* − (1 − *m*2)

*k*B*T*c

$$\chi = \frac{\partial \mathcal{M}}{\partial B} = \mathcal{N}\mu^* \frac{\partial m}{\partial B} = \frac{\mathcal{N}\mu^* 2}{k_\text{B}T_\text{c}} \frac{1 - m^2}{t - (1 - m^2)}. \tag{27.35}$$

476 THERMAL PHYSICS

0.25

2

χ˜

1

 kB

![](_page_496_Figure_1.jpeg)

<span id="page-496-0"></span>0.5 0.75 C*V* /*N*

![](_page_496_Figure_3.jpeg)

0.25 0.5 0.75 1 1.25 1.5 1.75 2 1 2

*B*/*Jq* = 0.05 (low peak) and *b* = 0.02 (high peak) according to the parametric equations Eq. (27.37). For *B* = 0, the [susceptibility di](#page-496-0)verges as *T* → *T*c.

For *t* 1 we have *m*  1 so

$$\chi \approx \frac{N\mu^{*2}}{k_{\rm B}(T - T_{\rm c})},\tag{27.36}$$

χ ≈ *N* μ∗2

T/Tc

**FIGURE 27–5** Dimensionless magnetic susceptibility, χ˜, versus dimensionless temperature *t* = *T*/*T*c for *b* = μ∗

$$t = \frac{\tanh x}{x} + \frac{b}{x}; \quad \tilde{\chi} := \frac{\chi k_{\rm B} T_{\rm c}}{\mathcal{N} \mu^{\ast 2}} = \frac{x \text{sech}^2 x}{(\tanh x + b) - x \text{sech}^2 x}. \tag{27.37}$$

*t* = tanh *x x* + *b x* ; χ˜ := χ*k*B*T*c *N* μ∗2 = *x* sech2*x* (tanh *x* + *b*) − *x* sech2 *x* . (27.37) Figure 27–5 shows a plot of the dimensionless susceptibility χ˜ as a function of *t* = *T*/*T*c for two positive magnetic fields. As the field strength is decreased, the peak in the vicinity of *t* = 1 becomes progressively higher and ultimately diverges as *B*→0. We can see the nature

$$
\tilde{\chi} \approx \frac{1}{2} (1 - t)^{-1} \quad \text{for } t < 1 \text{ and } t \approx 1. \tag{27.38}
$$

Thus χ diverges like (1 − *t*)−γ with a critical exponent γ = 1. Although the mean field model is incorrect, this value of γ is close to values 1.2-1.4 measured for magnetic systems

- [8, p. 336].
	-
- 27.2 Pair Statistics
- More insight about the Ising model can be gained by studying the **statistics of nearest-**
- **neighbor pairs**. To do this, we follow Pathria [8, p. 318] and introduce the following
- notation:

• *N* = total number of spins • *N*+ = total number of "up" spins • *N*− = total number of "down" spins

$$q\mathcal{N}_{+} = 2\mathcal{N}_{++} + \mathcal{N}_{+-}; \quad q\mathcal{N}_{-} = 2\mathcal{N}_{--} + \mathcal{N}_{+-} \tag{27.39}$$

• *N*+− = total number of "opposite" nearest-neighbor pairs In general, we certainly have *N* = *N*+ + *N*−. We treat the case of periodic boundary conditions so that all lattice sites are equivalent. It follows that:

$$\mathcal{N}_{-} = \mathcal{N} - \mathcal{N}_{+} \tag{27.40}$$

*Chapter 27* • Ising Model 477

$$\mathcal{N}_{+-} = \mathfrak{q}\mathcal{N}_{+} - 2\mathcal{N}_{++} \tag{27.41}$$

$$\mathcal{N}_{--} = \mathfrak{q}\mathcal{N}/2 + \mathcal{N}_{++} - \mathfrak{q}\mathcal{N}_{+}.\tag{27.42}$$

*N*− = *N* − *N*+ (27.40)

$$-\frac{1}{2}\sum_{l,j}I_{lj}\sigma_l\sigma_j = -I\left(\mathcal{N}_{++} + \mathcal{N}_{--} - \mathcal{N}_{+-}\right) = -I\left(\mathfrak{q}\mathcal{N}/2 + 4\mathcal{N}_{++} - 2\mathfrak{q}\mathcal{N}_{+}\right) \tag{27.43}$$

The part of the Ising Hamiltonian that is independent of the magnetic field is − 1 -

2

gives

$$M = \mu^* \left( \mathcal{N}_+ - \mathcal{N}_- \right) = \mu^* \left( 2\mathcal{N}_+ - \mathcal{N} \right). \tag{27.44}$$

*i*,*j* and the magnetic moment for such a configuration is *M* = μ∗ (*N*+ − *N*−) = μ∗ (2*N*+ − *N* ). (27.44) The difficulty of solving the Ising problem, even for zero magnetic field, can be appreciated

### by realizing that it amounts to enumerating all possible configurations of *N*+ and *N*++, a difficult combinatorial problem.

27.2.1 Average Pair Statistics for Mean Field We can learn more about the nature of the mean field approximation by taking averages of the above equations. The average of Eq. (27.43) with correlations ignored, so σ*i*σ*j*=σ2,

$$-q\mathcal{N}\langle\sigma\rangle^2/2 = -J\left(q\mathcal{N}/2 + 4\langle\mathcal{N}_{++}\rangle - 2q\langle\mathcal{N}_{+}\rangle\right) \tag{27.45}$$

$$
\mathcal{N}\langle\sigma\rangle = 2\langle\mathcal{N}_{+}\rangle - \mathcal{N}.\tag{27.46}
$$

478 THERMAL PHYSICS

$$p_+ := \frac{\langle \mathcal{N}_+ \rangle}{\mathcal{N}} = \frac{1}{2} (1 + \langle \sigma \rangle),\tag{27.47}$$

$$p_- := \frac{\langle \mathcal{N}_- \rangle}{\mathcal{N}} = \frac{1}{2} (1 - \langle \sigma \rangle),\tag{27.48}$$

$$p_{++} \coloneqq \frac{\langle \mathcal{N}_{++} \rangle}{\mathcal{N}q/2} = \frac{1}{4}(1 + \langle \sigma \rangle)^2 = p_+^2,\tag{27.49}$$

$$p_{+-} := \frac{\langle \mathcal{N}_{+-} \rangle}{\mathcal{N}q/2} = \frac{1}{2}(1 + \langle \sigma \rangle)(1 - \langle \sigma \rangle) = 2p_{+}p_{-},\tag{27.50}$$

*N* = 1 2 *p*++ := *N*++ *N q*/2 = 1 4 (1 + σ) 2 = *p*2 +, [(27.](#page-498-0)49)

*p*+− := *N*+− *N q*/2 = 1 2 (1 + σ)(1 − σ) = 2*p*+*p*−, (27.50)

<span id="page-498-0"></span>*p*−− := *N*−− *N q*/2 = 1 4 (1 − σ) 2 = *p*2 −. (27.51) We observe that *p*++, *p*+−, and *p*−− are just the terms in the expansion of (*p*+ + *p*−)2. This indicates that the spins are randomly distributed in the mean field approximation and further emphasizes that correlations have been ignored. Plots of these probabilities as a function of temperature are shown in Figure 27–6 for

*B* → 0 from positive values. At the critical temperature, σ = 0 so *p*+ = *p*− = 1/2, *p*++ = *p*−− = 1/4, and *p*+− = 1/2. From the shapes of the *p*+− and *p*−− plots, we see that the

![](_page_498_Figure_11.jpeg)

t t **FIGURE 27–6** Probabilities *p*+ and *p*− of up and down spins (left) and pairs *p*++, *p*+−, and *p*−− as a function of dimensionless temperature *t* = *T*/*T*c for the Ising model in the mean field approximation for *B* → 0 from positive

0.2 0.4 0.6 0.8 1

0.2 0.4 0.6 0.8 1

values.

<span id="page-499-1"></span>*H* = −1

-

<span id="page-499-0"></span>
$$\mathcal{H} = -\frac{1}{2} \sum_{l,j} J_{lj} \sigma_l \sigma_j = -J \sum_{l=1}^{N} \sigma_l \sigma_{l+1} = -J \sum_{l=1}^{N} \tau_l,\tag{27.52}$$

27.3 Solution in One Dimension for Zero Field In one dimension with periodic boundary conditions, it is possible to solve exactly the

$$\cdots \cdots \tag{2.7.27}$$

$$\prod_{l=1}^{N} \tau_l = \prod_{l=1}^{N} \sigma_l \sigma_{l+1} = \prod_{l=1}^{N} \sigma_l^2 = 1. \tag{27.53}$$

2 *i*,*j i*=1 *i*=1 where the pair operators τ*i* := σ*i*σ*i*+1. [For p](#page-499-0)eriodic boundary conditions, we have

$$Z = \sum_{\sigma_1} \cdots \sum_{\sigma_{\mathcal{N}}} \exp\left[\mathcal{Y} \sum_l \sigma_l \sigma_{l+1}\right] = 2 \sum_{\tau_1} \cdots \sum_{\tau_{\mathcal{N}}} \exp\left[\mathcal{Y} \sum_l \tau_l\right],\tag{27.54}$$

Not[e](#page-499-1) [that](#page-499-1) the τ*i* take on the values ±1. The canonical partition function for the whole system is therefore exp - - exp - 

*Z* = σ1 ···σ*N y i* σ*i*σ*i*+1 = 2 τ1 ···τ*N y i* τ*i* , (27.54) where the sums are constrained by Eq. (27.53) and *y* := β*J*. The factor of 2 on the right-

$$Z = 2\sum_{\mathbf{r}_1} \mathbf{e}^{\mathcal{V}\mathbf{r}_1} \cdots \sum_{\mathbf{r}_{N'}} \mathbf{e}^{\mathcal{V}\mathbf{r}_{N'}} = 2(\mathbf{e}^{\mathcal{V}} + \mathbf{e}^{-\mathcal{V}})^{N'} = 2(2\cosh y)^{N'}, \quad \text{no constraint.} \tag{27.55}$$

Eq. (27.54) to obtain *Z* = 2 - τ1 e*y*τ1 ···- τ*N* e*y*τ*N* = 2(e*y* + e−*y*) *N* = 2(2 cosh *y*) *N* , no constraint. (27.55)

Equation (27.55) would be correct for a chain of length *N* with open ends, except not all spins would be equivalent for such a chain. This is, however, a very small effect for large *N*

$$2(\mathbf{e}^{\mathcal{V}} + \mathbf{e}^{-\mathcal{V}})^{\mathcal{N}} = 2\sum_{r=1}^{\mathcal{N}} \frac{\mathcal{N}!}{r!(\mathcal{N}-r)!} (\mathbf{e}^{\mathcal{V}})^{\mathcal{N}-r} (\mathbf{e}^{-\mathcal{V}})^r. \tag{27.56}$$

2(e*y* + e−*y*) *N* = 2 - *N r*=1 *N* ! *r*!(*N* − *r*)! (e*y*) *N*−*r* (e−*y*) *r* . (27.56)

$$2(\mathbf{e}^{\mathcal{V}} - \mathbf{e}^{-\mathcal{V}})^{\mathcal{N}} = 2\sum_{r=1}^{\mathcal{N}} \frac{\mathcal{N}!}{r!(\mathcal{N}-r)!} (\mathbf{e}^{\mathcal{V}})^{\mathcal{N}-r} (-\mathbf{e}^{-\mathcal{V}})^r \tag{27.57}$$

5Note that σ*i*σ*i*+1 = 1 when both factors are 1 and when both factors are −1; in each case, τ*i* = 1.

*r*!(*N* − *r*)!

*r*=1

$$Z = 2\frac{(\mathbf{e}^y + \mathbf{e}^{-y})^N + (\mathbf{e}^y - \mathbf{e}^{-y})^N}{2} = (\mathbf{e}^y + \mathbf{e}^{-y})^N + (\mathbf{e}^y - \mathbf{e}^{-y})^N. \tag{27.58}$$

$$Z = (2\cosh y)^{\mathcal{N}} + (2\sinh y)^{\mathcal{N}},\tag{27.59}$$

*N* . (27.58)

get twice the terms with even *r*, double what we want. The correct partition function for periodic boundary conditions is therefore

### *Z* = 2 2 = (e*y* + e−*y*) In terms of hyperbolic functions,

*Z* = (2 cosh *y*) *N* + (2 sinh *y*) *N* , (27.59) which agrees with the exact result obtained by using a transfer matrix, which we present in the next section.

$$\mathcal{H} = -J\sum_{l=1}^{N} \sigma_l \sigma_{l+1} - (1/2)\mu^* \mathcal{B} \sum_{l=1}^{N} (\sigma_l + \sigma_{l+1}). \tag{27.60}$$

*N* + (e*y* − e−*y*)

periodic boundary conditions in one dimension, we can write the Ising Hamiltonian in the form

the form

<span id="page-500-0"></span>
$$\exp(-\beta \mathcal{H}) = \exp\left[\mathbf{y}\sum_{l=1}^{N} \sigma_l \sigma_{l+1} + (\mathbf{x}/2) \sum_{l=1}^{N} (\sigma_l + \sigma_{l+1})\right],\tag{27.61}$$

Then

<span id="page-500-2"></span>(e*y* + e−*y* )*N* + (e*y* − e−*y*)*N*

<span id="page-500-1"></span>
$$Z = \sum_{\{\sigma_l\} = \pm 1} \exp(-\beta \mathcal{H}) \equiv \sum_{\sigma_1 = \pm 1} \sum_{\sigma_2 = \pm 1} \cdots \sum_{\sigma_N = \pm 1} \exp(-\beta \mathcal{H}).\tag{27.62}$$

where *x* := βμ∗*B* and *y* = β*J*. The partition function is given b[y](#page-500-1) *Z* = - exp(−β*H*) ≡ - - ··· - exp(−β*H*). (27.62)

$$\exp[\mathbf{y}\sigma_l\sigma_{l+1} + (\mathbf{x}/2)(\sigma_l + \sigma_{l+1})].\tag{27.63}$$

be written as a product of terms of the form exp[*y*σ*i*σ*i*+1 + (*x*/2)(σ*i* + σ*i*+1)]. (27.63) Such a term depends only on the product σ*i*σ*i*+1, which can take on only the values ±1, and the sum σ*i* + σ*i*+1, which can take on only the values −2, 0, 2, irrespective of the value of *i*. Therefore, for *any* value of *i*, the expression given by Eq. (27.63) can take on only the

$$Z = \sum_{\{\sigma_l\} = \pm 1} \langle \sigma_1 | \hat{P} | \sigma_2 \rangle \langle \sigma_2 | \hat{P} | \sigma_3 \rangle \cdots \langle \sigma_{\mathcal{N}-1} | \hat{P} | \sigma_{\mathcal{N}} \rangle \langle \sigma_{\mathcal{N}} | \hat{P} | \sigma_1 \rangle,\tag{27.64}$$

{σ*i*}=±1

*P* =

{σ*i*}=±1

$$P = \begin{pmatrix} \mathbf{e}^{y+x} & \mathbf{e}^{-y} \\ \mathbf{e}^{-y} & \mathbf{e}^{y-x} \end{pmatrix}. \tag{27.65}$$

$$
\langle 1|\hat{P}|1\rangle = \begin{pmatrix} 1 & 0 \end{pmatrix} \begin{pmatrix} \mathbf{e}^{y+x} & \mathbf{e}^{-y} \\ \mathbf{e}^{-y} & \mathbf{e}^{y-x} \end{pmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 1 & 0 \end{pmatrix} \begin{pmatrix} \mathbf{e}^{y+x} \\ \mathbf{e}^{-y} \end{pmatrix} = \mathbf{e}^{y+x}, \tag{27.66}
$$

whereas

$$\langle -1|\mathring{P}|1\rangle = \begin{pmatrix} 0 & 1 \end{pmatrix} \begin{pmatrix} \mathbf{e}^{\mathbf{y}+\mathbf{x}} & \mathbf{e}^{-\mathbf{y}} \\ \mathbf{e}^{-\mathbf{y}} & \mathbf{e}^{\mathbf{y}-\mathbf{x}} \end{pmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 0 & 1 \end{pmatrix} \begin{pmatrix} \mathbf{e}^{\mathbf{y}+\mathbf{x}} \\ \mathbf{e}^{-\mathbf{y}} \end{pmatrix} = \mathbf{e}^{-\mathbf{y}}.\tag{27.67}$$

their respective transposes, which are column vectors. For example, 1|*P*ˆ|1 = 1 0 e*y*+*x* e−*y* e−*y* e*y*−*x* 1 = 1 0 e*y*+*x* e−*y* = e*y*+*x*, (27.66)

<span id="page-501-1"></span>
$$Z = \sum_{\sigma_1=\pm 1} \langle \sigma_1 | \hat{P}^{\mathcal{N}} | \sigma_1 \rangle = \text{trace } \hat{P}^{\mathcal{N}} = \lambda_1^{\mathcal{N}} + \lambda_2^{\mathcal{N}},\tag{27.68}$$

e−*y*

−1|*P*ˆ|1 = 0 1 e−*y* e*y*−*x* 0 = 0 1

*Z* = -

σ1=±1

Since σ*i*=±1 |σ*i*σ*i*|=|11|+|− 1−1| is equal to the unit operator in a two-state space for any value of *i*, we have

> 

e*y*+*x* − λ e−*y* e−*y* e*y*−*x* − λ

$$\det \begin{vmatrix} \mathbf{e}^{\mathbf{y} + \mathbf{x}} - \lambda & \mathbf{e}^{-\mathbf{y}} \\ \mathbf{e}^{-\mathbf{y}} & \mathbf{e}^{\mathbf{y} - \mathbf{x}} - \lambda \end{vmatrix} = \mathbf{0}.\tag{27.69}$$

where λ1 and λ2 are the eigenvalues of the matrix *P*. The partition function can therefore be calculated by diagonalizing the matrix *P*, which

This results in

$$
\lambda^2 - 2\lambda \mathbf{e}^y \cosh \mathbf{x} + \mathbf{e}^{2y} - \mathbf{e}^{-2y} = \mathbf{0},
\tag{27.70}
$$

= 0. (27.69)

det 

can be accomplished by solving

$$
\lambda_{1,2} = \mathbf{e}^y \cosh \mathbf{x} \pm \sqrt{\mathbf{e}^{2y} \sinh^2 \mathbf{x} + \mathbf{e}^{-2y}},
\tag{27.71}
$$

which yields the eigenvalues

<span id="page-501-0"></span>λ1,2 = e*y* cosh *x* ± e2*y* sinh2 *x* + e−2*y* , (27.71) where the plus sign goes with subscript 1. We first examine lim[iting c](#page-500-2)ases and then the general case. For *y* = 0, which is the case of noninteracting spins in a magnetic field, we obtain λ1 = 2 cosh *x* [and](#page-501-0) λ2 = 0 resulting in *Z* = (2 cosh *x*) *N* , which is the familiar result for a two-state paramagnetic system. In this

case, the internal energy is *U*/*N* = −μ∗*B* tanh *x*, the magnetization is *M*/*N* μ∗ = tanh *x*, and the entropy is *S*/*N k*B = *x* − *x* tanh*x* + ln(1 + e−2*x*), which goes to 0 for *T* = 0 and to ln 2 for *T* = ∞ as expected.

$$Z = (2\cosh y)^{\mathcal{N}} + (2\sinh y)^{\mathcal{N}} = (2\cosh y)^{\mathcal{N}} \left[ 1 + (\tanh y)^{\mathcal{N}} \right] \tag{27.72}$$

*Z* = (2 cosh *y*) *N* + (2 sinh *y*) *N* = (2 cosh *y*) *N* 1 + (tanh *y*) *N* (27.72) in agreement with Eq. (27.59). The factor [1 + (tanh*y*)*N* ] in Eq. (27.72) ranges in value between 1 and 2 and turns out not to be important in calculating the energy, although it could be kept for aesthetic reasons to get an entropy of *S* = *k*B ln 2 at *T* = 0 because of the doubly degenerate ground state (all σ*i* = 1 or all σ*i* = −1). However, this small entropy at *T* = 0 is not of order *N* and is an unimportant technicality, as we shall see subsequently.

$$\mathcal{U} = -\frac{\partial \ln Z}{\partial \beta} = -\mathcal{N} \left\{ \tanh y + \frac{(\tanh y)^{N-1} \text{sech}^2 y}{1 + (\tanh y)^N} \right\},\tag{27.73}$$

482 THERMAL PHYSICS

The internal energy is

<span id="page-502-1"></span>
$$U = -\frac{\partial \ln Z}{\partial \beta} = -\mathcal{N}f \tanh y \left[ \frac{1 + a^{\mathcal{N} - 2}}{1 + a^{\mathcal{N}}} \right],\tag{27.74}$$

*U* = −∂ ln*Z* ∂β = −*N J* tanh *y* + (tanh *y*)*N*−1sech2*y* 1 + (tanh *y*)*N* , (27.73) which may also be written *U* = −∂ ln *Z* 1 + *aN*−2 

$$U_0 = -\mathcal{N}f \tanh \mathbf{y}.\tag{27.75}$$

where *a* := tanh*y*. Since 0 ≤ *a* ≤ 1, the term in square brackets involving *a* is nearly equal to 1 for large *N* . For *N* > 2 it is equal to 1 at *a* = 0 and *a* = 1. It has a maximum6 value of

$$\text{Co} = \frac{\partial U_0}{\partial T} = -Nk\text{a}(\beta l)^2 \text{sech}^2 \text{y}.\tag{27.76}$$

2sech2*y*. (27.76)

*U*0 = −*N J* tanh *y*. (27.75) The corresponding heat capacity for *B* = 0 is therefore

<span id="page-502-0"></span>*C*0 = ∂*U*0

agreement.

$$\cdots \to \cdot$$

$$\mathcal{S}/k_{\mathcal{B}} = \beta U + \ln Z = \beta U + \mathcal{N}y + \mathcal{N}\ln(1 + e^{-2y}) + \ln\left[1 + (\tanh y)^{\mathcal{N}}\right].\tag{27.77}$$

to zero at high *T*. Thus, there is no sign of a phase transition at any *T* > 0. The entropy is given by *S*/*k*B = β*U* + [ln](#page-501-1) *Z* = β*U* + *N y* + *N* ln(1 + e−2*y*) + ln 1 + (tanh *y*) *N* . (27.77) For *T* → ∞, *y* → 0, and *S*/*k*B → *N* ln 2 because the populations of σ*i* = ±1 are equal. For *T* → 0, *y* → ∞, β*U* → −*N y* (which cancels the *N y* term from ln *Z*), ln(1 + e−2*y*) → 0

$$\mathbf{S}_0/k_\mathrm{B} = \mathcal{N}\mathbf{y}(1-\tanh\mathbf{y}) + \mathcal{N}\ln(1+\mathbf{e}^{-2y}).\tag{27.78}$$

Eq. (27.77) is not of order *N* , it can be dropped. Thus the entropy for *B* = 0 is given by *[S](#page-502-1)*0/*k*B = *N y*(1 − tanh *y*) + *N* ln(1 + e−2*y*). (27.78)

$$M = k_{\rm B} T \frac{\partial}{\partial B} \ln[\lambda_1^{\lambda'} + \lambda_2^{\lambda'}],\tag{27.79}$$

∂*B* 1 + λ*N* 2 ], (27.79) 6The maximum occurs at values of *a* that satisfy *N a*2 +2*aN* = *N* −2. We can obtain an approximate solution by setting *a* = 1 − *b*/*N* and noting that *aN* = e−*b* as *N* → ∞. Thus a root occurs at approximately *a*2 = 1 − (2/*N* )(1 + e−*b*) or *a* = 1 − (1/*N* )(1 + e−*b*). This gives 1 + e−*b* = *b* whose solution is *b* = 1.27846. Then the factor in brackets in Eq. (27.74) becomes approximately 1 + (1/*N* )(2*b*e−*b*)/(1 + e−*b*) = 1 + 0.55693/*N* . A numerical solution of the exact equations gives a corresponding value of 1 + 5.5684 × 10−6 for *N* = 105, in good

ln[λ*N*

*M* = *k*B*T* ∂

$$\frac{M}{N\mu^*} = \frac{\lambda_1^{N-1} \partial \lambda_1 / \partial \mathbf{x} + \lambda_2^{N-1} \partial \lambda_2 / \partial \mathbf{x}}{\lambda_1^N + \lambda_2^N}. \tag{27.80}$$

But

$$\frac{\partial \lambda_{1,2}}{\partial \mathbf{x}} = \pm \frac{\mathbf{e}^y \sinh \mathbf{x}}{\sqrt{\mathbf{e}^{2y} \sinh^2 \mathbf{x} + \mathbf{e}^{-2y}}} \lambda_{1,2},\tag{27.81}$$

which results in *M N* μ∗ = λ*N*−1 1 ∂λ1/∂*x* + λ*N*−1 2 ∂λ2/∂*x* . (27.80)

<span id="page-503-0"></span>
$$\frac{M}{\mathcal{N}\mu^*} = \frac{\sinh \mathbf{x}}{\sqrt{\sinh^2 \mathbf{x} + \mathbf{e}^{-4y}}} \frac{\lambda_1^N - \lambda_2^N}{\lambda_1^N + \lambda_2^N}. \tag{27.82}$$

∂λ1,2 ∂*x* = ± e2*y* sinh2 *x* + e−2*y* λ1,2, (27.81) where the plus sign goes with subscript 1 and the minus sign goes with subscript 2. The magnetic moment is therefore given by *M N* μ∗ = sinh *x* sinh2 *x* + e−4*y* λ*N* 1 − λ*N* 2 λ*N* 1 + λ*N* 2 . (27.82) The important thing to notice about Eq. (27.82) is that it is proportional to sinh *x* which goes to zero as *x* → 0, wh[ile all o](#page-503-0)f the other factors remain finite. Since *x* = βμ∗*B*, this

means there is no spontaneous magnetization for *B* = 0 at any *T* > 0. In other words, *this exact solution to the one-dimensional Ising model displays no phase transition, contrary to*

$$
\lambda_{1,2} \approx \mathbf{e}^y \cosh \mathbf{x} \pm \mathbf{e}^y \sinh \mathbf{x} = \mathbf{e}^{y \pm x}.\tag{27.83}
$$

comparison to λ1, in which case the last factor in Eq. (27.82) would be unity. In the case that the interaction between spins is very strong, such that *y* = *J*/*k*B*T* 1,

one has approximately

$$M \approx \mathcal{N}\mu^* \tanh \mathcal{N}\mathbf{x} \tag{27.84}$$

λ1,2 ≈ e*y* cosh *x* ± e*y* sinh *x* = e*y*±*x*. (27.83) In that case, as *y* → ∞, Eq. (27.82) becomes *M* ≈ *N* μ∗ tanh *N x* (27.84) which has a very large slope proportional to *N* 2 as *x* → 0. This is sometimes interpreted to suggest that a phase transition is about to happen at *T* = 0, that is, effectively *T*c = 0.

An alternative interpretation would be to note that *a very small magnetic field would lead to the saturation magnetization M* = *N* μ∗ as *T* approaches zero. Such a field would need

### to satisfy μ∗*B* > *k*B*T*/*N* .

27.5 Other Methods of Solution The Ising model has been solved exactly in two dimensions for several lattices and approximately by various methods in spaces of higher dimensionality. See Pathria and Beale [9, p. 488] for an extensive discussion of two-dimensional Ising models and several related models. They report critical values of *K*c = *J*/*k*b*T*c for several exact solutions. For the Onsager solution of the square lattice, previously mentioned, *K*c = (1/2) sinh−1 (1) = (1/2)ln( √2 + 1) ≈ 0.4407. For a triangular lattice, *K*c = (1/2) sinh−1(1/ √3) ≈ 0.2747 and for a honeycomb lattice, *K*c = (1/2) sinh−1 ( √3) ≈ 0.6585. In three dimensions, numerical solutions [70] yield *K*c = 0.36982, 0.15740, and 0.10209 for diamond cubic, FCC, and BCC lattices, respectively. In many cases, associated critical exponents have been calculated.

Even though the Ising model is quite simple, it has stimulated a great deal of activity and has led to important insight that is useful in understanding more realistic models. Renormalization group (RG) methodology, discussed very briefly below, has been used extensively to simulate the Ising model and has led to major advances in the study of phase transitions in more realistic models.

### 27.6 Monte Carlo Simulation

As we have seen, the solution of the Ising model by means of the mean field approximation is incorrect because correlations among the spins are not taken into account. Monte Carlo (MC) simulation is an important tool that can be used to include such correlations. It can also be used to solve many other problems in statistical physics as well as other fields. It is a huge subject to which we can only give an introduction. For comprehensive treatments, the reader is referred to a number of recent books, [71–74].

### 27.6.1 MC Simulation of the Ising Model

We introduce computer simulation by using MC methods to treat the Ising model in two dimensions for a square lattice. The basic idea is to work with a square system having *n*×*n* spins, each of which can take on the values *si* = ±1. We define a **configuration** of the system to be a specification of the set {*si*} of *N* = *n*2 spin values. It is convenient to think of {*si*} as a vector **s** with components *s*1,*s*2, ... ,*sN* . In the absence of a magnetic field, the energy of such a configuration is taken to be

$$E(\mathbf{s}) = -\frac{J}{2} \sum_{l,j}^{mn} \mathbf{s}_l \mathbf{s}_f = -J \sum_{l,j}^{mp} \mathbf{s}_l \mathbf{s}_f,\tag{27.85}$$

where the first sum is over nearest neighbors and the second sum is over nearest-neighbor pairs. The objective of the simulation is to find a set of configurations such that the probability *P*(**s**) of any given configuration is proportional to its Boltzmann factor,

$$P(\mathbf{s}) \propto \exp[-\beta E(\mathbf{s})].\tag{27.86}$$

This can be accomplished by taking a random walk through configuration space in steps called MC steps. At the end of the *k*th step, we suppose the configuration to be in a state **s** and then proceed by means of a rule, to be discussed below, to establish a configuration **s** at the next MC step, *k* + 1. This is accomplished by means of a **Markov process** [75, p. 135], according to which the conditional transition probability *Wk*(**s** → **s** ) to the state **s** , given the occurrence of the state **s** at step *k*, depends only on the previous state **s**, independent of any prior state **s** at step *p* < *k*. This process is repeated a large number of times, resulting in the generation of a so-called **Markov chain**. The steps in configuration space are often referred to as MC time steps that are imagined to take place

*Chapter 27* • Ising Model 485 at equal intervals of some dimensionless (but not continuous) MC time, *t* = *k*. Howeve[r,](#page-505-0) the progression through configuration space by means of MC time steps should not be confused with following the dynamics of the system in real time, as would take place in a simulation called molecular dynamics.7 We shall proceed to discuss a particular algorithm, usually referred to the **Metropolis algorithm** [76]. This algorithm employs MC sampling methods for a Markov process that leads to the Boltzmann distribution. It has been generalized by Hastings [77] to treat many other problems by similar methods. The Metropolis algorithm can be implemented by beginning with some arbitrary initial configuration, say **s**, having energy *E*(**s**), randomly selecting a given spin, reversing its value (1 → −1 or − 1 → 1) and calculating the energy *E*(**s** ) of a *trial* configuration at step 1. Such a spin can be selected by generating8 a pseudo-random number, *r* between 0 and 1, and comparing *N r* with the number used

- to label each spin, 1, 2, ... , *N* , to see which is closest. In event that the selected spin is on the border of the *n* × *n* square, one uses periodic boundary conditions (in the *x*- and
- *y*-directions) to ascertain the spin of any missing nearest neighbor. Then at step 1 the trial configuration **s** is rejected or accepted according to the following rules depending on the energy difference *E*(**s** , **s**) = *E*(**s** ) − *E*(**s**): • If *E*(**s** , **s**) < 0, the trial configuration **s** is accepted and becomes the actual configuration at the next MC time step (initially, time step 1).

• If *E*(**s** , **s**) ≥ 0, the configuration at the next MC time step is the trial configuration **s** with probability exp[−β *E*(**s** , **s**)], but reverts to the former configuration **s** with probability [1−exp[−β *E*(**s** , **s**)]. This can be accomplished by comparison of a pseudorandom number *r* between 0 and 1 with the Boltzmann factor exp[−β *E*(**s** , **s**)]. This same process is then repeated to progress from step 1 to step 2, etc., until a very large number *N N* of MC steps has been taken. The MC chain will begin to follow a trajectory in configuration space that corresponds approximately to the Boltzmann distribution.9 Then by studying a correlation function between the configuration **s** at step *q* and **s** at step *q* − *m* for sufficiently large *q* > *N* , an interval of *m* MC time steps can established beyond which correlations become negligible. This establishes a dimensionless MC correlation time, τ = *m*. At that stage, one can begin to store these statistically independent configurations at intervals of *p* steps for some *p* > *m* and this set of configurations is deemed to be representative of a Boltzmann distribution of configurations. From that distribution, various quantities of interest can be computed; for example, the average

<span id="page-505-0"></span>value of a spin or the correlation of spins separated by a given distance. As discussed below,

9Theorems for MC chains [75, p. 142] exist to demonstrate some conditions for which this will occur.

other considerations are necessary to obtain an efficient simulation.

<sup>7</sup>For a classical system, molecular dynamics would be accomplished by integrating numerically Newton's equations for a system of *N* particles, given some initial condition. 8A number of algorithms for generating pseudo-random numbers are readily available. See [73, chapter 16]

for an extensive discussion.

<span id="page-506-0"></span>
$$P_{k+1}(\mathbf{s}) - P_k(\mathbf{s}) = \sum_{\mathbf{s'}} \left\{-W_k(\mathbf{s} \to \mathbf{s'})P_k(\mathbf{s}) + W_k(\mathbf{s'} \to \mathbf{s})P_k(\mathbf{s'})\right\}.\tag{27.87}$$

486 THERMAL PHYSICS So what is the physical basis of the Metropolis algorithm? It i[s base](#page-506-0)d on a so-called master equation of the form10

$$P_k(\mathbf{s}) \to P(\mathbf{s}) = (1/Z) \exp[-\beta E(\mathbf{s})],\tag{27.88}$$

*s*

$$0 = \sum_{\mathbf{s'}} \left\{-\mathcal{W}_{\mathbf{k}}(\mathbf{s} \rightarrow \mathbf{s'}) \exp[-\beta E(\mathbf{s})] + \mathcal{W}_{\mathbf{k}}(\mathbf{s'} \rightarrow \mathbf{s}) \exp[-\beta E(\mathbf{s'})] \right\},\tag{27.89}$$

Boltzmann distribution

*term in the sum equal to zero*, resulting in

avoid its use.

*Wk*(**s** → **s**

*Pk*(**s**) → *P*(**s**) = (1/*Z*) exp[−β*E*(**s**)], [(2](#page-506-0)7.88) where *Z* is the partition function needed to normalize *P*. Then Eq. (27.87) becomes 0 = - *s* −*Wk*(**s** → **s** ) exp[−β*E*(**s**)] + *Wk*(**s** → **s**) exp[−β*E*(**s** )] , (27.89) where the partition function has been canceled. As a guide to finding an algorithm that will lead to the desired distribution, we want

$$P_{k+1}(\mathbf{s}) = \sum_{\mathbf{s'}} W_k(\mathbf{s'} \to \mathbf{s}) P_k(\mathbf{s'}),\tag{27.90}$$

statistical mechanics [14, p. 144]. We return briefly to the master equation Eq. (27.87) and note that **s** *Wk*(**s** → **s** ) = 1, so it can be rewritten as *Pk*+1(**s**) = - *s Wk*(**s** → **s**)*Pk*(**s** ), (27.90) which has the form of a matrix equation except the matrix is stochastic. As *k* → ∞, we

want *P*∞(**s**) to approach the Boltzmann distribution. But we want to avoid a so-called limit cycle in which the system, which starts in some state *P*0(**s**), reaches a dynamic equilibrium in which only a subset of states of the system are visited [73, p. 37]. With the foregoing considerations in mind, we need to remember that we are not following the true dynamics of the system, so all we need is an algorithm that leads efficiently to the correct distribution. This can be acco[mplis](#page-506-0)hed by making use of the

$$\mathcal{W}_k(\mathbf{s}\rightarrow\mathbf{s}')\exp[-\beta E(\mathbf{s})] = \mathcal{W}_k(\mathbf{s}'\rightarrow\mathbf{s})\exp[-\beta E(\mathbf{s}')].\tag{27.91}$$

)]. (27.91)

10In the MC literature, one often writes this equation with the notation *P***s**(*t*) ≡ *Pk*(**s**), where *t* = *k* is dimensionless MC time. Then *Pk*+1(**s**)−*Pk*(**s**) = *P***s**(*t* +1)−*P***s**(*t*). In that case, *P***s**(*t* +1)−*P***s**(*t*) would be the finite forward difference approximation to the derivative d*P***s**(*t*)/d*t* and Eq. (27.87) could be written as a differential equation with the quantities *W* regarded as transition rates. Although this is common, it is misleading so we

) exp[−β*E*(**s**)] = *Wk*(**s** → **s**) exp[−β*E*(**s**

, **s**)]].

<span id="page-507-2"></span>
$$W_k(\mathbf{s}\rightarrow\mathbf{s}') = \exp[-\beta\Delta E(\mathbf{s}',\mathbf{s})]W_k(\mathbf{s}'\rightarrow\mathbf{s}),\tag{27.92}$$

*Chapter 27* • Ising Model 487 Although Eq. (27.91) is not necessary to satisfy Eq. (27.89), it is a sufficient condition. It can

<span id="page-507-0"></span>be written in the form *Wk*(**s** → **s** ) = exp[−β *E*(**s** , **s**)]*Wk*(**s** → **s**), (27.92) where *E*(**s** , **s**) = *E*(**s**

$$\mathcal{W}_{k}(\mathbf{s}\rightarrow\mathbf{s}')=\mathcal{W}_{0}\begin{cases} 1 & \text{for } \Delta E(\mathbf{s}',\mathbf{s})<0\\ \exp[-\beta\Delta E(\mathbf{s}',\mathbf{s})] & \text{for } \Delta E(\mathbf{s}',\mathbf{s})\ge 0. \end{cases} \tag{27.93}$$

<span id="page-507-1"></span>to **s** , so there is no possibility of a limit cycle. T[he Me](#page-507-1)tropolis [algorith](#page-507-2)m is a convenient and efficien[t](#page-507-0) [way](#page-507-0) of satisfying Eq. (27.92).

$$W_k(\mathbf{s'} \to \mathbf{s}) = W_0 \begin{cases} 1 & \text{for } \Delta E(\mathbf{s}, \mathbf{s'}) < 0 \Rightarrow \Delta E(\mathbf{s'}, \mathbf{s}) \ge 0\\ \exp[-\beta \Delta E(\mathbf{s}, \mathbf{s'})] & \text{for } \Delta E(\mathbf{s}, \mathbf{s'}) \ge 0 \Rightarrow \Delta E(\mathbf{s'}, \mathbf{s}) < 0. \end{cases} \tag{27.94}$$

*Wk*(**s** → **s** ) = *W*0 1 for *E*(**s** , **s**) < 0 exp[−β *E*(**s** , **s**)] for *E*(**s** , **s**) ≥ 0. (27.93) Then evidently *Wk*(**s** → **s**) = *W*0 1 for *E*(**s**, **s** ) < 0 ⇒ *E*(**s** , **s**) ≥ 0 exp[−β *E*(**s**, **s** )] for *E*(**s**, **s** ) ≥ 0 ⇒ *E*(**s** , **s**) < 0. (27.94) For *E*(**s** , **s**) < 0, we can substitute the top line of Eq. (27.93) and the bottom line of Eq. (27.94) into Eq. (27.92) and see that it is satisfied. Similarly, for *E*(**s** , **s**) ≥ 0, we can substitute the bottom line of Eq. (27.93) and the top line of Eq. (27.94) into Eq. (27.92)

and see that it is satisfied. Since *W*0 = 0 can be canceled after these substitutions, it can be chosen for convenience. A very efficient choice is *W*0 = 1, which leads to the maximum probability that the new state will be accepted. With *W*0 = 1, Eq. (27.93) gives the Metropolis algorithm.11 Although the above description of a MC simulation presents the basic methodology, it omits many practical considerations. For example, even for a fairly small system with *n* = 50, *N* = *n*2 = 2500, so there are 22500 ≈ 10753 possible configurations. In principle, one could calculate the Boltzmann factor for each of them, sum the results to get a partition function, and hence calculate the Boltzmann probabilities for each, but that would involve so much computation that it is absurd. Fortunately, most such configurations have much higher energies than others, and therefore much smaller Boltzmann factors, so small they are negligible. The Metropolis algorithm avoids this problem by sampling only those configurations that have a significant probability in the Boltzmann distribution

(**Boltzmann sampling**). This technique is an example of **importance sampling** which makes MC simulation tractable for many other applications. Nevertheless, one must still develop practical criteria to decide the number *N* of iterations that are needed for the Markov chain to settle into an approximation of the Boltzmann distribution. Moreover, system size will be limited by the actual time and cost

11Since we are using the condition of detailed balance, only two configurations are involved in updating from MC step *k* to step *k*+1. So if **s** does not become **s** at step *k*+1, it remains **s** with probability [1−exp[−β *E*(**s**

that a computer must run to accurately compute and store the equilibrium distribution.

Fortunately, the problem has been well-studied and efficient algorithms have been devised. Some of these sample the spins in some order until all *N* spins have been sampled at least once, a so-called MC sweep, and then rely on empirical rules to decide how many MC sweeps are needed to calculate a MC Boltzmann chain with reasonable accuracy [73, p. 55]. See also [78, 79] for some specialized techniques. Empirical rules can be established by carrying out the simulation for systems for which analytical solutions are available. See figure 16.1 of [9, p. 643] for a graph of the specific heat of the twodimensional Ising model calculated by MC simulation as compared to that calculated from the exact solution. In that case, for *n* = 128, 105 sweeps gives good agreement except near the critical temperature where 106 sweeps are necessary. In general, empirical rules to decide the accuracy of a simulated equilibrium distribution must be established by running the simulation even longer and comparing with previous results. In any case, one should also run the simulation with different initial conditions to see if the results are statistically equivalent.

Just looking at the configurations produced by MC simulation can reveal patterns that are very different at high and low temperatures. At low temperatures, differences in the energies of configurations are extremely important and one can see large islands of spins of the same kind. At high temperatures, differences in energy of configurations are not so important and the resulting patterns show much smaller clusters of each spin in no particular arrangement. Results can also be analyzed quantitatively by generating a large set {**s**MC *i* } of statistically independent configurations and taking the averages · · · MC of various quantities with respect them, each weighted equally with probability 1/*N*MC. For example, one could compute the average value of an individual spin,

$$
\langle \mathbf{s} \rangle = \left\langle \frac{\sum_{l=1}^{\mathcal{N}} \mathbf{s}_l}{\mathcal{N}} \right\rangle_{\text{MC}} = \frac{1}{\mathcal{N}_{\text{MC}}} \sum_{l=1}^{\mathcal{N}_{\text{MC}}} \left( \frac{\sum_{j=1}^{\mathcal{N}} \mathbf{s}_j}{\mathcal{N}} \right)_{\{\mathbf{s}_l^{\text{MC}}\}}.\tag{27.95}
$$

To analyze patterns, one could choose *Nij* pairs of spins (*sisj*)*d* that are separated by a distance *d* and compute a correlation function of the form

$$\mathbf{C}(\mathbf{d}) = \left\langle \frac{\sum_{lj} (\mathbf{s}_l \mathbf{s}_j)_d}{\mathcal{N}_{lj}} \right\rangle_{\text{MC}} - \left\langle \mathbf{s} \right\rangle^2. \tag{27.96}$$

Study of *C*(*d*) as a function of *d* would help to quantify the cluster sizes viewed in patterns. It can also be used to establish a correlation length ξ beyond which *C*(ξ ) becomes negligibly small.

Near a critical point, MC simulations become difficult because the correlation length ξ becomes very large. Thus large systems and long-run times would be necessary to obtain accuracy. This problem can be alleviated by using the **renormalization group** (RG) approach. As suggested by Kadanoff in 1966 [80], the basic idea is to perform a length scaling that leads to an approximately equivalent problem with scaled coupling constants, such as *J* → *J* , now known as a **Kadanoff transformation**. The success of the technique is based on the idea that aspects of the problem, such as the existence of a phase transition, are insensitive to the lattice constant *a*. Specifically, for a new lattice constant *a* = *a*, where > 1, there is insensitivity of results provided *a*  ξ and conditions are close to criticality. This scaling-up idea can also be viewed as removing spins from the system, or more generally as reducing the number of degrees of freedom of a more general system, a process known as **decimation**. A systematic way of handling transformations based on this idea was developed later by Wilson [81, 82] by means of RG theory. By using such techniques, one can begin with very weak coupling constants, for which an approximate solution is possible. Then by successive scalings, one can use a recurrence relation to step up to values of the coupling constants or other parameters that are of interest. A successful application of this technique will result in successive transformations leading to a fixed point corresponding to criticality in parameter space. A detailed presentation of RG techniques is beyond the scope of this book. For a lucid introduction see chapter 5 of Chandler [12]; for a more extensive treatment, including the RG formulation, see chapter 14 of Pathria and Beale [9].

Other types of sampling can be accomplished by doing a MC simulation for a given problem and using the configurations so obtained to simulate a different problem. We illustrate this for two cases, the first involving a different energy but the same temperature, and the second involving a change in temperature for the same energy.

In the first case, suppose that

$$E(\mathbf{s}) = E_0(\mathbf{s}) + E_1(\mathbf{s}).\tag{27.97}$$

Then for *E*0(**s**) we have a probability and partition function given by

$$P\mathbf{o}(\mathbf{s}) = (Z\mathbf{o})^{-1} \exp[-\beta E\mathbf{o}(\mathbf{s})]; \quad Z\mathbf{o} = \sum_{\mathbf{s}} \exp[-\beta E\mathbf{o}(\mathbf{s})].\tag{27.98}$$

By using MC simulation, we obtain a set of configurations {**s**0 *i* }, *i* = 1, 2, ... , *N*MC that approximate *P*0(**s**) if they are equally weighted with probability 1/*N*MC. Then the average value of some quantity *R*(**s**) is given by

$$\langle R \rangle_0 = \sum_{\mathbf{s}} P_0(\mathbf{s}) R(\mathbf{s}) \approx \left( \mathcal{N}_{\text{MC}} \right)^{-1} \sum_{l=1}^{\mathcal{N}_{\text{MC}}} R(\langle \mathbf{s}_l^0 \rangle). \tag{27.99}$$

For *E*(**s**) we have

$$P(\mathbf{s}) = Z^{-1} \exp[-\beta E(\mathbf{s})] = Z^{-1} Z_0 P_0(\mathbf{s}) \exp[-\beta E_1(\mathbf{s})],\tag{27.100}$$

where

$$Z = \sum_{\mathbf{s}} \exp[-\beta E_0(\mathbf{s})] \exp[-\beta E_1(\mathbf{s})] = Z_0 \sum_{\mathbf{s}} P_0(\mathbf{s}) \exp[-\beta E_1(\mathbf{s})].\tag{27.101}$$

Thus,

$$P(\mathbf{s}) = \frac{P_0(\mathbf{s}) \exp[-\beta E_1(\mathbf{s})]}{\sum_{\mathbf{s}} P_0(\mathbf{s}) \exp[-\beta E_1(\mathbf{s})]} = \frac{P_0(\mathbf{s}) \exp[-\beta E_1(\mathbf{s})]}{\langle \exp[-\beta E_1(\mathbf{s})] \rangle_0}. \tag{27.102}$$

*R*β = -

**s**

$$\langle R \rangle = \sum_{\mathbf{s}} P(\mathbf{s}) R(\mathbf{s}) = \frac{\langle R(\mathbf{s}) \exp[-\beta E_1(\mathbf{s})] \rangle_0}{\langle \exp[-\beta E_1(\mathbf{s})] \rangle_0}. \tag{27.103}$$

490 THERMAL PHYSICS

Then the average value of *R*(**s**) is given by

$$P(\mathbf{s}, \beta) = \left[ Z(\beta) \right]^{-1} \exp[-\beta E(\mathbf{s})]; \quad Z(\beta) = \sum_{\mathbf{s}} \exp[-\beta E(\mathbf{s})], \tag{27.104}$$

When the averages · · · 0 in Eq. (27.103) are computed by the right-hand member of Eq. (27.99), which is only approximate, accurate results are only expected if *E*1(**s**) is a small perturbation.

$$\langle R \rangle_{\beta} = \sum_{\mathbf{s}} P(\mathbf{s}, \beta) R(\mathbf{s}) \approx \left( \bigvee_{\mathbf{MC}} \right)^{-1} \sum_{l=1}^{\mathcal{N}_{\mathbf{MC}}} R(\{\mathbf{s}_l(\beta)\}). \tag{27.105}$$

resulting in a set of configurations {**s***i*(β)}, *i* = 1, 2, ... , *N*MC. The average value of some *R*(**s**) corresponding to β is then

$$P(\mathbf{s}, \beta + \Delta\beta) = \frac{P(\mathbf{s}, \beta) \exp[-\Delta\beta E(\mathbf{s})]}{\langle \exp[-\Delta\beta E(\mathbf{s})] \rangle_{\beta}} \tag{27.106}$$

Then we change the temperature by changing β to β + β and seek to evaluate *P*(**s**, β +

field, one has

Boltzmann distribution

$$\langle R \rangle_{\left(\beta + \Delta\beta\right)} = \frac{\langle R(\mathbf{s}) \exp[-\Delta\beta E(\mathbf{s})] \rangle_{\beta}}{\langle \exp[-\Delta\beta E(\mathbf{s})] \rangle_{\beta}}.\tag{27.107}$$

exp[− β*E*(**s**)]β and

*R*(β+ β) = *R*(**s**) exp[− β*E*(**s**)]β exp[− β*E*(**s**)]β . (27.107) When the averages · · · β are evaluated from MC simulations at β, Eq. (27.107) is likely to be accurate only for small β. Although the two cases above illustrate how the properties of the Boltzmann distribution can be used to treat changes of the Hamiltonian, or of β, by MC sampling, they should not be construed as efficient algorithms. Histogram methods such as those used by Ferrenburg and Swendsen [83, 84] are much more accurate, efficient, and versatile. These methods batch the results of MC simulation to generate **histograms** that depend on

$$E_{l,B}(\mathbf{s}) = -J \sum_{l,j}^{mp} \mathbf{s}_l \mathbf{s}_j - \mu^* \mathbf{B} \sum_l \mathbf{s}_l,\tag{27.108}$$

*EJ*,*B*(**s**) = −*J i*,*j sisj* − μ∗*B i si*, (27.108) so the parameters *K* := β*J* and *h* := βμ∗*B* enter the probability distribution. Associated with given *K* and *H*, one can use MC simulation to calculate histograms of values of the dimensionless spin-spin interaction, *S* = *nnp i*,*j sisj*, and the dimensionless magnetization, *M* = *i si*. Those histograms can then be used to generate histograms of *S* and *M* for *K* + *K* and *h* + *h* by methods similar to those discussed above.

Hamiltonian of the form

*Z*∗

(*h*3*N N* !)

−1 

*Chapter 27* • Ising Model 491

$$\mathcal{H} = \mathcal{T}(\mathbf{p}) + V(\mathbf{q}),\tag{27.109}$$

path integral quantum MC techniques, see Chandler [12, p. 170]. 27.6.2 MC Simulation of Classical Particles

$$\mathcal{T}(\mathbf{p}) = \sum_{l=1}^{3N} p_l^2 / 2m \tag{27.110}$$

*H* = *T* (**p**) + *V*(**q**), (27.109) where **p** and **q** are 3*N* -dimensional vectors of momenta and coordinates, respectively. The quantity

$$Z_{\rm C}^{*} = (h^{3N} \mathcal{N}!)^{-1} \int \mathbf{d} \mathbf{p} \mathbf{d} \mathbf{q} \exp(-\beta \mathcal{H}) = \int \mathbf{d} \mathbf{p} \exp(-\beta \mathcal{T}(\mathbf{p})) \int \mathbf{d} \mathbf{q} \exp(-\beta V(\mathbf{q})).\tag{27.111}$$

is the kinetic energy and *V*(**q**) is the potential energy, usually taken to be a function of pairwise interaction energies of particles. The classical partition function is12

$$(h^{3N}\mathcal{N}!)^{-1}\int \mathrm{d}\mathbf{p} \, \exp(-\beta \mathcal{T}(\mathbf{p})) = (\mathcal{N}!)^{-1}(mk_\mathrm{B}T/2\pi\hbar^2)^{3N/2} = (\mathcal{N}!)^{-1}m_\mathrm{Q}^N,\tag{27.112}$$

The integrals over the momenta factor into Gaussian integrals that are easily evaluated to give

tures, but such a factor is irrelevant to the simulation of particle configurations.

<span id="page-511-1"></span>
$$Q \coloneqq \int \mathbf{dq} \exp(-\beta V(\mathbf{q})) \tag{27.113}$$

where *n*Q is the quantum concentration. The integral *Q* := d**q** exp(−β*V*(**q**)) (27.113)

$$P(|\!\langle q \!\rangle|) = Q^{-1} \exp(-\beta V(\langle q \!\rangle)). \tag{27.114}$$

<span id="page-511-0"></span>function of any configuration {*qi*} of the coordinates is given by *P*({*qi*}) = *Q*−1 exp(−β*V*({*qi*}). (27.114) Equation (27.114) is the Boltzmann distribution of coordinate configurations that can be simulated by using the Metropolis algorithm, which can be done without knowledge of *Q*. For example, one of the coordinates *qi* could be shifted by some small amount to position *q i* to give a trial configuration and then β *V* = β(*V* − *V*) can be evaluated to decide whether to keep the trial configuration. For short-range forces, this evaluation would involve only a small number of particles. This is particularly simple for simulation of particles that are hard spheres, since β *V* is either zero or infinity (the latter occur-

ring when the shift would cause hard spheres to overlap). Quantities such as the pair

<sup>12</sup>We have included a factor (*h*3*N N* !)−1 if appropriate to connect with quantum mechanics at high tempera-

correlation function *g*(*r*) can be calculated from the configurations obtained from an MC simulation.

As discussed in Section 20.5, the virial theorem can be used to relate *g*(*r*)to the equation of state of a nonideal gas, as given by Eq. (20.77). This equation contains the derivative ∂*u*/∂*r* of the potential function *u*(*r*) for pairwise central-force interactions of the particles. For a hard-sphere gas of particles having diameter σ, *u*(*r*) is a step function at σ, so the formal derivative of *u* is a delta function and must be handled with care. As shown by Widom [17, p. 126], a carefully taken limit leads to a hard-sphere gas pressure *p*hsg given by

$$\frac{p_{\rm hsg}}{mk_{\rm B}T} = 1 - \frac{2}{3}\pi n \sigma^3 \mathbf{g}(\sigma^+),\tag{27.115}$$

where *g*(σ +) is the value of the pair correlation function for a hard-sphere gas in the limit that *r* approaches σ from larger values. See Figure 20–1 and the surrounding discussion of *g*(*r*). *g*(σ +) can be evaluated from the results of computer simulation as a function of *n*. An approximate analytical fit to the data can be represented by the Carnahan-Starling [85] equation of state

<span id="page-512-3"></span>
$$\frac{p_{\rm hsg}}{mk_{\rm B}T} = \frac{1+\mathbf{y}+\mathbf{y}^2-\mathbf{y}^3}{(1-\mathbf{y})^3} \equiv \mathcal{W}(\mathbf{y}), \quad \text{hard-sphere gas,} \tag{27.116}$$

where *y* = *vsn* = (π/6)σ3*n* is the volume of hard spheres per total volume. The function *W*(*y*) is in approximate agreement with an expansion of the pressure in terms of virial coefficients [9, p. 314].

One might wonder about the origin of the excess pressure, *pxs*, contained in *p*hsg in addition to that for an ideal gas. We shall proceed to show that *pxs* is related to the change of excess configurational entropy when *y* changes. To do this, we write *p*hsg = *pi* + *pxs*, where *pi* = *nk*B*T* is the ideal gas pressure and

<span id="page-512-2"></span>
$$p^{\rm xs} = nk_{\rm B}T\left[W(\mathbf{y}) - 1\right].\tag{27.117}$$

For the hard-sphere gas, there is no penetration of the spheres, so the molar internal energy, *u*(*T*), depends only on the temperature, as is also the case for an ideal gas. Therefore, the differential of the entropy becomes

<span id="page-512-1"></span>
$$\mathbf{ds} = \frac{\mathbf{d}u}{T} + \frac{p}{T}\mathbf{d}v = \frac{\mathbf{d}u(T)}{\mathbf{d}T}\frac{\mathbf{d}T}{T} - \frac{p}{n^2T}\mathbf{d}n = \frac{c_v(T)}{T}\mathbf{d}T - \frac{p}{nT}\frac{\mathbf{d}y}{y},\tag{27.118}$$

where *cv* (*T*) is the molar heat capacity at constant volume. By integrating at constant *T*, we obtain

<span id="page-512-0"></span>
$$\mathbf{s}(\mathbf{y},T) = -k_{\mathrm{B}} \ln \mathbf{y} + \tilde{\mathbf{s}}(T) - k_{\mathrm{B}} \int_{0}^{\mathcal{V}} \left[ \frac{\mathbf{W}(\mathbf{x})}{\mathbf{x}} - \frac{1}{\mathbf{x}} \right] \mathbf{d} \mathbf{x},\tag{27.119}$$

where *s*˜(*T*) is a function of integration. Since *p* = −*nTy* ∂*s*(*y*, *T*)/∂*y T* , comparison of the differential of Eq. [(27.119)](#page-512-0) with Eq. [(27.118)](#page-512-1) shows that d*s*˜(*T*) = *cv* (*T*)/*T*, so *s*˜(*T*) = [*cv* (*T*)/*T*] d*T* + constant, as expected. Thus, the first term in Eq. [(27.119)](#page-512-0) represents the configurational molar entropy *si*(*y*) of an ideal gas and the last term represents the excess configurational molar entropy *sxs*(*y*) of the hard-sphere gas. The lower limit of the integral has been set equal to zero so that only *si*(*y*) + *s*˜(*T*) remains as *y* → 0. Evaluation of the integral gives

$$\mathbf{s}^{\mathbf{x}\mathbf{s}}(\mathbf{y}) = -k_{\mathrm{B}} \int_{0}^{\mathcal{V}} \left[ \frac{\mathcal{W}(\mathbf{x})}{\mathbf{x}} - \frac{1}{\mathbf{x}} \right] d\mathbf{x} = -k_{\mathrm{B}} \frac{\mathcal{Y}(4 - 3\mathbf{y})}{(1 - \mathbf{y})^{2}}.\tag{27.120}$$

The excess pressure is given by

$$p^{\rm xs} = -\eta \mathcal{Y} \frac{\partial \mathbf{s}^{\rm xs}(\mathbf{y})}{\partial \mathbf{y}} = n k_{\rm B} T \left[ \mathcal{W}(\mathbf{y}) - 1 \right],\tag{27.121}$$

in agreement with Eq. [(27.117)](#page-512-2).

Therefore, the excess pressure *pxs* of the hard-sphere gas arises because the excess configurational molar entropy *sxs*(*y*) is a decreasing function of *y*. This decrease of *sxs*(*y*) must be related to the decrease of unoccupied volume as *y* increases. Although we have demonstrated this by using the Carnahan-Starling approximate function *W*(*y*), the same conclusion would follow if a more accurate function were used.

Widom [17, p. 106] has shown that an approximate equation of state of a normal liquid can be obtained by adding to the hard-sphere gas pressure a term −α*n*2, where −α*n* < 0 represents an average potential energy per atom due to binding forces. The essence of the argument is that the attractive forces between liquid atoms nearly cancel for a given atom but the associated potentials are additive and nearly uniform. The result is

<span id="page-513-0"></span>
$$p = k \lg \text{Tr} \frac{1 + \mathbf{y} + \mathbf{y}^2 - \mathbf{y}^3}{(1 - \mathbf{y})^3} - \alpha \mathbf{n}^2,\tag{27.122}$$

in which the hard-sphere radius σ, contained in *y*, should be interpreted as an effective radius related to the repulsive part of the actual potential. If the right-hand side of Eq. [(27.116)](#page-512-3) is expanded for small *y* to lowest order, the result is 1/(1 − 4*y*) = 1/(1 − 4*vsn*). Then Eq. [(27.122)](#page-513-0) becomes

$$p = \frac{k_{\rm B}T}{(n^{-1} - 4v_{\rm s})} - \alpha n^2,\tag{27.123}$$

which is just another form of the van der Waals equation, Eq. (9.2), but in different units[.13](#page-513-1) Equation [(27.122)](#page-513-0) can be analyzed by the same method used to analyze the van der Waals fluid. The spinodal curve in the *y*, *T* plane is given by *vsk*B*T*/α = 2*y*/[*yW*(*y*)] , where the prime denotes the derivative with respect to *y*. The maximum of the spinodal curve occurs at *y* = 0.1304 and the critical temperature is given by *vsk*B*T*/α = 0.09433.

By means of computer simulation, one finds that the hard-sphere model displays a phase transition between a hard-sphere gas at low volume fractions of the spheres and a hard-sphere crystalline solid phase at high volume fractions (see figure 16.3 of [9, p. 649]).

<span id="page-513-1"></span><sup>13</sup>The correspondence can be made by setting *n* = *NA*/*v*, where *NA* is Avogadro's number and *v* is the volume per mole. Then *b* = 4*NAvs* and *a* = *N* 2 *A* α.

The gas phase ends at *y* = 0.491 and the solid phase begins at *y* = 0.543, with co-existence of phases for volume fractions in between. For *y* > 0.543, Speedy [86] gives the pressure *p*hsc of the hard-sphere crystal,

$$\frac{p_{\rm hsc}}{nk\lg T} = \frac{3}{(1-z)} - 0.5921 \frac{(z - 0.7072)}{(z - 0.601)}, \quad \text{hard-sphere crystal},\tag{27.124}$$

in terms of the relative solid fraction *z* = *n*σ3/ √2 = *y*/*y*cp = 1.35*y*, where *y*cp = π √2/6 = 0.7405 corresponds to a close-packed FCC crystal. It is also possible to conduct simulations [87] that avoid the transition from the hard-sphere gas to the hard-sphere crystal and follow the disordered state into the metastable region where the pressure tends to infinity at *z* = 0.644 ± 0.005, which corresponds well with the Bernal [88] packing fraction established experimentally.

The above simple example of the hard-sphere gas begins to illustrate the power of computer simulation in describing the liquid state, something that is very limited by using analytical methods alone. MC simulation has been used for simulation of many systems that involve other classical particles for decades. A favorite for simulation is the Lennard-Jones potential,

$$
\mu(r) = 4\varepsilon \left[ \left( \frac{\sigma}{r} \right)^{12} - \left( \frac{\sigma}{r} \right)^{6} \right], \tag{27.125}
$$

where ε > 0 is an energy parameter and σ is a length parameter. The first term is strongly repulsive and its form is selected for convenience; the second is attractive and yields a force of the same form as that between electric dipoles. The potential minimum occurs at *r*min = 21/6σ = 1.12σ at which *u* = − ε. The Lennard-Jones potential was used for simulations over 50 years ago that were compared to experimental results for argon [89]. More recent simulations using the Lennard-Jones potential have dealt with liquid-crystal phase transitions [90], including those involving several crystal phases [91].

As computing power has improved exponentially over the years, MC simulation has become a potent tool for the statistical study of models of materials with more realistic potentials, resulting in greater variety and accuracy of results. The reader is referred to several books cited above as well as the vast journal literature.

![](_page_515_Picture_0.jpeg)

This page intentionally left blank

![](_page_517_Picture_0.jpeg)

# Stirling's Approximation

In the process of going from statistical mechanics to thermodynamics, we will often use Stirling's approximation in the form

<span id="page-517-2"></span>
$$
\ln(N!) \sim N \ln N - N,\tag{A.1}
$$

which is a good approximation when *N* is a large number. A good approximation for *N*! itself is

<span id="page-517-0"></span>
$$N! \sim N^N \mathbf{e}^{-N} (2\pi N)^{1/2}. \tag{A.2}$$

Taking the logarithm of Eq. [(A.2)](#page-517-0) gives

<span id="page-517-1"></span>
$$
\ln(N!) \sim N\ln(N) - N + (1/2)\ln(2\pi N),
\tag{A.3}
$$

but the last term in Eq. [(A.3)](#page-517-1) is quite negligible for large *N*. For example, for *N* = 106, the last term is 7.83 and the sum of the first two terms is 12815510.56. In statistical mechanics, we usually deal with ln *N*! and much larger values of *N*, so this extra term in Eq. [(A.3)](#page-517-1) is completely negligible. In Eq. [(A.2)](#page-517-0), however, its counterpart (2π*N*)1/2 occurs as a multiplicative factor and must be kept to achieve reasonable accuracy.

For *N* > 0, it can be shown [92, p. 253] that

<span id="page-517-3"></span>
$$N! = N^N \mathbf{e}^{-N} (2\pi N)^{1/2} \mathbf{e}^{\theta/(12N)},\tag{A.4}$$

where 0 <θ< 1.

For the particular case of a polynomial coefficient = *N*!/(*N*1!*N*2!··· *Nr* !) where *N* = *r i*=1 *Ni*, Eq. [(A.1)](#page-517-2) leads to

$$\begin{aligned} \ln \mathfrak{Q} &\sim N \ln N - \sum_{l=1}^{r} N_{l} \ln N_{l} - N + \sum_{l=1}^{r} N_{l} \\ &= N \ln N - \sum_{l=1}^{r} N_{l} \ln N_{l} \\ &= -\sum_{l=1}^{r} N_{l} \ln(N_{l}/N), \end{aligned} \tag{A.5}$$

which is an extensive function of the *Ni*. Note in this special case that the final result would have been obtained even if we had dropped the second term in Eq. [(A.1)](#page-517-2). Expressions of this type arise frequently in statistical mechanics and are used to represent extensive thermodynamic functions, particularly the entropy.

One can use MathematicaR to compute numerical values of *N*! either exactly or from Stirling's approximation and compare the results. [Table A–1](#page-518-0) gives some values of ln *N*! and its approximations according to Eqs. [(A.1)](#page-517-2) and [(A.3)](#page-517-1). [Table A–2](#page-518-1) gives some values of *N*! and

| N      | ln N!       | N ln N − N  | N ln N − N + (1/2)ln(2πN) |
|--------|-------------|-------------|---------------------------|
| 10     | 15.10441257 | 13.02585093 | 15.09608201               |
| 100    | 363.7393756 | 360.5170186 | 363.7385422               |
| 1000   | 5912.128178 | 5907.755279 | 5912.128095               |
| 10,000 | 82108.92784 | 82103.40372 | 82108.92783               |

<span id="page-518-0"></span>**Table A–1** Illustration of Accuracy of Stirling's Approximation for ln *N*!

<span id="page-518-1"></span>**Table A–2** Illustration of Accuracy of Stirling's Approximation for *N*!

| N  | N!        | (2πN)1/2NNe−N | (2πN)1/2NNe−N[1<br>+ 1/(12N)] |
|----|-----------|---------------|-------------------------------|
| 1  | 1         | 0.9221370     | 0.9989818                     |
| 2  | 2         | 1.919004      | 1.998963                      |
| 5  | 120       | 118.0192      | 119.9862                      |
| 10 | 3,628,800 | 3,598,696     | 3,628,685                     |

its approximation by Eq. [(A.2)](#page-517-0) and its correction to next order by a factor of [1 − 1/(12*N*)]. Even for these small values of *N*, the results are quite reasonable. For numbers *N* > 1010 typical of thermodynamic systems, Stirling's approximation is excellent.

One should still be cautious, however, in using Stirling's approximation for ln *N*! to evaluate complex expressions. For example, the probability *p* that a well-shuffled deck of cards, when cut into two equal parts, will contain an equal number of red and black cards in each part is given by *p* = (26!/13!)4/52! = 16232365000/74417546961 = 0.218126. If Stirling's approximation equation [(A.1)](#page-517-2) is used to evaluate ln *p*, the result is ln *p* = 0 which would give the ridiculous result *p* = 1. By using Eq. [(A.3)](#page-517-1), one obtains ln *p* = − (1/2) ln(13π/2) which results in *p* = 0.221293, correct within 1.5%. This numerical example illustrates that the use of Eq. [(A.1)](#page-517-2) ignores the pre-factor (2π*N*)1/2 in Eq. [(A.2)](#page-517-0), which is fine for calculating logarithms, but leads to inaccurate results when those results are exponentiated to compute factorials themselves or ratios of them.

### A.1 Elementary Motivation of Eq. [(A.1)](#page-517-2)

Equation [(A.1)](#page-517-2) can be motivated by elementary methods. We first note that

$$I(q) := \int_1^q \ln u \, \mathrm{d}u = u \ln u - u \Big|_1^q = q \ln q - q + 1. \tag{A.6}$$

For *q* = *N*, we can bound this integral from above and below by sums of rectangular areas (upper and lower staircases) as illustrated in [Figure A–1](#page-519-0) for *N* = 10. We obtain

$$
\ln 1 + \ln 2 + \dots + \ln(N - 1) < I(N) < \ln 2 + \ln 3 + \dots + \ln N,\tag{A.7}
$$

<span id="page-519-0"></span>![](_page_519_Figure_1.jpeg)

**FIGURE A–1** Staircase diagram used to illustrate bounds for the area under the curve ln *u* for 1 < *u* < 10. The area under the upper staircase is larger than that under ln *u* while the area under the lower staircase (dashed) is smaller than that under ln *u*.

which can be rewritten as

<span id="page-519-1"></span>
$$
\ln(N-1)! < N\ln N - N + 1 < \ln N!. \tag{A.8}
$$

Subtracting ln *N*! + 1 from Eq. [(A.8)](#page-519-1) and dividing by ln *N*! we obtain

<span id="page-519-2"></span>
$$-\frac{(1+\ln(N))}{\ln N!} < \frac{N\ln N - N - \ln N!}{\ln N!} < -\frac{1}{\ln N!},\tag{A.9}$$

which shows that the fractional error in Eq. [(A.1)](#page-517-2) is of order 1/*N*. Note also from Eq. [(A.9)](#page-519-2) that Eq. [(A.1)](#page-517-2) will give a slight underestimate of ln *N*!.

### A.2 Asymptotic Series

Equation [(A.4)](#page-517-3) is based on Stirling's asymptotic series [92, p. 253]

<span id="page-519-3"></span>
$$\Gamma(\mathbf{x}) \sim \mathbf{x}^{\mathbf{x}} \mathbf{e}^{-\mathbf{x}} (2\pi/\mathbf{x})^{1/2} \left[ 1 + \frac{1}{12\mathbf{x}} + \frac{1}{288\mathbf{x}^2} - \frac{139}{51840\mathbf{x}^3} - \frac{571}{2488320\mathbf{x}^4} + O\left(\frac{1}{\mathbf{x}^5}\right) \right] \tag{A.10}$$

for the gamma function, (*x*). The coefficients in Eq. [(A.10)](#page-519-3) are not very simple and are related to Bernoulli numbers. The gamma function is defined by the integral

<span id="page-519-4"></span>
$$\Gamma(\mathbf{x}) = \int_0^\infty t^{\mathbf{x}-1} \mathbf{e}^{-t} \, \mathbf{d}t \tag{A.11}$$

for the continuous variable *x* > 0. In general, (*x* + 1) = *x*(*x*), which may be verified for *x* > 0 by integration by parts in Eq. [(A.11)](#page-519-4). For integer *N*, we have (*N* + 1) = *N*!. Another special value worth noting is (1/2) = √π. The gamma function can be

<span id="page-520-0"></span>![](_page_520_Figure_1.jpeg)

**FIGURE A–2** Graph of the function (*x*) versus *x* for continuous values of *x*. For *x* equal to a positive integer *N*(*N*) = (*N* − 1)!. For *N* equal to zero or a negative integer, (*N*) → ±∞. Values of (*x*) for negative *x* are obtained by means of analytic continuation using (*x*) = (*x* + 1)/*x* and values of the function defined by Eq. [(A.11)](#page-519-4). Note especially (1) = 0! = 1, (2) = 1! = 1, (3) = 2! = 2, and (4) = 3! = 6.

extended to negative values of *x* and to complex variables by a process known as analytical continuation. In general, *z*! ≡ (*z* + 1) = *z*(*z*), where *z* = *x* + *iy* is a complex variable. [Figure A–2](#page-520-0) shows a graph of the function (*x*) versus *x* for real continuous values of *x*.

### A.2.1 Asymptotic Versus Convergent Series

Asymptotic series should be contrasted with convergent series. If we speak of a convergent power series

<span id="page-520-1"></span>
$$f(z) = \sum_{n=0}^{\infty} a_n z^n,\tag{A.12}$$

we mean that the difference

$$\left| f(z) - \sum_{n=0}^{m} a_n z^n \right| \tag{A.13}$$

can be made as small as desired for fixed *z* by taking *m* sufficiently large. On the other hand, if the series

<span id="page-521-1"></span>
$$F(\mathbf{z}) \sim \sum_{n=0}^{\infty} \frac{A_n}{\mathbf{z}^n} \tag{\text{A.14}}$$

is asymptotic, then [92, p. 151]

<span id="page-521-3"></span>
$$|z|^m \left| F(z) - \sum_{n=0}^m \frac{A_n}{z^n} \right| \tag{A.15}$$

can be made as small as desired for fixed *m* by taking |*z*| sufficiently large.[1](#page-521-0) Thus to get more accuracy in Eq. [(A.12)](#page-520-1), we take more terms; however, to get more accuracy in Eq. [(A.14)](#page-521-1) we cut off the series and take larger |*z*|. In fact, for fixed *z* we usually *must* cut off an asymptotic series because many asymptotic series do not converge, so taking more terms might give a worse result.

A generalization of Eq. [(A.14)](#page-521-1) is to say that if

$$F(\mathbf{z}) = \frac{G(\mathbf{z})}{H(\mathbf{z})} \sim \sum_{n=0}^{\infty} \frac{A_n}{\mathbf{z}^n},\tag{A.16}$$

then

<span id="page-521-2"></span>
$$\mathcal{G}(\mathbf{z}) \sim H(\mathbf{z}) \sum_{n=0}^{\infty} \frac{A_n}{\mathbf{z}^n}. \tag{A.17}$$

<span id="page-521-0"></span>We note that Eq. [(A.10)](#page-519-3) is actually of the form of Eq. [(A.17)](#page-521-2). Equation [(A.10)](#page-519-3) can be derived by consecutive integration by parts and then proving that the remainder, after *m* terms, satisfies Eq. [(A.15)](#page-521-3). Equation [(A.4)](#page-517-3) can be proven in a similar way.

This page intentionally left blank

# B

# Use of Jacobians to Convert Partial Derivatives

Often in thermodynamics one is faced with the problem of converting partial derivatives with certain quantities held constant to expressions involving other partial derivatives with different quantities held constant. For example, one might want to relate the isothermal compressibility κ*T* = *V* −1(∂*V*/∂*P*)*T*,*N* to the isentropic (sometimes called adiabatic) compressibility κ*S* = *V* −1(∂*V*/∂*P*)*S*,*N* . This can be done by trial and error by using the chain rule of partial differentiation together with appropriate Maxwell relations. The use of Jacobians, however, provides a systematic approach to this problem. For other treatments of this topic, see Landau and Lifshitz [7, p. 50] and the first edition of Callen [2].

### B.1 Properties of Jacobians

We review briefly the definition and main properties of Jacobians. We illustrate these for three variables, but the results hold for any number of variables.

We consider the variables *u*, *v*, *w* that depend on *x*, *y*, *z*. A Jacobian is defined as a determinant of partial derivatives as follows:

$$
\begin{array}{c|cccc}
\boldsymbol{\partial}\boldsymbol{\uplangle}\boldsymbol{u},\boldsymbol{v},\boldsymbol{w}\boldsymbol{\uprangle} \\
\hline
\boldsymbol{\partial}\left(\mathbf{x},\mathbf{y},\mathbf{z}\right) \\
\hline
\end{array} = \begin{vmatrix}
\boldsymbol{\partial}\boldsymbol{u}/\boldsymbol{\partial\mathbf{x}} & \boldsymbol{\partial\mathbf{u}}/\boldsymbol{\partial\mathbf{y}} & \boldsymbol{\partial\mathbf{u}}/\boldsymbol{\partial\mathbf{z}} \\
\boldsymbol{\partial}\boldsymbol{v}/\boldsymbol{\partial\mathbf{x}} & \boldsymbol{\partial\mathbf{v}}/\boldsymbol{\partial\mathbf{y}} & \boldsymbol{\partial\mathbf{v}}/\boldsymbol{\partial\mathbf{z}} \\
\boldsymbol{\partial\mathbf{w}/\partial\mathbf{x}} & \boldsymbol{\partial\mathbf{w}/\partial\mathbf{y}} & \boldsymbol{\partial\mathbf{w}/\partial\mathbf{z}}
\end{vmatrix} = \begin{vmatrix}
\boldsymbol{\partial\mathbf{u}/\partial\mathbf{x}} & \boldsymbol{\partial\mathbf{v}/\partial\mathbf{x}} & \boldsymbol{\partial\mathbf{w}/\partial\mathbf{x}} \\
\boldsymbol{\partial\mathbf{u}/\partial\mathbf{y}} & \boldsymbol{\partial\mathbf{v}/\partial\mathbf{y}} & \boldsymbol{\partial\mathbf{w}/\partial\mathbf{y}} \\
\boldsymbol{\partial\mathbf{u}/\partial\mathbf{z}} & \boldsymbol{\partial\mathbf{v}/\partial\mathbf{z}} & \boldsymbol{\partial\mathbf{w}/\partial\mathbf{z}}
\end{vmatrix}.\tag{\mathbb{R},1}
$$

Interchange of two rows or two columns of a determinant gives rise to an overall minus sign. Thus, for example,

$$\frac{\partial \left(\mathfrak{u}, v, \mathfrak{w}\right)}{\partial \left(\mathbf{x}, \mathbf{y}, \mathbf{z}\right)} = -\frac{\partial \left(v, \mathfrak{u}, \mathfrak{w}\right)}{\partial \left(\mathbf{x}, \mathbf{y}, \mathbf{z}\right)} = \frac{\partial \left(v, \mathfrak{u}, \mathfrak{w}\right)}{\partial \left(\mathbf{y}, \mathbf{x}, \mathbf{z}\right)} = -\frac{\partial \left(\mathfrak{u}, v, \mathfrak{w}\right)}{\partial \left(\mathbf{y}, \mathbf{x}, \mathbf{z}\right)}.\tag{\text{B.2}}$$

If *A* and *B* are square matrices, it is well known that the determinant of their matrix product is the product of their determinants, that is, |*AB*|=|*A*||*B*|. Then by the chain rule of partial differentiation it follows that

$$\frac{\partial}{\partial \left(\mathbf{x}, \mathbf{y}, \mathbf{z}\right)} = \frac{\partial}{\partial \left(\mathbf{r}, \mathbf{s}, t\right)} \frac{\partial}{\partial \left(\mathbf{r}, \mathbf{s}, t\right)}\tag{\text{B.3}}$$

and

$$\frac{\partial}{\partial \left(\mathbf{x}, \mathbf{y}, \mathbf{z}\right)} = 1 \int \frac{\partial \left(\mathbf{x}, \mathbf{y}, \mathbf{z}\right)}{\partial \left(\mathbf{u}, v, w\right)} \,. \tag{\text{B.4}}$$

Thus, determinants obey an algebra similar to fractions.

There is a simple connection of a determinant to a single partial derivative. Since

$$
\frac{\partial}{\partial \mathbf{(x,y,z)}} = \begin{vmatrix}
\partial \mathbf{u}/\partial \mathbf{x} & \partial \mathbf{u}/\partial \mathbf{y} & \partial \mathbf{u}/\partial \mathbf{z} \\
\partial \mathbf{y}/\partial \mathbf{x} & \partial \mathbf{y}/\partial \mathbf{y} & \partial \mathbf{y}/\partial \mathbf{z} \\
\partial \mathbf{z}/\partial \mathbf{x} & \partial \mathbf{z}/\partial \mathbf{y} & \partial \mathbf{z}/\partial \mathbf{z}
\end{vmatrix} = \begin{vmatrix}
\partial \mathbf{u}/\partial \mathbf{x} & \partial \mathbf{u}/\partial \mathbf{y} & \partial \mathbf{u}/\partial \mathbf{z} \\
\mathbf{0} & 1 & \mathbf{0} \\
\mathbf{0} & \mathbf{0} & 1
\end{vmatrix},\tag{B.5}
$$

it follows that

$$
\left(\frac{\partial u}{\partial \mathbf{x}}\right)_{\mathbf{y},\mathbf{z}} = \frac{\partial \left(u,\mathbf{y},\mathbf{z}\right)}{\partial \left(\mathbf{x},\mathbf{y},\mathbf{z}\right)}.\tag{\text{B.6}}
$$

### B.2 Connection to Thermodynamics

One often wants to relate thermodynamic derivatives to measurable quantities such as the heat capacity at constant pressure, *Cp*; the isobaric coefficient of thermal expansion, α; and the isothermal compressibility, κ*T* , where

$$\mathbf{C}_{p} = T \left( \frac{\partial S}{\partial T} \right)_{p,N}; \quad a = \frac{1}{V} \left( \frac{\partial V}{\partial T} \right)_{p,N}; \quad \kappa_{T} = -\frac{1}{V} \left( \frac{\partial V}{\partial p} \right)_{T,N}. \tag{\text{B.7}}$$

**Example 1** We first relate the heat capacity at constant volume, namely

$$C_V = T \left(\frac{\partial S}{\partial T}\right)_{V,N},\tag{B.8}$$

to *Cp*. This was done in the text (see Eq. (5.32)) by elementary methods but we now use determinants. Thus

$$\text{Cov} = T \frac{\partial \left( \text{S, } V, N \right)}{\partial \left( T, V, N \right)} = T \frac{\partial \left( \text{S, } V, N \right)}{\partial \left( T, p, N \right)} \frac{\partial \left( T, p, N \right)}{\partial \left( T, V, N \right)}. \tag{B.9}$$

We recognize that

$$\frac{\partial}{\partial \left(T, V, N\right)} = 1 \int \left(\frac{\partial V}{\partial p}\right)_{T, N} \tag{B.10}$$

and readily compute[1](#page-524-0)

$$\frac{\partial \left(S, V, N\right)}{\partial \left(T, p, N\right)} = \left(\frac{\partial S}{\partial T}\right)_{p, N} \left(\frac{\partial V}{\partial p}\right)_{T, N} - \left(\frac{\partial S}{\partial p}\right)_{T, N} \left(\frac{\partial V}{\partial T}\right)_{p, N} \tag{B.11}$$

This results in

<span id="page-524-1"></span>
$$\mathbf{C}\mathbf{V} = \mathbf{C}_{\mathcal{P}} - T \left(\frac{\partial S}{\partial p}\right)_{T,N} \left(\frac{\partial V}{\partial T}\right)_{p,N} \bigg/ \left(\frac{\partial V}{\partial p}\right)_{T,N} \tag{\text{B.12}}$$

From the differential d*G* = −*S* d*T* + *V* d*p* + μd*N* we obtain the Maxwell relation - ∂*S*/∂*p T*,*N* = −(∂*V*/∂*T*)*p*,*N* , so Eq. [(B.12)](#page-524-1) becomes

<span id="page-524-0"></span>1The last line of the 3 × 3 determinant is 0, 0, 1 so the result is a 2 × 2 determinant.

$$\mathbf{C}_{V} = \mathbf{C}_{p} + T \left[ \left( \frac{\partial V}{\partial T} \right)_{p,N} \right]^2 \int \left( \frac{\partial V}{\partial p} \right)_{T,N} \tag{\text{B.13}}$$

which may be rewritten

<span id="page-525-0"></span>
$$\mathbf{C}\mathbf{v} = \mathbf{C}_{\mathcal{P}} - T\mathbf{V}\boldsymbol{\alpha}^{2}/\kappa\mathbf{r}.\tag{\text{B.14}}$$

A result for this same quantity that looks somewhat different can be obtained by starting with *Cp*. Thus, more briefly,

$$\begin{split} C_{p} &= T \frac{\partial}{\partial \left( T, p, N \right)} = T \frac{\partial}{\partial \left( T, V, N \right)} \frac{\partial}{\partial \left( T, p, N \right)} \\ &= T \left[ \left( \frac{\partial S}{\partial T} \right)_{V, N} \left( \frac{\partial p}{\partial V} \right)_{T, N} - \left( \frac{\partial S}{\partial V} \right)_{T, N} \left( \frac{\partial p}{\partial T} \right)_{V, N} \right] \left( \frac{\partial V}{\partial p} \right)_{T, N} \\ &= C_{V} - T \left[ \left( \frac{\partial p}{\partial T} \right)_{V, N} \right]^2 \left( \frac{\partial V}{\partial p} \right)_{T, N} . \end{split} \tag{8.15}$$

So

<span id="page-525-1"></span>
$$C_P = C_V + TV \left[ \left( \frac{\partial p}{\partial T} \right)_{V,N} \right]^2 \kappa_T. \tag{B.16}$$

Both Eqs. [(B.14)](#page-525-0) and [(B.16)](#page-525-1) show that *Cp* ≥ *CV* but they appear to be different. They can be reconciled, however, by noting that

$$\mathbf{d}V = \left(\frac{\partial V}{\partial T}\right)_{p,N} \mathbf{d}T + \left(\frac{\partial V}{\partial p}\right)_{T,N} \mathbf{d}p + \left(\frac{\partial V}{\partial N}\right)_{p,T} \mathbf{d}N \tag{\text{B.17}}$$

from which we readily deduce that

<span id="page-525-4"></span>
$$
\left(\frac{\partial p}{\partial T}\right)_{V,N} = -\left(\frac{\partial V}{\partial T}\right)_{p,N} \bigg/ \left(\frac{\partial V}{\partial p}\right)_{T,N} = \alpha / \kappa_T.\tag{B.18}
$$

**Example 2** A more powerful use of Jacobians can be used to relate the isentropic compressibility

<span id="page-525-3"></span>
$$\kappa_S = -\frac{1}{V} \left( \frac{\partial V}{\partial p} \right)_{S,V} \tag{B.19}$$

to the isothermal compressibility κ*T* . Thus,

$$
\left(\frac{\partial V}{\partial p}\right)_{\text{S,N}} = \frac{\partial \left(V, \text{S,N}\right)}{\partial \left(p, \text{S,N}\right)} = \frac{\partial \left(V, \text{S,N}\right)}{\partial \left(V, T, N\right)} \frac{\partial \left(V, T, N\right)}{\partial \left(p, T, N\right)} \frac{\partial \left(p, T, N\right)}{\partial \left(p, \text{S,N}\right)}.\tag{\text{B.20}}$$

In this case, each Jacobian can be identified as a single partial derivative and we readily deduce

<span id="page-525-2"></span>
$$
\kappa_{\mathcal{S}}/\kappa_T = \mathcal{C}_V/\mathcal{C}_p.\tag{\mathbb{B}.21}
$$

From this relationship, we see that κ*T* ≥ κ*S*. Furthermore, division of Eq. [(B.14)](#page-525-0) by *Cp*, substitution of Eq. [(B.21)](#page-525-2) and rearrangement leads to

$$
\kappa_{\mathbb{S}} = \kappa_T - TV\alpha^2/\mathbb{C}_p.\tag{\mathbb{B}.22}
$$

Similarly, dividing Eq. [(B.16)](#page-525-1) by *CV* and substituting of Eq. [(B.21)](#page-525-2) gives

$$\frac{1}{\kappa_S} = \frac{1}{\kappa_T} + TV\left[\left(\frac{\partial p}{\partial T}\right)_{V,N}\right]^2\\\frac{1}{C_V} = \frac{1}{\kappa_T} + \frac{TVa^2}{\kappa_T^2 C_V}.\tag{B.23}$$

**Example 3** By analogy to Eq. [(B.19)](#page-525-3), one can define an isentropic (sometimes called adiabatic) coefficient of expansion

$$
\alpha_S = \frac{1}{V} \left( \frac{\partial V}{\partial T} \right)_{S,V} \tag{B.24}
$$

and relate it to the isothermal coefficient of expansion α. Thus

$$
\left(\frac{\partial V}{\partial T}\right)_{S,N} = \frac{\partial \left(V, S, N\right)}{\partial \left(T, S, N\right)} = \frac{\partial \left(V, S, N\right)}{\partial \left(V, T, N\right)} \frac{\partial \left(V, T, N\right)}{\partial \left(T, S, N\right)} = -\left(\frac{\partial S}{\partial T}\right)_{V, N} \left(\frac{\partial V}{\partial S}\right)_{T,N} \tag{B.25}
$$

We recognize (∂*S*/∂*T*)*V*,*N* = *CV* /*T*. From d*F* = −*S* d*T* −*p* d*V* +μd*N*, we obtain the Maxwell relation (∂*S*/∂*V*)*T*,*N* = - ∂*p*/∂*T V*,*N* = α/κ*T* , where Eq. [(B.18)](#page-525-4) has been used in the last step. Putting everything together gives

$$
\alpha_S = -\frac{C_V \kappa_T}{V T \alpha}.\tag{\text{B.26}}
$$

This result shows unexpectedly that α*S* varies inversely with α and has the opposite sign. For an ideal gas it becomes α*S* = −*CV* /*pV* = −*CV* /*NRT*, which follows easily from Eq. (3.56) for the entropy of one mole of an ideal gas.

**Example 4** For a monocomponent system, the Kramers potential *K* = *U* − *TS* − μ*N* so we have d*K* = −*S* d*T* − *p* d*V* − *N* dμ. The independent variables are *T*, *V* and μ. As shown in Chapter 21, this potential is related to the grand partition function *Z* by Eq. (21.13). We proceed to express the heat capacity at constant volume in terms of derivatives with respect to these independent variables as follows:

$$C_{V} = T\left(\frac{\partial S}{\partial T}\right)_{V,N} = T\frac{\partial}{\partial}\frac{(S,V,N)}{(T,V,N)} = T\frac{\partial}{\partial}\frac{(S,V,N)}{(T,V,\mu)}\frac{\partial}{\partial}\frac{(T,V,\mu)}{(T,V,N)}$$

$$= T\left[\left(\frac{\partial S}{\partial T}\right)_{\mu,V}\left(\frac{\partial N}{\partial \mu}\right)_{T,V} - \left(\frac{\partial S}{\partial \mu}\right)_{T,V}\left(\frac{\partial N}{\partial T}\right)_{\mu,V}\right] \left(\frac{\partial \mu}{\partial N}\right)_{T,V}$$

$$= T\left(\frac{\partial S}{\partial T}\right)_{\mu,V} - T\left[\left(\frac{\partial S}{\partial \mu}\right)_{T,V}\right]^2 / \left(\frac{\partial N}{\partial \mu}\right)_{T,V},\tag{B.27}$$

where the Maxwell relation (∂*S*/∂μ)*T*,*V* = (∂*N*/∂*T*)μ,*V* from d*K* has been used.

**Example 5** If there is a functional relationship among three variables *x*, *y*, *z*, then

<span id="page-526-0"></span>
$$
\frac{\partial}{\partial \left(\mathbf{z}, \mathbf{x}\right)} \frac{\partial}{\partial \left(\mathbf{y}, \mathbf{z}\right)} \frac{\partial}{\partial \left(\mathbf{y}, \mathbf{z}\right)} \frac{\partial \left(\mathbf{z}, \mathbf{x}\right)}{\partial \left(\mathbf{y}, \mathbf{z}\right)} = 1.\tag{\text{B.28}}
$$

Interpreting each Jacobian as a partial derivative we obtain

$$\left[\mathbf{I} - \left(\partial \mathbf{y}/\partial \mathbf{z}\right)_x\right] \mathbf{I} - \left(\partial \mathbf{z}/\partial \mathbf{x}\right)_Y \left[\mathbf{I} - \left(\partial \mathbf{x}/\partial \mathbf{y}\right)_z\right] = \mathbf{I} \tag{\text{B.29}}$$

or simply

<span id="page-527-0"></span>
$$\left(\partial \mathbf{y}/\partial \mathbf{z}\right)_{\mathbf{x}} (\partial \mathbf{z}/\partial \mathbf{x})_{\mathbf{y}} \left(\partial \mathbf{x}/\partial \mathbf{y}\right)_{\mathbf{z}} = -1. \tag{\text{B.30}}$$

Although the Jacobians in Eq. [(B.28)](#page-526-0) behave like fractions, the corresponding partial derivatives are each accompanied by a minus sign; therefore, they do not quite behave like fractions, resulting in the net minus sign on the right of Eq. [(B.30)](#page-527-0). Equation (5.31) is a relation of this type where the independent variables are *p*, *V*, *T* with *N* being constant in all derivatives and therefore irrelevant.

This page intentionally left blank

# C

# Differential Geometry of Surfaces

In this appendix, we develop some formulae based on the differential geometry of surfaces that are useful in the treatment of surfaces and interfaces, as discussed in Chapters 13 and 14. We also explore some more aspects of the *ξ* vector used to treat anisotropic solidfluid interfaces, as well as the calculus of variations needed to treat curved interfaces. For convenience, we give the main differential and integral formulas that involve the surface gradient ∇*s*, surface divergence ∇*s*· and surface curl ∇*s*× operators. This is followed by a formula for ∇*s*·*ξ* that we use to derive a generalization of Herring's formula for the chemical potential at a point on curved surface, as well as a formula for the equilibrium shape. The equilibrium shape is also calculated from a variational formulation that can be used to prove the Wulff construction for differentiable anisotropic surface free energy.

### C.1 Alternative Formulae for ξ Vector

In Chapter 14 (see Eqs. (14.30) and (14.31)) we defined the vector

<span id="page-529-1"></span>
$$\xi_a(\hat{\mathbf{n}}) := \frac{\partial \tilde{\boldsymbol{\gamma}}(\mathbf{P})}{\partial P_a}; \quad \xi(\hat{\mathbf{n}}) := \nabla p \tilde{\boldsymbol{\gamma}}(\mathbf{P}), \tag{C.1}$$

where γ (˜ **P**) = *P*γ (**n**ˆ), **P** = *P***n**ˆ and γ (**n**ˆ) is the interfacial free energy per unit area as a function of its unit normal **n**ˆ, with other variables held constant and suppressed. We also showed that γ = *ξ* ·**n**ˆ, dγ = *ξ* · d**n**ˆ and **n**ˆ · d*ξ* = 0, where all derivatives are assumed to exist and be continuous. Now we develop some alternative ways of calculating *ξ* (**n**ˆ) directly from derivatives with respect to **n**ˆ.

First, we simply recognize that the chain rule of differentiation can be used to compensate for the fact that the components of **n**ˆ are not independent. Thus

$$\xi_{\alpha} = \frac{\partial \llbracket P\gamma (\mathbf{P} / P) \rrbracket}{\partial P_{\alpha}} = \gamma \frac{P_{\alpha}}{P} + P \sum_{\beta=1}^{3} \frac{\partial \gamma}{\partial n_{\beta}} \frac{\partial (P_{\beta} / P)}{\partial P_{\alpha}},\tag{C.2}$$

where the partial derivatives with respect to *n*β are formal derivatives taken as if the *n*β were independent. But

$$\frac{\partial (P_{\beta}/P)}{\partial P_{a}} = \frac{\delta_{a\beta}}{P} - \frac{P_{a}P_{\beta}}{P^{3}}\tag{C.3}$$

so

<span id="page-529-0"></span>
$$\xi_{\alpha} = \chi \ n_{\alpha} + \sum_{\beta=1}^{3} \frac{\partial \chi}{\partial n_{\beta}} (\delta_{\alpha \beta} - n_{\alpha} n_{\beta}). \tag{C.4}$$

509

If we define a formal gradient operator ∇*n* whose components are ∂/∂*n*α, Eq. [(C.4)](#page-529-0) can be written in the vector form

<span id="page-530-0"></span>
$$\boldsymbol{\xi}(\hat{\mathbf{n}}) = \boldsymbol{\gamma}\,\hat{\mathbf{n}} + [\nabla_{\boldsymbol{n}}\boldsymbol{\chi} - \hat{\mathbf{n}}(\hat{\mathbf{n}} \cdot \nabla_{\boldsymbol{n}}\boldsymbol{\chi})].\tag{C.5}$$

Given the various ways that γ can be expressed in terms of the components of **n**ˆ, the quantity ∇*n*γ is not unique but the quantity [∇*n*γ − **n**ˆ(**n**ˆ · ∇*n*γ )] is unique and represents the tangential part *ξ t* of *ξ* .

Another option can be used to simplify Eq. [(C.5)](#page-530-0) even further. Given a function γ (*n*α) of the components *n*α, one can always write it in the form

$$\gamma_h := \nu \left( \frac{n_a}{(n_x^2 + n_y^2 + n_z^2)^{1/2}} \right) \tag{C.6}$$

so that it is a homogeneous function of degree zero in the components of **n**ˆ. Then from Euler's theorem,

$$\sum_{\beta=1}^{3} n_{\beta} \frac{\partial \mathcal{Y}_{\hbar}}{\partial n_{\beta}} = 0 \tag{C.7}$$

or more succinctly **n**ˆ · ∇*n*γ*h* = 0. Then Eq. [(C.5)](#page-530-0) reduces to

$$
\boldsymbol{\xi}(\hat{\mathbf{n}}) = \boldsymbol{\chi}\,\hat{\mathbf{n}} + \nabla_{\boldsymbol{\eta}}\boldsymbol{\chi}\boldsymbol{\eta}.\tag{C.8}
$$

**Example Problem C.1.** For a crystal having cubic symmetry, the leading anisotropy is

$$\boldsymbol{\gamma}(\hat{\mathbf{n}}) = \boldsymbol{\gamma}_0 + \boldsymbol{\gamma}_4 (\boldsymbol{n}_\times^4 + \boldsymbol{n}_\times^4 + \boldsymbol{n}_\times^4),\tag{C.9}$$

where γ0 and γ4 are constants. Calculate *ξ* (**n**ˆ) directly by differentiation with respect to the components of **n**ˆ.

**Solution C.1.** We write

$$\gamma_h = \wp_0 + \chi_4 \frac{(n_\chi^4 + n_\chi^4 + n_z^4)}{(n_\chi^2 + n_\chi^2 + n_z^2)^2} \tag{C.10}$$

so

$$\nabla_{\mathbf{n}}\gamma_{\mathbf{h}} = 4\gamma_{4}\frac{(n_{\mathbf{x}}^{3}\hat{\mathbf{i}} + n_{\mathbf{y}}^{3}\hat{\mathbf{j}} + n_{\mathbf{z}}^{3}\hat{\mathbf{k}})}{(n_{\mathbf{x}}^{2} + n_{\mathbf{y}}^{2} + n_{\mathbf{z}}^{2})^{2}} - 4\gamma_{4}\hat{\mathbf{n}}\frac{(n_{\mathbf{x}}^{4} + n_{\mathbf{y}}^{4} + n_{\mathbf{z}}^{4})}{(n_{\mathbf{x}}^{2} + n_{\mathbf{y}}^{2} + n_{\mathbf{z}}^{2})^{3}}.\tag{C.11}$$

Now that the differentiation is finished, we can set both denominators equal to one. Thus

$$\mathbf{f}_1 = 4\gamma_4 \mathbf{\hat{i}} (n_x^3 \hat{\mathbf{i}} + n_y^3 \hat{\mathbf{j}} + n_z^3 \hat{\mathbf{k}}) - 4\hat{\mathbf{n}} (n_x^4 + n_y^4 + n_z^4) \,\mathrm{[}\tag{C.12}$$

and of course *ξn* = γ **n**ˆ, in agreement with Eq. (14.40).

A popular alternative is to express **P** in terms of spherical polar coordinates with radius *r* = *P*, where θ is the polar angle and ϕ is the azimuthal angle. Then the gradient operator ∇*P* becomes

, (C.13)

$$\nabla_{\mathbf{r}} = \hat{\mathbf{r}}\frac{\partial}{\partial r} + \frac{1}{r} \left[ \hat{\boldsymbol{\theta}}\frac{\partial}{\partial \boldsymbol{\theta}} + \hat{\boldsymbol{\varphi}}\frac{1}{\sin \theta} \frac{\partial}{\partial \boldsymbol{\varphi}} \right],\tag{C.13}$$

where the unit vectors

element is

$$\begin{aligned} \hat{\mathbf{r}} &= \sin\theta\,\cos\varphi\,\hat{\mathbf{i}} + \sin\theta\,\sin\varphi\,\hat{\mathbf{j}} + \cos\theta\,\hat{\mathbf{k}};\\ \hat{\theta} &= \cos\theta\,\cos\varphi\,\hat{\mathbf{i}} + \cos\theta\,\sin\varphi\,\hat{\mathbf{j}} - \sin\theta\,\hat{\mathbf{k}};\\ \hat{\boldsymbol{\varphi}} &= -\sin\varphi\,\hat{\mathbf{i}} + \cos\varphi\,\hat{\mathbf{j}},\end{aligned} \tag{C.14}$$

∇*r* = **r**ˆ ∂ ∂*r* + 1 *r* ˆ *θ* ∂ ∂θ + ˆ*ϕ* 1 sinθ ∂ ∂ϕ

$$\boldsymbol{\xi} = \nabla_{\boldsymbol{I}} [\boldsymbol{r} \,\boldsymbol{\gamma} (\boldsymbol{\theta}, \boldsymbol{\varphi})] = \mathbf{\hat{r}} \boldsymbol{\gamma} + \left[ \dot{\boldsymbol{\theta}} \frac{\partial \boldsymbol{\gamma}}{\partial \boldsymbol{\theta}} + \dot{\boldsymbol{\varphi}} \frac{1}{\sin \boldsymbol{\theta}} \frac{\partial \boldsymbol{\gamma}}{\partial \boldsymbol{\varphi}} \right]. \tag{C.15}$$

<span id="page-531-0"></span>ˆ *θ* = cos θ cos ϕ ˆ **i** + [cos](#page-536-0) θ sinϕ ˆ **j** − sin θ ˆ **k**; *ϕ*ˆ = −sin ϕ ˆ **i** + cos ϕ ˆ **j**, (C.14) can be related to ˆ **i**,ˆ **j**, ˆ **k** in a Cartesian space. Thus *ξ* = ∇*r* [*r* γ (θ, ϕ)] = **r**ˆγ + ˆ *θ* ∂γ ∂θ + ˆ*ϕ* 1 sin θ ∂γ ∂ϕ . (C.15)

Here, **r**ˆ must be identified with the local normal vector **n**ˆ at a point on the surface of the

### crystal, where ˆ *θ* and *ϕ*ˆ are local unit tangent vectors. This representation can be confusing because **r** is not the radius vector to some point on that surface unless that surface happens to be a sphere of radius *r*. See Section C.3 for a representation that relates to a

general surface. C.2 Surface Differential Geometry

We present some elements of surface differential geometry that are useful in treating curved interfaces with anisotropic γ (**n**). We also introduce the surface gradient operator ∇*s* and give equations for the surface divergence ∇*s*·**V** and some of its properties. We follow a straightforward treatment by Weatherburn [93, 94].

$$\mathbf{r}_u := \frac{\partial \mathbf{r}(u, v)}{\partial u}; \quad \mathbf{r}_v := \frac{\partial \mathbf{r}(u, v)}{\partial v} \tag{C.16}$$

functions are assumed to have continuous first and second derivatives. The vectors **r***u* := ∂**r**(*u*, *v*) ∂*u* ; **r***v* := ∂**r**(*u*, *v*) ∂*v* (C.16) are locally tangent to the surface at the point *u*, *v*; they are not collinear but they are not

$$
\hat{\mathbf{n}} = \frac{\mathbf{r}_{\mathcal{U}} \times \mathbf{r}_{\upsilon}}{|\mathbf{r}_{\mathcal{U}} \times \mathbf{r}_{\upsilon}|} = \frac{\mathbf{H}}{H},
\tag{C.17}
$$

**n**ˆ = **r***u* × **r***v* |**r***u* × **r***v* | = **H** *H* , (C.17) where the vector **H** := **r***u* × **r***v* and *H* = |**r***u* × **r***v* | is its magnitude. The vector area

$$\mathbf{dA} = \hat{\mathbf{n}} \, \mathbf{d}A = \hat{\mathbf{n}} \, |\mathbf{r}_{\mathcal{U}} \times \mathbf{r}_{v}| \, \mathbf{d}\mu \, \mathbf{d}v = \hat{\mathbf{n}}H \, \mathbf{d}\mu \, \mathbf{d}v = (\mathbf{r}_{\mathcal{U}} \times \mathbf{r}_{v}) \, \mathbf{d}\mu \, \mathbf{d}v. \tag{C.18}$$

d**A** = **n**ˆ d*A* = **n**ˆ |**r***u* × **r***v* | d*u* d*v* = **n**ˆ*H* d*u* d*v* = (**r***u* × **r***v* ) d*u* d*v*. (C.18)

$$E := \mathbf{r}_{\mathcal{U}} \cdot \mathbf{r}_{\mathcal{U}}; \quad F := \mathbf{r}_{\mathcal{U}} \cdot \mathbf{r}_{\mathcal{V}}; \quad G := \mathbf{r}_{\mathcal{V}} \cdot \mathbf{r}_{\mathcal{V}}.\tag{C.19}$$

$$\mathbf{r}_{\mu}^{\dagger} := \frac{\mathbf{r}_{v} \times \hat{\mathbf{n}}}{H}; \quad \mathbf{r}_{v}^{\dagger} := \frac{\hat{\mathbf{n}} \times \mathbf{r}_{u}}{H}, \tag{C.20}$$

512 THERMAL PHYSICS

<span id="page-532-0"></span>†

 **n**ˆ *u* **n**ˆ *v*

<span id="page-532-1"></span>**r**†

$$\mathbf{r}_{\mu}^{\dagger} \cdot \mathbf{r}_{\iota} = 1; \quad \mathbf{r}_{\mu}^{\dagger} \cdot \mathbf{r}_{v} = \mathbf{r}_{v}^{\dagger} \cdot \mathbf{r}_{\iota} = 0; \quad \mathbf{r}_{v}^{\dagger} \cdot \mathbf{r}_{v} = 1. \tag{C.21}$$

In order to handle the possible non-orthogonality of **r***u* and **r***v* , we introduce the reciprocal vectors

$$
\hat{\mathbf{n}}_{\mathsf{U}} := \frac{\partial \hat{\mathbf{n}}(\boldsymbol{u}, v)}{\partial \boldsymbol{u}}; \quad \hat{\mathbf{n}}_{\boldsymbol{v}} := \frac{\partial \hat{\mathbf{n}}(\boldsymbol{u}, v)}{\partial \boldsymbol{v}} \tag{C.22}
$$

which are orthogonal to **n**ˆ and satisfy **r**† *u* · **r***u* = 1; **r**† *u* · **r***v* = **r**† *v* · **r***u* = 0; **r**† *v* · **r***v* = 1. (C.21)

$$d\hat{\mathbf{n}} = \mathbf{d}\left(\frac{\mathbf{H}}{H}\right) = \frac{\mathbf{dH}}{H} - \mathbf{H}\frac{\mathbf{d}H}{H^2} = \frac{\mathbf{dH}}{H} - \left(\hat{\mathbf{n}} \cdot \frac{\mathbf{dH}}{H}\right)\hat{\mathbf{n}}.\tag{C.23}$$

∂*u* ∂*v* (C.22) which are necessarily normal to **n**ˆ. They can therefore be resolved along **r***u* and **r***v* or alternatively along **r** † *u* and **r**† *v* . Moreover, *d***n**ˆ = d **H** *H* = d**H** *H* − **H** d*H H*2 = d**H** *H* − **n**ˆ · d**H** *H* **n**ˆ. (C.23)

*v*

$$
\begin{pmatrix} \hat{\mathbf{n}}_{\boldsymbol{u}} \\ \hat{\mathbf{n}}_{\boldsymbol{v}} \end{pmatrix} = \begin{pmatrix} L & M \\ M & N \end{pmatrix} \begin{pmatrix} \mathbf{r}_{\boldsymbol{u}}^{\dagger} \\ \mathbf{r}_{\boldsymbol{v}}^{\dagger} \end{pmatrix} = \begin{pmatrix} P & R \\ Q & S \end{pmatrix} \begin{pmatrix} \mathbf{r}_{\boldsymbol{u}} \\ \mathbf{r}_{\boldsymbol{v}} \end{pmatrix}, \tag{C.24}
$$
 
$$\text{where}$$

summarized in matrix notation by the equation

Then if we write **n**ˆ *u* = *L***r**

$$L := -\hat{\mathbf{n}} \cdot \mathbf{r}_{\mu\nu}; \quad M := -\hat{\mathbf{n}} \cdot \mathbf{r}_{\mu\upsilon}; \quad N := -\hat{\mathbf{n}} \cdot \mathbf{r}_{\upsilon\upsilon} \tag{C.25}$$

where

and

$$\begin{aligned} P &= \frac{LG - MF}{H^2}; \ R = \frac{ME - LF}{H^2};\\ Q &= \frac{MG - NF}{H^2}; \ S = \frac{NE - MF}{H^2}. \end{aligned} \tag{C.26}$$
 
$$\begin{aligned} \text{i.e. on } &((C.26)^\circ, -1, +1, \dots, -11, \dots) \\\ \text{2.11} \end{aligned} \tag{C.26}$$

*H*2 ; *R* = *ME* − *LF H*2 ;

$$\mathbf{r}_u^\dagger = \frac{\mathbf{Gr}_{\mathcal{U}} - F\mathbf{r}_v}{H^2}; \quad \mathbf{r}_v^\dagger = \frac{-F\mathbf{r}_{\mathcal{U}} + E\mathbf{r}_v}{H^2}.\tag{C.27}$$

**r**† *u* = *G***r***u* − *F***r***v H*2 ; **r**† *v* = −*F***r***u* + *E***r***v H*2 . (C.27)

$$\mathcal{K} \equiv \frac{1}{R_1} + \frac{1}{R_2} = P + \mathcal{S}; \quad \mathcal{G} \equiv \frac{1}{R_1}\frac{1}{R_2} = P\mathcal{S} - Q\mathcal{R} = \frac{LN - M^2}{H^2},\tag{C.28}$$
 
$$\text{where } R_1 \text{ and } R_2 \text{ are the minimal ndii} \text{ of curvature measured in wincinol planes that}$$

*K* ≡ 1 *R*1 + *R*2 = *P* + *S*; *G* ≡ 1 *R*1 *R*2 *H*2 , (C.28) where *R*1 and *R*2 are the principal radii of curvature measured in principal planes that

are orthogonal to each other and that contain **n**ˆ. One could transform to coordinates in

<sup>1</sup>Note that **n**ˆ *u* and **n**ˆ *v* are not unit vectors; they are derivatives of unit vectors.

*Appendix C* • Differential G[eomet](#page-532-0)ry of Surfaces 513 the principal planes by means of a series of linear transformations that would ultimately result in transforming that matrix by means of a similarity transformation that preserves

$$
\hat{\mathbf{n}}_{\rm ll} = P \mathbf{r}_{\rm ll} = (L/E)\mathbf{r}_{\rm ll}; \quad \hat{\mathbf{n}}_{v} = S \mathbf{r}_{v} = (N/G)\mathbf{r}_{v}. \tag{C.29}
$$

orthogonal coordinates at the point of the surface under consideration and that they have been oriented so that **r***uv* = 0. Then *F* = 0, the line element would be d*s*2 =

$$\frac{1}{R_1} = \left(\frac{\mathrm{d}\theta}{\mathrm{ds}}\right)_u = \frac{\hat{\mathbf{t}}_u \cdot \hat{\mathbf{n}}_u \, \mathrm{d}u}{E^{1/2} \mathrm{d}u} = \frac{L}{E} = P; \quad \frac{1}{R_2} = \left(\frac{\mathrm{d}\theta}{\mathrm{ds}}\right)_v = \frac{\hat{\mathbf{t}}_v \cdot \hat{\mathbf{n}}_v \, \mathrm{d}v}{G^{1/2} \mathrm{d}v} = \frac{N}{G} = \mathrm{S}.\tag{C.30}$$

Equation (C.24) would become simply

be written

$$\mathbf{d}\hat{\mathbf{n}} = \frac{1}{R_1}\mathbf{r}_{ll}\,\mathrm{d}u + \frac{1}{R_2}\mathbf{r}_v\,\mathrm{d}v,\quad\text{principal axes,}\tag{C.31}$$

= **t**ˆ*v* · **n**ˆ *v* d*v*

1 = dθ = **t**ˆ*u* · **n**ˆ *u* d*u E*1/2d*u* = *L E* = *P*; 1 = dθ 

> d**n**ˆ = 1 *R*1

*R*1 d*s u R*2 d*s v G*1/2 d*v* = *N* Thus w[e hav](#page-532-0)e

$$\frac{1}{R_{1,2}} = \frac{P+S}{2} \pm \sqrt{\left(\frac{P-S}{2}\right)^2 + QR},\tag{C.32}$$

*G* = *S*. (C.30)

which is equivalent to the formulae of Rodrigues. In the general case, the principal curvatures are given by 1 *R*1,2 = *P* + *S* 2 ± *P* − *S* 2 2 + *QR*, (C.32) which can be found by determining the eigenvalues that correspond to the principal axes. An outline of this transformation is the following: If we denote the second matrix in Eq. (C.24) by *P*, it may be taken into diagonal form by a transformation of the form *Q*−1*PQ* where the matrix *Q* = *A* −1/2*B* encompasses three successive transformations. The matrix *A* is orthogonal and takes the line element into diagonal form with positive definite eigenvalues. is the resulting diagonal eigenvalue matrix and 1/2 is its square root; it provides a stretching transformation. The combination of transformations *A* −1/2 takes the line element into the form d*s*2 = d*X*2 +d*Y* 2 and takes *P* into a symmetric matrix. The final matrix *B* is an orthogonal matrix that rotates the already orthogonal axes into the

*v* · **n**ˆ *v* ; *G* = **n** · **n**ˆ *u* × **n**ˆ *v*

$$\mathcal{K} = \mathbf{r}_{\mu}^{\dagger} \cdot \hat{\mathbf{n}}_{\mu} + \mathbf{r}_{v}^{\dagger} \cdot \hat{\mathbf{n}}_{v}; \quad \mathcal{G} = \frac{\mathbf{n} \cdot \hat{\mathbf{n}}_{\mu} \times \hat{\mathbf{n}}_{v}}{H}. \tag{C.33}$$

*K* = **r**†

C.2.1 Surface Differential Operators

*u* · **n**ˆ *u* + **r**†

$$\nabla_t \phi \cdot \mathbf{dr} = \mathbf{d}\phi = \frac{\partial \phi}{\partial u} \, \mathbf{d}u + \frac{\partial \phi}{\partial v} \, \mathbf{d}v,\tag{C.34}$$

*H* . (C.33)

$$\nabla_{\sf s} = \mathbf{r}_{\sf u}^{\sf t} \frac{\partial}{\partial \sf u} + \mathbf{r}_{v}^{\sf t} \frac{\partial}{\partial \sf v}. \tag{C.35}$$

514 THERMAL PHYSICS

that

given by

three dimensions.

$$\mathbf{V} = V^{\mu}\mathbf{r}_{\mu} + V^{\upsilon}\mathbf{r}_{\upsilon} + V^{\eta}\mathbf{\hat{n}},\tag{\text{C.36}}$$

where φ(*u*, *v*) is a scalar function defined on the surface. Since d**r** = **r***u* d*u*+**r***v* d*v* it follows

<span id="page-534-0"></span>
$$\nabla_{\mathcal{S}} \cdot \mathbf{V} = \nabla_{\mathcal{S}} \cdot (V^{\mu} \mathbf{r}_{\mathcal{U}} + V^{v} \mathbf{r}_{v}) + V^{n} \nabla_{\mathcal{S}} \cdot \hat{\mathbf{n}} \tag{\mathbb{C}.37}$$

∇*s* = **r**† *u* ∂*u* + **r**† *v* ∂*v* . (C.35) For a v[ector](#page-534-0) of the form

<span id="page-534-1"></span>
$$
\nabla_{\sf s} \cdot \hat{\bf n} = \mathcal{K},
\tag{C.38}
$$

*u*

one can form a surface divergence

$$\nabla_t \cdot \mathbf{V} = \nabla_t \cdot (V^\mu \mathbf{r}_\mu + V^v \mathbf{r}_v) + V^\mu \boldsymbol{\lambda}.\tag{C.39}$$

and **r**† *v* are perpendicular to **n**ˆ. By the first member of Eq. (C.33) we see that ∇*s* · **n**ˆ = *K*, (C.38) so Eq. (C.37) becomes ∇*s* · **V** = ∇*s* · (*Vu***r***u* + *Vv* **r***v* ) + *VnK*. (C.39)

$$\nabla_{\mathcal{S}} \cdot \mathbf{V} = \frac{1}{H} \left[ \frac{\partial}{\partial u} (H \mathcal{V}^{\mu}) + \frac{\partial}{\partial v} (H \mathcal{V}^{v}) \right] + V^{n} \mathcal{K}. \tag{C.40}$$

tangential components of **V** each lead to two terms because **r***u* and **r***v* are not constants. After some algebra one obtains

$$\nabla_{\mathbf{s}} \cdot \mathbf{r} = \left[ \mathbf{r}_{\mu}^{\dagger} \frac{\partial}{\partial \mu} + \mathbf{r}_{v}^{\dagger} \frac{\partial}{\partial v} \right] \cdot \mathbf{r} = \mathbf{r}_{\mu}^{\dagger} \cdot \mathbf{r}_{\mu} + \mathbf{r}_{v}^{\dagger} \cdot \mathbf{r}_{v} = 2. \tag{C.41}$$

A case of special importance occurs when **V** = **r**(*u*, *v*), the position vector itself. Then ∇*s* · **r** = **r**† *u* ∂ + **r**† *v* ∂ · **r** = **r**† *u* · **r***u* + **r**† *v* · **r***v* = 2. (C.41)

$$\nabla_{\mathcal{g}}^2 \phi = \nabla_{\mathcal{g}} \cdot \nabla_{\mathcal{g}} \phi = \frac{1}{H} \left[ \frac{\partial}{\partial u} \left( \frac{\mathcal{G} \phi u - F \phi_v}{H} \right) + \frac{\partial}{\partial v} \left( \frac{\mathcal{G} \phi u - F \phi_v}{H} \right) \right]. \tag{C.42}$$

∇2 *s* φ = ∇*s* · ∇*s*φ = 1 *H* ∂ ∂*u G*φ*u* − *F*φ*v H* + ∂ ∂*v G*φ*u* − *F*φ*v H* . (C.42)

$$
\nabla_{\mathcal{S}} \times \mathbf{V} = \frac{\hat{\mathbf{n}}}{H} \left[ \frac{\partial}{\partial u} \left( F V^{\mu} + G V^{\upsilon} \right) - \frac{\partial}{\partial v} \left( E V^{\mu} + F V^{\upsilon} \right) \right]
$$

$$
+ \frac{1}{H} \left[ \left( M V^{\mu} + N V^{\upsilon} \right) \mathbf{r}_{\mathcal{U}} - \left( L V^{\mu} + M V^{\upsilon} \right) \mathbf{r}_{\upsilon} \right] - \hat{\mathbf{n}} \times \nabla_{\mathcal{S}} V^{\mu}. \tag{C.43}
$$

+ 1 *H MVu* + *NVv* **r***u* − *LVu* + *MVv* **r***v* − **n**ˆ × ∇*sVn*. (C.43) A special case is ∇*s* × **n**ˆ = 0. Moreover, ∇*s* × ∇*s*φ can be shown to be a vector in the tangent plane, not necessarily zero; this is a significant deviation from ∇×∇φ = 0 in

$$\delta \mathbf{r}(\boldsymbol{\mu}, \boldsymbol{v}) := \mathbf{r} - \mathbf{r}_0(\boldsymbol{\mu}, \boldsymbol{v}) = \hat{\mathbf{n}}_0(\boldsymbol{\mu}, \boldsymbol{v}) \,\boldsymbol{\eta}(\boldsymbol{\mu}, \boldsymbol{v}),\tag{C.44}$$

*Appendix C* • Differential Geometry of Surfaces 515

$$
\delta \mathbf{H} = \mathbf{r}_{\mathrm{ll}} \times \delta \mathbf{r}_{\mathrm{v}} - \mathbf{r}_{\mathrm{v}} \times \delta \mathbf{r}_{\mathrm{ll}} = (\mathbf{r}_{\mathrm{0d}} \times \hat{\mathbf{n}}_{\mathrm{0v}} - \mathbf{r}_{\mathrm{0v}} \times \hat{\mathbf{n}}_{\mathrm{0d}}) \eta + (\mathbf{r}_{\mathrm{il}} \times \hat{\mathbf{n}}_{\mathrm{0}}) \eta_{\mathrm{v}} - (\mathbf{r}_{\mathrm{v}} \times \hat{\mathbf{n}}_{\mathrm{0}}) \eta_{\mathrm{ll}} \tag{C.45}
$$

normal variation of the form δ**r**(*u*, *v*) := **r** − **r**0(*u*, *v*) = **n**ˆ 0(*u*, *v*) η(*u*, *v*), (C.44) where **r**0(*u*, *v*) is a point on some initial surface, **r** [is th](#page-532-1)e position on a neighboring varied surface, **n**ˆ 0(*u*, *v*) is the unit normal on the original surface and the infinitesimal quantity

$$
\delta \mathbf{H} = \mathbf{H}_0 \,\mathrm{K}_0 \,\eta - H_0 \nabla_\mathcal{S} \eta. \tag{C.46}
$$

δ**H** = **r***u* × δ**r***v* − **r***v* × δ**r***u* = (**r**0*u* × **n**ˆ 0*v* − **r**0*v* × **n**ˆ 0*u*)η + (**r***u* × **n**ˆ 0)η*v* − (**r***v* × **n**ˆ 0)η*u* (C.45) to first order in η. The coefficient of η can be calculated by using Eq. (C.24) and carrying out

<span id="page-535-1"></span>δ**H** = **H**0 *K*0 η − *H*0∇*s*η. (C.46)

$$
\delta \hat{\mathbf{n}} = -\nabla_{\theta} \eta. \tag{C.47}
$$

### Since d**n**ˆ is perpendicular to **n**ˆ, we see from Eq. (C.23) that the first term in δ**H** makes no contribution to δ**n**ˆ but the second term contributes to give the important result

be written in the form

 *u*,*v*

δ**n**ˆ = −∇*s*η. (C.47) C.2.2 Integral Theorems The surface divergence theorem is similar to the Gauss divergence theorem except it applies to a surface whose curvature must be accounted for. It applies to a curved surface *A* having local unit normal **n**ˆ surrounded by a closed skew curve *C* with vector line element

<span id="page-535-2"></span>
$$
\int_{A} \nabla_{\sf s} \cdot \mathbf{V} \, \mathrm{d}A = \oint_{C} \mathbf{V}_{I} \cdot \hat{\mathbf{t}} \, \mathrm{d}\ell + \int_{A} V^{n} \mathcal{K} \, \mathrm{d}A,\tag{\text{C.48}}
$$

points in the direction d × **n**ˆ. The theorem states that *A* ∇*s* · **V**d*A* = **V***t* · **t**ˆ d + *VnK* d*A*, (C.48)

$$
\int_{A} \nabla_{\mathbf{J}} \cdot \mathbf{V} \, \mathbf{d}A = \oint_{C} \hat{\mathbf{n}} \cdot \mathbf{V}_{l} \times \mathbf{d}\ell + \int_{A} V^{\eta} \mathcal{K} \, \text{d}A. \tag{C.49}
$$

<span id="page-535-0"></span> *A* ∇*s* · **V**d*A* = *C* **n**ˆ · **V***t* × d + *A VnK* d*A*. (C.49)

$$\int_{A} \nabla_{\mathbf{J}} \cdot \mathbf{V}_{l} \, \mathrm{d}A = \int_{\mathrm{u},v} (\nabla_{\mathbf{J}} \cdot \mathbf{V}_{l}) H \, \mathrm{d}u \, \mathrm{d}v = \int_{\mathrm{u},v} \left[ \frac{\partial (HV^{u})}{\partial \mathbf{u}} + \frac{\partial (HV^{v})}{\partial v} \right] \mathrm{d}u \, \mathrm{d}v,\tag{C.50}$$
 
$$\text{where each coordinate is internal, } \operatorname{atan2}\left(\frac{\partial \mathbf{J}}{\partial \mathbf{u}}\right) = \int_{\mathrm{u},v} \mathrm{d}v \, \mathrm{d}v,\tag{C.50}$$

*A* ∇*s* · **V***t* d*A* = *u*,*v* (∇*s* · **V***t*)*H* d*u* d*v* = *u*,*v* ∂*u* ∂*v* d*u* d*v*, (C.50)

*u*,*v*

$$\int_{\mathfrak{u},v} \left[ \frac{\partial (HV^u)}{\partial \boldsymbol{u}} + \frac{\partial (HV^v)}{\partial \boldsymbol{v}} \right] \, \mathrm{d}\boldsymbol{u} \, \mathrm{d}\boldsymbol{v} = \oint_{\mathfrak{u},v} HV^{\mathrm{ul}} \, \mathrm{d}\boldsymbol{v} - \oint_{\mathfrak{u},v} HV^{v} \, \mathrm{d}\boldsymbol{u},\tag{\text{C.51}}$$

*u*,*v*

$$\begin{split} \mathbf{V}_{l} \cdot \mathbf{d}\boldsymbol{\ell} \times \hat{\mathbf{n}} &= (V^{\mu} \mathbf{r}_{l} + V^{v} \mathbf{r}_{v}) \cdot (\mathbf{r}_{\mu} \, \mathrm{d}u + \mathbf{r}_{v} \, \mathrm{d}v) \times \hat{\mathbf{n}} \\ &= (V^{\mu} \mathbf{r}_{l} + V^{v} \mathbf{r}_{v}) \cdot H(-\mathbf{r}_{v}^{\dagger} \, \mathrm{d}u + \mathbf{r}_{u}^{\dagger} \, \mathrm{d}v) = HV^{\mu} \, \mathrm{d}v - HV^{v} \, \mathrm{d}u,\end{split} \tag{C.52}$$

where the minus sign on the second term on the right arises because of a choice of positive circulation according to the right-hand rule. The integrand in the line integral in Eq. (C.49)

can be written

$$\int_{A} (\nabla_{\sf s} \times \mathbf{V}) \cdot \mathbf{dA} = \oint_{C} \mathbf{V} \cdot \mathbf{d}\mathbf{\ell},\tag{C.53}$$

<span id="page-536-0"></span>the same as Eq. (C.51). Therefore, the tangential part of **V** contributes the line integral in Eq. (C.48) or Eq. [(C.49](#page-529-1)) and the normal component *Vn* generates the term containing the

curvature *K*. In a flat two-dimensional space, one would have only the line integral.

### There is also a surface curl (Stokes) theorem, specifically (∇*s* × **V**) · d**A** = **V** · d, (C.53)

*A C* which is similar to the Stokes theorem for the three-dimensional curl.

*ξ* = ∇*H*[*H*γ (**H**/*H*)] = γ **n**ˆ + *H*∇*H* γ . (C.54)

$$\boldsymbol{\xi} = \nabla_H [H\boldsymbol{\gamma}(\mathbf{H}/H)] = \boldsymbol{\gamma}\hat{\mathbf{n}} + H\nabla_H \boldsymbol{\gamma}.\tag{C.54}$$

C.3 ξ Vector for General Surfaces

*u* · *H*∇*H* γ = (**r***v* × **n**ˆ) · ∇*H* γ ;

$$
\dot{\xi} = \xi^{\mu} \mathbf{r}_{\mu} + \xi^{\upsilon} \mathbf{r}_{\upsilon} + \xi^{\upsilon} \dot{\mathbf{n}},\tag{C.55}
$$

where

consideration, to obtain

$$\begin{aligned} \xi^u &= \mathbf{r}_u^\dagger \cdot H \nabla_H \boldsymbol{\gamma} = (\mathbf{r}_v \times \hat{\mathbf{n}}) \cdot \nabla_H \boldsymbol{\gamma};\\ \xi^v &= \mathbf{r}_v^\dagger \cdot H \nabla_H \boldsymbol{\gamma} = (\hat{\mathbf{n}} \times \mathbf{r}_u) \cdot \nabla_H \boldsymbol{\gamma};\\ \xi^n &= \boldsymbol{\gamma}. \end{aligned} \tag{C.56}$$

ξ*u* = **r**† ξ *v* = **r**†

$$
\gamma = \gamma^*(\alpha, \beta),
\tag{C.57}
$$

<span id="page-536-1"></span>, (C.58)

To calculate ∇*H* γ , we write γ = γ ∗(α, β), (C.57)

> ˆ **j** − β**n**ˆ

$$\boldsymbol{\xi}_{I} = H \boldsymbol{\nabla}_{H} \boldsymbol{\chi} = \frac{\partial \boldsymbol{\gamma}^{*}}{\partial \boldsymbol{\alpha}} \left( \hat{\mathbf{i}} - a \hat{\mathbf{n}} \right) + \frac{\partial \boldsymbol{\gamma}^{*}}{\partial \boldsymbol{\beta}} \left( \hat{\mathbf{j}} - \beta \hat{\mathbf{n}} \right), \tag{C.58}$$

*ξt* = *H*∇*H* γ = ∂γ ∗ ∂α ˆ **i** − α**n**ˆ + ∂γ ∗ ∂β

$$\begin{split} \xi^{\mu} &= \frac{\partial \boldsymbol{\lambda}^{*}}{\partial \boldsymbol{\alpha}} \left( \mathbf{r}_{u}^{\dagger} \cdot \hat{\mathbf{i}} \right) + \frac{\partial \boldsymbol{\lambda}^{*}}{\partial \beta} \left( \mathbf{r}_{u}^{\dagger} \cdot \hat{\mathbf{j}} \right); \\ \xi^{v} &= \frac{\partial \boldsymbol{\lambda}^{*}}{\partial \boldsymbol{\alpha}} \left( \mathbf{r}_{v}^{\dagger} \cdot \hat{\mathbf{i}} \right) + \frac{\partial \boldsymbol{\lambda}^{*}}{\partial \beta} \left( \mathbf{r}_{v}^{\dagger} \cdot \hat{\mathbf{j}} \right). \end{split} \tag{C.59}$$

<span id="page-537-0"></span>
$$\mathbf{x} = \boldsymbol{\mu}; \quad \mathbf{y} = v; \quad \mathbf{z} = \boldsymbol{w}(\boldsymbol{\mu}, v). \tag{C.60}$$

<span id="page-537-3"></span>
$$\mathbf{r}_{\mathsf{u}} = \hat{\mathbf{i}} + p\hat{\mathbf{k}}; \quad \mathbf{r}_{\upsilon} = \hat{\mathbf{j}} + q\hat{\mathbf{k}}; \quad \mathbf{H} = -p\hat{\mathbf{i}} - q\hat{\mathbf{j}} + \hat{\mathbf{k}} \tag{C.61}$$

To proceed further, we adopt a specific parameterization of the surface:

**r**†

the compact result

<span id="page-537-1"></span>*u* = [(1 + *q*2)ˆ

$$H = \sqrt{1 + p^2 + q^2}; \quad \alpha = -p/H; \quad \beta = -q/H. \tag{C.62}$$

Then with *p* := *wu* and *q* := *wv* w[e hav](#page-536-1)e

$$\mathbf{r}_{\mu}^{\dagger} = \mathbf{l}(1+q^2)\hat{\mathbf{i}} - pq\hat{\mathbf{j}} + p\hat{\mathbf{k}}\mathbf{j}/H^2; \quad \mathbf{r}_{v}^{\dagger} = \mathbf{l} - pq\hat{\mathbf{i}} + (1+p^2)\hat{\mathbf{j}} + q\hat{\mathbf{k}}\mathbf{j}/H^2. \tag{C.63}$$

so that *H* = 

$$
\xi^u = \frac{(1+q^2)}{H^2} \frac{\partial \gamma^*}{\partial \alpha} - \frac{pq}{H^2} \frac{\partial \gamma^*}{\partial \beta} = -H \frac{\partial \gamma(p,q)}{\partial p};
$$

$$
\xi^v = -\frac{pq}{H^2} \frac{\partial \gamma^*}{\partial \alpha} + \frac{(1+q^2)}{H^2} \frac{\partial \gamma^*}{\partial \beta} = -H \frac{\partial \gamma(p,q)}{\partial q}.\tag{C.64}
$$

ξ*u* = (1 + *q*2) *H*2 ∂γ ∗ ∂α − *pq H*2 ∂γ ∗ [∂β](#page-531-0) = −*H* ∂γ(*p*, *q*) ∂*p* ; ξ *v* = − *pq H*2 ∂γ ∗ ∂α + (1 + *q*2) *H*2 ∂γ ∗ ∂β = −*H* ∂γ(*p*, *q*) ∂*q* . (C.64)

$$\nabla_{\mathbf{y}} \cdot \mathbf{f} = -\frac{1}{H} \left[ \frac{\partial}{\partial \mathbf{x}} \left( H^2 \frac{\partial \mathbf{y}}{\partial p} \right) + \frac{\partial}{\partial \mathbf{y}} \left( H^2 \frac{\partial \mathbf{y}}{\partial q} \right) \right] + \mathbf{y} \,\%. \tag{C.65}$$

*p* = ∂*z*/∂*x* and *q* = ∂*z*/∂*y*, resulting in ∇*s* · *ξ* = − 1 ∂ *H*2 ∂γ + ∂ *H*2 ∂γ + γ *K*. (C.65)

$$
\mathbb{K} = \frac{\mathbf{r}_{\mathcal{U}}^{\dagger} \cdot \mathbf{H}_{\mathcal{U}} + \mathbf{r}_{v}^{\dagger} \cdot \mathbf{H}_{v}}{H}.\tag{C.66}
$$

In our canonical \"Cartesian\" matrix\"

**H***u*/*H* − **H***Hu*/*H*2 and **H** is perpendicular to **r** †

<span id="page-537-2"></span>*H*

∂*x*

$$\mathcal{K} = -\frac{(1+p)^2 z_{\text{xx}} - 2pqz_{\text{xy}} + (1+q)^2 z_{\text{yy}}}{H^3}.\tag{C.67}$$

*K* = − (1 + *p*)2*zxx* − 2*pqzxy* + (1 + *q*)2*zyy*

∂*x*

$$
\mathcal{K} = -\frac{\partial}{\partial x} \frac{\partial H}{\partial p} - \frac{\partial}{\partial y} \frac{\partial H}{\partial q} \,. \tag{C.68}
$$

*K* = − ∂ ∂*x* ∂*H* ∂*p* − ∂ ∂*y* ∂*H* ∂*q* . (C.68) Equation (C.68) can be combined with Eq. (C.65) to produce, after considerable algebra,

∂*y*

$$\nabla_{\mathcal{S}} \cdot \boldsymbol{\xi} = -\frac{\partial}{\partial \mathbf{x}} \frac{\partial \Phi}{\partial p} - \frac{\partial}{\partial y} \frac{\partial \Phi}{\partial q},\tag{C.69}$$

<span id="page-538-0"></span>
$$\nabla_{\mathbf{s}} \cdot \boldsymbol{\xi} = - (\Phi_{pp} \mathbf{z}_{\mathbf{x}\mathbf{t}} + 2\Phi_{pq} \mathbf{z}_{\mathbf{y}\mathbf{y}} + \Phi_{qq} \mathbf{z}_{\mathbf{y}\mathbf{y}}),\tag{\text{C.70}}$$

518 THERMAL PHYSICS

### where := *H*γ . This resul[t can](#page-538-0) be obtained more easily by means of a variational calculation (see Section C.4.1) committed to our choice of a Monge representation from

the outset. Note particularly the form ∇*s* · *ξ* = −(*ppzxx* + 2*pqzxy* + *qqzyy*), (C.70)

$$\begin{split} \Phi_{pp} &= \frac{(1+p^2)\chi}{(1+p^2+q^2)^{3/2}} + \frac{2p\chi\rho}{(1+p^2+q^2)^{1/2}} + (1+p^2+q^2)^{1/2}\chi\rho; \\ \Phi_{pq} &= -\frac{pq\chi}{(1+p^2+q^2)^{3/2}} + \frac{q\chi\rho+p\chi_q}{(1+p^2+q^2)^{1/2}} + (1+p^2+q^2)^{1/2}\chi\rho; \\ \Phi_{qq} &= \frac{(1+q^2)\chi}{(1+p^2+q^2)^{3/2}} + \frac{2q\chi\rho}{(1+p^2+q^2)^{1/2}} + (1+p^2+q^2)^{1/2}\chi\rho. \end{split} \tag{C.71}$$

*pp* = (1 + *p*2)γ (1 + *p*2 + *q*2)3/2 + (1 + *p*2 + *q*2)1/2 + (1 + *[p](#page-538-0)*2 + *q*2) 1/2γ*pp*; *pq* = − *pq*γ (1 + *p*2 + *q*2)3/2 + *q*γ*p* + *p*γ*q* (1 + *p*2 + *q*2)1/2 + (1 + *p*2 + *q*2) 1/2γ*pq*;

$$\mathcal{K} = -\frac{(1+q^2)z_{\text{xx}} - 2pqz_{\text{xy}} + (1+p^2)z_{\text{yy}}}{(1+p^2+q^2)^{3/2}}\tag{C.72}$$

<span id="page-538-1"></span>For the case in which γ is a constant, Eq. (C.70) must give just γ *K*, where *K* is the mean curvature, so we obtain the well known formula *K* = −(1 [+](#page-538-1) *q*2)*zxx* − 2*pqzxy* + (1 + *p*2)*zyy* (1 + *p*2 + *q*2)3/2 (C.72) for the sum of the principal curvatures. Simplification of Eq. (C.70) for anisotropic γ can be obtained by choosing very special Cartesian axes at each point of the equilibrium shape.

$$\nabla_{\mathbf{t}} \cdot \mathbf{\dot{\xi}} = -(\mathbf{y} + \chi_{\mathbf{pp}}) \mathbf{z}_{\mathbf{xx}} - 2\chi_{\mathbf{pq}} \mathbf{z}_{\mathbf{xy}} - (\mathbf{y} + \chi_{\mathbf{qq}}) \mathbf{z}_{\mathbf{yy}}, \quad \text{at a point } \mathbf{x}_0, \mathbf{y}_0, \text{ for } \mathbf{z} \text{ along } \hat{\mathbf{n}}_0. \tag{C.73}$$

locally tangent to the shape. In that case, *p* = *q* = 0 when evaluated at the chosen point, which gives ∇*s* · *ξ* = −(γ + γ*pp*)*zxx* − 2γ*pqzxy* − (γ + γ*qq*)*zyy*, at a point *x*0, *y*0, for *z* along **n**ˆ 0. (C.73)

$$\nabla_{\mathbf{s}} \cdot \xi = \frac{\gamma + \gamma \eta \rho}{R_1} + \frac{\gamma + \gamma \eta \rho}{R_2}, \quad \text{at a point } \mathbf{x}_0, y_0, \text{ for } z \text{ along } \hat{\mathbf{n}}_0 \text{, principal axes,} \tag{\text{C.74}}$$

∇*s* · *ξ* = γ + γ*pp* + γ + γ*qq* , at a point *x*0, *y*0, for *z* along **n**ˆ 0, principal axes, (C.74)

*R*1 *R*2 where 1/*R*1 = −∂2*z*/∂*x*2 = *K*1 and 1/*R*2 = −∂2*z*/∂*y*2 = *K*2 are principal curvatures. In the vicinity of the surface point *x*0, *y*0 under consideration, the angle θ made by **n**ˆ with **n**ˆ 0 = **k**ˆ is given by cos θ = **n**ˆ · **k**ˆ = (1 + *p*2 + *q*2)−1/2 so tan2 θ = *p*2 + *q*2. For principal planes, tan θ1 = ±*p* and tanθ2 = ±*q*. With this notation, Eq. (C.74) can be written in the

$$\nabla_{\mathbf{s}} \cdot \xi = \frac{\chi + \chi_{\theta_1 \theta_1}}{R_1} + \frac{\chi + \chi_{\theta_2 \theta_2}}{R_2}, \quad \text{at a point } \mathbf{x}_0, \mathbf{y}_0, \text{ principal planes}, \tag{\text{C.75}}$$

*R*1 *R*2 where the derivatives are to be evaluated at θ1 = 0 and θ2 = 0.

Herring form

<span id="page-539-1"></span>ω*F*

<span id="page-539-0"></span>
$$
\omega_v^F - \omega_v^s = \frac{\chi + \chi_{\theta_1\theta_1}}{R_1} + \frac{\chi + \chi_{\theta_2\theta_2}}{R_2},\tag{C.76}
$$

*Appendix C* • Differential Geometry of Surfaces 519

$$
\mu = \mu_{\infty} + \Omega_0 \left[ \frac{\gamma + \gamma_{\theta 1} \rho_1}{R_1} + \frac{\gamma + \gamma_{\theta 2} \rho_2}{R_2} \right]. \tag{C.77}
$$

which is a somewhat more general version of [Herri](#page-538-1)ng's result. The original Herring formula [38, 41] pertained to the case of a solid-vapor interface for a single component for which Eq. (14.102) of the text becomes μ = μ∞ + 0 γ + γθ1θ1 *R*[1](#page-539-1) + γ + γθ2θ2 *R*2 . (C.77)

it requires one to find the principal axes of curvature beforehand. In particular, it is not

$$
\alpha_v^F - \alpha_v^g = -(\chi + \chi_{pp})\mathbf{z}_{\mathbf{x}\mathbf{x}} - 2\chi_{pq}\mathbf{z}_{\mathbf{x}\mathbf{y}} - (\chi + \chi_{qq})\mathbf{z}_{\mathbf{y}\mathbf{y}}.\tag{\text{C.78}}
$$

a differential equation for the equilibrium shape, since it applies only at a single point. A more useful expression that still applies only at a point but does not require finding the principal axes can be obtained by using Eq. (C.73), namely ω*F v* − ω*s v* = −(γ + γ*pp*)*zxx* − 2γ*pqzxy* − (γ + γ*qq*)*zyy*. (C.78) An elegant geometrical interpretation of the terms γ + γθ1θ1 and γ + γθ2θ2 was given by Johnson [95] for the case in which Eq. (C.77) is applied to give a *local* equilibrium condition at the surface of a body that is *not* the equilibrium shape. In that case, *R*1 and *R*2 are principal radii of the non-equilibrium body at the point under consideration. Johnson shows that γ + γθ1θ1 and γ + γθ2θ2 are proportional to the radii of curvature ρ1 and ρ2 of the equilibrium shape *projected* onto principal planes of the non-equilibrium body. Since

### the convex part of the *ξ* plot is similar to the equilibrium shape, it turns out that γ + γθ1θ1 and γ + γθ2θ2 are equal to the radii of curvature of the *ξ* plot, calculated in the respective

energy

where = γ *H* = γ (*p*, *q*)

principal planes of the non-equilibrium body. C.4.1 Variational Formulation If we adopt a Monge representation *z* = *z*(*x*, *y*) of the interface, one can formulate the

$$
\int_{A_{\rm{xy}}} \Phi \,\mathrm{d}x \,\mathrm{d}y,\tag{C.79}
$$

 *Axy* d*x* d*y*, (C.79)

$$\int_{A_{\rm{xy}}} z(\mathbf{x}, \mathbf{y}) \, \mathrm{d}\mathbf{x} \, \mathrm{d}\mathbf{y}.\tag{C.80}$$

*Axy z*(*x*, *y*) d*x* d*y*. (C.80) Here, is the free energy per unit area of the *x*, *y* plane and the integration is over *Axy*, a fixed projected area in the *x*, *y* plane. By means of a Lagrange multiplier 2λ, we obtain the variational problem

520 THERMAL PHYSICS

 *Axy*  ∂ ∂*x* ∂ ∂*p* δ*z* + ∂ ∂*y*

$$
\delta \int_{A_{\rm{dy}}} [\Phi - 2\lambda z] \,\mathrm{d}x \,\mathrm{d}y = 0. \tag{C.81}
$$

$$\int_{A_{\rm xy}} \left[ \frac{\partial \Phi}{\partial p} \delta p + \frac{\partial \Phi}{\partial q} \delta q - 2\lambda \delta z \right] \, \text{dx} \, \text{dy} = 0. \tag{C.82}$$

$$\int_{A_{\rm{V}}} \left\{ \frac{\partial}{\partial \mathbf{x}} \left( \frac{\partial \Phi}{\partial p} \delta \mathbf{z} \right) + \frac{\partial}{\partial \mathbf{y}} \left( \frac{\partial \Phi}{\partial q} \delta \mathbf{z} \right) - \left[ \frac{\partial}{\partial \mathbf{x}} \left( \frac{\partial \Phi}{\partial p} \right) + \frac{\partial}{\partial \mathbf{y}} \left( \frac{\partial \Phi}{\partial q} \right) + 2\lambda \right] \delta \mathbf{z} \right\} d\mathbf{x} d\mathbf{y} = \mathbf{0}. \tag{C.83}$$

 *Axy* ∂ ∂*p* δ*p* + ∂ ∂*q* δ*q* − 2λδ*z* d*x* d*y* = 0. (C.82) Then with δ*p* = [δ∂](#page-537-2)*z*/∂*x* = ∂(δ*z*)/∂*x* and δ*q* = δ∂*z*/∂*y* = ∂(δ*z*)/∂*y*, we obtain

$$-\frac{\partial}{\partial \mathbf{x}} \left( \frac{\partial \Phi}{\partial p} \right) - \frac{\partial}{\partial \mathbf{y}} \left( \frac{\partial \Phi}{\partial q} \right) = 2\lambda. \tag{C.84}$$

The first two terms can be integrated to the boundary where the result vanishes, either because δ*z* vanishes or because the boundary is closed. Since δ*z* is arbitrary within *Axy*, its

<span id="page-540-0"></span>∂ ∂*q* δ*z* −

coefficient in the integral must vanish, resulting in − ∂ ∂ − ∂ ∂ 

$$
\left(\frac{\partial(\partial\Phi/\partial p)}{\partial x}\right)_{\mathbf{y}} = \frac{\partial\left(\partial\Phi/\partial p,\mathbf{y}\right)}{\partial\left(\mathbf{x},\mathbf{y}\right)}; \quad \left(\frac{\partial(\partial\Phi/\partial q)}{\partial\mathbf{y}}\right)_{\mathbf{x}} = \frac{\partial\left(\mathbf{x},\partial\Phi/\partial q\right)}{\partial\left(\mathbf{x},\mathbf{y}\right)}.\tag{\text{C.85}}$$

by Landau and Lifshitz [7, p. 460]. We replace these derivatives by Jacobians as follows:

$$-\frac{\partial\left(\partial\Phi/\partial p,\mathbf{y}\right)}{\partial\left(p,q\right)} - \frac{\partial\left(\mathbf{x},\partial\Phi/\partial q\right)}{\partial\left(p,q\right)} = 2\lambda \frac{\partial\left(\mathbf{x},\mathbf{y}\right)}{\partial\left(p,q\right)}.\tag{C.86}$$

We multiply the resulting expression by the [Jacob](#page-540-1)ian ∂(*x*, *y*)/∂(*p*, *q*) to obtain

∂(∂/∂*p*) ∂*x*

<span id="page-540-1"></span> *y*

<span id="page-540-2"></span>− ∂ 

<span id="page-540-3"></span>∂ 

$$
\phi(p,q) = z - xp - yq \tag{C.87}
$$

Then we introduce the fun[ction](#page-540-2)

$$\mathbf{d}\phi = -\mathbf{x}\,\mathrm{d}p - \mathbf{y}\,\mathrm{d}q\tag{C.88}$$

. (C.89)

whose differential

∂/∂*p*, *y* 

*p*, *q*

$$\frac{\partial \left(\partial \Phi/\partial p, \partial \phi/\partial q\right)}{\partial \left(p, q\right)} + \frac{\partial \left(\partial \phi/\partial p, \partial \Phi/\partial q\right)}{\partial \left(p, q\right)} = 2\lambda \frac{\partial \left(\partial \phi/\partial p, \partial \phi/\partial q\right)}{\partial \left(p, q\right)}.\tag{C.89}$$

*p*, *q*

∂ 

∂ ∂/∂*p*, ∂φ/∂*q* ∂ *p*, *q* + ∂ ∂φ/∂*p*, ∂/∂*q* ∂ *p*, *q* = 2λ

$$
\Phi(\mathbf{p}, \mathbf{q})/\lambda = \mathbf{z} - \mathbf{x}\mathbf{p} - \mathbf{y}\mathbf{q} = \mathbf{z} - \mathbf{x}\frac{\partial \mathbf{z}}{\partial \mathbf{x}} - \mathbf{y}\frac{\partial \mathbf{z}}{\partial \mathbf{y}},\tag{C.90}
$$

(*p*, *q*)/λ = *z* − *xp* − *yq* = *z* − *x* ∂*x* − *y* ∂*y* , (C.90)

$$\mathbf{d}(\Phi/\lambda) = -\mathbf{x}\,\mathbf{d}\boldsymbol{p} - \mathbf{y}\,\mathbf{d}\boldsymbol{q},\tag{\text{C.91}}$$

so

$$\left(\frac{\partial(\Phi/\lambda)}{\partial p}\right)_q = -\text{x}; \quad \left(\frac{\partial(\Phi/\lambda)}{\partial q}\right)_p = -\text{y}.\tag{C.92}$$

Therefore, the inverse of Eq. [(C.90)](#page-540-3) is

$$z = (\Phi/\lambda) + px + yq = (\Phi/\lambda) - p\frac{\partial(\Phi/\lambda)}{\partial p} - q\frac{\partial(\Phi/\lambda)}{\partial q} \tag{C.93}$$

which also has the form of a Legendre transform. The transformation *X* = λ*x*, *Y* = λ*y* and *Z* = λ*z* gives the forms of these equations developed in Section 14.7.

The form of Eq. [(C.90)](#page-540-3) can be used to obtain the Wulff construction for the equilibrium shape. It can be rewritten in the form

<span id="page-541-0"></span>
$$
\gamma(p,q) = \lambda \frac{z - \mathbf{x}p - \mathbf{y}q}{\sqrt{1 + p^2 + q^2}},\tag{C.94}
$$

which is a first order nonlinear partial differential equation for *z*(*x*, *y*). The components of the unit surface normal are

$$n_{\mathcal{X}} = \frac{-p}{\sqrt{1+p^2+q^2}}; \quad n_{\mathcal{Y}} = \frac{-q}{\sqrt{1+p^2+q^2}}; \quad n_{\mathcal{Z}} = \frac{1}{\sqrt{1+p^2+q^2}},\tag{C.95}$$

in agreement with Eq. [(C.62)](#page-537-3). Regarding *p* and *q* to be parameters, the right-hand side of Eq. [(C.94)](#page-541-0) represents a family of tangent planes to the equilibrium shape and the envelope of such planes is the integral of that nonlinear partial differential equation for *z*(*x*, *y*). This is the basis of the Wulff construction. This becomes more obvious if we write Eq. [(C.94)](#page-541-0) in the form

<span id="page-541-1"></span>
$$
\gamma(\hat{\mathbf{n}}) = \lambda \,\mathbf{r} \cdot \hat{\mathbf{n}}\tag{C.96}
$$

from which it is clear that γ is proportional to the so-called support function for the equilibrium shape. In terms of the scaled coordinates **R** = λ**r**, it is the support function for the shape. In fact we know from Section 14.7 that *ξ* = λ**r** so we can also write

<span id="page-541-2"></span>
$$
\boldsymbol{\gamma} \cdot \mathbf{\hat{n}} = \boldsymbol{\xi} \cdot \mathbf{\hat{n}},\tag{C.97}
$$

which we know to be one of the properties of the *ξ* vector. There is a subtle but important difference between Eqs. [(C.96)](#page-541-1) and [(C.97)](#page-541-2) that is worth attention. If the equilibrium shape has missing orientations, Eq. [(C.96)](#page-541-1) only gives the true γ (**n**ˆ) for those orientations that actually appear on the shape; for orientations that are missing it gives another function that we called (**n**ˆ) in Section 14.4. On the other hand, if *ξ* were known for all orientations, including the ears that must be truncated to give the equilibrium shape, one would obtain γ (**n**ˆ) for all orientations from Eq. [(C.97)](#page-541-2).

This page intentionally left blank

D

# Equilibrium of Two-State Systems

We use the microcanonical ensemble to make a detailed study of equilibrium of a composite system consisting of two subsystems, each having different numbers of spin 1/2 particles. This will serve as an explicit demonstration of how the composite system achieves its most probable state, as well as the approximations that lead to additivity of entropy. We follow closely a treatment of two identical spin systems by Kittel and Kroemer [6, p. 37] but allow each system to have a different number of spins and evaluate explicitly the overlap integral to determine the entropy of the combined system.

First we consider a system made up of *N* spins, each fixed in a solid and having two non-degenerate energy levels. We examine a configuration of the system in which the lower state with energy −*m*0*B* (spin up) is occupied by *n*1 spins and the upper state with energy *m*0*B* (spin down) is occupied by *n*2 = *N* − *n*1 spins. Here, *m*0 > 0 is the magnetic moment of a spin and *B* is the strength of the magnetic field. Following Kittel and Kroemer, we introduce the spin excess, 2*s*, where

$$
\Delta \mathbf{s} = \mathbf{:}
\ n_1 - n_2,\tag{\text{D.1}}
$$

which results in

$$n_1 = \frac{\mathcal{N}}{2} + \text{s}; \quad n_2 = \frac{\mathcal{N}}{2} - \text{s.} \tag{D.2}$$

Here, *s* can be integral ... , −3, −2, −1, 0, 1, 2, 3, ... or half integral ... , −5 2 , −3 2 , −1 2 , 1 2 , 3 2 , 5 2 , ..., depending on whether *N* is even or odd. In any case, 2*s* will represent the exces[s1](#page-543-0) number of spins in the ground state, and 0 ≤ *s* ≤ *N* /2. The energy of this state is

$$E = n_1(-m_0B) + n_2(m_0B) = -2\text{sm}_0B.\tag{D.3}$$

We assume that these spins are identical but distinguishable by virtue of their fixed positions in a solid. Then the number of microstates of the system that corresponds to the given configuration is

<span id="page-543-1"></span>
$$\frac{\mathcal{N}!}{n_1! n_2!} = \frac{\mathcal{N}!}{n_1! (\mathcal{N} - n_1)!} = \frac{\mathcal{N}!}{(\frac{\mathcal{N}}{2} + s)! (\frac{\mathcal{N}}{2} - s)!} =: \tilde{\mathbf{g}}(\mathcal{N}; \mathbf{s}), \tag{\text{D.4}}$$

where *g*˜(*N* ;*s*) is a multiplicity function that plays the same role as the multiplicity function *g*(*N* ,*M*) in Section 16.2 except in terms of a different variable, the correspondence being *s* = *N* /2 − *M*. Thus, the entropy

<span id="page-543-0"></span>1Kittel and Kroemer take *N* to be even, so *s* can be considered to be the number of spin flips with respect to equally populated states. Negative values of *s* correspond to states of the whole system in which the upper spin state has a higher population than the lower one, and hence formally to negative temperatures, which we do not allow. At infinite temperature, the upper and lower spin states are equally populated and *s* = 0.

$$S = k_{\rm B} \ln \Omega(N, E) = k_{\rm B} \ln \tilde{\mathbf{g}}(N; \mathbf{s}), \tag{D.5}$$

where *k*B is Boltzmann's constant.

We proceed to illustrate explicitly what happens to the entropy when two spin systems, one of size *N*1 and the other of size *N*2, combine to form a system of size *N* = *N*1 + *N*2. To do this, we note that the coefficients of *tn* in the binomial expansion

$$(1+t)^{\mathcal{N}} = \sum_{n=0}^{\mathcal{N}} \frac{\mathcal{N}!}{n!(\mathcal{N}-n)!} t^n \tag{D.6}$$

are the same as those that enter into Eq. [(D.4)](#page-543-1). In view of the relation

$$(1+t)^{N_1}(1+t)^{N_2} = (1+t)^{N_1},\tag{D.7}$$

we seek to relate the multiplicity functions for the system with *N* spins to the multiplicity functions of the systems having *N*1 and *N*2 spins by expanding each binomial and equating the coefficients of like powers of *t*. Thus

$$\sum_{r_1=0}^{\mathcal{N}_1} \frac{\mathcal{N}_1!}{r_1!(\mathcal{N}_1 - r_1)!} t^{r_1} \sum_{r_2=0}^{\mathcal{N}_2} \frac{\mathcal{N}_2!}{r_2!(\mathcal{N}_2 - r_2)!} t^{r_2} = \sum_{r=0}^{\mathcal{N}} \frac{\mathcal{N}!}{r!(\mathcal{N} - r)!} t^r. \tag{D.8}$$

Equating the coefficient of *tr* results in

<span id="page-544-1"></span>
$$\sum_{r_1} \frac{\mathcal{N}_1!}{r_1!(\mathcal{N}_1 - r_1)!} \frac{\mathcal{N}_2!}{r_2!(\mathcal{N}_2 - r_2)!} = \frac{\mathcal{N}!}{r!(\mathcal{N} - r)!},\tag{D.9}$$

where the sum over *r*1 is restricted b[y2](#page-544-0) the set of constraints *r*1 + *r*2 = *r*, 0 ≤ *r*1 ≤ *N*1 and 0 ≤ *r*2 ≤ *N*2, which also guarantees 0 ≤ *r* ≤ *N* . In terms of the multiplicity functions *g*˜, Eq. [(D.9)](#page-544-1) can be written

<span id="page-544-2"></span>
$$\sum_{\mathbf{s}_1} \tilde{\mathbf{g}}(\mathcal{N}_1; \mathbf{s}_1) \tilde{\mathbf{g}}(\mathcal{N}_2; \mathbf{s} - \mathbf{s}_1) = \tilde{\mathbf{g}}(\mathcal{N}; \mathbf{s}); \quad \mathcal{N} = \mathcal{N}_1 + \mathcal{N}_2,\tag{D.10}$$

where the sum over *s*1 has the additional restrictions 0 ≤ *s*1 ≤ *N*1/2 and 0 ≤ *s*2 = *s* − *s*1 ≤ *N*2/2.

We know that*s* = *s*1+*s*2 because of conservation of energy. We are interested in systems having a huge number of spins, say of order 1022, in which case Eq. [(D.10)](#page-544-2) can be simplified greatly because the sum on the left will be dominated by its largest terms. To see this, one can use Stirling's approximation[3](#page-544-3) which leads to

<span id="page-544-4"></span>
$$\tilde{\mathbf{g}}(\mathcal{N}; \mathbf{s}) = \tilde{\mathbf{g}}(\mathcal{N}; \mathbf{0}) \, \mathbf{e}^{-2s^2/N},\tag{\text{D.11}}$$

<span id="page-544-0"></span>2An equivalent way of restricting the sum over *r*1 is to require *r*1+*r*2 = *r* and replace the factorials with gamma functions according the relation *n*!(*n* + 1). Then since (*m*) = ±∞ when *m* is zero or a negative integer, one can sum over all non-vanishing terms.

<span id="page-544-3"></span>3We use *N* ! ∼ *N N* e−*N* (2π*N* )1/2 for better accuracy, since we deal here with the factorial rather than its logarithm. To obtain Eq. (D11) one must expand formally in the small variable 2|*s*|/*N* ; however, this Gaussian approximation is accurate to quite large values of *s* as shown by the local DeMovire-Laplace theorem. See Gnedenko [75, p. 94] for details.

<span id="page-545-0"></span>![](_page_545_Figure_1.jpeg)

**FIGURE D–1** Illustration of the high and narrow peak resulting from the product of two Gaussian peaks of equal height as a function of *s*1 for *N*1 = *N*2 = 100 and *s* = 60. Since the peaks are so high we have plotted their logarithms to the base 10, specifically log10 *g*˜(*N*1;*s*1), log10 *g*˜(*N*2;*s* − *s*1), and log10[*g*˜(*N*1;*s*1)*g*˜(*N*2;*s* − *s*1)]. Even for these small numbers, we see that the Gaussian peak due to overlap has a height of about 10120 and a width of about 10 at half height.

where

<span id="page-545-3"></span>
$$
\tilde{\mathbf{g}}(\mathcal{N}; \mathbf{0}) := \sqrt{\frac{2}{\pi \mathcal{N}}} \, 2^{\mathcal{N}} \,. \tag{D.12}
$$

This is often referred to as the **Gaussian approximation** and applies also to *g*˜(*N*1;*s*1) and *g*˜(*N*2;*s*2). For huge *N* , the function *g*˜(*N* ;*s*) is highly peaked near *s*1 = 0 and is a quasicontinuous function of *s*. The same is true for *g*˜(*N*1;*s*1) and *g*˜(*N*2;*s*2) as functions of *s*1 and *s*2. We can therefore approximate the sum in Eq. [(D.10)](#page-544-2) by an integral to obtain

<span id="page-545-1"></span>
$$\int d\mathbf{s} \,\tilde{\mathbf{g}}(\mathcal{N};0)\tilde{\mathbf{g}}(\mathcal{N};0)\mathbf{e}^{-2\mathbf{s}_1^2/\mathcal{N}_1}\mathbf{e}^{-2(s-s_1)^2/\mathcal{N}_2} = \tilde{\mathbf{g}}(\mathcal{N};0)\mathbf{e}^{-2\mathbf{s}^2/\mathcal{N}}.\tag{\text{D.13}}$$

As illustrated in [Figure D–1,](#page-545-0) the integral in Eq. [(D.13)](#page-545-1) is over the region of overlap of two Gaussians, one centered at *s*1 = 0 and the other centered at *s*2 = *s* − *s*1. The product of these overlapping Gaussian peaks forms an even higher and narrower Gaussian peak. For huge numbers of spins typical of a thermodynamic system, the overlap peak is so high and narrow that it dominates the integral in Eq. [(D.13)](#page-545-1).

The overlap peak occurs at the maximum of the product *g*˜(*N*1;*s*1)*g*˜(*N*2;*s*2), with *s*2 = *s* − *s*1. We can find the position of this peak by differentiation of *g*˜(*N*1;*s*1)*g*˜(*N*2;*s*2) with respect to *s*1 or, more simply, by differentiating its logarithm with respect to *s*1 to obtain

<span id="page-545-2"></span>
$$\frac{\partial \ln \tilde{\mathbf{g}}(\mathcal{N}_1; \mathbf{s}_1)}{\partial \mathbf{s}_1} = \frac{\partial \ln \tilde{\mathbf{g}}(\mathcal{N}_2; \mathbf{s}_2)}{\partial \mathbf{s}_2}; \quad \mathbf{s}_2 = \mathbf{s} - \mathbf{s}_1. \tag{D.14}$$

Equation [(D.14)](#page-545-2) determines values *s*∗ 1 and *s*∗ 2 = *s* − *s*∗ 1 that correspond to the overlap peak. Therefore, *s*∗ 1 and *s*∗ 2 correspond to the dominant contributions of the thermodynamic macrostates of the subsystems. The total energy is divided between the two subsystems so that Eq. [(D.14)](#page-545-2) is satisfied, which is equivalent to equalizing their temperatures.

In terms of the explicit representations of *g*˜(*N*1;*s*1) and *g*˜(*N*2;*s*2) (see Eqs. [(D.11)](#page-544-4) and [(D.12)](#page-545-3)), we can write Eq. [(D.14)](#page-545-2) in the form

$$\frac{\partial}{\partial \mathfrak{s}_1} \left[ \ln \tilde{\mathbf{g}}(\mathcal{N}_1; \mathbf{0}) - 2s_1^2 / \mathcal{N}_1 \right] = \frac{\partial}{\partial \mathfrak{s}_2} \left[ \ln \mathbf{g}(\mathcal{N}_2; \mathbf{0}) - 2s_2^2 / \mathcal{N}_2 \right] \tag{D.15}$$

which results in

<span id="page-546-0"></span>
$$\frac{\mathbf{s}_1^*}{\mathcal{N}_1} = \frac{\mathbf{s}_2^*}{\mathcal{N}_2} = \frac{\mathbf{s}}{\mathcal{N}},\tag{\text{D.16}}$$

where the last equality follows because *s*∗ 1 + *s*∗ 2 = *s* and *N*1 + *N*2 = *N* .

We have yet to demonstrate the additivity of entropy when these subsystems are combined. To do this, we return to Eq. [(D.13)](#page-545-1) and introduce the variable δ = *s*1 − *s*∗ 1 such that δ = 0 corresponds to the peak of the product of the Gaussians. After some algebra and the use of Eq. [(D.16)](#page-546-0), the integrand in Eq. [(D.13)](#page-545-1) can be written

<span id="page-546-1"></span>
$$
\tilde{\mathbf{g}}(\mathcal{N}_1; \mathbf{s}_1) \tilde{\mathbf{g}}(\mathcal{N}_2; \mathbf{s} - \mathbf{s}_1) = (\tilde{\mathbf{g}}_1 \tilde{\mathbf{g}}_2) \text{max} \mathbf{e}^{-\delta^2 / \delta_0^2}, \tag{D.17}
$$

where

<span id="page-546-5"></span>
$$\mathbf{g}(\tilde{\mathbf{g}};\tilde{\mathbf{g}}2)_{\text{max}} \coloneqq \tilde{\mathbf{g}}(\mathcal{N}_{\text{1}};\mathbf{s}_{1}^{*}) \tilde{\mathbf{g}}(\mathcal{N}_{\text{1}};\mathbf{s}_{2}^{*}) = \tilde{\mathbf{g}}(\mathcal{N}_{\text{1}};\mathbf{0}) \tilde{\mathbf{g}}(\mathcal{N}_{\text{2}};\mathbf{0}) \mathbf{e}^{-2\mathbf{s}^{2}/\mathcal{N}} \tag{\text{D.18}}$$

and

<span id="page-546-4"></span>
$$
\delta_0 := \sqrt{\frac{\mathcal{N}_1 \mathcal{N}_2}{2\mathcal{N}}}.\tag{D.19}
$$

Therefore Eq. [(D.13)](#page-545-1) becomes approximately

<span id="page-546-2"></span>
$$(\tilde{\mathbf{g}}_1 \tilde{\mathbf{g}}_2)_{\text{max}} \int \mathbf{e}^{-\delta^2 / \delta_0^2} \, \mathbf{d}\delta = \tilde{\mathbf{g}}(\mathcal{N}; \mathbf{s}). \tag{D.20}$$

Since the Gaussian peak represented by Eq. [(D.17)](#page-546-1) is so high and narrow, the range of integration of the integral in Eq. [(D.20)](#page-546-2) can be taken to be −∞ to ∞, in which case it becomes √πδ0. Thus Eq. [(D.20)](#page-546-2) becomes

<span id="page-546-3"></span>
$$(\sqrt{\pi}\delta_0(\tilde{\mathbf{g}}_1\tilde{\mathbf{g}}_2)_{\text{max}} = \tilde{\mathbf{g}}(N; \mathbf{s}).\tag{D.21}$$

From Eq. [(D.21)](#page-546-3), we see with the help of Eqs. [(D.11)](#page-544-4) and [(D.19)](#page-546-4) that (*g*˜1*g*˜2)max is *not* equal to *g*˜(*N* ;*s*) because of the multiplicative factor √πδ0. But if we take the *logarithm* of both sides to relate to the entropy, we see that

<span id="page-546-6"></span>
$$
\ln(\tilde{\mathbf{g}}_1 \tilde{\mathbf{g}}_2)_{\text{max}} + \frac{1}{2} \ln \pi + \frac{1}{2} \ln \left( \frac{\mathcal{N}_1 \mathcal{N}_2}{2\mathcal{N}} \right) = \ln \tilde{\mathbf{g}}(\mathcal{N}; \mathbf{s}).\tag{D.22}
$$

In view of Eqs. [(D.12)](#page-545-3) and [(D.18)](#page-546-5), we see that the first term in Eq. [(D.22)](#page-546-6) is of order *N* , the second is of order 1, and the third is of order ln *N* . The second two terms are negligible compared to the first, so we have

$$
\ln(\tilde{\mathbf{g}}_1 \tilde{\mathbf{g}}_2)_{\text{max}} = \ln \tilde{\mathbf{g}}(N_1; \mathbf{s}_2^*) + \ln \tilde{\mathbf{g}}(N_2; \mathbf{s}_1^*) = \ln \tilde{\mathbf{g}}(N; \mathbf{s}), \tag{D.23}
$$

which demonstrates the additivity of the entropy.

In other words, in the thermodynamic limit of large numbers of spins, each of the spin subsystems can be regarded as being in its most probable state, consistent with a common temperature that governs how they share the total energy of their combined equilibrium state. This is a general property, believed to be true of all thermodynamic systems. Here we have only demonstrated it explicitly in a simple case.

This page intentionally left blank

# E

# Aspects of Canonical Transformations

We present some aspects of canonical transformations that are used in classical mechanics to transform from one set of generalized coordinates *q* = *q*1, *q*2, ... , *qN* and their conjugate momenta *p* = *p*1, *p*2, ... , *pN* to another independent set *Q* = *Q*1, *Q*2, ... , *QN* and *P* = *P*1, *P*2, ... , *PN* according to relations of the form

<span id="page-549-1"></span>
$$q_l = q_l(Q, P, t); \quad p_l = p_l(Q, P, t). \tag{\mathbb{E}.1}$$

In this somewhat compressed notation, we regard *q*, *p*, *Q*, and *P* to be *N*-dimensional vectors which we do not write in bold face in order to avoid cumbersome expressions. For *N* particles each moving in three dimensions, we would have *N* = 3*N* and the entire phase space for the system would have dimension 6*N* , but we retain the more general notation which could be applicable in a two-dimensional world, where *N* = 2*N* , or if certain degrees of freedom are suppressed.

We shall treat the general case in which the Hamiltonian *H*(*q*, *p*,*t*) as well as the transformation equations depend on time, even though our primary interest will be applications to conservative systems for which there is no explicit dependence on time. As is well known, the dynamical equations are given in the original variables by Hamilton's equations

<span id="page-549-0"></span>
$$
\dot{\mathbf{q}}_l = \frac{\partial \mathcal{H}}{\partial p_l}; \quad \dot{\mathbf{p}}_l = -\frac{\partial \mathcal{H}}{\partial q_l}. \tag{E.2}
$$

Here, a dot above a variable denotes its total time derivative, d/d*t*. For a canonical transformation, dynamical equations are given in terms of the new variables by equations of the same form

$$
\dot{Q}_l = \frac{\partial \mathcal{K}}{\partial P_l}; \quad \dot{P}_l = -\frac{\partial \mathcal{K}}{\partial Q_l}, \tag{E.3}
$$

where *K*(*Q*, *P*,*t*) is the new Hamiltonian.

Our treatment of this general case follows closely a treatment by Courant [96, p. 248] but in the modern notation of classical mechanics, as in Goldstein [97, p. 378]. It also includes a demonstration that the necessary and sufficient conditions for a canonical transformation, to be derived below, lead explicitly to Hamilton's equations for the new variables. Courant proceeds to show that canonical transformations belong to the so-called **symplectic group**, from which many properties follow easily[.1](#page-550-0) In particular, it will be shown that the Jacobian

<span id="page-550-5"></span>
$$J = \frac{\partial \left(q, p\right)}{\partial \left(Q, P\right)} \equiv \frac{\partial \left(q_1, q_2, \dots, q_N, p_1, p_2, \dots, p_N\right)}{\partial \left(Q_1, Q_2, \dots, Q_N, P_1, P_2, \dots, P_N\right)} = \pm 1. \tag{\text{E.4}}$$

Since the absolute value of this Jacobian |*J*| = 1, the volume element in phase space takes the same form d*Q*1d*Q*2 ··· d*QN* d*P*1d*P*2 ··· d*PN* in terms of the transformed variables as it did in terms of the original variables, namely d*q*1d*q*2 ··· d*qN*d*p*1d*p*2 ··· d*pN* . *This fact can sometimes be used to simplify the calculation of the classical partition function*.

### E.1 Necessary and Sufficient Conditions

We begin by recalling that Hamilton's equations can be derived by means of the variational principle

<span id="page-550-3"></span>
$$
\delta \int_{l_1}^{l_2} \left[ \sum_l p_l \dot{q}_l - \mathcal{H}(q, p, t) \right] \mathbf{d}t = \mathbf{0}, \tag{E.5}
$$

where δ denotes virtual synchronou[s2](#page-550-1) variations of the actual trajectory that connects a fixed point in phase space at time *t*1 to another fixed point in phase space at time *t*2. The resulting Euler-Lagrange equations, obtained by considering variations in coordinates and momenta to be independent, are just the 2*N* first order Hamilton equations, Eq. [(E.2)](#page-549-0). The transformation to the new variables will have the same form if a similar variational principal holds, namely

<span id="page-550-2"></span>
$$\delta \int_{t_1}^{t_2} \left[ \sum_k P_k \dot{Q}_k - \mathcal{K}(Q, P, t) \right] \, \text{d}t = \mathbf{0}. \tag{E.6}$$

We are, of course, free to add the total time derivative of some function *F*(*Q*, *P*,*t*) to the integrand in Eq. [(E.6)](#page-550-2) to obtain

$$\delta \int_{t_1}^{t_2} \left[ \sum_k P_k \dot{Q}_k - \mathcal{K}(Q, P, t) + \frac{\mathbf{d} F(Q, P, t)}{\mathbf{d}t} \right] \mathbf{d}t = \mathbf{0} \tag{\text{E.7}}$$

because the end points are fixed, so

<span id="page-550-4"></span>
$$\delta \int_{t_1}^{t_2} \frac{\mathrm{d}F(Q, P, t)}{\mathrm{d}t} \, \mathrm{d}t = \delta \, F(Q, P, t)|_{t_1}^{t_2} = \mathbf{0}. \tag{\text{E.8}}$$

<span id="page-550-0"></span><sup>1</sup>The author would like to acknowledge David Kinderlehrer for bringing this to his attention and for introducing him to the relevant literature.

<span id="page-550-1"></span><sup>2</sup>Here, synchronous means that the independent variations δ*q* and δ*p* are at a fixed time. For details, see Goldstein [60, p. 225].

By comparison of Eqs. [(E.5)](#page-550-3) and [(E.8)](#page-550-4), we deduce that a canonical transformation is possible if functions *K* and *F* can be found such that the equation[3](#page-551-0)

<span id="page-551-1"></span>
$$\sum_{l} p_l \dot{q}_l - \mathcal{H}(q, p, t) = \sum_{k} P_k \dot{Q}_k - \mathcal{K}(Q, P, t) + \frac{\mathrm{d}F(Q, P, t)}{\mathrm{d}t} \tag{\text{E.9}}$$

holds *identically* as a function of the variables *Q*, *P*, *Q*˙ , *P*˙,*t*, where it is understood that the left-hand side is to be evaluated by substitution of Eq. [(E.1)](#page-549-1).

By carrying out the substitution and differentiation in Eq. [(E.9)](#page-551-1), one obtains the following set of equations from the coefficients of *Q*˙ *k*, of *P*˙ *k* and remaining terms:

<span id="page-551-2"></span>
$$\frac{\partial F}{\partial Q_k} = \sum_l p_l \frac{\partial q_l}{\partial Q_k} - P_{kl};\tag{\text{E.10}}$$

<span id="page-551-3"></span>
$$\frac{\partial F}{\partial P_k} = \sum_l p_l \frac{\partial q_l}{\partial P_k};\tag{E.11}$$

<span id="page-551-5"></span><span id="page-551-4"></span>
$$\frac{\partial F}{\partial t} = \mathcal{K}(Q, P, t) - \mathcal{H}(q, p, t) + \sum_{l} p_l \frac{\partial q_l}{\partial t}. \tag{E.12}$$

Since these equations determine the partial derivatives of *F*, they will be solvable if and only if all second mixed partial derivatives are independent of the order of differentiation. We first deal with Eqs. [(E.10)](#page-551-2) and [(E.11)](#page-551-3) and then return later to Eq. [(E.12)](#page-551-4) which can be satisfied by a suitable choice of *K*(*Q*, *P*,*t*). We obtain:

$$\frac{\partial^2 F}{\partial P_j \partial P_k} - \frac{\partial^2 F}{\partial P_k \partial P_j} = \sum_l \left( \frac{\partial q_l}{\partial P_k} \frac{\partial p_l}{\partial P_j} - \frac{\partial q_l}{\partial P_j} \frac{\partial p_l}{\partial P_k} \right) = 0;\tag{E.13}$$

$$\frac{\partial^2 F}{\partial P_j \partial Q_k} - \frac{\partial^2 F}{\partial Q_k \partial P_j} = \sum_l \left( \frac{\partial q_l}{\partial Q_k} \frac{\partial p_l}{\partial P_j} - \frac{\partial q_l}{\partial P_j} \frac{\partial p_l}{\partial Q_k} \right) - \delta_{jk} = 0;\tag{E.14}$$

$$\frac{\partial^2 F}{\partial Q_l \partial Q_k} - \frac{\partial^2 F}{\partial Q_k \partial Q_l} = \sum_l \left( \frac{\partial q_l}{\partial Q_k} \frac{\partial p_l}{\partial Q_l} - \frac{\partial q_l}{\partial Q_l} \frac{\partial p_l}{\partial Q_k} \right) = 0. \tag{E.15}$$

Equations [(E.13)](#page-551-5) to [(E.15)](#page-551-6) are the necessary and sufficient conditions for a canonical transformation. They can be written in a compact form in terms of **Lagrange brackets**

<span id="page-551-6"></span>
$$\{\text{S, T}\}_{qp} := \sum_{l} \left( \frac{\partial q_l}{\partial \text{S}} \frac{\partial p_l}{\partial T} - \frac{\partial q_l}{\partial T} \frac{\partial p_l}{\partial \text{S}} \right), \tag{\text{E.16}}$$

where *S* and *T* are any two members of the set *Q*, *P*. In that case these conditions become

<span id="page-551-7"></span>
$$\mathbb{E}\left[P_k, P_l\right]_{qp} = 0; \quad \mathbb{I}\left[Q_k, P_l\right]_{qp} = \delta_{kj}; \quad \mathbb{I}\left[Q_k, Q_l\right]_{qp} = 0. \tag{\mathbb{E}.17}$$

<span id="page-551-0"></span>3This treatment is different from treatments that involve generating functions that are functions of both the old and new variables because the 2*N* variables *Q*, *P* in Eq. [(E.1)](#page-549-1) are always independent. Thus if *F*(*Q*, *P*,*t*) were replaced by *F*1(*Q*, *q*,*t*), one could obtain a canonical transformation only if the 2*N* variables *Q*, *q* were independent, which would not be the case for a coordinate transformation alone. The present approach therefore leads to general conditions that are necessary and sufficient.

Of course we could carry out everything by interchanging the roles of the original and new variables, in which case equivalent conditions would be

<span id="page-552-2"></span>
$$[p_k, p_l]_{QP} = 0; \quad [q_k, p_l]_{QP} = \delta_{kj}; \quad [q_k, q_l]_{QP} = 0. \tag{E.18}$$

We now return to consider the mixed second derivatives involving time. From Eq. [(E.12)](#page-551-4) we compute

$$\frac{\partial^2 F}{\partial P_j \partial t} = \frac{\partial \mathcal{K}}{\partial P_j} - \sum_l \left( \frac{\partial \mathcal{H}}{\partial p_l} \frac{\partial p_l}{\partial P_j} + \frac{\partial \mathcal{H}}{\partial q_l} \frac{\partial q_l}{\partial P_j} \right) + \sum_l \frac{\partial p_l}{\partial P_j} \frac{\partial q_l}{\partial t} + \sum_l p_l \frac{\partial^2 q_l}{\partial P_j \partial t}$$

$$= \frac{\partial \mathcal{K}}{\partial P_j} - \sum_l \left( \dot{q}_l \frac{\partial p_l}{\partial P_j} - \dot{p}_l \frac{\partial q_l}{\partial P_j} \right) + \sum_l \frac{\partial p_l}{\partial P_j} \frac{\partial q_l}{\partial t} + \sum_l p_l \frac{\partial^2 q_l}{\partial P_j \partial t} \tag{E.19}$$

and from Eq. [(E.11)](#page-551-3)

<span id="page-552-1"></span><span id="page-552-0"></span>
$$\frac{\partial^2 F}{\partial t \partial P_{\parallel}} = \frac{\partial q_l}{\partial P_{\parallel}} \frac{\partial p_l}{\partial t} + \sum_l p_l \frac{\partial^2 q_l}{\partial t \partial P_{\parallel}}. \tag{E.20}$$

Equating these mixed partials and solving for ∂*K*/∂*Pj*, we obtain

$$\begin{split} \frac{\partial \mathcal{K}}{\partial P_{j}} &= \sum_{l} \left( \dot{q}_{l} \frac{\partial p_{l}}{\partial P_{j}} - \dot{p}_{l} \frac{\partial q_{l}}{\partial P_{j}} \right) - \sum_{l} \frac{\partial p_{l}}{\partial P_{j}} \frac{\partial q_{l}}{\partial t} + \frac{\partial q_{l}}{\partial P_{j}} \frac{\partial p_{l}}{\partial t} \\ &= \sum_{k} [Q_{k}, P_{j}]_{qp} \dot{Q}_{k} + \sum_{k} [P_{k}, P_{j}]_{qp} \dot{P}_{k} = \sum_{k} \delta_{jk} \dot{Q}_{k} = \dot{Q}_{k} . \end{split} \tag{E.21}$$

Similarly, from ∂2*F*/∂*t*∂*Qj* = ∂2*F*/∂*Qj*∂*t* we obtain

$$\begin{split} \frac{\partial \mathcal{K}}{\partial Q_{l}} &= \sum_{l} \left( \dot{\mathsf{q}}_{l} \frac{\partial p_{l}}{\partial Q_{l}} - \dot{\mathsf{p}}_{l} \frac{\partial q_{l}}{\partial Q_{l}} \right) - \sum_{l} \frac{\partial p_{l}}{\partial Q_{l}} \frac{\partial q_{l}}{\partial t} + \frac{\partial q_{l}}{\partial Q_{l}} \frac{\partial p_{l}}{\partial t} \\ &= \sum_{k} [Q_{k}, Q_{l}]_{qp} \dot{Q}_{k} + \sum_{k} [P_{k}, Q_{l}]_{qp} \dot{P}_{k} = -\sum_{k} \delta_{jk} \dot{P}_{k} = -\dot{P}_{l}. \end{split} \tag{E.22}$$

Equations [(E.21)](#page-552-0) and [(E.22)](#page-552-1) show explicitly that the conditions Eq. [(E.17)](#page-551-7) lead to Hamilton's equations in the new variables.

### E.1.1 Symplectic Transformation

We now demonstrate that the conditions Eq. [(E.17)](#page-551-7) can be written in the form of a symplectic transformation. This can be accomplished by introducing two 2*N* × 2*N* matrices

$$M = \begin{pmatrix} \, \partial q/\partial Q & \partial q/\partial P \\ \partial p/\partial Q & \partial p/\partial P \end{pmatrix}; \qquad \qquad S = \begin{pmatrix} \mathbf{0} & 1 \\ -1 & \mathbf{0} \end{pmatrix}, \tag{\text{E.23}}$$

where each entry is, itself, an *N* × *N* matrix. For example, ∂*q*/∂*Q* has matrix elements (∂*q*/∂*Q*)*ij* = ∂*qi*/∂*Qj*. In particular, the Jacobian of the transformation, given by Eq. [(E.4)](#page-550-5), is just *J* = det *M*. In the matrix *S*, 1 is understood to be the *N* × *N* unit matrix and 0 is the *N* × *N* null matrix. We observe that

$$S^2 = \begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix} \begin{pmatrix} 0 & 1 \\ -1 & 0 \end{pmatrix} = \begin{pmatrix} -1 & 0 \\ 0 & -1 \end{pmatrix} = -\begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix},\tag{E.24}$$

so *S* plays the role of *i* = √−1 in this space. We also observe that

$$(\det \mathbf{S})^2 = \det \mathbf{S}^2 = (-1)^{2N} = 1,\tag{\text{E.25}}$$

so det *S* = ±1. Inspection shows that det *S* = −1 if *N* is odd and det *S* = 1 if *N* is even. Evidently the inverse *S*−1 = *S*˜, the transpose of *S*. We shall also need the transpose of *M*, namely ∂*q*/∂*Q* ∂-

$$
\tilde{M} = \begin{pmatrix}
\widehat{\frac{\partial \widehat{q/\partial Q}}{\partial q/\partial P}} \widehat{\frac{\partial \widehat{p/\partial Q}}{\partial p/\partial P}}
\end{pmatrix}.
\tag{\mathbb{E}.26}
$$

Then from the conditions given by Eq. [(E.17)](#page-551-7) it follows that

<span id="page-553-1"></span>
$$
\tilde{M}SM = \mathcal{S} \tag{\mathbb{E}.27}
$$

and *M* is said to be a symplectic matrix. To see this, first compute

$$
\partial_t \mathbf{S} \mathbf{M} = \begin{pmatrix} \mathbf{0} & \mathbf{1} \\ -\mathbf{1} & \mathbf{0} \end{pmatrix} \begin{pmatrix} \partial \mathbf{q}/\partial \mathbf{Q} & \partial \mathbf{q}/\partial \mathbf{P} \\ \partial \mathbf{p}/\partial \mathbf{Q} & \partial \mathbf{p}/\partial \mathbf{P} \end{pmatrix} = \begin{pmatrix} \partial \mathbf{p}/\partial \mathbf{Q} & \partial \mathbf{p}/\partial \mathbf{P} \\ -\partial \mathbf{q}/\partial \mathbf{Q} & -\partial \mathbf{q}/\partial \mathbf{P} \end{pmatrix}.\tag{E.28}
$$

Then *MSM* ˜ is given by

<span id="page-553-0"></span>
$$
\begin{pmatrix}
\overbrace{\alpha\Phi/\partial\Phi}^{\alpha} & \overbrace{\alpha\Phi/\partial\Phi}^{\alpha}
\end{pmatrix}
$$

$$
\begin{pmatrix}
\overbrace{\alpha\Phi/\partial\Phi}^{\alpha} & \overbrace{\partial p/\partial\Phi}^{\alpha} \\
\overbrace{\partial q/\partial P}^{\alpha} & \overbrace{\partial p/\partial P}^{\alpha}
\end{pmatrix}
\begin{pmatrix}
\overbrace{\partial p/\partial Q} & \overbrace{\partial p/\partial P} \\
-\overbrace{\partial q/\partial Q}^{\alpha} & -\overbrace{\partial q/\partial P}
\end{pmatrix}
=
\begin{pmatrix}
((QQ)) & ((QP)) \\
((PQ)) & ((PP))
\end{pmatrix}
\tag{E.29}
$$

where the symbols in double parentheses are *N* × *N* matrices given by the Lagrange brackets as follows:

$$((PP))_{\mathbf{k}\mathbf{j}} = [P_{\mathbf{k}}, P_{\mathbf{j}}]_{\mathbf{q}\mathbf{p}}; \quad ((QP))_{\mathbf{k}\mathbf{j}} = [Q_{\mathbf{k}}, P_{\mathbf{j}}]_{\mathbf{q}\mathbf{p}}; \quad ((QQ))_{\mathbf{k}\mathbf{j}} = [Q_{\mathbf{k}}, Q_{\mathbf{j}}]_{\mathbf{q}\mathbf{p}} \tag{\mathcal{E}.30}$$

with ((*QP*)) = −((*PQ*)). Then by Eq. [(E.17)](#page-551-7), we see that the right-hand side of Eq. [(E.29)](#page-553-0) is equal to S.

Having established Eq. [(E.27)](#page-553-1), we can now easily compute the Jacobian for any canonical transformation. We have

$$\det \tilde{M} \mathcal{M} M = \det \tilde{M} \det \mathcal{S} \det M = (\det M)^2 \det \mathcal{S} = \det \mathcal{S}. \tag{E.31}$$

Since det *S* = ±1, it can be canceled and we obtain (det *M*)2 = 1 from which

$$J = \det M = \pm 1.\tag{\mathbb{E}.32}$$

Thus, as stated above, for a canonical transformation the volume element in phase space takes the same form d*Q*1d*Q*2 ··· d*QN* d*P*1d*P*2 ··· d*PN* in terms of the new variables as it did in terms of the original variables, namely d*q*1d*q*2 ··· d*qN* d*p*1d*p*2 ··· d*pN* . This may seem counterintuitive because one is so familiar with the fact that the volume element in real Cartesian space is d*x*d*y*d*z*, whereas in cylindrical coordinates it is *r*2 sin θd*r*dθdφ, which contains scale factors. But for canonical transformations, we must remember that *both* coordinates and their conjugate momenta are transformed. It often happens that after integration over conjugate momenta, familiar scale factors for the coordinates appear.

Symplectic matrices form a group. Since det *M* = ±1, the inverse matrix *M*−1 exists. Multiplication of Eq. [(E.27)](#page-553-1) from the right by *M*−1 and from the left by *M*˜ −1 gives -

$$S = \breve{M}^{-1} S M^{-1} = \widetilde{(M^{-1})} S M^{-1},\tag{\text{E.33}}$$

so *M*−1 is also symplectic. Furthermore, if *M* and *W* are symplectic, their product *A* = *MW* is symplectic because

$$
\tilde{A}\mathcal{A}\mathcal{A} = \tilde{W}\tilde{M}\mathcal{M}\mathcal{W} = \tilde{W}\mathcal{S}\mathcal{W} = \mathcal{S},\tag{E.34}
$$

which establishes the group property. Multiplication pertains to successive canonical transformations, which generate yet another canonical transformation.

### E.2 Restricted Canonical Transformations

An important special case is a restricted canonical transformation in which the transformation from *q*, *p* to *Q*, *P* does not involve the time explicitly, namely,

$$q_l = q_l(Q, P); \quad p_l = p_l(Q, P). \tag{E.35}$$

Under these circumstances, the terms containing ∂*qi*/∂*t* on the right-hand side of Eq. [(E.12)](#page-551-4) will vanish and it will be possible to choose the function *F* to have no explicit dependence on time, that is, *F* = *F*(*Q*, *P*). In that case, one can obtain a canonical transformation in which

$$\mathcal{H}(\mathbf{q}, \mathbf{p}, \mathbf{t}) = \mathcal{K}(\mathbf{Q}, \mathbf{P}, \mathbf{t}), \tag{\text{E.36}}$$

so the new Hamiltonian can be obtained by substituting *q*(*Q*, *P*) and *p*(*Q*, *P*) in the original Hamiltonian.

Of course the transformation will only be canonical if the conditions given by Eq. [(E.17)](#page-551-7) or, alternatively, Eq. [(E.18)](#page-552-2) apply. For this restricted situation, however, we can follow Goldstein [97, p. 391] to derive a simpler set of conditions that will guarantee that the transformation will be canonical. Thus

<span id="page-554-0"></span>
$$\frac{\partial \mathcal{K}}{\partial P_l} = \sum_k \left( \frac{\partial \mathcal{H}}{\partial q_k} \frac{\partial q_k}{\partial P_l} + \frac{\partial \mathcal{H}}{\partial p_k} \frac{\partial p_k}{\partial P_l} \right) \tag{E.37}$$

and

<span id="page-554-1"></span>
$$\dot{Q}_l = \sum_k \left( \frac{\partial Q_l}{\partial q_k} \dot{q}_k + \frac{\partial Q_l}{\partial p_k} \dot{p}_k \right) = \sum_k \left( -\frac{\partial \mathcal{H}}{\partial q_k} \frac{\partial Q_l}{\partial p_k} + \frac{\partial \mathcal{H}}{\partial p_k} \frac{\partial Q_l}{\partial q_k} \right). \tag{E.38}$$

For the transformation to be canonical, we need ∂*K*/∂*Pi* = *Q*˙ *i* and for this to be true for any function *H*(*q*, *p*,*t*), we see from comparison of Eq. [(E.37)](#page-554-0) with Eq. [(E.38)](#page-554-1) that

<span id="page-554-2"></span>
$$\frac{\partial q_k}{\partial P_l} = -\frac{\partial Q_l}{\partial p_k}; \quad \frac{\partial p_k}{\partial P_l} = \frac{\partial Q_l}{\partial q_k}. \tag{E.39}$$

Similarly

$$\frac{\partial \mathcal{K}}{\partial Q_l} = \sum_k \left( \frac{\partial \mathcal{H}}{\partial q_k} \frac{\partial q_k}{\partial Q_l} + \frac{\partial \mathcal{H}}{\partial p_k} \frac{\partial p_k}{\partial Q_l} \right) \tag{\text{E.40}}$$

and

$$-\dot{P}_l = -\sum_k \left(\frac{\partial P_l}{\partial q_k}\dot{q}_k + \frac{\partial P_l}{\partial p_k}\dot{p}_k\right) = \sum_k \left(\frac{\partial \mathcal{H}}{\partial q_k}\frac{\partial P_l}{\partial p_k} - \frac{\partial \mathcal{H}}{\partial p_k}\frac{\partial P_l}{\partial q_k}\right). \tag{E.41}$$

So requiring ∂*K*/∂*Qi* = −*P*˙*i* leads to

<span id="page-555-0"></span>
$$\frac{\partial q_k}{\partial Q_l} = \frac{\partial P_l}{\partial p_k}; \quad \frac{\partial p_k}{\partial Q_l} = -\frac{\partial P_l}{\partial q_k}.\tag{\mathbb{E}.42}$$

In Eqs. [(E.39)](#page-554-2) and [(E.42)](#page-555-0) it is important to bear in mind that the variable set for each of these partial derivatives is either *q*, *p* or *Q*, *P*. Thus, in a somewhat expanded notation,

$$\frac{\partial p_k}{\partial P_l} \equiv \left(\frac{\partial p_k}{\partial P_l}\right)_Q; \qquad \text{whereas} \quad \frac{\partial P_l}{\partial p_k} \equiv \left(\frac{\partial P_l}{\partial p_k}\right)_q,\tag{E.43}$$

so ∂*pk*/∂*Pi* is not the reciprocal of ∂*Pi*/∂*pk*.

By using Eqs. [(E.39)](#page-554-2) and [(E.42)](#page-555-0) it is easy to see that the general conditions for a canonical transformation are satisfied. For example, for [*Pk*, *Pj*]*qp* we have

$$\sum_{l} \left( \frac{\partial q_l}{\partial P_k} \frac{\partial p_l}{\partial P_j} - \frac{\partial q_l}{\partial P_j} \frac{\partial p_l}{\partial P_k} \right) = \sum_{l} \left( \frac{\partial q_l}{\partial P_k} \frac{\partial Q_l}{\partial q_l} + \frac{\partial Q_l}{\partial p_k} \frac{\partial p_l}{\partial P_k} \right) = \frac{\partial Q_l}{\partial P_k} = 0,\tag{E.44}$$

where Eq. [(E.39)](#page-554-2) has been used. Similarly, for [*Qk*, *Pj*]*qp*,

$$\sum_{l} \left( \frac{\partial q_l}{\partial Q_k} \frac{\partial p_l}{\partial P_l} - \frac{\partial q_l}{\partial P_l} \frac{\partial p_l}{\partial Q_k} \right) = \sum_{l} \left( \frac{\partial q_l}{\partial Q_k} \frac{\partial Q_l}{\partial q_l} + \frac{\partial Q_l}{\partial p_l} \frac{\partial p_l}{\partial Q_k} \right) = \frac{\partial Q_l}{\partial Q_k} = \delta_{lk} \tag{\text{E.45}}$$

And finally for [*Qk*, *Qj*]*qp*,

$$\sum_{l} \left( \frac{\partial q_l}{\partial Q_k} \frac{\partial p_l}{\partial Q_j} - \frac{\partial q_l}{\partial Q_j} \frac{\partial p_l}{\partial Q_k} \right) = \sum_{l} \left( \frac{\partial P_k}{\partial p_l} \frac{\partial p_l}{\partial Q_j} + \frac{\partial q_l}{\partial Q_j} \frac{\partial P_k}{\partial Q_l} \right) = \frac{\partial P_k}{\partial Q_l} = 0. \tag{E.46}$$

This page intentionally left blank

# Rotation of Rigid Bodies

There is no such thing as a rigid body but under many circumstances, solid bodies can often be treated to a good approximation as if they were rigid. Moreover, molecules can be approximated by rigid bodies composed of point masses provided that vibrational modes are not excited. We therefore summarize some useful properties of such bodies.

The formulae below pertain to bodies whose center of mass is at rest. We know that the total kinetic energy of a body is the sum of the kinetic energy of the center of mass and the kinetic energy with respect to the center of mass. Similarly, the total angular momentum is the sum of the angular momentum with respect to the center of mass plus the angular momentum of the center of mass with respect to the origin of coordinates. For this and other reasons that afford simplification, we treat only bodies whose centers of mass are at rest.

We denote the coordinate of a point of such a body by the vector **r**. We shall write a number of formulae for the continuum case for which mass is distributed according to a density ρ(**r**). To obtain formulae for the case of discrete masses, one only needs to write the density as a sum of delta functions, for example, ρ(**r**) = - *i mi*δ(**r** − **r***i*) in which case the integrals are replaced by sums.[1](#page-557-0)

### <span id="page-557-2"></span>F.1 Moment of Inertia

The **moment of inertia** of a body with respect to some axis passing through its center of mass is defined by the formula

<span id="page-557-1"></span>
$$\mathcal{TL} := \int \rho(\mathbf{r}) \, r_{\perp}^2 \, \mathrm{d}V,\tag{\text{E1}}$$

where the integral is over the volume of the body and *r*⊥ is the distance to a point in the body measured perpendicular to the specified axis. We can specify the axis by supposing it to lie along a unit vector **a**ˆ in which case *r*2 ⊥ = |**a**ˆ × **r**| 2 = *r*2 − (**r** · **a**ˆ)2. Thus Eq. [(F.1)](#page-557-1) can be written more explicitly as

$$\mathcal{L}(\hat{\mathbf{a}}) = \int \rho(\mathbf{r}) \left(r^2 - (\mathbf{r} \cdot \hat{\mathbf{a}})^2\right) \mathrm{d}V = \mathcal{Z}(-\hat{\mathbf{a}}) = \sum_{a,\beta} \hat{a}_a \mathcal{Z}_{a\beta} \hat{a}_\beta,\tag{\text{F2}}$$

<span id="page-557-0"></span><sup>1</sup>The notation ρ(**r**) is applicable if the body is at rest. In [Section F.1](#page-557-2) we discuss some cases of rotating bodies. This is handled by treating discrete masses located at positions **r***i*(*t*) that depend on time. In that case we should write ρ(**r**(*t*)) but we will suppress the dependence on *t* for simplicity. In [Section F.5](#page-561-0) we use a rotating coordinate system **r** in which the body is at rest, so in that case we write ρ(**r** ).

where α and β denote Cartesian coordinates and the symmetric **moment of inertia tensor**

<span id="page-558-0"></span>
$$\mathcal{I}_{a\beta} := \int \rho(\mathbf{r}) \left( r^2 \delta_{a\beta} - \mathbf{x}_a \mathbf{x}_\beta \right) \mathrm{d}V. \tag{F.3}$$

For the case of a rigid body made up of discrete masses *mi* located at positions **r***i*, as mentioned previously, Eq. [(F.3)](#page-558-0) become[s2](#page-558-1)

<span id="page-558-2"></span>
$$\mathcal{L}_{a\beta} := \sum_{l} m_{l} \left( r_{l}^{2} \delta_{\alpha\beta} - \mathbf{x}_{l\alpha} \mathbf{x}_{l\beta} \right). \tag{\text{F.4}}$$

In dyadic notation, this tensor could be written

<span id="page-558-3"></span>
$$I = \sum_{l} m_{l} [r_{l}^{2} \mathbb{1} - \mathbf{r}_{l} \mathbf{r}_{l}],\tag{55}$$

where 1 corresponds to the unit tensor.

From its definition, it is clear that the actual components of *I*αβ will depend on the orientation of the body with respect to the chosen axes. If the body is at rest with respect to these axes, these components will be constants. We observe that *I*αβ = *I*βα so this tensor can be diagonalized by means of a choice of axes, rotated with respect to some original choice of axes. Such a transformation can be accomplished by means of an orthogonal transformation. It is worth noting, however, that the quantity *I*(**a**ˆ) with respect to any fixed axis **a**ˆ is unchanged if the body is rotated about that axis because it only depends on *r*⊥.

If the rigid body is in motion with respect to the axes of the chosen reference frame, the *components* of the tensor *I*αβ will generally depend on time. For reasons just mentioned, however, the value of *I*(**a**ˆ) will not depend on time as the body rotates about any *fixed* axis. This provides some simplification of some of the formulae given below but also leads to some complications in formulae in which time derivatives of *I*αβ occur. In such cases, one must either evaluate such time derivatives explicitly or employ a reformulation in which two coordinate systems are used, one at rest with respect to the body and in which the components of *I*αβ will be constants, and another with respect to which the body can rotate.

### F.1.1 Diatomic Molecule

The moment of inertia tensor for a diatomic molecule consisting of two point particles can be calculated from Eq. [(F.3)](#page-558-0) by replacing the density by a sum of two delta functions,

$$
\rho(\mathbf{r}) = m_1 \delta(\mathbf{r} - \mathbf{r}_1) + m_2 \delta(\mathbf{r} - \mathbf{r}_2),
\tag{E6}
$$

where one particle of mass *m*1 is located at **r**1 and the other particle of mass *m*2 is located at **r**2. Thus

<span id="page-558-1"></span>2If an origin other than the center of mass is used, it is apparent from Eq. [(F.4)](#page-558-2) that one must add to *I*αβ the quantity *M*(*R*2δαβ −*R*α*R*β ), where *M* is the total mass and **R** is the vector from the new origin to the center of mass. Cross terms vanish because of the definition of the center of mass. This tensor would contribute an additional term *M*|**a**ˆ × **R**| 2 to *I*(**a**ˆ).

$$\mathcal{L}_{a\beta} = m_1 \left[ r_1^2 \delta_{a\beta} - \mathbf{x}_{1a} \mathbf{x}_{1\beta} \right] + m_2 \left[ r_2^2 \delta_{a\beta} - \mathbf{x}_{2a} \mathbf{x}_{2\beta} \right]. \tag{\text{F7}}$$

$$z_1 = \frac{m_2}{m_1 + m_2} \ell_0; \quad z_2 = -\frac{m_1}{m_1 + m_2} \ell_0. \tag{E8}$$

*I*αβ = *m*1 *r*2 1 δαβ − *x*1α*x*1β + *m*2 *r*2 2 δαβ − *x*2α*x*2β . (F.7) We recall that the origin is to be located at the center of mass and proceed to calculate *I*αβ

$$\mathcal{Z}_{\text{xx}} = \mathcal{Z}_{\text{yy}} = m_1 \mathcal{Z}_1^2 + m_2 \mathcal{Z}_2^2 = \frac{\ell_0^2}{(m_1 + m_2)^2} (m_1 m_2^2 + m_2 m_1^2) = \ell_0^2 \frac{m_1 m_2}{m_1 + m_2}.\tag{E9}$$

*m*1 + *m*2 *m*1 + *m*2 0, (F.8)

[where](#page-567-0) 0 = |*z*1 − *z*2| is the distance of separation between particles. In this coordinate system, *r*1 = *z*1 and *r*2 = *z*2 so we see immediately that *Izz* = 0 and *Ixx* = *Iyy* = *m*1*z*2 1 + *m*2*z*2 2 = 2 0 (*m*1 + *m*2)2 (*m*1*m*2 2 + *m*2*m*2 1) = 2 0 *m*1*m*2 *m*1 + *m*2 . (F.9) The quantity multiplying 2 0 is known as the reduced mass, familiar from mechanics.

### would be a small value of *Izz* = (2/5)(*m*1*a*2 increased by this same amount. Since most of the mass of an atom resides in its nucleus,

observe that **a**ˆ · **L** = **a**ˆ · *I* · *ω* = **a**ˆ · *I* · **a**ˆ ω = *I*(**a**ˆ)ω.

F.2 Angular Momentum

say of radius *r*0, the ratio *Izz*/*Ixx* will be of the order of magnitude of (*r*0/0) 2 ∼ 10−8. See Section F.8 for a related discussion.

If the particles were not point particles, but spheres of radii *a*1 and *a*2 respectively, there

<span id="page-559-0"></span>1 + *m*2*a*2

<span id="page-559-1"></span>
$$\mathbf{L} := \int \rho(\mathbf{r}) \, \mathbf{r} \times \mathbf{v} \, \mathrm{d}V,\tag{\text{E.10}}$$

2) and each of *Ixx* and *Iyy* would be

The **angular momentum** with respect to the center of mass is defined by

$$\hat{\mathbf{a}} \cdot \mathbf{L} = \int \rho(\mathbf{r}) \hat{\mathbf{a}} \cdot \mathbf{r} \times \mathbf{v} \,\mathrm{d}V = \int \rho(\mathbf{r}) \hat{\mathbf{a}} \times \mathbf{r} \cdot \mathbf{v} \,\mathrm{d}V = \int \rho(\mathbf{r}) \mathbf{r} \times \mathbf{v} \cdot \hat{\mathbf{a}} \,\mathrm{d}V = \mathbf{L} \cdot \hat{\mathbf{a}} \tag{\text{F.11}}$$

where **v** is the velocity of the body at the point **r**. T[he](#page-559-0) [qu](#page-559-0)antity **a**ˆ · **L** = ρ(**r**) **a**ˆ · **r** × **v** d*V* = ρ(**r**) **a**ˆ × **r** · **v** d*V* = ρ(**r**) **r** × **v** · **a**ˆ d*V* = **L** · **a**ˆ (F.11) is the angular momentum with respect to the axis **a**ˆ. This follows becau[se](#page-558-0) **a**ˆ × **r** has magnitude *r*⊥ and a direction perpendicular to the plane made by **a**ˆ and **r**. Its dot product

with **v** selects the component of **v** perpendicular to this plane in a direction related to the **a**ˆ axis in accordance with the right-hand rule. We define a vector *ω* := **a**ˆω, where ω is an angular velocity. Then for rotation of a rigid body about an axis **a**ˆ, in the sense of the right-hand rule, we can write **v** = *ω* × **r** in which case **r** × **v** = **r** × (*ω* × *r*) = [*r*2*ω* − (**r** · *ω*)**r**]=[*r*21 − **rr**] · *ω*, where 1 is the unit dyadic and **rr**

$$\mathbf{L} = \mathbf{I} \cdot \boldsymbol{\omega},\tag{\text{E12}}$$

**L** = *I* · *ω*, (F.12) where *I* is the moment of inertia tensor with components given by Eq. (F.3). We also

$$T = \frac{1}{2} \int \rho(\mathbf{r}) \mathbf{v} \cdot \mathbf{v} \,\mathrm{d}V. \tag{\text{F.13}}$$

540 THERMAL PHYSICS

2 

<span id="page-560-2"></span><span id="page-560-0"></span>
$$T = \frac{1}{2}\,\boldsymbol{\omega}\cdot\boldsymbol{I}\cdot\boldsymbol{\omega} = \frac{1}{2}\,\boldsymbol{\omega}\cdot\mathbf{L} = \frac{1}{2}\,\mathcal{Z}(\hat{\mathbf{a}})\,\boldsymbol{\omega}^2. \tag{\text{F.14}}$$

The kin[etic](#page-559-1) [e](#page-559-1)nergy with respect to the center of mass is3

$$T = \frac{1}{2} \left( \mathcal{I}_{\text{xx}} \, \boldsymbol{\alpha}_{\text{x}}^2 + \mathcal{I}_{\text{yy}} \, \boldsymbol{\alpha}_{\text{y}}^2 + \mathcal{I}_{\text{zz}} \, \boldsymbol{\alpha}_{\text{z}}^2 \right) \tag{€15}$$

For rigid r[otati](#page-560-0)on, **v** · **v** = (*ω* × **r**) · (*ω* × **r**) = *ω* · [*r*21 − **rr**] · *ω*, so

and Eq. (F.12) becomes

F.3 Kinetic Energy

$$L_{\mathbf{x}} = \mathcal{T}_{\mathbf{xx}} \, \boldsymbol{\alpha}_{\mathbf{x}}; \quad L_{\mathbf{y}} = \mathcal{T}_{\mathbf{yy}} \, \boldsymbol{\alpha}_{\mathbf{y}}; \quad L_{\mathbf{z}} = \mathcal{T}_{\mathbf{zz}} \, \boldsymbol{\alpha}_{\mathbf{z}}.\tag{F.16}$$

<span id="page-560-4"></span>If we use a coordinate system in which *I* is momentarily diagonal, we would have4 *T* = 1

$$T = \frac{L_x^2}{2\mathcal{I}_{\infty}} + \frac{L_y^2}{2\mathcal{I}_{yy}} + \frac{L_z^2}{2\mathcal{I}_{zz}}.\tag{E17}$$

### Then Eq. (F.15) can be written in the form

Eq. (F.19) can be written in the form

*T* = *L*2 *x* 2*Ixx* + *L*2 *y* 2*Iyy* + *L*2 *z* 2*Izz* . (F.17) F.4 Time Derivatives As remarked toward the e[nd](#page-558-3) [o](#page-558-3)f Section F.1, the components of *I*αβ will depend on time if a body is rotating with respect to the coordinates of the reference frame. We first calculate the time derivative of Eq. (F.5) at a moment when the body is rotating with angular velocity

<span id="page-560-1"></span>*[Lx](#page-558-3)* = *Ixx* ω*x*; *Ly* = *Iyy* ω*y*; *Lz* = *Izz* ω*z*. (F.16)

$$\frac{\mathbf{d}}{\mathbf{d}t}(\mathbf{r}_l \mathbf{r}_l) = \mathbf{v}_l \mathbf{r}_l + \mathbf{r}_l \mathbf{v}_l = (\boldsymbol{\omega} \times \mathbf{r}_l) \mathbf{r}_l - \mathbf{r}_l (\mathbf{r}_l \times \boldsymbol{\omega}) = \boldsymbol{\omega} \times \mathbf{r}_l \mathbf{r}_l - \mathbf{r}_l \mathbf{r}_l \times \boldsymbol{\omega},\tag{E18}$$

tim[e deri](#page-560-1)vative of the dyadic **r***i***r***i* is d d*t* (**r***i***r***i*) = **v***i***r***i* + **r***i***v***i* = (*ω* × **r***i*)**r***i* − **r***i*(**r***i* × *ω*) = *ω* × **r***i***r***i* − **r***i***r***i* × *ω*, (F.18)

$$\frac{d}{dt}I = -\sum_{l} m_{l} [\boldsymbol{\omega} \times \mathbf{r}_{l} \mathbf{r}_{l} - \mathbf{r}_{l} \mathbf{r}_{l} \times \boldsymbol{\omega}].\tag{E19}$$

d d*t I* = − *i mi*[*ω* × **r***i***r***i* − **r***i***r***i* × *ω*]. (F.19) It also turns out that *ω* × 1 = 1 × *ω*, which can be shown by straightforward algebra by writing 1 = ˆ **i**ˆ **i**+ˆ **j**ˆ **j**+ ˆ **k**ˆ **k** in terms of the unit vectors of a Cartesian coordinate system. Hence

<span id="page-560-3"></span>
$$\frac{\mathrm{d}I}{\mathrm{d}t} = \omega \times I - I \times \omega. \tag{\mathrm{F}20}$$

d*I*

d*t* = *ω* × *I* − *I* × *ω*. (F.20)

<sup>3</sup>In Chapter 1 we called this quantity *Ti* to distinguish it from the total kinetic energy. 4If the axis of rotation remains fixed, *I*(**a**ˆ) would not change with time, as shown by Eq. (F.21).

$$\frac{\mathbf{d}}{\mathbf{d}t}\mathcal{T}(\hat{\mathbf{a}}) = \hat{\mathbf{a}} \cdot \frac{\mathbf{d}I}{\mathbf{d}t} \cdot \hat{\mathbf{a}} = \hat{\mathbf{a}} \cdot (\boldsymbol{\omega} \times I - I \times \boldsymbol{\omega}) \cdot \hat{\mathbf{a}} = 0 \tag{\text{F21}}$$

*Appendix F* • Rotation of Rigid Bodies 541

<span id="page-561-1"></span>d d*t*

d*T*

<span id="page-561-2"></span>d*ω*

$$\frac{\mathrm{dL}}{\mathrm{d}t} = \mathrm{I} \cdot \frac{\mathrm{d}\omega}{\mathrm{d}t} + \frac{\mathrm{d}I}{\mathrm{d}t} \cdot \omega = \mathrm{I} \cdot \frac{\mathrm{d}\omega}{\mathrm{d}t} + \omega \times \mathrm{I} \cdot \omega \tag{\text{F.22}}$$

because we can interchange the dot and the cross on either side of *I* and the cross product

$$\frac{d\mathbf{L}}{dt} = \mathbf{I} \cdot \frac{d\boldsymbol{\omega}}{dt} + \boldsymbol{\omega} \times \mathbf{L}.\tag{5.23}$$

On the other hand, from Eq. (F.12) we see that d**L** d*t* = *I* · d*ω* d*t* + d*I* d*t* · *ω* = *I* · d*ω* [d](#page-560-3)*t* + *ω* × *I* · *ω* (F.22)

or finally

$$\frac{\mathrm{d}T}{\mathrm{d}t} = \frac{1}{2} \frac{\mathrm{d}\omega}{\mathrm{d}t} \cdot I \cdot \omega + \frac{1}{2} \,\omega \cdot I \cdot \frac{\mathrm{d}\omega}{\mathrm{d}t} + \frac{1}{2} \,\omega \cdot \frac{\mathrm{d}I}{\mathrm{d}t} \cdot \omega. \tag{\text{F24}}$$

The "extra" term *ω* ×**L** co[mes](#page-561-1) from the dependence of *I* on time when calculated in a fixed frame in which the body is rotating.

$$\frac{dT}{dt} = \boldsymbol{\omega} \cdot \boldsymbol{I} \cdot \frac{\mathbf{d}\boldsymbol{\omega}}{\mathbf{d}t} = \mathbf{L} \cdot \frac{\mathbf{d}\boldsymbol{\omega}}{\mathbf{d}t},\tag{\text{F.25}}$$

d*t* = 1 2 d*t* · *I* · *ω* + 2 *ω* · *I* · d*t* + 2 *ω* · d*t* · *ω*. (F.24)

The last term vanishes after substitution of Eq. (F.20) and the other two combine to give *dT dt* = *ω* · *I* · d*ω* d*t* = **L** · d*ω* d*t* , (F.25)

<span id="page-561-0"></span>
$$
\boldsymbol{\omega} \cdot \mathbf{N} = \boldsymbol{\omega} \cdot \boldsymbol{I} \cdot \frac{\mathbf{d} \boldsymbol{\omega}}{\mathbf{d}t} = \frac{\mathbf{d}T}{\mathbf{d}t} \tag{\text{F.26}}
$$

momentum is conserved. If i[t does not, w](#page-560-4)e can take the dot product with *ω* to obtain *ω* · **N** = *ω* · *I* · d*ω* d*t* = d*T* d*t* (F.26)

from which we recognize that the left-hand side is the power supplied by the torque, which is equal to the time rate of change of the kinetic energy. If the torque vanishes, the kinetic

### energy is constant, as expected.

F.5 Rotating Coordinate System Some of the complications of Section F.4 can be avoided by using two coordinate systems, the unprimed system with coordinates *x*, *y*, *z* as dealt with above, which we here take to be an inertial frame, and a primed system with coordinates *x* , *y* , *z* having the same origin and coordinate axes imbedded in the rigid body. The axes of the primed system rotate with the body. A point *i* in the body can be described by either a vector **r***i* = *xi* ˆ **i** + *yi* ˆ **j** + *zi***k**ˆ or a vector **r** *i* = *x i* ˆ **i** + *y i* ˆ **j** + *z i* **k**ˆ , and since it is the same point, we have **r***i* = **r** *i* . As the body rotates, the coordinates *xi*, *yi*, *zi* change with time but the unit vectors ˆ **i**,ˆ **j**, ˆ **k** remain

542 THERMAL PHYSICS constant in time; on the other hand, the coordinates *x i* , *y i* , *z i* remain constant in time but the unit vectors ˆ **i** ,ˆ **j** , ˆ **k** rotate with time.

$$I' = \sum_{l} m_{l} \left[ r_{l}^{2} \mathbb{1} - \mathbf{r}_{l}^{\prime} \mathbf{r}_{l}^{\prime} \right] = \hat{\mathbf{I}}^{\prime} \mathcal{Z}_{1} \hat{\mathbf{I}}^{\prime} + \hat{\mathbf{J}}^{\prime} \mathcal{Z}_{2} \hat{\mathbf{J}}^{\prime} + \hat{\mathbf{k}}^{\prime} \mathcal{Z}_{3} \hat{\mathbf{k}}^{\prime}. \tag{\text{E.27}}$$

one could choose the orientation of the primed axes with respect to the body, once and for all, such that the moment of inertia tensor is diagonal, with diagonal elements *I*1 = *Ixx* , *I*2 = *Iyy* , and *I*3 = *Izz* and with off diagonal elements *Ix y* = *Iyz* = *Iz x* = 0. In such a representation, the moment of inertia dyadic would be 

<span id="page-562-1"></span>*I* = *i mi* [*r*2 *i* 1 − **r** *i* **r** *i* ] = ˆ **i** *I*1ˆ **i** + ˆ **j** *I*2ˆ **j** + ˆ **k** *I*3 ˆ **k** . (F.27) In this notation, the prime on *I* is only a reminder that it is the moment of inertia dyadic

$$\mathbf{L}' = \mathbf{I}' \cdot \mathbf{o}' = \mathcal{Z}\iota\alpha_{\hat{\lambda}}\hat{\mathbf{i}}' + \mathcal{Z}\iota\alpha_{\hat{\lambda}}\hat{\mathbf{j}}' + \mathcal{Z}\iota\alpha_{2}\hat{\mathbf{k}}',\tag{F28}$$

<span id="page-562-0"></span>, (F.28)

these dyadics are different, those for *I* being independent of time. Similarly, the angular momentum can be represented by **L** = *Lx*ˆ **i** + *Ly*ˆ **j** + *Lz* ˆ **k** or

### alternatively **L** = *Lx*ˆ **i** + *Ly*ˆ **j** + *Lz* ˆ **k** , with **L** = **L L** = *I* · *ω* = *I*1ω*x*ˆ **i**

*Gz* ˆ **k**

But dˆ **i** 

, with **[G](#page-562-0)** = **G**

/d*t* = *ω* × ˆ

d**G**

**i**

time derivative is

 + *I*2ω*y*ˆ + *I*3ω*z* ˆ where *ω* = ω*x*ˆ **i** + ω*y*ˆ **j** + ω*z* ˆ **k** or alternatively *ω* = ω*x*ˆ **i** + ω*y*ˆ **j** + ω*z* ˆ **k** , with *ω* = *ω* . F.5.1 Time Derivatives Revisited

**j**

$$\begin{split} \frac{\mathbf{dG}}{\mathbf{dt}} &= \frac{\mathbf{dG}_{\mathbf{x}}}{\mathbf{dt}} \hat{\mathbf{t}} + \frac{\mathbf{dG}_{\mathbf{y}}}{\mathbf{dt}} \hat{\mathbf{t}} + \frac{\mathbf{dG}_{\mathbf{z}}}{\mathbf{dt}} \hat{\mathbf{k}} \\ &= \frac{\mathbf{dG}_{\mathbf{x}}^{\prime} \hat{\mathbf{t}}^{\prime}}{\mathbf{dt}} \hat{\mathbf{t}}^{\prime} + \frac{\mathbf{dG}_{\mathbf{y}}^{\prime} \hat{\mathbf{t}}^{\prime}}{\mathbf{dt}} \hat{\mathbf{t}}^{\prime} + \frac{\mathbf{dG}_{\mathbf{z}}^{\prime} \hat{\mathbf{k}}^{\prime}}{\mathbf{dt}} \hat{\mathbf{t}}^{\prime} + \mathbf{G}_{\mathbf{z}} \frac{\mathbf{d} \hat{\mathbf{t}}^{\prime}}{\mathbf{dt}} + \mathbf{G}_{\mathbf{y}^{\prime}} \frac{\mathbf{d} \hat{\mathbf{t}}^{\prime}}{\mathbf{dt}} + \mathbf{G}_{\mathbf{z}^{\prime}} \frac{\mathbf{d} \hat{\mathbf{k}}^{\prime}}{\mathbf{dt}} = \frac{\mathbf{dG}^{\prime}}{\mathbf{dt}}. \end{split} \tag{5.29}$$

. Since **L** = *I* · *ω* we also have

**k**

d*t* d*t* d*t* = d*G x* ˆ **i** + d*G y* ˆ + d*G z* ˆ **k** + *Gx* dˆ **i** dˆ **j** dˆ **k**

d*t*

 d**G**

$$\mathbf{\hat{z}} \times \mathbf{r} \text{ and similarly for } \mathbf{u} \mathbf{j} \text{ /} \mathbf{u} \text{ and } \mathbf{u} \mathbf{k} \text{ /} \mathbf{u} \text{, so}$$

$$\frac{\mathbf{dG}}{\mathbf{d}t} = \frac{\mathbf{dG}_x \mathbf{\hat{i}} \mathbf{\hat{i}}}{\mathbf{d}t} \mathbf{\hat{i}} + \frac{\mathbf{dG}_y \mathbf{\hat{j}}}{\mathbf{d}t} \mathbf{\hat{j}} + \frac{\mathbf{dG}_z \mathbf{\hat{k}}}{\mathbf{d}t} \mathbf{\hat{k}} + \boldsymbol{\omega} \times \mathbf{G} \text{.}\tag{8.30}$$

d**G** d*t* = d*G x* ˆ **i** + d*G y* ˆ **j** + d*G*

d*t*

$$
\left(\frac{\text{dG}}{\text{dt}}\right)_{\text{fixed}} = \left(\frac{\text{dG}'}{\text{dt}}\right)_{\text{rotating}} + \omega \times \text{G}',\tag{5.31}
$$

$$
\left(\frac{\text{d}}{\text{s}}\right)_{\text{fixed}} = \left(\frac{\text{d}\text{G}'}{\text{s}}\right)_{\text{rotating}} + \omega \times \text{G}',\tag{5.31}
$$

. (F.30)

d*t* fixed = d*t* rotating , (F.31) but this notation can be easily misinterpreted because in d**G** /d*t* rotating one only differentiates the *components* of **G** , not the unit vectors. Another word of caution concerns the interpretation of the expressions

*z*

ˆ **k** + *ω* × **G**

$$
\boldsymbol{\omega} \times \mathbf{G} = \boldsymbol{\omega} \times \mathbf{G}' = \boldsymbol{\omega}' \times \mathbf{G} = \boldsymbol{\omega}' \times \mathbf{G}'.\tag{E32}
$$

*Appendix F* • Rotation of Rigid Bodies 543

*ω* × **G** = *ω* × **G** = *ω* × **G** = *ω* × **G** . (F.32) The first and the last are easy to evaluate in terms of the usual rule for cross products

$$\frac{\mathbf{dr}}{\mathbf{dt}} = \boldsymbol{\omega} \times \mathbf{r} = \boldsymbol{\omega}' \times \mathbf{r}' = \frac{\mathbf{dr}'}{\mathbf{dt}}.\tag{\text{F.33}}$$

**G** in Eq. (F.30) would lead directly t[o an](#page-561-1) expression for d**G**/d*t* resolved al[ong t](#page-563-0)he primed

<span id="page-563-0"></span>
$$\frac{d\mathbf{L}}{dt} = \mathcal{I}_1 \frac{\mathbf{d}\alpha_{\mathbf{x'}}}{\mathbf{d}t} \mathbf{\hat{i}'} + \mathcal{I}_2 \frac{\mathbf{d}\alpha_{\mathbf{y'}}}{\mathbf{d}t} \mathbf{\hat{j}'} + \mathcal{I}_3 \frac{\mathbf{d}\alpha_{\mathbf{z'}}}{\mathbf{d}t} \mathbf{\hat{k}'} + \boldsymbol{\omega}' \times \mathbf{L}' \tag{\text{F.34}}$$

d**r** d*t* = *ω* × **r** = *ω* × **r** = d**r** d*t* . (F.33) For the case of the angular momentum **L**, we see from Eq. (F.28) that d**L** d*t* = *I*1 dω*x* d*t* ˆ **i** + *I*2 dω*y* d*t* ˆ **j** + *I*3 dω*z* ˆ **k** + *ω* [×](#page-563-1) **L** (F.34)

$$N_1 = \mathcal{Z}_1 \dot{\omega}_1 + \alpha_2 \alpha_3 (\mathcal{Z}_3 - \mathcal{Z}_2);$$

$$N_2 = \mathcal{Z}_2 \dot{\alpha}_2 + \alpha_3 \alpha_1 (\mathcal{Z}_1 - \mathcal{Z}_3);$$

$$N_3 = \mathcal{Z}_3 \dot{\alpha}_3 + \alpha_1 \alpha_2 (\mathcal{Z}_2 - \mathcal{Z}_1),\tag{E.35}$$

the *components* of torque in the p[rimed](#page-561-2) system are *N*1 = *I*1ω˙ 1 + ω2ω3(*I*3 − *I*2); *N*2 = *I*2ω˙ 2 + ω3ω1(*I*1 − *I*3);

<span id="page-563-2"></span>
$$
\boldsymbol{\omega}' \cdot \mathbf{N}' = \mathcal{I}_1 \boldsymbol{\omega}_1 \dot{\boldsymbol{\omega}}_1 + \mathcal{I}_2 \boldsymbol{\omega}_2 \dot{\boldsymbol{\omega}}_2 + \mathcal{I}_3 \boldsymbol{\omega}_3 \dot{\boldsymbol{\omega}}_3 = \frac{\mathbf{d}T'}{\mathbf{d}t} \tag{\text{F.36}}
$$

**equations of motion** of a rigid body. The power delivered by the torque is then

*d***L**

vectors.

d**L**

where *x*

, *y*

the rotating frame, so

<span id="page-563-3"></span><span id="page-563-1"></span>
$$T' = \frac{1}{2} (\mathcal{Z}_1 a_1^2 + \mathcal{Z}_2 a_2^2 + \mathcal{Z}_3 a_3^2) = T. \tag{E37}$$

which should be compared to Eq. (F.26) with *T* = 1 2 (*I*1ω2 1 + *I*2ω2 2 + *I*3ω2 3) = *T*. (F.37)

In the unprimed fram[e,](#page-563-0) *T* is given by Eq. (F.14). The advantage of Eq. (F.37) is that the

$$\frac{d\mathbf{I}'}{dt} = \boldsymbol{\omega}' \times \mathbf{I}' - \mathbf{I}' \times \boldsymbol{\omega}' \tag{\text{F.38}}$$

d**I** d*t* = *ω* × **I** − **I** × *ω* (F.38) which, of course, has the same form as Eq. (F.20) and holds whether or not the principal

$$\frac{d\mathbf{L}'}{dt} = \frac{d}{dt}(\mathbf{I}' \cdot \boldsymbol{\omega}') = \mathbf{I}' \cdot \dot{\boldsymbol{\omega}}' + \frac{d\mathbf{I}'}{dt} \cdot \boldsymbol{\omega}' = \mathbf{I}' \cdot \dot{\boldsymbol{\omega}}' + \boldsymbol{\omega}' \times \mathbf{I}' \cdot \boldsymbol{\omega}' \tag{E39}$$

*dt* = *d dt* (**I** *dt* · *ω* = **I** which agrees with Eq. (F.34) if principal axes are used. Similarly,

$$\frac{\mathrm{d}T'}{\mathrm{d}t} = \frac{1}{2} \frac{\mathrm{d}}{\mathrm{d}t} (\boldsymbol{\omega}' \cdot \mathbf{I}' \cdot \boldsymbol{\omega}') = \boldsymbol{\omega}' \cdot \mathbf{I}' \cdot \dot{\boldsymbol{\omega}}' \tag{\text{F40}}$$

which agrees with Eq. [(F.36)](#page-563-2) if principal axes are used.

### F.6 Matrix Formulation

Our principal interest as far as classical statistical mechanics is concerned is to express the Hamiltonian in terms of canonical coordinates and momenta. Since the energy is provided by Eq. [(F.37)](#page-563-3), it remains to express *ω* in terms of the transformation from the fixed to the rotating coordinate system. This can be done by writing the transformation in the matrix form

$$\mathbf{x}' = A\mathbf{x} \tag{\text{E41}}$$

with inverse

<span id="page-564-0"></span>
$$\mathbf{x} = \mathbf{A}^{\mathrm{T}} \mathbf{x}',\tag{\mathbb{R}A2}$$

where *x* and *x* are column vectors. *A* is an orthogonal matrix that depends on time and *A*T is its transpose, which is also its inverse. Following the notation and convention of Goldstein [60, p. 107], we can write *A* in terms of the Euler angles φ, θ, and ψ as a product of three successive rotations in the form

<span id="page-564-2"></span>
$$A = BCD,\tag{\text{E.43}}$$

where

$$D = \begin{pmatrix} \cos \phi & \sin \phi & 0 \\ -\sin \phi & \cos \phi & 0 \\ 0 & 0 & 1 \end{pmatrix}; \quad C = \begin{pmatrix} 1 & 0 & 0 \\ 0 & \cos \theta & \sin \theta \\ 0 & -\sin \theta & \cos \theta \end{pmatrix}; \quad B = \begin{pmatrix} \cos \psi & \sin \psi & 0 \\ -\sin \psi & \cos \psi & 0 \\ 0 & 0 & 1 \end{pmatrix}. \tag{F44}$$

When the matrix *A* multiplies the column vector *x*, matrix *D* causes a rotation by φ around the *z*-axis; then *C* causes a rotation by θ about the rotated *x*-axis, resulting in the rotated *z*axis becoming the *z* -axis; and finally *B* causes a rotation by ψ about the *z* -axis to establish the *x* - and *y* -axes. See Figures 4-6 of Goldstein [60].

Since the coordinates *x* are independent of time, differentiation of Eq. [(F.42)](#page-564-0) with respect to time gives

<span id="page-564-1"></span>
$$
\dot{\mathbf{x}} = \dot{A}^{\mathbf{T}} \mathbf{x}' = \dot{A}^{\mathbf{T}} A \mathbf{x}.\tag{\text{E45}}
$$

Since *A*T*A* = *E*, where *E* is the unit matrix whose time derivative is zero, we have

$$
\dot{A}^T \mathbf{A} = -A^T \dot{A} = -(\dot{A}^T A)^T,\tag{\text{F.46}}
$$

so *A*˙ T*A* is an antisymmetric matrix that we can write in the form

$$
\dot{A}^{\mathrm{T}}A \equiv \boldsymbol{\omega} = \begin{pmatrix} \mathbf{0} & \omega_{\mathbf{xy}} & \omega_{\mathbf{xz}} \\ -\omega_{\mathbf{xy}} & \mathbf{0} & \omega_{\mathbf{yz}} \\ -\omega_{\mathbf{xz}} & -\omega_{\mathbf{yz}} & \mathbf{0} \end{pmatrix} = \begin{pmatrix} \mathbf{0} & -\omega_{\mathbf{z}} & \omega_{\mathbf{y}} \\ \omega_{\mathbf{z}} & \mathbf{0} & -\omega_{\mathbf{x}} \\ -\omega_{\mathbf{y}} & \omega_{\mathbf{x}} & \mathbf{0} \end{pmatrix},\tag{\text{F47}}
$$

where ω*x*, ω*y* and ω*z* are components of a pseudovector *ω*. With this notation, we note that Eq. [(F.45)](#page-564-1) is the matrix representation of **v** = ω × **r**. Furthermore,

<span id="page-565-0"></span>
$$
v^2 = \mathbf{v} \cdot \mathbf{v} = \dot{\mathbf{x}}^T \dot{\mathbf{x}} = \mathbf{x}^T \dot{A}^T \dot{A} \dot{A}^T \mathbf{A} \mathbf{x} = \mathbf{x}^T \boldsymbol{\omega}^T \boldsymbol{\alpha} \mathbf{x}.\tag{\text{F48}}$$

Matrix multiplication shows readily that ωTω is a symmetric matrix with components

$$(\boldsymbol{\omega}^{\mathrm{T}}\boldsymbol{\omega})_{a\boldsymbol{\beta}} = \delta_{a\boldsymbol{\beta}} - \boldsymbol{\alpha}_{a}\boldsymbol{\alpha}_{\boldsymbol{\beta}},\tag{\text{F49}}$$

where δαβ is the Kronecker delta (elements of the unit matrix). Inserting this result in Eq. [(F.48)](#page-565-0) with *x* now corresponding to the *i*th point of a rigid body, multiplying by the mass *mi* and a factor of 1/2 and summing over all points of the body, one obtains the kinetic energy

$$T = \frac{1}{2} \sum_{\mu\nu} \omega_{\mu} \mathcal{Z}_{\mu\nu} \omega_{\nu} \tag{\text{E.50}}$$

which is equivalent to Eq. [(F.14)](#page-560-2).

A similar equation can be obtained in terms of the primed coordinates by returning to Eq. [(F.45)](#page-564-1) to obtain *v* 2 = *x*TωTω *x* , where the antisymmetric matrix

$$A\dot{A}^{\mathrm{T}} \equiv \omega^{\prime} = \begin{pmatrix} \mathbf{0} & -\boldsymbol{\alpha}_{\mathcal{Z}^{\prime}} & \boldsymbol{\alpha}_{\mathcal{Y}^{\prime}} \\ \boldsymbol{\alpha}_{\mathcal{Z}^{\prime}} & \mathbf{0} & -\boldsymbol{\alpha}_{\mathcal{X}^{\prime}} \\ -\boldsymbol{\alpha}_{\mathcal{Y}^{\prime}} & \boldsymbol{\alpha}_{\mathcal{X}^{\prime}} & \mathbf{0} \end{pmatrix}. \tag{\text{F.51}}$$

Here, ω*x* , ω*y* , and ω*z* are to be regarded as the components of a pseudovector *ω* . Then by the same reasoning as in the unprimed case,

$$T = \frac{1}{2} \sum_{\mu'v'} \alpha_{\mu'} \mathcal{Z}_{\mu'v'} \alpha_{v'},\tag{\text{F.52}}$$

where the components of the moment of inertia tensor *I*μν are evaluated in the primed frame, which rotates with the rigid body, and are therefore independent of time. If the axes in the primed frame are chosen as principal axes of the body, then

$$T = \frac{1}{2} (\mathcal{L}_1 \omega_1^2 + \mathcal{L}_2 \omega_2^2 + \mathcal{L}_3 \omega_3^2) \tag{\text{F.53}}$$

as in Eq. [(F.37)](#page-563-3).

The transformation from the matrix ω to the matrix ω is a similarity transformation because

$$
\omega' = A\dot{A}^T = A\dot{A}^T A A^T = A\omega A^T.\tag{\text{E.54}}
$$

By expressing the antisymmetric matrices ω and ω in terms of the Levi-Cavita symbols αβγ , a rather lengthy calculation shows that

$$
\omega_{\alpha}^{\prime} = \det A \sum_{\lambda} A_{\alpha\lambda} \omega_{\lambda} \tag{\text{F.55}}
$$

which defines the transformation of a pseudovector. For the matrix *A* given by Eq. [(F.43)](#page-564-2), det *A* = 1 so ω transforms as a vector.

It remains to express the components of ω and ω in terms of the Euler angles and their time derivatives. This can be done in a straightforward way by appealing to the matrix formulation just described. Thus we have

$$
\omega = \dot{A}^T A = (\dot{D}^T C^T B^T + D^T \dot{C}^T B^T + D^T C^T \dot{B}^T) BCD \tag{E56}
$$

and

$$
\boldsymbol{\alpha}' = \mathbf{A}\dot{\mathbf{A}}^{\mathrm{T}} = \mathbf{B}\mathbf{C}\mathbf{D}(\dot{\mathbf{D}}^{\mathrm{T}}\mathbf{C}^{\mathrm{T}}\mathbf{B}^{\mathrm{T}} + \mathbf{D}^{\mathrm{T}}\dot{\mathbf{C}}^{\mathrm{T}}\mathbf{B}^{\mathrm{T}} + \mathbf{D}^{\mathrm{T}}\mathbf{C}^{\mathrm{T}}\dot{\mathbf{B}}^{\mathrm{T}}).\tag{\text{E57}}$$

After an exercise in matrix algebra, we deduce

$$\boldsymbol{\alpha}_{\text{\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text}} = \sin\theta\,\sin\phi\,\dot{\psi} + \cos\phi\,\dot{\theta}; \quad \boldsymbol{\alpha}_{\text{\text\textquotestextquad\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\text\$$

and

<span id="page-566-0"></span>
$$
\omega_{\mathcal{X}'} = \sin\theta\,\sin\psi\,\dot{\phi} + \cos\psi\,\dot{\theta}; \quad \omega_{\mathcal{Y}'} = \sin\theta\,\cos\psi\,\dot{\phi} - \sin\psi\,\dot{\theta}; \quad \omega_{\mathcal{Z}'} = \cos\theta\,\dot{\phi} + \dot{\psi}.\tag{F.59}
$$

*The results in the current section are used in Section 20.7 to calculate the classical partition functions of polyatomic molecules*.

### F.7 Canonical Variables

For a free rotator, we are now in the position to write the Hamiltonian in the form

$$\mathcal{H} = \frac{1}{2} (\mathcal{T}_1 \alpha_1^2 + \mathcal{T}_2 \alpha_2^2 + \mathcal{T}_3 \alpha_3^2),\tag{\text{E.60}}$$

where ω1 ≡ ω*x* , ω2 ≡ ω*y* , ω3 ≡ ω*z* are given by Eq. [(F.59)](#page-566-0) with *x* , *y* , *z* understood to correspond to the *principal* axes in the rotating frame of reference. The canonical momenta *p*φ, *p*θ , *p*ψ conjugate to the three Euler angles φ, θ, ψ may be found by differentiation[5:](#page-566-1)

$$p_{\phi} = \frac{\partial \mathcal{H}}{\partial \dot{\phi}} = \mathcal{I}_1 \omega_1 \sin \theta \sin \psi + \mathcal{I}_2 \omega_2 \sin \theta \cos \psi + \mathcal{I}_3 \omega_3 \cos \theta$$

$$= L_1 \sin \theta \sin \psi + L_2 \sin \theta \cos \psi + L_3 \cos \theta. \tag{561}$$

Here, *L*1, *L*2, *L*3 are the principal angular momenta, which are components of the vector **L** given by Eq. [(F.28)](#page-562-1). Similarly,

$$p_{\theta} = \frac{\partial \mathcal{H}}{\partial \dot{\theta}} = \mathcal{Z}_1 \omega_1 \cos \psi - \mathcal{Z}_2 \omega_2 = L_1 \cos \psi - L_2 \sin \psi \tag{E62}$$

and

$$p_{\psi} = \frac{\partial \mathcal{H}}{\partial \dot{\psi}} = \mathcal{I}_3 \omega_3 = L_3. \tag{F63}$$

In terms of the principal angular momenta, the Hamiltonian may be written

<span id="page-566-2"></span>
$$\mathcal{H} = \frac{L_1^2}{2\mathcal{Z}_1} + \frac{L_2^2}{2\mathcal{Z}_2} + \frac{L_3^2}{2\mathcal{Z}_3}. \tag{E64}$$

<span id="page-566-1"></span>5Since we are only dealing with the kinetic energy, *H* = *L*, where *L* is the Lagrangian.

### <span id="page-567-0"></span>F.8 Quantum Energy Levels for Diatomic Molecule

The quantum energy levels associated with a Hamiltonian of the form of Eq. [(F.64)](#page-566-2) are rather tricky to calculate because the angular momenta *L*1 and *L*2 relate to a rotating coordinate system and because the vanishing of *I*3 is only an approximation based on the assumption that each atom can be considered to be a point particle. To better understand this problem, we examine the more general case in which the kinetic energy is given by Eq. [(F.64)](#page-566-2) with *I*1 = *I*2 ≡ *I* and *I*3 *I* but *I*3 = 0. This is the problem of a symmetrical top and is treated by Landau and Lifshitz [66, p. 383]. The Hamiltonian is

$$\mathcal{H} = \frac{L_1^2 + L_2^2}{2\mathcal{T}} + \frac{L_3^2}{2\mathcal{T}_3} = \frac{L^2}{2\mathcal{T}} + \frac{L_3^2}{2} \left(\frac{1}{\mathcal{I}_3} - \frac{1}{\mathcal{I}}\right),\tag{5.65}$$

where *L*2 = *L*2 1 +*L*2 2 +*L*2 3. They proceed to show that the commutation relations among the *Li* are the same as for a non-rotating coordinate system except for complex conjugation, which has no effect on the energy eigenvalues. Thus the eigenvalues of *L*2 are*h*¯ 2*j*(*j*+1) and those of *L*2 3 are *h*¯ 2*k*2, where *k* = −*j*, ... , −1, 0, 1, ... , *j*. The energy eigenvalues are therefore

$$
\varepsilon_{jk} = \frac{\hbar^2}{2\mathcal{T}} j(\mathbf{j} + 1) + \frac{\hbar^2}{2} \left(\frac{1}{\mathcal{Z}_3} - \frac{1}{\mathcal{I}}\right) k^2. \tag{E.66}
$$

Since ±*k* lead to the same energy, all levels except for *k* = 0 are at least two-fold degenerate. *But for I*3 ≈ 0*, all levels except for k* = 0 *are extremely large! They are so large, in fact, that they are not excited at any reasonable temperature before the molecule dissociates. So one ordinarily just ignores these levels and deals only with*

$$s_{j0} = \frac{\hbar^2}{2\mathcal{T}}\mathbf{j}(\mathbf{j}+1),\tag{\text{F.67}}$$

*which is the result quoted in the text,* Eqs. (18.82) and (21.150). Moreover, with only *k* = 0, these levels would appear to be non-degenerate. But here, the rotating coordinate system comes into play. It introduces a degeneracy of 2*j* + 1 associated with the orientation of these angular momenta with respect to a fixed coordinate system [66, footnote on p. 384]. This is, finally, in agreement with the results quoted in the text and often related to a strictly two-dimensional analysis.

This page intentionally left blank

G

# Thermodynamic Perturbation Theory

For most problems in statistical mechanics, an exact analytical solution is impossible to obtain, so we need methods to obtain approximate solutions. Fortunately, there are many problems of interest in which the Hamiltonian can be expressed in the form

$$\mathcal{H} = \mathcal{H}_0 + V \tag{G.1}$$

in which an exact solution is known for the unperturbed Hamiltonian *H*0 and where *V* is a small correction, in a sense to be clarified below. Under these circumstances, it is possible to obtain an approximate solution in terms of averages of powers of *V* with respect to a Boltzmann distribution for the unperturbed Hamiltonian.

This technique is called thermodynamic perturbation theory, which is a mixture of perturbation theory and thermodynamic ensemble averaging. In this appendix, we discuss this topic in the context of the canonical ensemble. We first take up the classical case and then the quantum case, which requires slightly different considerations. We follow closely a treatment by Landau and Lifshitz [7, p. 93].

### G.1 Classical Case

We write

$$\mathcal{H}(\mathbf{p}, \mathbf{q}) = \mathcal{H}\mathbf{o}(\mathbf{p}, \mathbf{q}) + V(\mathbf{p}, \mathbf{q}) \tag{G.2}$$

and express the classica[l1](#page-569-0) canonical partition function in the form

$$Z_{\mathbb{C}}(\beta) = \int \mathbf{e}^{-\beta \mathcal{H}(p,q)} \, \mathrm{d}\omega = \int \mathbf{e}^{-\beta [\mathcal{H}_0(p,q) + V(p,q)]} \, \mathrm{d}\omega,\tag{\text{G.3}}$$

where *p* and *q* are each 3*N* -dimensional vectors and *d*ω represents the volume element in this 6*N* -dimensional phase space. We then expand the second exponential in powers of *V* to second order to obtain

$$Z_{\mathbb{C}}(\beta) = \int \mathbf{e}^{-\beta \mathcal{H}_0(p,q)} \left[ 1 - \beta V(p,q) + \frac{(\beta V(p,q))^2}{2} \right] \, \mathrm{d}\omega. \tag{G.4}$$

<span id="page-569-0"></span><sup>1</sup>To agree with quantum mechanics, we need to divide *ZC* by *h*3*N* for *N* particles or by *h*3*N N* ! for identical indistinguishable particles, as in the case of a dilute ideal gas. Here we omit those factors for simplicity.

$$
\langle B \rangle_0 := \frac{\int \mathbf{e}^{-\beta \mathcal{H}_0(p, q)} B(p, q) \, \mathrm{d}\omega}{\int \mathbf{e}^{-\beta \mathcal{H}_0(p, q)} \, \mathrm{d}\omega}. \tag{G.5}
$$

550 THERMAL PHYSICS

$$Z_{\mathbb{C}}(\beta) = Zo(\beta)\left[1 - \beta \langle V \rangle o + (1/2)\,\beta^2 \langle V^2 \rangle o\right],\tag{G.6}$$

We define an averaging process of any quantity *B*(*p*, *q*) with respect to the unperturbed distribution as follows:

> -*B*0 :=

$$\text{Zo}(\beta) := \int \mathbf{e}^{-\beta \mathcal{H}o(p,q)} \, \mathbf{d}\alpha. \tag{G.7}$$

Then Eq. (G.4) takes the form *ZC*(β) = *Z*0(β) 1 − β-*V*0 + (1/2) β2-*V*20 , (G.6)

$$F = F_0 - k_\mathrm{B} T \ln \left[ 1 - \beta \langle V \rangle_0 + (1/2) \beta^2 \langle V^2 \rangle_0 \right] = F_0 + \langle V \rangle_0 - (1/2) \beta \langle V^2 \rangle_0 + (1/2) \beta^2 \langle V \rangle_0^2,\tag{G.8}$$

*Z*0(β) := e−β*H*0(*p*,*q*) dω. (G.7) We now use the formula for the Helmholtz free energy *F* = −*k*B*T* ln *ZC* to obtain, again to

<span id="page-570-0"></span>
$$F = F_0 + \langle V \rangle_0 - \frac{\langle (V - \langle V \rangle_0)^2 \rangle_0}{2k_B T}. \tag{G.9}$$

where *F*0 = −*k*B*T* ln *Z*0 is the unperturbed Helmholtz free energy. This result can be written in the form *F* = *F*0 + -*V*0 − -(*V* − -*V*0)20 2*k*B*T* . (G.9)

Equation (G.9) shows that the free energy is first changed by the average value of *V* and

### then diminished by a second-order term proportional to the variance of *V*. Both the mean and the variance are proportional to *N* , so the condition for the validity of the expansion

1 − β-

second order in *V*,

Eq. (G.1) are

system, *E*0

*F* = *F*0 − *k*B*T* ln

is that *V* per particle be small compared to *k*B*T*. G.2 Quantum Case

$$E_n = E_n^0 + V_{nn} + \sum_{m \neq n} \frac{|V_{nm}|^2}{E_n^0 - E_m^0},\tag{G.10}$$

*En* = *E*0 *n* + *Vnn* + *m*=*n* |*Vnm*| 2 *E*0 *n* − *E*0 *m* , (G.10) where *n* stands for a set of quantum numbers that label the unperturbed states of the

*n*

$$Z(\beta) = \sum_{n} \mathbf{e}^{-\beta E_{0}} = \sum_{n} \mathbf{e}^{-\beta E_{n}^{0}} \left[ 1 - \beta V_{nn} - \beta \sum_{m \neq n} \frac{|V_{nm}|^{2}}{E_{n}^{0} - E_{m}^{0}} + (1/2)\beta^{2}V_{nn}^{2} \right] \tag{G.11}$$
 
$$\text{to aocond order in } V \text{ and define a quantum quasoaring numooca.}$$

*n n* ⎣1 − β*Vnn* − β *m*=*n E*0 *n* − *E*0 *m*

<span id="page-570-1"></span>-

$$(T_h)_0 := \frac{\sum_n \mathbf{e}^{-\beta E_n^0} T_n}{\sum_n \mathbf{e}^{-\beta E_n^0}}.\tag{G.12}$$

*nn*

$$Z(\beta) = Z_0(\beta) \left[ 1 - \beta \langle V_{nn} \rangle_0 - \beta \left\langle \sum_{m \neq n} \frac{|V_{nm}|^2}{E_n^0 - E_m^0} + (1/2)\beta^2 V_{nn}^2 \right\rangle_0 \right],\tag{G.13}$$

*Appendix G* • Thermodynamic Perturbation Theory 551

where

$$Z_0(\beta) = \sum_n \mathbf{e}^{-\beta E_n^0}.\tag{\text{G.14}}$$

<span id="page-571-0"></span>⎤

*m*

*n* . (G.18)

⎡ 

Then the partition function becomes

$$F = F\mathbf{o} + \langle V_{mn}\rangle \mathbf{o} + \left\langle \sum_{m \neq n} \frac{|V_{nm}|^2}{E_n^0 - E_m^0} \right\rangle_0 - (1/2)\beta \langle V_{mn}^2 \rangle \mathbf{o} + (1/2)\beta \langle V_{mn} \rangle_0^2,\tag{G.15}$$

2

*Z*0(β) = e−β*E*0 *n* . (G.14)

*n*

$$F = F_0 + \langle V_{nm} \rangle_0 + \left\langle \sum_{m \neq n} \frac{|V_{nm}|^2}{E_n^0 - E_m^0} \right\rangle_0 - \frac{\langle (V_{nn} - \langle V_{nm} \rangle \mathbf{o})^2 \rangle_0}{2k\mathfrak{g}T} \tag{\text{G.16}}$$

*F* = *F*0 + *m*=*n E*0 *n* − *E*0 *m* 0 where *F*0 = −*k*B*T* ln *Z*0. This last result can be rewritten in the form

$$\begin{split} \left< \sum_{m \neq n} \frac{|V_{nm}|^2}{E_n^0 - E_m^0} \right>_0 &= \frac{1}{Z_0} \sum_n \sum_m \frac{|V_{nm}|^2}{E_n^0 - E_m^0} \mathbf{e}^{-\beta E_n^0} = \frac{1}{Z_0} \sum_m \sum_{n \neq m} \frac{|V_{nm}|^2}{E_m^0 - E_n^0} \mathbf{e}^{-\beta E_m^0} \\ &= -\frac{1}{2Z_0} \sum_n \sum_{m \neq n} \frac{|V_{nm}|^2}{E_n^0 - E_m^0} \left( \mathbf{e}^{-\beta E_m^0} - \mathbf{e}^{-\beta E_n^0} \right). \end{split} \tag{6.17}$$
 
$$\dots \mathbf{0} \qquad \dots \qquad \dots \qquad .$$

 *m*=*n E*0 *n* − *E*0 *m* 0 *Z*0 *n m*=*n E*0 *n* − *E*0 *m* e−β*E*0 *Z*0 *m n*=*m E*0 *m* − *E*0 *n* e−β*E*0 = − 1 |*Vnm*| 2 e−β*E*0 *m* − e−β*E*0 *n* . (G.17)

2*Z*0 *n m*=*n E*0 *n* − *E*0 *m* Since e−β*E*0 *m* [−](#page-571-0) e−β*E*0 *n* and *E*0 *n* − *E*0 *m* have the same sign, this extra term is negative, so *both*

> ≈ − 1 2*kT*

2*kT*

⎣

*m*=*n*

$$-\frac{1}{2}\sum_{n}\sum_{m\neq n}\frac{|V_{nm}|^2}{E_n^0 - E_m^0} \left(\mathbf{e}^{-\beta E_m^0} - \mathbf{e}^{-\beta E_n^0}\right) = -\frac{1}{2}\sum_{n}\sum_{m\neq n} \frac{|V_{nm}|^2}{E_n^0 - E_m^0} \mathbf{e}^{-\beta E_n^0} \left(\mathbf{e}^{-\beta(E_m^0 - E_n^0)} - 1\right)$$

$$\approx -\frac{1}{2kT} \sum_{n}\sum_{m\neq n} |V_{nm}|^2 \mathbf{e}^{-\beta E_n^0}.\tag{G.18}$$

|*Vnm*|

−1 2

elements of the matrix *A*.

$$F = F_0 + \langle V_{nn} \rangle_0 - \frac{1}{2kT} \left[ \left\langle \sum_{m \neq n} |V_{nm}|^2 + \left(V_{nn} - \langle V_{nn} \rangle_0\right)^2 \right\rangle_0 \right]. \tag{G.19}$$

0

2e−β*E*0

2In making this identification, note that *n m*=*n Amn* = *m n*=*m Anm* = the sum of all off-diagonal

$$\frac{1}{Z_0} \sum_n \mathbf{e}^{-\beta E_n^0} \left[ \sum_{m \neq n} |V_{nm}|^2 + V_{nn}^2 - \langle V_{nn} \rangle_0^2 \right]. \tag{G.20}$$

552 THERMAL PHYSICS

⎡

*[n](#page-572-0)n* =

$$\sum_{m \neq n} |V_{nm}|^2 + V_{nn}^2 = \sum_{m \neq n} V_{nm} V_{nm}^* + V_{nn}^2 = \sum_{m \neq n} V_{nm} V_{mn} + V_{nn}^2 = \sum_m V_{nm} V_{mn} = (V^2)_{nn}.\tag{G.21}$$

*nn* = 

$$\frac{1}{Z_0} \sum_n \mathbf{e}^{-\beta E_n^0} \left[ (V^2)_{nn} - (V_{nn})_0^2 \right] = \langle (V^2)_{nn} \rangle_0 - \langle V_{nn} \rangle_0^2 \tag{G.22}$$

*Vnn* 2

⎤

 |*Vnm*| 2 + *V*2 *nn* = *VnmV*∗ *nm* + *V*2

Thus Eq. (G.20) reduces to

*m*=*n*

*m*=*n*

$$F = F_0 + \langle V_{nn} \rangle_0 - \frac{\langle (V - \langle V_{nn} \rangle 0)_{nn}^2 \rangle_0}{2k_{\rm B}T} \tag{G.23}$$

<span id="page-572-0"></span>*VnmVmn* =(*V*2)*nn*. (G.21)

0 (G.22)

1 e−β*E*0 *n* (*V*2)*nn* − -*Vnn* 2 0 = -(*V*2)*nn*0 − -

*Z*0 *n* and Eq. (G.16) takes the form

*VnmVmn* + *V*2

$$Z_0(\beta) = \sum_n \mathbf{e}^{-\beta E_n^0} = \text{tr } \mathbf{e}^{-\beta \mathcal{H}_0}.\tag{\text{G.24}}$$

which is similar to Eq. (G.9) for the classical c[ase.](#page-570-1) Finally, we remark that Eq. (G.23) can be expressed in an invariant form by using

ρˆ

*Z*0(β) =

$$
\hat{\rho}^0 = \frac{\mathbf{e}^{-\beta \mathcal{H}o}}{\text{tr}\,\mathbf{e}^{-\beta \mathcal{H}o}}.\tag{\text{G.25}}
$$

*n* Furthermore, we can introduce [the un](#page-571-0)perturbed density operator

In this approximate form of Eq. (G.16) it is more obvious that the second-order correction

$$
\langle \mathcal{O} \rangle_0 = \text{tr } (\hat{\rho}^0 \mathcal{O}) \tag{G.26}
$$

Then the averaging process expressed by Eq. (G.12) can be written in the form

to *F* is negative, as in the classical case.

$$F = F_0 + \text{tr}\left(\hat{\rho}^0 V\right) - \frac{\text{tr}\left\{\hat{\rho}^0 [V - \text{tr}\left(\hat{\rho}^0 V\right)]^2\right\}}{2k_\text{B}T}. \tag{G.27}$$

for any operator *O*. Thus *F* = *F*0 + tr (ρˆ 0*V*) − tr ρˆ0[*V* − tr (ρˆ0*V*)] 2 2*k*B*T* . (G.27)

H Selected Mathematical Relations

### employed in the text. We concentrate on simplicity of presentation and refer the reader to the mathematical literature for rigorous proofs. We first define Bernoulli numbers and

In this appendix we develop and summarize selected mathematical relations that are

Bernoulli polynomials to clarify conventions used in the literature. Then we state the Euler-Maclaurin sum formula in general terms, specialize it to approximate infinite sums with integrals, and give examples of its use in computing partition functions. H.1 Bernoulli Numbers and Polynomials

### Bernoulli numbers frequently appear as coefficients in the representation of integrals by

*t*

by the integral representations [92, p. 126]1

simplifying the integrand.

H.1.1 Bernoulli Numbers

asymptotic series as well as in formulae for the correction terms used to approximate infinite sums by integrals. Unfortunately there are alternative definitions and conventions used to define Bernoulli numbers and the associated Bernoulli polynomials.

$$\begin{split} \frac{z}{2} \cot \frac{z}{2} &= 1 - B_1 \frac{z^2}{2!} - B_2 \frac{z^4}{4!} - B_3 \frac{z^6}{6!} - \cdots \\ &= 1 - \sum_{n=1}^{\infty} B_n \frac{z^{2n}}{(2n)!} . \end{split} \tag{H.1}$$

2 cot 2 = 1 − *B*1 2! − *B*2 4! − *B*3 6! ∞ *z*2*n*

*z*

*z*

$$\begin{split} \frac{t}{\mathbf{e}^t - 1} = -\frac{t}{2} + \frac{t}{2i} \cot \frac{t}{2i} &= 1 - \frac{t}{2} + B_1 \frac{t^2}{2!} - B_2 \frac{t^4}{4!} + B_3 \frac{t^6}{6!} - \cdots \\ &= 1 - \frac{t}{2} + \sum_{n=1}^{\infty} (-1)^{n+1} B_n \frac{t^{2n}}{(2n)!}, \end{split} \tag{\text{H.2}}$$

<span id="page-573-0"></span>= 1 − *t* 2 + -∞ *n*=1 (−1) *n*+1*Bn t*2*n* (2*n*)! , (H.2) where the alternations in sign result from *i* 2 = −1. Although it is not obvious from these series expansions, it turns out that all *Bn* are positive numbers which can be established

553

<sup>1</sup>Whittaker and Watson [92] leave the last form as an exercise. It can be obtained by substituting *x* = 2π*t* and then *x* = π*t* in the first integral in Eq. (H.3) to obtain alternative expressions for *Bn*, solving for (22*n* − 1)*Bn* and

<span id="page-574-0"></span>
$$B_{\rm lb} = 4n \int_0^\infty \frac{t^{2n-1}}{\mathbf{e}^{2\pi t} - 1} \, \mathrm{d}t = \frac{2n}{\pi^{2n} (2^{2n} - 1)} \int_0^\infty \frac{\mathbf{x}^{2n-1}}{\sinh \mathbf{x}} \, \mathrm{d}\mathbf{x} > \mathbf{0}.\tag{\text{H.3}}$$

*We use these positive Bn in this book*, for example, *B*1 = 1/6, *B*2 = 1/30, *B*3 = 1/42, *B*4 = 1/30, *B*5 = 5/66, *B*6 = 691/2730, *B*7 = 7/6, etc., from which we note that the sequence is not monotonic.

An alternative set of numbers *B*˜ *n*, also called Bernoulli numbers, can be defined by [98, p. 804]

$$\frac{t}{\mathbf{e}^t - 1} = \sum_{n=0}^{\infty} \vec{B}_n \frac{t^n}{n!}. \tag{\text{H.4}}$$

In this case, *B*˜ 0 = 1, *B*˜ 1 = −1 2 , *B*˜ 2*p*+1 = 0, and *B*˜ 2*p* = (−1) *p*+1*Bp* for *p* ≥ 1. Another convention is *B*∗ *n* = (−1) *n*+1*Bn*.

### H.1.2 Bernoulli Polynomials

Bernoulli polynomials φ*n*(*z*) for *n* ≥ 1 can be defined by [92]

$$\frac{t(\mathbf{e}^{zt} - 1)}{\mathbf{e}^t - 1} = \sum_{n=1}^{\infty} \phi_n(z) \frac{t^n}{(n)!}; \quad |t| < 2\pi. \tag{\text{H.5}}$$

Evidently φ*n*(0) = 0 for all *n* ≥ 1, φ*n*(1) = 0 for *n* > 1, but φ1(1) = 1. From the defining equation one can establish the difference equation

$$
\phi_n(z+1) - \phi_n(z) = nz^{n-1}; \quad n \ge 1. \tag{H.6}
$$

Alternative Bernoulli polynomials *Bn*(*z*) for *n* ≥ 0 can be defined by [98]

$$\frac{t\mathbf{e}^{zt}}{\mathbf{e}^{t}-1} = \sum_{n=1}^{\infty} B_{n}(\mathbf{z}) \frac{t^{n}}{(n)!}; \quad |t| < 2\pi. \tag{\text{H.7}}$$

In this case, *B*0(*z*) = 1 and the remaining polynomials can be shown to satisfy φ*n*(*z*) = *Bn*(*z*) − *B*˜ *n*, *n* ≥ 1, so there is no difference between these polynomials for odd *n* > 1.

### H.2 Euler-Maclaurin Sum Formula

As shown by Whittaker and Watson [92, p. 128] a very general form of the Euler-Maclaurin sum formula can be obtained by using Bernoulli polynomials and a formula due to Darboux. That sum formula is

$$\begin{split} f(\mathbf{z}) - f(\mathbf{a}) &= \frac{1}{2} (\mathbf{z} - \mathbf{a}) \left[ f'(\mathbf{z}) + f'(\mathbf{a}) \right] \\ &+ \sum_{k=1}^{p-1} (-1)^k (\mathbf{z} - \mathbf{a})^{2k} \frac{B_k}{(2k)!} \left[ f^{(2k)}(\mathbf{z}) - f^{(2k)}(\mathbf{a}) \right] \\ &+ \frac{(\mathbf{z} - \mathbf{a})^{2p+1}}{(2p)!} \int_0^1 \phi_{2p}(t) f^{(2p+1)}(\mathbf{a} + t(\mathbf{z} - \mathbf{a})), \end{split} \tag{H.8}$$

$$\begin{split} \int_{a}^{a+\nu} F(\mathbf{x}) \, \mathbf{dx} &= \frac{1}{2} \nu \left[ F(a + \nu) + F(a) \right] \\ &+ \sum_{k=1}^{p-1} (-1)^{k} w^{2k} \frac{B_{k}}{(2k)!} \left[ F^{(2k-1)}(a + \nu) - F^{(2k-1)}(a) \right] \\ &+ \frac{w^{2p+1}}{(2p)!} \int_{0}^{1} \phi \rho(t) F^{(2p)}(a + t\nu) . \end{split} \tag{H.9}$$

 *a*+*w a F*(*x*) d*x* =1 2 *w* [*F*(*a* + *w*) + *F*(*a*)]

*F*(*z*) = *f*

*a*

-

=*a*

-∞

=0

at infinity, we obtain

*b*

$$\int_{a}^{a+r\nu} F(\mathbf{x}) \, d\mathbf{x} = \nu \left[ \frac{1}{2} F(a+r\nu) + F(a+(r-1)\nu) + \dots + F(a+\nu) + \frac{1}{2} F(a) \right]$$

$$+ \sum_{k=1}^{p-1} (-1)^k w^{2k} \frac{B_k}{(2k)!} \left[ F^{(2k-1)}(a+rw) - F^{(2k-1)}(a) \right]$$

$$+ \frac{\nu^{2p+1}}{(2p)!} \int_0^1 \phi_{2p}(t) \sum_{s=0}^{r-1} F^{(2p)}(a+s\nu+tw). \tag{\text{H.10}}$$

+ *k*=1 (−1) *kw*2*k Bk* (2*k*)! *F*(2*k*−1) (*a* + *rw*) − *F*(2*k*−1) (*a*) + *w*2*p*+1 1 φ2*p*(*t*) *r*−1 *F*(2*p*) (*a* + *sw* + *tw*). (H.10)

$$\begin{split} \int_{a}^{a+\tau w} F(\mathbf{x}) \, \mathbf{dx} &= w \sum_{\ell=0}^{r} F(\mathbf{a} + \ell w) - \frac{w}{2} \left[ F(\mathbf{a} + \tau w) + F(\mathbf{a}) \right] \\ &+ \sum_{k=1}^{\infty} (-1)^{k} w^{2k} \frac{B_{k}}{(2k)!} \left[ F^{(2k-1)}(\mathbf{a} + \tau w) - F^{(2k-1)}(\mathbf{a}) \right]. \end{split} \tag{\text{H.11}}$$

*a* =0 +-∞ *k*=1 (−1) *kw*2*k Bk* (2*k*)! *F*(2*k*−1) (*a* + *rw*) − *F*(2*k*−1) (*a*) . (H.11)

$$\sum_{\ell=a}^{b} F(\ell) = \int_{a}^{b} F(\mathbf{x})d\mathbf{x} + \frac{1}{2} \left[ F(a) + F(b) \right]$$

$$+ \sum_{k=1}^{\infty} (-1)^{k} \frac{B_{k}}{(2k)!} \left[ F^{(2k-1)}(a) - F^{(2k-1)}(b) \right]. \tag{H.12}$$

+*k*=1 (−1) (2*k*)! *F*(2*k*−1) (*a*) − *F*(2*k*−1) (*b*) . (H.12) For the frequently occurring case *a* = 0 and *b* = ∞ when both *F* and its derivatives vanish

*k*=1

$$\sum_{\ell=0}^{\infty} F(\ell) = \int_0^{\infty} F(\mathbf{x})d\mathbf{x} + \frac{1}{2}F(\mathbf{0}) + \sum_{k=1}^{\infty} (-1)^k \frac{B_k}{(2k)!} F^{(2k-1)}(\mathbf{0}).\tag{H.13}$$

2

*j*=1

556 THERMAL PHYSICS This formula is only justified if the integral and both series converge. Alternatively, it might give an asymptotic result in some parameter on which *F* depends. H.2.1 Approximate Evaluation of Infinite Sums

$$\sum_{n=0}^{\infty} f(n) = \int_0^{\infty} f(n) \, \mathrm{d}n + \frac{1}{2} f(0) + \sum_{j=1}^{\infty} (-1)^j \frac{B_j}{(2j)!} f^{(2j-1)}(0)$$

$$= \int_0^{\infty} f(n) \, \mathrm{d}n + \frac{1}{2} f(0) - \frac{1}{12} f'(0) + \frac{1}{720} f'''(0) - \frac{1}{30240} f^{(5)}(0) + \dotsb \tag{\text{H.14}}$$

purpose. With the change of notation *F* → *f* , it becomes explicitly -∞ *f* (*n*) = ∞ *f* (*n*) d*n* + 1 *f* (0) +-∞ (−1) *j Bj* (2*j*)! *f* (2*j*−1) (0)

= ∞ 0 *f* (*n*) d*n* + 1 2 *f* (0) − 1 12 *f* (0) + 1 720*f* (0) − 1 30240*f* (5) (0) +··· (H.14) As noted above, this expansion is only justified if the series converges. Otherwise, it might

$$\mathbf{z} = \sum_{j=0}^{\infty} (2j+1) \exp[-j(j+1)\mathbf{x}],\tag{\text{H.15}}$$

(see Eq. (18.83)) *z* = -∞ (2*j* + 1) exp[−*j*(*j* + 1)*x*], (H.15)

*j*=0 where *x* := ε0/*k*B*T*, correct to order (ε0/*k*B*T*)2 at high temperatures. Then compute the corresponding heat capacity.

$$z = \frac{1}{x} + \frac{1}{3} + \frac{x}{15} + \frac{4x^2}{315} + O(x^3). \tag{H.16}$$

$$\ln z = \ln \left[ \frac{1}{x} \left( 1 + \frac{x}{3} + \frac{x^2}{15} + \frac{4x^3}{315} + O(x^4) \right) \right] = -\ln x + \frac{x}{3} + \frac{x^2}{90} + \frac{8x^3}{2835} + O(x^4). \tag{H.17}$$
 
$$\text{e}$$
 
$$\ln$$

*x*

ln *z* = ln

Therefore,

*n*=0

give an asymptotic approximation.

120*x*2 + *O*(*x*3), *f* (7)(0) = *O*(*x*3). Thus

1 *x* 1 + *x*

0

$$c = \frac{\partial}{\partial T} \left( -\frac{\partial \ln z}{\partial \beta} \right) = k_{\mathbb{B}} \mathbf{x}^2 \frac{\partial^2 \ln z}{\partial \mathbf{x}^2} = k_{\mathbb{B}} \left( 1 + \frac{\mathbf{x}^2}{45} + \frac{16\mathbf{x}^3}{945} + O(\mathbf{x}^4) \right),\tag{\text{H.18}}$$

*c* = ∂ ∂*T* −∂ ln *z* ∂β  = *k*B*x*2 ∂2 ln *z* ∂*x*2 = *k*B 1 + 45 + 945 + *O*(*x*4) , (H.18) which shows clearly that *c* asymptotes *k*B from larger values as *T* → ∞, as is evident from Figure 18–12. Although the trend is clear, the accuracy is poor unless *x* is very small, so the series appears to be asymptotic in ε0/*k*B*T* as *T* → ∞. It has no hope of representing *c* near *T* = 0 where the leading term is *c* = *x*2e−2*x* as *x* → ∞.

 = −ln *x* +

$$\begin{split} \sum_{n=0}^{\infty} \mathbf{g}(n+a) &= \int_{0}^{\infty} \mathbf{g}(n+a) \, \mathrm{d}n + \frac{1}{2} \mathbf{g}(a) + \sum_{j=1}^{\infty} \frac{B_{j}}{(2j)!} \mathbf{g}^{(2j-1)}(a) \\ &= \int_{0}^{\infty} \mathbf{g}(n+a) \, \mathrm{d}n + \frac{1}{2} \mathbf{g}(a) - \frac{1}{12} \mathbf{g}'(a) + \frac{1}{720} \mathbf{g}'''(a) - \frac{1}{30240} \mathbf{g}^{(5)}(a) + \cdots \ . \end{split} \tag{\text{H.19}}$$

In some applications the function *f* (*n*) = *g*(*n* + α), where 0 ≤ α < 1, with α = 1/2 of

∞

special importance. In that case, Eq. (H.14) becomes

<span id="page-577-0"></span>
$$\int_0^\infty \mathbf{g}(n+a) \,\mathrm{d}n = \int_a^\infty \mathbf{g}(\mathbf{x}) \,\mathrm{d}\mathbf{x} = \int_0^\infty \mathbf{g}(\mathbf{x}) \,\mathrm{d}\mathbf{x} - \int_0^a \mathbf{g}(\mathbf{x}) \,\mathrm{d}\mathbf{x}.\tag{\text{H.20}}$$

= ∞ 0 *g*(*n* + α) d*n* + 1 2 *g*(α) − 1 12*g* (α) + 1 720*g*(α) − 1 30240*g*(5) (α) +··· . (H.19)

$$\int_0^a \mathbf{g}(\mathbf{x})d\mathbf{x} = \int_0^a \sum_{r=0}^\infty \mathbf{g}^{(r)}(\mathbf{0}) \frac{\mathbf{x}^r}{r!} = \sum_{r=0}^\infty \mathbf{g}^{(r)}(\mathbf{0}) \frac{a^{r+1}}{(r+1)!}.\tag{\text{H.21}}$$

In the last integral, we expand *g*(*x*) in a series about *x* = 0 and integrate term by term to obtain ∞

$$\sum_{n=0}^{\infty} \mathbf{g}(n+a) = \int_0^{\infty} \mathbf{g}(\mathbf{x}) d\mathbf{x} + \left(\frac{1}{2} - a\right) \mathbf{g}(\mathbf{0}) + \left(-\frac{1}{12} + \frac{a}{2} - \frac{a^2}{2}\right) \mathbf{g}'(\mathbf{0})$$

$$+ \left(-\frac{a}{12} + \frac{a^2}{4} - \frac{a^3}{6}\right) \mathbf{g}''(\mathbf{0}) + \left(\frac{1}{720} - \frac{a^2}{24} + \frac{a^3}{12} - \frac{a^4}{24}\right) \mathbf{g}'''(\mathbf{0}) + \cdots \quad\dots \quad\text{(H.22)}$$

*n*=0 *g*(*n* + α) = ∞ 0 *g*(*x*)*dx* + 1 2 − α *g*(0) + − 1 12 + α 2 − α2 2 *g* (0) − α 1

(0) − 7

$$\begin{aligned} \text{ann } \mathbf{u} &\text{ann } \\ \sum_{n=0}^{\infty} \mathbf{g}(n + \frac{1}{2}) &= \int_{0}^{\infty} \mathbf{g}(\mathbf{x}) \, \mathbf{dx} + \frac{1}{24} \mathbf{g}'(\mathbf{0}) - \frac{7}{5760} \mathbf{g}'''(\mathbf{0}) + \cdots \, \, . \end{aligned} \tag{H.23}$$

left with

obtain

∞

-∞

*g*(*n* + α) =

 ∞ 0

> ∞ 0

+

-∞

*g*(*n* + 1

2 ) =

 ∞ 0

∞

*n*=0

*n*=0

 ∞ 0

*g*(*x*) d*x* +

1 24*g*

$$\sum_{n=0}^{\infty} \exp[-\mathbf{y}(n + \frac{1}{2})] = \frac{\mathbf{e}^{-\mathbf{y}/2}}{1 - \mathbf{e}^{-\mathbf{y}}} \tag{\text{H.24}}$$

5760*g*(0) +··· . (H.23)

*n*=0 exp[−*y*(*n* + 1 2 )] = 1 − e−*y* (H.24) for *y* 1 and compare with the exact result (right-hand side) which was obtained by summing

the geometric series.

**Solution H.2.** The leading term is

$$\int_0^\infty \mathbf{e}^{-\mathbf{y}\cdot\mathbf{x}} \, \mathbf{dx} = \frac{1}{\mathbf{y}}.\tag{\text{H.25}}$$

$$\begin{aligned} \mathbf{g}^{\prime\prime}(0) &= -\mathbf{y} \text{ and } \mathbf{g}^{\prime\prime}(0) = -\mathbf{y}^3 \text{ so} \\ &\sum_{n=0}^{\infty} \exp[-\mathbf{y}(n + \frac{1}{2})] = \frac{1}{\mathcal{Y}} - \frac{\mathcal{Y}}{24} + \frac{7\mathcal{Y}^3}{5760} + \dotsb \end{aligned} \tag{\text{H.26}}$$

Expanding the exact result gives

$$\frac{\mathbf{e}^{-\mathbf{y}/2}}{1-\mathbf{e}^{-\mathbf{y}}} = \frac{1}{\mathbf{y}} - \frac{\mathbf{y}}{24} + \frac{7\mathbf{y}^3}{5760} - \frac{31\mathbf{y}^5}{967680} + O(\mathbf{y}^7). \tag{H.27}$$

I

# Creation and Annihilation Operators

In this appendix we derive some properties of creation and annihilation operators *a* and *a*† that are useful in quantum mechanics and statistical mechanics. They are also used to express the operators of quantized fields in terms of expansions. We first motivate the operators used to treat bosons by appealing to the quantum treatment of the simple harmonic oscillator in a straightforward way. Then, having established the commutation relations for *a* and *a*†, we derive by purely algebraic operations their properties as they act on vectors in a Hilbert space. We then relate back to the quantum harmonic oscillator and derive a few useful expressions for the coordinate and momentum operators, *x* and *p*. Finally, we introduce the corresponding operators used to create bosons and fermions as well as eigenstates for systems containing many of them.

### I.1 Harmonic Oscillator

We consider a simple one-dimensional harmonic oscillator of mass *m* and frequency ω described by the Hamiltonian

$$\mathcal{H} = \frac{p^2}{2m} + \frac{m\omega^2}{2}\mathbf{x}^2,\tag{\text{I.1}}$$

where *p* and *x* are operators that satisfy the well-known commutation relations

$$\mathbf{r}\cdot[\mathbf{p},\mathbf{x}] \equiv (p\mathbf{x} - \mathbf{x}\mathbf{p}) = -i\hbar.\tag{1.2}$$

Of course *p* = *p*† and *x* = *x*† are Hermitian, where the superscript † denotes the Hermitian conjugate.

We introduce the dimensionless creation operator

<span id="page-579-0"></span>
$$a = \left(\frac{m\omega}{2\hbar}\right)^{1/2} \left(\mathbf{x} + \frac{i}{m\omega}\boldsymbol{p}\right) \tag{\text{I.3}}$$

and its Hermitian conjugate

<span id="page-579-1"></span>
$$a^\dagger = \left(\frac{m\omega}{2\hbar}\right)^{1/2} \left(\mathbf{x} - \frac{\mathbf{i}}{m\omega}\,\mathbf{p}\right) \tag{\text{I.4}}$$

which will play the role of an annihilation operator. Then the commutator

$$[a, a^\dagger] = \frac{i}{m\omega} \frac{m\omega}{2\hbar} ([p, x] - [\mathbf{x}, p]) = 1\tag{1.5}$$

$$
\hbar\omega\,aa^\dagger = \frac{p^2}{2m} + \frac{m\omega^2}{2}\mathbf{x}^2 + \hbar\omega\tag{\text{I.6}}
$$

$$
\hbar\omega\,a^\dagger a = \frac{p^2}{2m} + \frac{m\omega^2}{2}\mathbf{x}^2 - \hbar\omega,\tag{1.7}
$$

and of course [*a*, *a*] = 0 and [*a*†, *a*†] = 0. Then a little algebra shows that

560 THERMAL PHYSICS

$$\mathcal{H} = \frac{1}{2}\hbar\omega(aa^\dagger + a^\dagger a) = \hbar\omega(aa^\dagger - \frac{1}{2}) = \hbar\omega(a^\dagger a + \frac{1}{2}).\tag{1.8}$$

and *h*¯ω *a*†*a* = *p*2 2*m* + *m*ω2 2 *x*2 − *h*¯ ω, [(I.7)](#page-579-0) whic[h](#page-579-1) [ca](#page-579-1)n be added to deduce *H* = 1 *h*¯ω(*aa*† + *a*†*a*) = *h*¯ ω(*aa*† − 1 ) = *h*¯ω(*a*†*a* + 1 ). (I.8)

2 2 2 As will be shown below, the eigenvalues of *a*†*a* are the integers *n* = 0, 1, 2, 3, ... and the eigenvalues of *aa*† are also integers *q* = 1, 2, 3, ... , starting at one instead of zero. The

$$x = \left(\frac{2\hbar}{m\omega}\right)^{1/2}\frac{a+a^\dagger}{2}; \quad p = \frac{m\omega}{i}\left(\frac{2\hbar}{m\omega}\right)^{1/2}\frac{a-a^\dagger}{2} \tag{1.9}$$

Schrödinger wave functions. Before leaving this section, we note a few useful relations. The inverses of Eqs. (I.3)

*x* =

 2*h*¯ *m*ω

$$x^2 = \frac{\hbar}{m\omega} \left( a^\dagger a + \frac{1}{2} + \frac{aa + a^\dagger a^\dagger}{2} \right) \tag{1.10}$$

and a little algebra shows that

λ, we have

and (I.4) are

$$p^2 = m\hbar\omega\left(a^\dagger a + \frac{1}{2} - \frac{aa + a^\dagger a^\dagger}{2}\right) \tag{1.11}$$

and *a*†*a* + 2 − *aa* + *a*†*a*† 

1

*p*2 = *mh*¯ ω

### which, of course, are Hermitian. These results are used in Section 26.6.2.

I.2 Boson Operators We proceed to find the eigenvalues of the Hermitian operators *aa*† and *a*†*a*. From the commutator Eq. (I.5), we see that *aa*† = *a*†*a* + 1, so multiplication from the left and then from the right by *a*†*a* shows that the operators *a*†*a* and *aa*† commute and can be

2

$$a^\dagger a|\psi\rangle = \lambda|\psi\rangle,\tag{1.12}$$

(I.11)

*a*†*a*|ψ = λ|ψ, (I.12)

$$aa^\dagger|\psi\rangle = (a^\dagger a + 1)|\psi\rangle = (\lambda + 1)|\psi\rangle,\tag{\text{I.13}}$$

*aa*†|ψ = (*a*†*a* + 1)|ψ = (λ + 1)|ψ, (I.13) so |ψ is also an eigenvector of *aa*† with eigenvalue λ˜ = λ + 1.

$$
\langle \phi | \phi \rangle = \langle \psi | a^{\dagger} a | \psi \rangle = \langle \psi | \lambda | \psi \rangle = \lambda \langle \psi | \psi \rangle. \tag{1.14}
$$

<span id="page-581-0"></span>
$$
\lambda = \frac{\langle \phi | \phi \rangle}{\langle \psi | \psi \rangle} \ge 0 \tag{l.15}
$$

It is easy to see that λ can never be negative. Let *a*|ψ=|φ so that φ|=ψ|*a*†. Then

$$
\langle a^\dagger a \vert a \vert \psi \rangle = (a a^\dagger - 1) a \vert \psi \rangle = (a(a^\dagger a) - a) \vert \psi \rangle = a(\lambda - 1) \vert \psi \rangle = (\lambda - 1) a \vert \psi \rangle. \tag{\text{I.16}}
$$

We therefore deduce λ = φ|φ ψ|ψ ≥ 0 (I.15) with λ = 0 possible only if *a*|ψ ≡ 0. Thus, the eigenvalues of *aa*† will satisfy λ˜ = λ + 1 ≥ 1. Next, we apply the operator *a*†*a* to *a*|ψ to obtain (*a*†*a*)*a*|ψ = (*aa*† − 1)*a*|ψ = (*a*(*a*†*a*) − *a*)|ψ = *a*(λ − 1)|ψ = (λ − 1)*a*|ψ. (I.16)

$$(a^\dagger a)a^\eta |\psi\rangle = (\lambda - n)a^\eta |\psi\rangle = (n - n)a^\eta |\psi\rangle = 0. \tag{1.17}$$

by continued application of *a*[, we d](#page-581-0)educe that *am*|ψis an eigenstate of *a*†*a* with eigenvalue λ−*m*. If λ were not an integer, we could choose *m* to be large enough to produce a negative

$$a^\dagger a|0\rangle = 0|0\rangle. \tag{1.18}$$

(*a*†*a*)*an*|ψ = (λ − *n*)*an*|ψ = (*n* − *n*)*an*|ψ = 0. (I.17) Therefore, there exists an eigenvector |0 proportional to *an*|ψ such that

$$a|0\rangle \equiv 0\tag{l.19}$$

Furthermore, since the state *a*|0, if it existed, would be an eigenvector of *a*†*a* with

to prevent such a state from existing.

case *n* applications of *a* will give

eigenvalue −1, which by Eq. (I.15) is impossible, it must be true that *a*|0 ≡ 0 (I.19)

$$a^\dagger a|n\rangle = n|n\rangle; \quad \langle n|n\rangle = 1. \tag{1.20}$$

denote their corresponding normalized eigenvectors by |*n* so that

<span id="page-581-1"></span>
$$aa^\dagger|n\rangle = (n+1)|n\rangle. \tag{1.21}$$

The eigenvalues of *aa*† will then be *n* + 1 = 1, 2, 3, ... and we will have

$$
\langle a^\dagger a \rangle a^\dagger |n\rangle = a^\dagger (a a^\dagger) |n\rangle = (n+1) a^\dagger |n\rangle,\tag{1.22}
$$

(*a*†*a*)*a*†|*n* = *a*†(*aa*†)|*n* = (*n* + 1)*a*†|*n*, (I.22) which shows that *a*†|*n* is an eigenstate of *a*†*a* with eigenvalue *n* + 1, so it is proportional

$$|n+1\rangle = \frac{1}{(n+1)^{1/2}} a^\dagger |n\rangle. \tag{1.23}$$

|*n* + 1 = (*n* + 1)1/2 *a*†|*n*. (I.23) We can therefore generate all eigenvectors of *a*†*a* by successive application of *a*† to |0 to obtain

562 THERMAL PHYSICS

$$|n\rangle = \frac{1}{(n!)^{1/2}} (a^\dagger)^n |0\rangle. \tag{1.24}$$

$$<|n-1\rangle = \frac{1}{n^{1/2}} \, a|n\rangle. \tag{1.25}$$

$$|n-m\rangle = \left(\frac{(n-m)!}{n!}\right)^{1/2} a^n |n\rangle; \quad m \le n,\tag{1.26}$$

Similarly, we note that *n*|*a*†*a*|*n* = *n*, so

so

$$|0\rangle = \frac{1}{(n!)^{1/2}} \, d^n |n\rangle \tag{1.27}$$

|*n* − *m* = (*n* − *m*)! *n*! 1/2 *an*|*n*; *m* ≤ *n*, (I.26)

1

### |0 =

I.3 Fermion Operators

and *an*+1|*n* = 0 because *a*|0 ≡ 0. Given Eqs. (I.23) and (I.25), *a*† and *a* are often referred to as raising and lowering operators, respectively.

$$(a, a^\dagger) = 1; \quad (a, a) = 0; \quad (a^\dagger, a^\dagger) = 0,\tag{1.28}$$

(*n*!)1/2 *an*|*n* (I.27)

shall still denote them by *a* and *a*†, as is usual, despite the possible confusion with *a* and *a*† for bosons. These operators obey the relations

<span id="page-582-0"></span>
$$aa = -aa \equiv 0; \quad a^\dagger a^\dagger = -a^\dagger a^\dagger \equiv 0. \tag{1.29}$$

where the *anticommutator* {*A*, *B*} = *AB*+*BA*. The second two members of Eq. (I.28) actually require *aa* = −*aa* ≡ 0; *a*†*a*† = −*a*†*a*† ≡ 0. (I.29)

$$a^\dagger a|\psi\rangle = \lambda|\psi\rangle.\tag{1.30}$$

eigenvalue λ so that *a*†*a*|ψ = λ|ψ. (I.30)

$$
\lambda^2|\psi\rangle = a^\dagger a a^\dagger a |\psi\rangle = (1 - a a^\dagger) a^\dagger a |\psi\rangle = a^\dagger a |\psi\rangle = \lambda |\psi\rangle.\tag{1.31}
$$

λ2|ψ = *a*†*aa*†*a*|ψ = (1 − *aa*†)*a*†*a*|ψ = *a*†*a*|ψ = λ|ψ. (I.31) Therefore, λ2 = λ so the only possible eigenvalues of *a*†*a* are λ = 0 and λ = 1. We denote the corresponding eigenvectors by |0 and |1, respectively. Similarly, if |ψ˜ is an eigenvector of

$$
\tilde{\lambda}^2|\tilde{\psi}\rangle = aa^\dagger a a^\dagger|\tilde{\psi}\rangle = (1 - a^\dagger a) a a^\dagger|\tilde{\psi}\rangle = a a^\dagger|\tilde{\psi}\rangle = \tilde{\lambda}|\tilde{\psi}\rangle,\tag{1.32}
$$

λ˜ 2|ψ˜ = *aa*†*aa*†|ψ˜ = (1 − *a*†*a*)*aa*†|ψ˜ = *aa*†|ψ˜ = λ˜|ψ˜ , (I.32) so λ˜ 2 =λ˜ and λ˜ = 0, 1 are the only possible eigenvalues of *aa*†.

$$aa^\dagger|\psi\rangle = (1 - a^\dagger a)|\psi\rangle = (1 - \lambda)|\psi\rangle. \tag{1.33}$$

It therefore follows that

operator.

$$a^\dagger a|0\rangle = 0|0\rangle \quad a^\dagger a|1\rangle = 1|1\rangle,\tag{1.34}$$

<span id="page-583-0"></span>
$$aa^\dagger|0\rangle = 1|0\rangle \quad aa^\dagger|1\rangle = 0|1\rangle. \tag{1.35}$$

Next, we apply *aa*† to an eigenvector |ψ of *a*†*a* to obtain *aa*†|ψ = (1 − *a*†*a*)|ψ = (1 − λ)|ψ. (I.33)

$$(a^\dagger a)a^\dagger|0\rangle = (1 - aa^\dagger)a^\dagger|0\rangle = a^\dagger|0\rangle,\tag{1.36}$$

*[aa](#page-583-0)*†|0 = 1|0 *aa*†|1 = 0|1. (I.35) Therefore, if *a*†*a* is regarded as a number operator, then *aa*† behaves like an antinumber

$$(aa^\dagger)a|1\rangle = (1 - a^\dagger a)a|1\rangle = a|1\rangle,\tag{1.37}$$

(*a*†*a*)*a*†|0 = (1 − *aa*†)*a*†|0 = *a*†|0, (I.36)

from which we conclude that *a*†|0=|1, but of course *a*†|1 = *a*†*a*†|0 ≡ 0. Then we apply *aa*† to the state *a*|1 to obtain (*aa*†)*a*|1 = (1 − *a*†*a*)*a*|1 = *a*|1, (I.37)

### *a*2|1 ≡ 0. Summarizing, for fermions there are only two states, |0 and |1, so *a*†|0=|1 and

and use the left member of Eq. (I.35) to conclude that *a*|1=|0. Then we see that *a*|0 =

*a*†|1 ≡ 0 whereas *a*|1=|0 and *a*|0 ≡ 0.

$$
\hat{N} = a^\dagger a,\tag{1.38}
$$

Having now established in detail the allowed eigenvalues and eigenvectors of *a*†*a* and *aa*† for both bosons and fermions, we focus attention on the number operator *N*ˆ = *a*†*a*, (I.38)

$$\mathbb{I}[\hat{N}, a] = -a \quad \text{and} \quad \mathbb{I}[\hat{N}, a^\dagger] = a^\dagger. \tag{1.39}$$

commutation relations

$$
\hat{N}a|n\rangle = (a\hat{N} - a)|n\rangle = (n-1)a|n\rangle \tag{1.40}
$$

Therefore

and

$$
\hat{N}a^\dagger|n\rangle = (a^\dagger \hat{N} + a^\dagger)|n\rangle = (n+1)a^\dagger|n\rangle. \tag{1.41}
$$

*Na*ˆ †|*n* = (*a*†*N*ˆ + *a*†)|*n* = (*n* + 1)*a*†|*n*. (I.41) For both bosons and fermions, *a*|0 ≡ 0, but for fermions, we also have *a*†|1 ≡ 0. If we regard *n* as being the number of particles in a state, then *a* applied to |*n* results in a state, if such a state |*n* − 1 exists, having one less particle. Therefore, *a* is called an annihilation operator. Similarly, since *a*† applied to |*n* results in a state |*n* + 1, if such a state exists,

*Na*ˆ |*n* = (*aN*ˆ − *a*)|*n* = (*n* − 1)*a*|*n* (I.40)

tions become

becomes

564 THERMAL PHYSICS

$$[a_{\alpha}, a_{\beta}^{\dagger}] = \delta_{\alpha, \beta}; \quad [a_{\alpha}, a_{\beta}] = 0; \quad [a_{\alpha}^{\dagger}, a_{\beta}^{\dagger}] = 0. \tag{1.42}$$

<span id="page-584-0"></span>having one more particle, *a*† is called a creation operator. In the case of fermions, and in accordance with the Pauli exclusion principle, a state can have only zero or one particle. These ideas can be generalized to a number of identical particles whose single-particle

$$|n_{\boldsymbol{u}},n_{\boldsymbol{\beta}},n_{\boldsymbol{\gamma}},...\rangle = \frac{1}{(n_{\boldsymbol{u}}!n_{\boldsymbol{\beta}}!n_{\boldsymbol{\gamma}}!...)^{1/2}} (a_{\boldsymbol{u}}^{\dagger})^{n_{\boldsymbol{u}}} (a_{\boldsymbol{\beta}}^{\dagger})^{n_{\boldsymbol{\beta}}} (a_{\boldsymbol{\gamma}}^{\dagger})^{n_{\boldsymbol{\gamma}}} \cdots |0,0,0,...\rangle,\tag{1.43}$$

β ] = δα,β; [*a*α, *a*β ] = 0; [*a*† α, *a*† β ] = 0. (I.42) α*a*α and obviously *N*ˆ α and

The number operator for the single-particle state α is *N*ˆ α = *a*† *N*ˆ β commute and can have a common set of eigenstates. The c[ount](#page-584-0)erpart to Eq. (I.24)

prevent an uncertainty of ±1 in the phase.

$$\{a_a, a_\beta^\dagger\} = \delta_{a,\beta}; \quad \{a_a, a_\beta\} = 0; \quad \{a_a^\dagger, a_\beta^\dagger\} = 0. \tag{1.44}$$

|*n*α, *n*β , *n*γ , ... = 1 (*n*α!*n*β!*n*γ !···)1/2 (*a*† α) *n*α (*a*† β ) *n*β (*a*† γ ) *n*γ ···|0, 0, 0, ..., (I.43) where the ground state |0, 0, 0, ... is usually called the **vacuum state**. For fermions, the anticommutation relations become

$$|n_a, n_\beta, n_\gamma, \dots\rangle = (a_a^\dagger)^{n_a} (a_\beta^\dagger)^{n_\beta} (a_\gamma^\dagger)^{n_\gamma} \cdots |0, 0, 0, \dots\rangle,\tag{1.45}$$

In that case, *a*α*a*α = 0 and *a*† α*a*† α = 0 for all α, but for α = β, we have *a*α*a*β = − *a*β*a*α and *a*† α*a*† β = −*a*† β*a*† α. For fermions as well, *N*ˆ α and *N*ˆ β commute, although the fact that they do is not as obvious as for bosons. The relation corresponding to Eq. (I.43) is simply |*n*α, *n*β , *n*γ , ... = (*a*† α) *n*α (*a*† β) *n*β (*a*† γ ) *n*γ ···|0, 0, 0, ..., (I.45)

where the only allowed values of the *n*α are zero and one. Since these operators anticommute, one can order them [8, p. 268] with increasing subscripts (α<β<γ < ··· ) to

- 
- 
- R[eferences](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0030)
	-
	-
	-
	- [1] [E. Fermi, Thermodynamics, Dover, New York, 1956.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0055)
	- [2] [H.B. Callen, Thermodynamics, second ed., John Wiley, New York, 1985.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0060) [3] [J.W. Gibbs, The Scientific Papers of J. Willard Gibbs, vol. 1, Dover, New York, 1961.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0065)
	- [4] [J.W. Gibbs, Elementary Principles in Statistical Mechanics, Ox Bow Press, Woodbridge, CT, 1](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0070)891.
	- [5] [C.H.P. Lupis, Thermodynamics of Materials, North Holland, New York, 1983.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0075)
	- [6] C. Kittel, H. Kroemer, Thermal Physics, W.H. Freeman, New York, 1980.
	- [7] [L.D. Landau, E.M. Lifshitz, Statistical Physics, Addison-Wesley, Reading, MA, 1958.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0080)
	- [8] [R.K. Pathria, Statistical Mechanics, second ed., Pergamon Press, New York, 1996.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0085)
- [9] [R.K. Pathria, P.D. Beale, Statistical Mechanics, third ed., Elsevier, New York, 2011.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0090) [10] G. Holton, Y. Elkana, Albert Einstein: Historical and Cultural Perspectives, Dover, Mineola, NY, 1997. [11] [W.H. Cropper, Great Physicists, Oxford University Press, New York, 2004.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0095)
- [12] [D. Chandler, Introduction to Modern Statistical Mechanics, Oxford University Press, N](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0100)ew York, 1987. [13] H.D. Young, R.A. Freedman, University Physics, ninth ed., Addison-Wesley, New York, 1996.
- [14] [W. Greiner, L. Neise, H. Stöcker, Thermodynamics and Statistical Mechanics, Springer, New York,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0105)
	- [2000.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0110)
- [15] [M. Planck, Treatise on Thermodynamics, third ed., Translation of Seventh German, Dover, Mineola,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0115) NY, 1926. [16] [D. Kondepudi, I. Prigogine, Modern Thermodynamics, John Wiley, N](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0120)ew York, 1999.
- [17] [B. Widom, Statistical Mechanics, Cambridge University Press, Cambridge, UK](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0125), 2002.
- [18] [K. Denbigh, Principles of Chemical Equilibrium, third ed., Cambridge University Press, London,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0130) 1971.
- [19] L.S. Darken, R.W. Gurry, Physical Chemistry of Metals, McGraw-Hill, New York, 1953.
- [20] [R.B. Griffiths, A proof that the free energy of a spin system is extensive, J. Math. Phys. 5 (1964)](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0135) [1215-1222.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0140) [21] R.T. DeHoff, Thermodynamics in Materials Science, McGraw Hill, New York, 1993.
- [22] G.N. Lewis, M. Randall, Thermodynamics, McGraw-Hill, New York, 1961 (revised by K.S. Pitzer, L.
	- Brewer).

[27] J.S. Rowlinson, B. Widom, Molecular Theory of Capillarity, McGraw-Hill, New York, 1982.

- [23] R.A. Swalin, Thermodynamics of Solids, John Wiley, New York, 1967. [24] T.B. Massalski, Binary Phase Diagrams, vol. 1-3, ASM, Metals Park, OH, 1990.
- [25] H. Margenau, G.M. Murphy, The Mathematics of Physics and Chemistry, second ed., D. Van Nostrand, Princeton, NJ, 1956. [26] R. Courant, D. Hilbert, Methods of Mathematical Physics, vol. I, seventh printing ed., Interscience,
	- Princeton, NJ, 1966.

565

623-856.

- 
- 
- 566 [References](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0160)
- [28] J.W. Cahn, Thermodynamics of solid and fluid interfaces, in: W.C. Johnson, J.M. Blakely (Eds.), In
	- [terfacial Segregation, ASM International, International Materials Park, OH, 1979, pp. 3-23 (reprinted](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0170) in The Selected Works of John W. Cahn, pp. 379-399).
- [29] [W.C. Carter, W.C. Johnson (Eds.), The Selected Works of John W. Cahn, TMS, Warrendale, PA, 1998.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0175) [30] [H.M. Princen, The equilibrium shape of interfaces, drops, and bubb](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0180)les. Rigid and deformable particles at interfaces, in: E. Matijevic (Ed.), Surface and Colloid Science, Wiley-Interscience, New ´
- York, 1969. [31] [F.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [Larché,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [J.W.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [Cahn,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [A](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [linear](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [theory](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [of](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [thermochemical](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [equilibrium](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [of](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [solids](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [under](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [stress,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185) [Acta](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0185)
- Metall. 21 (1973) 1051-1063. [32] [F.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [Larché,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [J.W.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [Cahn,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [A](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [nonlinear](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [theory](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [of](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [thermochemical](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [equilibrium](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [of](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [solids](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [under](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [stress,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190) [Acta](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0190)
- Metall. 26 (1978) 53-60. [33] [W.W. Mullins, R.F. Sekerka, On the thermodynamics of crystalline solids, J. Chem. Phys. 82 (1985)](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0195)
- 5192-5202. [34] [R.F. Sekerka, J.W. Cahn, Solid-liquid equilibrium for non-hydrostatic stress, Acta Mater. 52 (2004)](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0200)
- 1663-1668. [35] D.C. Wallace, Thermodynamics of Crystals, John Wiley, New York, 1972. [36] [D.W. Hoffman, J.W. Cahn, A vector thermodynamics for anisotropic surfaces, Surf. Sci. 31 (1985)](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0205) 368-388.
- [37] J.W. Cahn, D.W. Hoffman, A vector thermodynamics for anisotropic surfaces—II. Curved and faceted surfaces, Acta Metall. 22 (1974) 1205-1214.
- [38] [C. Herring, Surface tension as a motivation for sintering, in: W.E. Kingston (Ed.), The Physics of](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0210) Powder Metallurgy, a Symposium Held at Bayside, L.I. New York, August 24-26, 1949, McGraw-Hill, New York, 1951, pp. 143-179. [39] [G. Wulff, Zur Frage des Geschwindigkeit des Wachstums und der Auflösung der Kristallflächen, Z.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0215) Kristallogr. Mineral. 34 (1901) 449-530.
- [40] W.W. Mullins, Solid surface morphologies governed by capillarity, in: W.D. Robertson, N.A. Gjostein [(Eds.), Metal Surfaces: Structure, Energetics and Kinetics, ASM International, International Mate](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0220)rials Park, OH, 1963, pp. 17-66 (papers presented at a joint symposium of the American Society of [Metals and the Metallurgical Society of AIME, October 1962).](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0225)
- [41] C. Herring, The use of classical macroscopic concepts in surface-energy problems, in: R. Gomer, [C.S. Smith (Eds.), Structure and Properties of Solid Surfaces, a Conference Arranged by the National](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0230) [Research Council, Lake Geneva, WI, September 1952, University of Chicago Press, Chicago,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0235) IL, 1953, pp. 5-81. [42] [F.C. Frank, Solid surface morphologies governed by capillarity, in: W.D. Robertson, N.A. Gjostein](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0240)
	- (Eds.), Metal Surfaces: Structure, Energetics and Kinetics, ASM International, International Mate[rials Park, OH, 1963, pp. 1-15, (papers presented at a joint symposium of the American Society of](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0245) Metals and the Metallurgical Society of AIME, October 1962).
- [43] R.F. Sekerka, Analytical criteria for missing orientations on three-dimensional equilibrium shapes,
- J. Cryst. Growth 275 (2005) 77-82. [44] C. Herring, Some theorems on the free energies of crystal surfaces, Phys. Rev. 82 (1951) 87-93.
- [45] W.W. Mullins, R.F. Sekerka, Application of linear programming theory to crystal faceting, J. Phys. Chem. Solids 23 (1962) 801-803.
- [46] A.P. Sutton, R.W. Ballufi, Interfaces in Crystalline Materials, Clarendon Press, Oxford, 1955. [47] N. Reingold, Science in America: A Documentary History 1900-1939, University of Chicago Press,
- Chicago, 1981. [48] C.E. Shannon, A mathematical theory of communication, Bell Syst. Tech. J. 27 (1948) 379-423;
- 
- 
- [References](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0265)[567](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0265)
- 
- [49] [C.E.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0275) [Shannon,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0275) [W.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0275) [Weaver,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0275) [The](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0275) [Mathematical](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0275) [Theory](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0275) [of](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0275) [Communications,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0275) [University](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0275) of Illinois Press, Urbana, IL, 1949.
- [50] [A.I.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [Khinchin,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [The](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [entropy](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [concept](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [in](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [probability](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [theory,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [in:](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [R.A.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [Silverman,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [M.D.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [Friedman](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [(Trans.,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0280) [Eds.), Mathematical Foundations of Information Theory, Dover, New York, 1957, pp. 2-28.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0285)
- [51] L. Boltzmann, Weitere Studen über das Warmegleichgewicht unter Gasmolekölen, Wien Berichte [66 (1872) 275, reprinted in Boltzmann's](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0290) *Abhandlungen*, vol. 1, Barth, Leipzig, 1909, p. 316.
- [52] [F. Reif, Fundamentals of Statistical and Thermal Physics, second ed., Waveland Press, Long Grove,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0295) IL, 2009.
- [53] [C.J. Thompson, Mathematical Statistical Mechanics, Princeton Un](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0300)iversity Press, Princeton, NJ, [1972.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0305)
- [54] [D. McQuarrie, Statistical Mechanics, University Science Book](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0310)s, Sausalito, CA, 2000. [55] [M. Planck, Zur Theorie des Gesetzes der Energieverteilung im Normalspectrum, Verh. Dtsch. Phys.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0315)
	- Ges. 2 (1900) 237-245.
- [56] [M. Planck, Über eine Verbesserung der Wien'schen Spectral-gleichung,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0320) Verh. Dtsch. Phys. Ges. 2 (1900) 202-204.
- [57] [L.I.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0325) [Schiff,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0325) [Quantum](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0325) [Mechanics,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0325) [third](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0325) [ed.,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0325) [Clarendon](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0325) [Press,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0325) [Oxford,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0325) [1968.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0325)
- [58] [N.W. Ashcroft, N.D. Mermin, Solid State Physics, Saunders College Publishing, New York,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0330) 1976.
- [59] [A. Messiah, Quantum Mechanics, vol. 2, John Wiley, New York, 1962.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0335) [60] [H. Goldstein, Classical Mechanics, Addison-Wesley, Reading, MA, 1959.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0340)
- [61] A.M. Guénault, Statistical Physics, Routledge, London, 1988.
- [62] [D.M. Dennison, A note on the specific heat of the hydrogen m](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0345)olecule, Proc. R. Soc. Lond. 115 (1927) [483.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0350)
- [63] L.A. Girifalco, Statistical Physics of Materials, John Wiley, New York, 1973. [64] [T.L. Hill, An Introduction to Statistical Thermodynamics, Dover, Mineola, NY, 1986.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0355)
- [65] [A. Sommerfeld, Zur Elektronentheorie der Metalle auf Grund der Fermischen Statistik, Z. Phys. 47](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0360) (1928) 1-3. [66] [L.D. Landau, E.M. Lifshitz, Quantum Mechanics—Non-relativistic Theory, second ed., Addis](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0365)
	- on-Wesley, Reading, MA, 1965.
- [67] [P.A.M. Dirac, The Principles of Quantum Mechanics, fourth ed., Oxford University Press, London,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0370)
- 1958. [68] [K. Huang, Statistical Mechanics, John Wiley, New York, 1963.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0375)
- [69] E. Merzbacher, Quantum Mechanics, John Wiley & Sons, New York, 1961. [70] [S. Galam, A. Mauger, A quasi-exact formula for Ising critical temperatures on hypercubic lattices,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0380) Physica A 235 (1997) 573-576.
- [71] K. Binder, D.W. Heermann, Monte Carlo Simulation in Statistical Physics, fifth ed., Springer, New York, 2013.
- [72] D.P. Landau, K. Binder, Monte Carlo Simulations in Statistical Physics, third ed., Cambridge, New York, 2009.
- [73] M.E.J. Newman, G.T. Barkema, Monte Carlo Methods in Statistical Physics, Oxford University Press, New York, 1999. [74] L.M. Sander, Equilibrium Statistical Physics: With Computer Simulations in Python, first ed.,
- Leonard M. Sander, Middletown, DE, 2013. [75] B.V. Gnedenko, The Theory of Probability and the Elements of Statistics, fifth ed., Chelsey, New York, 1989.

Press, London, 1932.

- 
- 
- 568 [References](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0405)
	-
	-
- [76] [N. Metropolis, A.W. Rosenbluth, A.H. Teller, E. Teller, Equations of state calculations by fast comput](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0415)ing machines, J. Chem. Phys. 21 (1953) 1087-1092. [77] [W.K. Hastings, Monte Carlo sampling methods using Markov chains and their applications, Biomet-](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0420)
- rica 57 (1970) 97-109. [78] [R.H. Swendsen, J.-S. Wang, Nonuniversal critical dynamics in Monte Carlo simulations, Phys. Rev.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0425)
- Lett. 58 (1987) 86-88. [79] [U. Wolff, Collective Monte Carlo updating for spin systems, Phys. Rev. Lett. 62 (1989) 361-363.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0430)
- [80] L.P. Kadanoff, Scaling laws for Ising models near Tc, Physics 2 (1966) 263. [81] [K.G. Wilson, Renormalization group and critical phenomena. I. Renormalization group and](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0435) Kadanoff scaling picture, Phys. Rev. B 4 (1971) 3174.
- [82] [K.G. Wilson, Renormalization group and critical phenomena. II. Phase space cell analysis of critical](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0440) behavior, Phys. Rev. B 4 (1971) 3184.
- [83] [A.M.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [Ferrenberg,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [R.H.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [Swendsen,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [New](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [Monte](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [Carlo](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [technique](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [for](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [studying](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [phase](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) [transitions,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0445) Phys. Rev. Lett. 61 (1988) 2635-2637.
- [84] [A.M.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[Ferrenberg,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[R.H.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[Swendsen,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[Optimized](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[Monte](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[Carlo](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[data](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[analysis,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[Phys.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[Rev.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[Lett.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[63](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450)[(1989)](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0450) 1195-1197. [85] [N.F. Carnahan, K.E. Starling, Equation of state for nonattracting rigid spheres, J. Chem. Phys. 51](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0460)
	- (1969) 635-636.
- [86] [R.J. Speedy, Pressure of the metastable hard sphere fluid, J. Phys. Condens. Matter 9 (1997)](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0465) 8591-8599.
- [87] [M.D. Rintoul, S. Torquata, Computer simulations of dense hard sphere systems, J. Chem. Phys. 105](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0470) (1996) 9258.
- [88] [J.D. Bernal, J. Mason, Co-ordination of randomly packed spheres, Nature 385 (1960) 910-911.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0475) [89] [W.W. Wood, F.R. Parker, Monte Carlo simulation of state of molecules interactin](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0480)g with the
- Lennard-Jones potential, J. Chem. Phys. 27 (1957) 720. [90] [J.-P. Hansen, L. Verlet, Phase transitions of the Lennard-Jones system, Phys. Rev. 184 (1969) 151.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0485)
- [91] [A. Travesset, Phase diagram of power law and Lennard-Jones systems: crystal phases](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0490), J. Chem. Phys. 141 (2014) 164501. [92] [E.T. Whittaker, G.N. Watson, A Course in Modern Analysis, fourth ed., Cambridge University Press,](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0495)
	- London, UK, 1969.
- [93] [C.E. Weatherburn, On differential invariants in geometry of surfaces with some applications to](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0500)
- mathematical physics, Q. J. Pure Appl. Math. 50 (1925) 230-269. [94] [C.E. Weatherburn, On families of curves and surfaces, Q. J. Pure Appl. Math. 50 (1927) 350-361.](http://refhub.elsevier.com/B978-0-12-803304-3.10000-6/rf0505) [95] C. Johnson, Generalization of the Gibbs-Thomson equation, Surf. Sci. 3 (1965) 429-444.
- [96] R. Courant, Calculus of Variations, Courant Institute of Mathematical Sciences, New York University,
- NY, 1962 (revised and amended by J. Moser). [97] H. Goldstein, Classical Mechanics, second ed., Addison-Wesley, Reading, MA, 1981.
- [98] M. Abramowitz, I.A. Stegun (Eds.), Handbook of Mathematical Functions, ninth ed., National Bureau of Standards, Washington, DC, 1970.
- [99] E. Schrödinger, Statistical Thermodynamics, second ed., Cambridge University Press, Cambridge, 1962. [100] J.H. van Vleck, The Theory of Electric and Magnetic Susceptibilities, first ed., Oxford University

![](_page_589_Figure_0.jpeg)

# Index

Note: Page numbers followed by *f* indicate figures, by *t* indicate tables, and by *np* indicate footnotes.

### **A**

Absolute activity, 362–363, 371, 405–406, 413–416, 447, 458 Absolute temperature, 4, 7, 13, 20, 32–34, 43, 47, 49, 51*f* , 53, 121, 124, 156, 247, 259, 262, 266, 289 Absolute zero of temperature, 4–5, 37, 49–51, 425 Acceptors, 443, 446–448, 447*f* Accessible quantum state, 49, 313 Activated process, 111–112 Activation energy, 111–112, 181, 392, 395, 440 Activity, 175 absolute, 362, 370–371, 405, 413–416, 447, 458 Actual state, 219 adsorption equation in, 220–221 Adiabatic demagnetization, 329–330*f* Adiabatic, 25–28, 272 and Carnot cycle, 35, 36*f* and isentropic process, 272 Bose gas, 423 coefficient of expansion, 506 compressibility, 105, 503 cyclic process, 35 definition, 25*np* demagnetization, 329, 330*f* ideal gas expansion, irreversible, 27–28, 44 ideal gas expansion, reversible, 25–27 reversible contraction, 44 reversible isentropic for ideal second law, entropy change, 34–35 with reversible work, 45 Adsorption equation of Gibbs actual state, 220–221 reference state, 218–219 Affinity, 173–175, 174*f*

Angular momentum, 537, 539–543 for paramagnetic system, 324 orbital, for electronic structure, 381 polyatomic molecule, 358 probability distribution for, 358 spin, for electronic structure, 381 Anisotropy of crystal surface or interfacial free energy per unit area, (γ), 196, 215, 221, 223–226, 510–511 illustration for cubic crystal, 223, 242 Annihilation operators, 559–564. *See also* Creation operators Anti-symmetric fermion states, 465–466 Anti-symmetrization operator, 467 Approximate evaluation of infinite sums, 556 evaluation of partition function (thermodynamic perturbation theory), 549–552 Arrhenius form, 112*f* –113, 181 Asymptotic, 277–278, 304*f* , 422, 449 expansion, 409–410, 435 series, 499–501, 553–556 series, *vs.* convergent series, 500–501 Avogadro's number, 3, 12, 48, 49, 126–127, 166, 289

### **B**

Band gap, 425, 442, 443*f* , 445 Beale, Paul, xv, xviii, 6, 350, 416, 419, 483, 489 Bernoulli numbers and polynomials, 553–554 Binary liquid, in gravity, 162–164 Binary solutions chemical components, 137 chemical potentials, 137–138 chord construction, 141

Binary solutions *(Continued)* Euler equation, 137–138 general solution, 153 Gibbs-Duhem equation, 137–138 graphical constructions, 139–141 ideal, 142–145 ideal solid and ideal liquid, 145–148 ideal solutions, 142–145 intercept and common tangent constructions, 139–141 lens type binary phase diagram, 145–146, 147–148 liquid in gravitational field, 162–164 miscibility gap, 137–141, 142–148, 153 molar Gibbs free energy, 139 mutual solubility, 144 phase diagram, ideal solid-liquid, 145–148 regular solution, 148–152 thermodynamics of, 137–141 Binary system, *see also* Multicomponent system partial molar quantities, 3, 74*f* , 75 Blackbody radiation, 298–302 Bohr magneton, 324–325, 437–439 Boltzmann, Ludwig, 251–252 constant *k*B, 12, 48, 49, 249–251 distribution, 285–289 equation, 252–253 Eta theorem, 247, 251–256 factor, 250, 263, 313, 322*np*, 337, 361, 373, 468, 484–485, 487 sampling, 487 Boltzons, 468 Bomb calorimeter, 168 Bose, Satyendra condensation, 413 chemical potential below *Tc*, 413 condensate fraction, 416*f* condensate region, 421–424 critical temperature *Tc*, 421 entropy below *Tc* , 417–418 heat capacity, 419*f* , 420–421 internal energy below *Tc*, 417–418 λ point, heat capacity, 420–421 pressure below *Tc*, 417

region in *v, p* plane, isotherms, 422–423 region in *v, T* plane, isotherms, 421–422 thermodynamic functions, 416–421 -Einstein distribution function, 374–375 ideal gas, 376–378, 410–412 Bosons, 465–468 at low temperatures, 413–416 operators, 560–562 number operators, 563–564 Bragg-Williams molecular field approximation, 471*np* Brillouin function, 325–326 Bromwich contour, 330–331 Bulk samples, homogeneous, 6–7

### **C**

Cahn, John W., 185 determinants for surface invariants, 194–197 layer model, 185, 192–197 Calorie, 17 Canonical distribution, 337*np* Canonical ensemble, 288, 457–458. *See also* Classical canonical ensemble Boltzmann factor, 337 canonical ensemble, classical averaging and equipartition, 343–345 canonical transformations, 354–356, 529–535 effusion of ideal gas, 340–342 Maxwell-Boltzmann distribution, 338–339 classical ideal gas, 313–316, 338–342 Maxwell-Boltzmann distribution, 338–339 quantum concentration, 339–340 definition, 305 density of states, 330–331 derivation from microcanonical, 305–312, 360–368 energy dispersion, fluctuation, 320–321, 367–368 factorization theorem, 312–313 grand, *see* Grand canonical ensemble (GCE) Helmholtz free energy, 306*np*, 307–309, 311, 315–316, 321–322 Maxwell-Boltzmann distribution, 317–319

as most probable distribution, 309–312 paramagnetism, 290–292, 321–330 adiabatic demagnetization, 329–330 classical treatment, 322–324 magnetic moment, 321–325 properties, 327–329 quantum treatment, 324–327 particles, negligible interaction energies, 285, 312–313 blackbody radiation, 298–302 harmonic oscillator, 293–302 heat capacity of a crystal, 297–298 rigid linear rotator, 303–304 two-state subsystems, 289–293 partition function, 330–331 diatomic molecular gas, 382–387 polyatomic molecule, 387–388 relation to density of states, 330–331 relation to Helmholtz free energy, 311, 315–316, 321–322 virial expansion coefficients, 348–354 virial theorem for time averages, 346–348 Canonical partition function, 457–458 for single spin, 471–472 Canonical transformations general transformation, 529–530 Jacobian value, 354–356, 529–530, 532–533 necessary and sufficient conditions, 530–534 restricted transformation, 534–535 symplectic transformation, 532–534 use of, 354–356 Canonical variables for freely rotating polyatomic molecule, 546 Capillary length, 201, 205–206, 211 rise in tube, 185, 200, 200*f* Carnot, Sadi, 35–38 cycle, 4, 32*np*, 35–36 efficiency, 36–37 engines, 35–38, 36*f* refrigerator, 38 Cauchy stress tensor, 216–217, 218–219 Celsius scale, 4*np* Chemical heat, 53

Chemically closed system, 15, 32, 33, 41, 53, 75, 84, 89–90, 167, 168–169, 173, 174 Chemical potential, 12, 53–54, 55, 61, 64–66, 69, 83, 91–93 of binary solutions, 137, 139*np*, 140*f* , 142–143, 145, 153 Bose gas below critical temperature, 413 electrochemical, 12, 155, 166 gravitational, 12, 155, 157–158 ideal gas, 54, 61 intrinsic, 12, 157–158 monatomic gas, 55 of monocomponent ideal gas, 54, 161 multicomponent systems, 53, 55, 171–172, 175–176 real gases, 64, 171, 176 Chemical reaction affinity, 173, 174*f* , 182 among ideal gases, 177, 178 at constant volume/pressure, 168 δ *G* (*G*) of, 173 δ *H* (*H*) of, 170 entropy production during, 75, 77, 174–175 equilibrium, 173–175 equilibrium conditions, explicit equilibrium constant, *K*, 176, 176*np*, 178–181 alternative, *Kc* dependence on pressure, 182 dependence on temperature, 180 extension of equilibrium conditions to include, 93 heat of, 170 heterogeneous solids/liquids with gases, 171, 179 in isolated system, 167 reaction product and quotient, 176–177 simultaneous reactions, 182–183 standard states, 171–173 stoichiometric coefficients, 76, 167 Chord construction, 129–130, 129*f* , 141, 142*f* , 153 binary solution, 141 Classical canonical ensemble, 337. *See also* Canonical ensemble averaging theorem and equipartition, 343

Classical canonical ensemble *(Continued)* classical ideal gas, 345 Cartesian coordinates, 340–341 effusion, 341, 342 Maxwell-Boltzmann distribution, 338–339 law of Dulong and Petit, 342–343, 345 rotating rigid polyatomic molecules, 356–358 use of canonical transformations, 354–356 virial coefficients, 348, 353 virial theorem, 346–348 Classical ideal gas, 338–342 canonical ensemble, 313–316 free particle in box, 314–316 grand canonical ensemble, 375–378, 380–388 Classical microcanonical ensemble. *See also* Microcanonical ensemble classical harmonic oscillators in three dimensions, 282, 283–284 classical ideal gas, 281–283 definition, 277 description, 280 Classical particles, Monte Carlo simulation, 491–494 Classical partition function, 337–338 evaluation, 342–343, 354 for single diatomic molecule, 355 Classical treatment of paramagnetism, 322–324 Clausius, Rudolf, 17 -Clapeyron equation, 110–115 first recognition of entropy postulate of, 31–34, 37 Closed system, 15 Coefficients of curvatures, 201–202 Coexistence curves, 109 Common tangent construction, 127–129, 129*f* of binary solutions, 139–141 Communication theory, 247 Composition, mole fractions, 62 Concave function, 95–96, 100 Concentrations, 64 Condensate region, Bose condensation in *v, p* plane, 422–423, 423*f* in *v, T* plane, 421–422, 422*f*

Conditions for equilibrium of composite systems, 81–83, 87 multicomponent subsystems, 81–83 mutual equilibrium, 93 extension to chemical reactions, 93 Conduction band, 442–444, 446, 447*f* Configuration distinguishable particles, 285–286 MC simulation, 484–491 Conjugate variable, 47, 67–68 Conservative external forces, 155 Constant pressure chemical reactions at, 168–170 heat capacity at, 20, 22–23, 420–421 Constant Boltzmann, 12, 48, 49, 249–251 Curie, 322–324 equilibrium, 175–182 ideal gas, 4 Planck, 55, 60, 68–69 Stefan-Boltzmann, 301 van der Waals fluid, 126–127 Constant volume chemical reactions at, 168–170 heat capacity at, 19–20, 22–23 Constrained equilibrium, 217 Construction, graphic chord binary, 141 monocomponent, 129–130 common tangent binary, 139–141 monocomponent, 127–129 intercept, 139–141 Maxwell equal area, 133–134, 133*f* Contact plane, 234–235 Convex function, 100–102 Correlations function for hard-sphere gas, 492 Monte Carlo, 485 of spin, 484, 485 Creation and annihilation operators. *See also* Annihilation operators boson and fermion number operators, 563–564

boson operators, 560–562 eigenstates of, 559, 561–562 fermion operators, 562–563 for harmonic oscillator, 559–560 vacuum state, 564 Critical exponent, 474–475 Critical point, 109 Critical temperature, 421–422 definition, 413, 471–472 Crystal heat capacity of, 297–298 equilibrium shape, 215–216, 227–228, 233 Crystalline solids, 215–216 Curie constant, 322–324 Curie's law, 292*f* , 322–324 Curie-Weiss law, 475–476 Curved interfaces in fluids capillary length, 200 constants, 198 contact angle, 204–205 dividing surface in comparison system, 197 Gibbs coefficients of curvatures, 201–202 interface junctions and contact angles, 202–205 surface of tension, 198 Curved solid-fluid interfaces. *See also* Planar solid-fluid interfaces description, 227–228 discontinuous derivatives of γ, 228–232 inverted γ-plot, 232–233

### **D**

Decimation, 488–489 de Donder, Théophile, 173*np* concept of affinity, 173 Degeneracy factor, 402 Degrees of freedom, 7–8, 55–56 Density dispersion, fluctuation, 367 matrix, 451–452 one-dimensional harmonic oscillator, 460–461 single free particle, 459–460 spin 1/2 particle, 461–465 operator, 451

assumption of random phases, 454 free particle, 459–460 grand canonical ensemble, 458 harmonic oscillator, 460–461 pure quantum state, 451–452 relationship to entropy, 47–48 statistical quantum state, 453 in terms of Pauli spin matrices, 461–462 time evolution, 455–456 various ensembles, 456–458 of states canonical ensemble, 330–331 definition, 330–331, 332 Detailed balance, principle of, 486–487 Diatomic molecular gas, 382 heteronuclear molecules, 382–385 homonuclear molecules, 385–387 polyatomic molecular gas, 387–388 Diatomic molecule moments of inertia, 303 quantum energy levels, 547 rigid linear rotator, 303 Dirac, Paul, 430 continuous spectrum, 452*np* delta function, 30, 430 Fermi-Dirac distribution, 373–374, 428–432 in semiconductors, 444*np* thermionic emission, 439 vector space, 468 Boson and Fermion number operators, 563–564 Boson operators, 560–562 eigenbras and eigenkets, 560–562 Fermion operators, 562–563 probability density ket, 51 Discontinuous derivatives of γ, 228–232 Disorder function, entropy, 247–251 Distinguishable particles, with negligible interaction blackbody (hohlraum) radiation, 298–302 canonical ensemble, 288 configuration, 285–286 crystal, heat capacity of, 297–298 derivation of Boltzmann distribution, 285–289 Distinguishable particles, with negligible interaction *(Continued)* ensemble, 288 factorization theorem, 312–313 harmonic oscillators, 293–302 identical but, 285 magnetic moment, 290–292 paramagnetism, 290–292 partition function, 286–287 rigid linear rotator, 303–304 Stirling's approximation, 287 two-state subsystems, 289–293 Divacancies, 393–394 Donors, 442–443, 446–447 Dopants, 442–443, 446–449

### **E**

Effusion definition, 340–341 energy flux with, 341 of ideal classical gas, 340–342 Eigenstates, 559, 561–562 Einstein, Albert Bose-Einstein distribution, 374–375 heat capacity, 297 nuclear reactions, 167 quotation re thermodynamics, xvii temperature, 297 Electric fields, external forces, 166 Electronic heat capacity, 381–382, 432–433. *See also* Heat capacity Elementary kinetic theory, of gases, 12–13 Elementary method, 498, 504–507 Endothermic reaction, 170 Energy, 3 criterion, 84–88 and entropy, equivalence, 87–88 local energy criterion, 86–87 dispersion canonical ensemble, 320–321 grand canonical ensemble, 367–368 free, Gibbs, 69 free, Helmholtz, 68–69 internal, 11, 15–16 kinetic of center of mass, 11

lack of partitioning, 19 mechanical, 8–12 single particle in one dimension, 8–9 in three dimensions, 9–10 as state function, 15–16 system of particles, 10–12 Ensembles, 257, 288 applied to point defects, 391–393 averages, 5–6 canonical, 457–458 grand canonical, 458 microcanonical, 457 pressure, 360, 389–390 Enthalpy, 28–29, 69 of chemical reaction, 75–78 criterion, 90–91 of melting, 29, 30 of multicomponent system, 62–63 of phase change, 46*f* stability requirements for, 102–103 Entropy, 5, 31 of Bose condensation, 418, 419 change calculation, 39 change due to heat transfer, 32 change for adiabatic process, 25*np* change for reversible path, 38 of chemical reaction, 75–78 criterion for equilibrium, 32, 79–84 equivalence to energy criterion, 87–88 Gibbs phase rule, 83, 93, 109, 141 disorder function, 247–251 disorder measurement, 247–251 elementary relationship to microstates, 47–48 formula, 400–402 for general ensemble, 397–398 example of maximization, 399–400 summation over energy levels, 402–403 ideal gas, 44 information theory, 247–256 of mixing, ideal gases, 275–276 of phase change, 46 probability of microstate, 47–48 relationship to microstates, 47–48

stability requirements for, 95–100 as state function, 31, 32 statistical interpretation, 47–48 of two systems, 250 Equations of state, 20, 23–24, 28, 41–43, 54, 61, 70, 98, 121, 138–139, 250 Equilibrium, 3 chemical reaction, 173–175 condensed phases, 175–176, 175*np* conditions for subsystems, 81–83 constant for chemical reaction, 176–178, 180 criteria, 79–81, 84–93 dependence on pressure, 182–183 dominant contributions, 525–526 enthalpy criterion, 90–91 entropy additivity, 523, 526–527 entropy criterion, 32, 79–84 explicit conditions for, 175–182 with external forces, 155–157 Gibbs free energy criterion, 89–90 in gravitational field, 157–164 Helmholtz free energy criterion, 88–89 heterogeneous reactions in gases, 179 internal energy criterion, 88 Kramers (grand) potential criterion, 91–92 multiplicity function, 523–524 of two-state systems, detailed study, 523-527 overlap integral, 523 phase rule, 83–84 pressure, dependence of *K(T, p)*, 182 reactions in gases, 177, 178 rotating systems, 164–166 shape, 227–228 of crystal, 215–216, 227–228 global *vs.* local, 239 Legendre transforms, 241–242 from ξ-vector, 236–239 state, macroscopic systems, 3 Summary, 92*t* temperature, dependence of *K(T, p)*, 180, 181

Equimolar surface, 188 Equipartition, 263 averaging theorem and, 343–345 principle, 343 Ergodic hypothesis, 260 Eta theorem, 251–252, 254–256 Euclidean geometry, 6 Euler equation, 60–62, 68, 72, 110–111, 137–138, 158, 169, 193, 201–202, 216–217, 322, 365, 390, 400, 419, 543 Euler-Maclaurin sum formula, 437–439, 554–556 Euler theorem, 59–60 for extensive functions, 60–62 of homogeneous functions, 59–64 for intensive functions, 63–64 Excited states concentration of particles, 414–415 function of *T/Tc*, 416*f* , 419 Exothermic reaction, 170 Extensive functions, Euler theorem for, 60–62 Extensive variables, 7 External forces binary liquid, 162–164 centrifuge, 165–166 conditions for equilibrium, 155–157 electric fields, 166 electrochemical potentials, 155, 166 gravitational segregation, 161–162 inhomogeneous pressure, 155 Lagrange multipliers, 156 multicomponent ideal gas, 160–162 non-uniform gravitational field, 164 rotating systems, 164–166 uniform gravitational field, 157–164 Extrinsic semiconductors, 442–443

### **F**

Faceting, of large planar face, 233–235, 233*f* Factorization for independent sites, 370–373 theorem, 312–313 Fahrenheit scale, 4 Fan of vectors, 228–229

Fermi, Enrico degenerate gas, 425 energy *F* , 428–429 heat capacity, 432–433 Sommerfeld expansion, 430–432 sphere in *k* space, 433–434 temperature *TF* , 427 thermal activation, electrons, 429–433 thermionic emission of electrons, 439–442 wavenumber *kF* , 426 -Dirac distribution function, 373–374, 428, 429, 430*f* , 432 energy, 427, 428–429, 431–432, 433–434, 439, 443–444 ideal gas, 376–378, 410–412 level, 432 sphere, 426–427 wavenumber, 426–427 Fermion operators, 562–563 number operators, 563–564 Fermions, 425–450, 467–468. *See* Bosons First law of thermodynamics combined with second law, 41–47 discussion of, 16–17 enthalpy, 28–29 heat capacities, 19–23 ideal gas expansion, 24–28 quasistatic work, 17–19 statement of, 15–17 Fluid-fluid interfaces contact lines, 202*np*, 207 curved interfaces, 197–202 interface junctions and contact angles, 202–205 planar interfaces in, 186–197 sessile drops, 185–186, 210–211 surface shape in gravity, 205–213 three-dimensional problems, 210–213 two-dimensional problems, 206–209 Forces, external conservative, equilibrium condition, 155 electrical, 166 non-uniform gravitational, 164

for rotating systems, 164–166 uniform gravitational, 157–164 Frenkel defects, 395 Fugacity, 64–67, 65*f* ratio, chemical reactions, 175–176 Functions *hv* (λ, a), 408–410, 410*f* Fundamental equation of system, 42, 43 Fundamental hypothesis, 258 statistical mechanics, 258–260

### **G**

Gamma function, 499, 500*f* Gamma-plot (γ -plot), 227, 228*f* discontinuous derivatives of, 228–232 inverted gamma-plot, 232–233 minimum gamma plot (-plot), 234–235, 235*f* Gauss divergence theorem on a surface, 515–516 Gaussian approximation, 524–525 curvature, 512–513 distribution, 317–319, 461 integral, 459–460 GCE. *See* Grand canonical ensemble (GCE) General ensemble, entropy for, 397–398 example of maximization, 399–400 summation over energy levels, 402–403 Giauque, William, xvi Gibbs, J. Willard adsorption equation, 190–192, 215–216 boltzon weighting factor, 468 coefficients of curvatures, 201–202 correction factor for extensivity, 268–271 correction factor, monatomic ideal gas with, 268–271 distribution, 305 dividing surface, 185, 186*f* , 187–190 -Duhem equation, 61–62, 109–110, 218–219 factor, 360–361 free energy, 69, 173, 174*f* binary solutions, 139 equilibrium criteria, 89–90 stability requirements for, 103–104 van der Waals fluid, 129–130

paradox, 268*np* phase rule for equilibrium, 83–84 theorem for mixed ideal gases, 268*np*, 274 -Thomson equation, 238–239 -Wulff equilibrium shape, 215–216, 227–228, 234–235 Grand canonical ensemble (GCE), 405–406, 458 adsorption Langmuir, Irving, 370–371 multiply occupied sites, 368 Bose-Einstein distribution, 374–375 Bose gases, 376–378 classical ideal gas, 375–378, 380–388 with internal structure, 380–388 limit, 359–360 consolidated distributions for ideal gases, 376 derivation from microcanonical, 360–368 description, 359–360 diatomic molecular gas, 382–387 energy dispersion, fluctuation, 367–368 factorization for independent sites, 370–373 Fermi-Dirac distribution, 373–374 Fermi gases, 376–378 Gibbs factor, 360–361 grand partition function, 361 factorization for ideal systems, 368–380 factorization for independent sites, 370–373 Kramers function, 363–366 for multicomponent systems, 388–389 power series in absolute activity, 362 relation to Kramers (grand) potential *K*, 416 grand (Kramers) potential, 416 Kramers function, 363–366 monatomic gas, 381–382 multicomponent systems, 388–389 occupation numbers, 368 orbital populations for ideal gases, 378–380 orbitals, 368 particle number dispersion, fluctuation, 366–367 Pauli exclusion principle, 368 polyatomic gases, 387 pressure ensemble, 389–396

Grand partition function, 437 Gravitational chemical potentials, 155, 157–158

### **H**

Hamiltonian, 277, 283–284, 466–467 kinetic energy for, 344 operator, 455 Hamilton's equations, 277, 278–279 Harmonic Hamiltonian, 342 Harmonic oscillator, 265–267, 559–560 in canonical ensemble, 283–284 classical, in three dimensions, 282, 283–284 creation and annihilation operators, 559–560 description, 265–267 distinguishable particles, 293–302 generating function, 267 in microcanonical ensemble, 265–267 multiplicity function for, 265*f* Heat, 3–4 caloric, 5*np* capacity difference *Cp* – *CV* , 23 of chemical reaction, 170 conduction, 5 defined by first law, 15 derivation of, 57–59, 504–505 of formation, 172 general, 22 of ideal gas, 21 latent, 45–47, 51*f* , 111, 114–115, 117*f* , 118*f* , 146, 238 of reaction, 170 reservoir, 34–35, 305, 306*np*, 320 transfer, 3–4, 5, 15, 17 of van der Waals fluid, 23 Heat capacity, 17, 20 behavior near absolute zero, 50 for Bose condensate, 419*f* at constant pressure *Cp*, 420 at constant volume *CV* , 420 of crystal, 297–298 definition, 20 of degenerate Fermi gas, 425, 432–433 of diatomic and polyatomic gases, 21 effective, due to phase transformation, 20 due to electronic structure, 381–382, 432–433

Heat capacity *(Continued)* and equipartition, 317–319 of a gas as a function of temperature, 384*f* of harmonic oscillator, 296*f* for hydrogen isotopes, 385–387 of ideal Fermi and Bose gases, 420 of ideal gas, 20–21, 22*t* of linear rotator, 303, 304*f* for polyatomic molecular gases, 387–388 for quadratic Hamiltonian, 342, 345 relationship of *Cp* to *CV* , 22, 57–59 relationship to energy dispersion (fluctuations), 320, 367–368 Schottky peak, 293*f* van der Waals equation, 23 of van der Waals fluid, 23, 125 Heisenberg, Werner model for interacting spins, 469 Helmholtz, Hermann von, 88–89 equation, 58*np* Helmholtz free energy, 59*np*, 68–69 canonical ensemble, 306*np*, 307–309, 311, 315–316, 321–322 equilibrium criteria, 88–89 maximum work, isothermal system, 88–89 relation to canonical ensemble, 307–308, 311 stability requirements for, 103 *vs.* temperature, 293*f* Hermitian conjugate, 455 operator, 451–452, 453 Herring, Conyers formula, 240–241, 518–521 sphere, 215–216, 230*f* construction, 229 discontinuous derivatives of γ, 229, 230–232 inverted γ-plot, 232 theorem for faceting, 234 Hess's law, 171 Heterogeneous reaction in gases, 171–172, 179 Heteronuclear diatomic molecular gas, 382–385 Holes in semiconductors, 442–444 Homogeneous function, 59–64

Homonuclear diatomic molecular gas, 385–387 Hypersurface, 277

### **I**

Ideal binary solution, 142–145 Ideal Bose gas, 425 entropy, 407–408 grand partition function, 405–406 heat capacity, 412 unified integrals and expansions, 406–408 virial expansions for, 410–412 Ideal entropy of mixing, 142–143 Ideal Fermi gas entropy, 407–408 free electron model, metal, 428–429, 432 grand partition function, 405–406 heat capacity, 412 Landau diamagnetism, 436–439 at low temperatures, 425–428 Pauli paramagnetism, 433–436 semiconductors, 442–450 thermal activation of electrons, 429–433 thermionic emission, 439–442 unified integrals and expansions, 406–408 virial expansions for, 410–412 Ideal gas, 4 adiabatic expansion, irreversible, 27–28 adiabatic expansion, reversible, 25–27, 45 canonical ensemble, 313–316 chemical potential, 54–55 chemical reactions, 177 classical, 281–283 canonical ensemble, 338–342 Cartesian coordinates, 339–340 effusion, 340–342 grand canonical ensemble, 359–360, 375–378, 380–388 Maxwell-Boltzmann distribution, 338–339 constant *R*, 4 energy independent of volume, 20–21 enthalpy independent of pressure, 28–29 entropy of mixing, 275–276 equation of state, 20–21 heat capacities, 20–21 isobaric expansion, reversible, 24–25 isochoric transformation, 24–25

isothermal process, reversible, 24 microcanonical ensemble, 267–273 monatomic, 267–271 multicomponent, 273–276 multicomponent in uniform gravity, 160–162 open systems, 54–55 orbital populations for, 378–380 pressure of, 12–13 scaling analysis, 272–273 standard states, 171–172 work due to expansion, 24–28 Ideal liquid, phase diagram for, 145–148 Ideal solid, phase diagram for, 145–148 Ideal solution, 142–145 Identical but distinguishable particles, 260*np* Identical indistinguishable particles, 267–268 Importance sampling, 487 Independent extensive variables, 7–8 Independent intensive variables, 7–8 Index of probability, 337*np* Indistinguishable particles, 465–468 bosons and fermions, 468 Gibbs correction factor, ideal gas, 270 Slater determinant, 467–468 wave functions, ideal Bose and Fermi gases, 467 weighting factors for ideal gases, 468 Infinitesimal transfers of energy, 16 Infinite sums approximate evaluation of, 556–558 convergence of, 408–409, 499–501 Information disorder function, 247–251 relation to entropy, 247–256 Integral formulae for Fermi, Bose, and classical gases, 406–410 Integral theorems for surfaces, 515–516 Intensive functions, Euler theorem to, 63–64 Intensive variables, 7 conjugate, 106–107 dependent, 218–219 Euler theorem, 60–62 independent, 7–8, 83, 138 locally concave function of, 102–103 non-conjugate Le Chatlier, 107

partial molar quantities, 71, 72 stability requirements, 104–105 Intercepts for binary system, 73–74 monocomponent system, 128 for multicomponent system, 74–75 Interfaces, fluid-fluid Cahn's layer model, 192–197 capillary rise in tube, 185, 200, 200*f* curved, 197–202 equimolar, 188–189, 191–192 Gibbs adsorption equation, fluids, 190–192 Gibbs dividing surface, 187–190 Laplace equation, pressure difference related to mean curvature, 199–200 meniscus on plate, 207, 207*f* physical quantities independent of dividing surface, 193 shape in gravity, 205–213 surface (interfacial) free energy γ, 187*np*, 193–194 surface (interfacial) tension σ, 189–190 surface of tension, 187*np*, 193–194, 198 three-dimensional drops and bubbles, 210–213 triple junctions, contact angles, 202–205 two-dimensional drops and bubbles, 208–209, 209*f* , 210*f* Young's equation, 204 Interfaces, solid-fluid, 211 adsorption equation actual state, 220–221 reference state, 218–219 anisotropy of surface free energy γ, 221–227, 240 anisotropy, ξ-vector formalism, 215–216 curved, 227–233 equilibrium shape from ξ-plot, 236–239 equilibrium shape, variational formulation, 509–511 equimolar, 191 faceting, Herring construction, 229 γ and ξ polar plots, 227 Gibbs-Thomson equation for anisotropic γ, 238–239

Interfaces, solid-fluid *(Continued)* Gibbs-Wulff (equilibrium) shape, 215–216 γ with discontinuous derivatives, 228–232 γ with discontinuous derivatives ξ-vector for, 230*f* Herring formula for surface chemical potential, 240–241, 518–521 inverted γ-plot, 232–233 surface (interfacial) free energy γ, 215 surface stress, strain, 215–216 triple junctions, 226–227 Interfacial free energy, 215–218 anisotropy, 215–216, 242–245 Internal energy *U*, 11, 13, 15–16, 19, 21, 24, 27, 29–30, 32–33, 39, 42–43, 47–48, 53–54, 61, 70–71 equilibrium criterion for, 79–81, 84, 87–88, 92*t* stability requirements for, 100–104 Interstitials description, 393–394 in ionic crystals, 394–396 Intrinsic chemical potentials, 157–158 Intrinsic semiconductors, 442–443, 445–446 law of mass action, 444 Inverted gamma-plot, 232–233 Ionic crystals, 394–396 Irreversible adiabatic expansion, 27–28 Irreversible process, 31–32, 33–34, 39, 41–42, 43, 44 Isentropic compressibility, 504–507 Isentropic transformation, 423–424 Ising, Ernst, Model of two-state coupled spins, 469 Boethe cluster model, 473 critical exponents, 483–484 exact solution in one dimension magnetic field, transfer matrix, 480–483 zero magnetic field, 479–480, 483 heat capacity per spin *vs.* temperature, 476*f* magnetic susceptibility *vs.* temperature, 476*f* magnetization per spin *vs.* temperature, 474*f* mean field treatment comparison with exact solutions, 473–474 critical temperature *Tc*, 471–472, 472–473*f* heat capacity, 475, 476*f*

magnetic susceptibility, 476*f* magnetization, 471, 474–477, 474*f* neglect of correlations, 471 Onsager's exact solution on two dimensions, 473 pair statistics for, 477–478, 478*f* Monte Carlo simulation, 484–491 "simple cubic" lattice, 473*t* solution in one dimension for zero field, 479–480 transfer matrix, 480–483 Isobaric coefficient, 504–507 of thermal expansion, 22 van der Waals fluid, 23 Isobaric expansion, reversible, 24–25 Isochoric transformation, 24–25 Isolated system, 15–17, 264, 305, 359–360, 389, 457 chemical reaction in, 167 entropy of, 32–35, 40, 44, 48–49, 250 equilibrium of, 79–84 Eta fu, 277 quasi-isolated, 260 stability of, 95 vacancies, 393, 457 Isothermal compressibility, 22, 504–507 Isothermal process, reversible, 24 Isotropic statistical state, 464, 465

### **J**

Jacobian for canonical transformations, 354–356 to convert partial derivatives, 503–507 definition of, 503 determinants, 503 properties of, 503–504 thermodynamics, connection, 504–507 to transform canonical momenta, 356–358 Joule, James, 16–17, 20–21 Joyce-Dixon approximation, 449–450

### **K**

Kadanoff transformation, 488–489 Kapitsa, Pyotr, xvi

Kelvin, Lord (Thomson, Sir William), 4 expansion of gas though porous plug, 21 postulate concerning second law, 31–33, 37 scale for temperature, 4*np* Kinetic energy, 8–9, 540 of atom, 3 motional, 11 system of particles, 10–11 Kinetic theory, elementary, 12–13 Kramers, Hans excess potential for interface, 188–190, 198 for equilibrium shape, 236 pseudi-Kramers, 217 function *q* for grand canonical ensemble, 363–366 potential *K* (grand potential), 69–70 equilibrium criterion, 91–92 for grand canonical ensemble, 361, 400 for ideal Fermi and Bose gases, 407, 416 and Jacobians, 506 for Pauli paramagnetism, 434

### **L**

Lagrange brackets, 531–533 Lagrange multiplier, 237 Lambda point, 418–419, 419*f* Landau, Lev, 436–439 diamagnetism, 436–439 Lande g-factor, 324–325 Langevin function, 322–324, 323*f* , 326*f* , 327*f* Langmuir, Irving adsorption, 370–371, 371*f* letter from Gilbert Norton Lewis, 247 Larché-Cahn (LC) solid, 216*np* Latent heat, 45–47 Law of atmospheres, 158–159 Law of Dulong and Petit, 342–343 Law of mass action, 178–179, 444 Le Chatlier-Braun principle, 107 Le Chatlier principle, 107 Legendre transforms, 67–71 enthalpy, 69 equilibrium shape, 241–242

Gibbs free energy, 69 Helmholtz free energy, 68–69 Kramers potential, 69–70 Massieu functions, 70 natural variables, 71 relation to equilibrium shapes, 241–242 Lennard-Jones potential, 494 Lever rule, 128–129, 141 Liouville's theorem, 278–280, 455–456 Liquidus, 147–148 Local equilibrium, 239 Lorentz force, 436

### **M**

Macroscopic state variables, 3–4, 5 Macroscopic system, 3–4 in equilibrium state, 3 temperature, 3–5 Macrostate, 47–48, 257–258, 259, 260 Magnetic moment, 290–292 Magnetic susceptibility, *vs.* temperature, 476*f* Markov chain, 484–485 Markov process, 484–485 Massieu functions, 70 Matrix formulation, 544–546 Maximum term method, 273 Maxwell, James Clerk -Boltzmann distribution, 255, 317–319, 338–340, 342 -Boltzmann statistics, 468 construction, 121, 133–135 distribution, 12–13 equation of electromagnetism, 299 relations, 41–42, 51–52, 56–57, 59, 69–70, 106, 115, 160 alternative method, 58–59 for open systems, 56–57 relationship of *Cp* to *CV* , 22, 57–59 relations among partial derivatives monocomponent systems, 41 multicomponent systems, 55–59 MC, *see* Monte Carlo simulation (MC) Mean curvature, 518 Mean-field approximation, 471

Mean field model, 472–474, 482–483 Metastable, 129–130 Method of intercepts, 73–75, 139–141 Metropolis algorithm, 485 Microcanonical ensemble, 257, 258, 457. *See also* Classical microcanonical ensemble average *vs.* time average, 259–260 canonical ensemble derivation from, 305–312 classical systems, 257, 277 harmonic oscillators in 3-d, 283–284 ideal gas, 281–283 Liouville's theorem, 278–280 state density of phase space, 277 definition, 258 entropy of mixing, 275–276 equilibrium of two-state systems, 523–527 fundamental hypothesis, 258–260 harmonic oscillator, 265–267 ideal gas, 267–273 Gibbs correction for extensivity, 268–271 isolated system, 257–258 two-state systems, 261–264 extensively of entropy, 261*np* Microstates, 258 Minimum gamma-plot, 234–235 Miscibility gap binary system, 139–141 solid-liquid, 146–148 solid-solid, 150*f* equations for, 146–148 explicit equations for, 130–131 monocomponent system, 109, 118–119 phase equilibrium and, 127–131 Mixed state. *See* Statistical states Mole fractions, 62 Moment of inertia, 537–539 diatomic molecule, 538–539 Monatomic ideal gas, 267–268, 381–382 with Gibbs correction factor, 268–271 Monocomponent, 111–113 Clausius-Clapeyron equation, 110–115 coexistence curves, 109–110, 113–114 critical point, 109–110 melting temperature *vs.* pressure, 114

miscibility gap, 118–119 phase diagram, *v, p* plane, 118–119 sketches of thermodynamic functions in *T, p* plane, 115–118 system, 504–507 triple point, 109–110 vapor pressure, 111–113 Monocomponent phase equilibrium, 109–110 Clausius-Clapeyron equation, 110–115 miscibility gaps, 118–119, 119*f* relative magnitudes, approximation, 114–115 single phase region, 109–110, 116–118 solid-liquid coexistence curve, approximation, 113–114 thermodynamic functions, sketching, 115–118 two phase transitions, 116, 118 vapor pressure curve, approximation, 111–113 in *v, p* plane, 118–119 Monovalent crystals, 391–393 Monte Carlo (MC) simulation of classical particles, 491–494 Ising model, 484–491 Multicomponent ideal gas, 273–276 in gravity, 160–162 Multicomponent open systems, 55–59 Multicomponent system grand canonical ensemble, 388–389 partial molar quantities, 74–75 Multiplicity function, 261 for harmonic oscillators, 265*f* Mutual exclusivity, 247–248

### **N**

Natural function, 62–63, 63*np* Natural irreversible process, 32, 33–34, 76, 77 Natural process, 31, 47–48 Natural variables, 62–63, 63*np*, 71–72, 95, 96, 96*np*, 102, 104–105 extensive/intensive, 104 sets of thermodynamic functions, 92–93 Negative ion interstitial, 395

Negative ion vacancy, 394 Nernst, Walther, 49–50 postulate, 49–50 Net ionized donor concentration, 448 Neumann, John von, 203 Neumann triangle, 203 Non-uniform gravitational field, 164 Normalized Gaussian distribution, 317–319

### **O**

Occupation numbers, 368, 466–467, 468 One-dimensional harmonic oscillator, 460–461 Onsager, Lars exact solution for two-dimensional Ising model, square lattice, 472–474 for other two-dimensional lattices, 483–484 Open thermodynamic systems, 53 entropy of chemical reaction, 75–78 Euler theorem of homogeneous functions, 59–64 fugacity, 64–67, 65*f* ideal gas, 54–55 legendre transformations, 67–71 Maxwell relations for, 56–59 multicomponent systems, 55–59 partial molar quantities, 71–75 single component system, 53–55 Orbitals, 368, 378–380

### **P**

Pair distribution function, 349–350, 350*f* Pair statistics average for mean field, 477–478 Ising model, 477–478 Paradox entropy *vs*. energy criteria, 84–85 Paramagnetism, 290–292 adiabatic demagnetization, 329–330 classical treatment, 322–324 Curie constant, 322–324 Langevin function, 322–324, 323*f* , 326*f* , 327*f* phenomenon, 321 properties, 327–329 quantum treatment, 324–327 Partial molar quantities, 71–75 binary system, 73–74

intercepts method, 73–75 multicomponent system, 74–75 Partial pressures, 274 Particle number dispersion, 366–367 Partition function, 286–287. *See also* Classical partition function approximate, thermodynamic perturbation theory, 549–552 canonical ensemble, 330–331 Pathria, 5–6, 268*np*, 269–270, 272–273, 280, 311–312, 340–341, 349–350, 376, 377–378, 415–416, 419, 461, 472–474, 477, 483–484, 488–489 Pauli, Wolfgang exclusion principle, 368, 385, 425, 427, 432 degenerate Fermi gas, 427 hydrogen nuclei, 385 paramagnetism, 434 of electrons, 425, 433–436, 438 high temperatures, 435–436 low temperatures, 435 magnetic field, 433–434 magnetic moment, 433–435 magnetization, 434 spin matrices definition and properties, 461–462 magnetic moment of electron, 433–435 polarization vector, 462 Periodic boundary condition, 459–460 Phase diagram, 109 binary system, 137, 145–146, 153 for ideal liquid/solid, 145–148 ideal solid and liquid, 145–148 monocomponent system, 110, 110*f* , 115*f v, p* plane, 118–119 equilibrium and miscibility gap, 127–131 rule, 83–84 Phase space, 257, 277 available, 280 state density, 277

Planar interfaces in fluid Cahn's layer model, 192–197 discontinuity region, 186*f* Gibbs adsorption equation, 190–192 Gibbs dividing surface model, 185, 187–190 immobile walls, 186–187 Planar solid-fluid interfaces, 215–221. *See also* Curved solid-fluid interfaces Planck, Max, xv, 20, 299, 302 blackbody radiation, 298–302 energy quantization hypothesis, 299–302 Planck's constant, 55, 260, 265, 281–283, 294–297 third law of thermodynamics, 49–50 Point defects, 391–396 Frenkel, 395 in ionic crystals, 394–396 Schottky, 391, 395 vacancies, divacancies and interstitials, 392*t*, 393–394 Poisson bracket, 279 Poisson distribution, 378–379 Polarization vector, 462 Polyatomic molecular gas, 387–388 Polynomial coefficient, 497 Positive ion interstitial, 395 Positive ion vacancy, 394 Potential energy, 8–9 Pressure, 3. *See also* Constant pressure dependence of *K(T, p)*, 182 of ideal gas, 12–13 standard atmosphere, 4 Pressure ensemble, 389–390, 397, 401–402 Pressure, ideal gas, 12 Prigogine, Ilya, 77, 170*np*, 178–179, 182–183 Principle of detailed balance, 486–487 Probability density function, 337*np* Probable distribution, 397 Progress variable affinity and, 174*f* heat of reaction, 170 for reaction, 167, 167*np* simultaneous reactions, 182–183

Projection operator, 451–452, 454–455, 461, 463–464 Pure state, 257, 451–452

### **Q**

Quantum concentration, 270–271, 273–274, 315 Quantum energy levels, 547 Quantum mechanics, 257, 258, 268 complete analysis, 270–271 Quantum statistics, electron gas, 428 Quantum treatment, of paramagnetism, 324–327 Quasi-continuous energies, 406 Quasi-isolated systems, 260 Quasistatic work, 17–19. *See also* Reversible work

### **R**

Rankine scale, 4–5 Reaction product, 176 Reaction quotient, 177 Real gases, chemical potential of, 64–67 Reference state, adsorption equation in, 218–219 Regular solution, 148–152 Relative magnitudes, approximation, 114–115 Renormalization group (RG), 488–489 Reversible adiabatic expansion, 25–27 Reversible isobaric expansion, 24–25 Reversible isothermal process, 24 Reversible work. *See* Quasistatic work RG. *See* Renormalization group (RG) Richardson-Dushman equation, 439–440 Richard's rule, 46–47, 114–115 Rigid body angular momentum, 539 canonical momenta, 546 canonical variables, 546 Euler angles, 544, 545–546 kinetic energy, 540 matrix formulation, 544–546 moment of inertia, 537–539 rotating coordinate system, 541–544 rotating rigid polyatomic molecules, 356–358 rotation of, 537–539, 540–546, 547 time derivatives, 540–541, 542–544 Rigid linear rotator, 303–304, 556

Rotated surface element in shape of parallelogram, 225, 225*f* Rotating coordinate system, 541–544 Rotating systems, external forces, 164–166

### **S**

Sackur-Tetrode equation, 315–316 Saturation magnetic moment, 290–292, 322–324, 326 Scaling analysis, ideal gas, 272–273 Schottky defects, 391 Schottky effect, 441 Schottky peak, 292–293 Schrödinger, Erwin, 293–294 representation, 451 Second law of thermodynamics Carnot cycle and engines, 35–38 combined with first law, 41–47 composite system, 32–34 discussion of, 33–35 entropy change, calculation, 39 entropy, statistical interpretation, 47–48 irreversible process, 31–32, 33–34, 37 latent heat, 45–47 statement of, 32–35 Semiconductors acceptors from valence band, 442–443 band gap, 442 conduction band, 442–444, 446, 447*f* degenerate, 449–450 density of states *vs.* electron energy, 443*f* donors to conduction band, 442–443 dopants, 446–449 with dopants, 446–449 electrons in conduction band, 442–443 holes in valence band, 442 intrinsic, 443–446 non-degenerate, 443–444 statistical mechanics of, 442 valence band, 442–444, 446, 447*f* Series expansions, 408 virial expansions, 410 Sessile bubble, 210–211, 212*f* Sessile drops, 185–186, 210–211

Shannon, Claude, 247 Shannon's information function, 247 Single component open system, 53–55 Single free particle momentum operator, 459, 460 periodic boundary condition, 459–460 Single particle in one dimension, 8–9 in three dimensions, 9–10 Solenoidal flow, 278–279 Solid-fluid interfaces aspects, 215 curved, 227–233 planar, 215–221 Solid-liquid coexistence curve, approximation, 113–114 Solid-solid interfaces, 242–243 Solidus, 147–148 Sommerfeld, Arnold, 409–410, 430–432 Sommerfeld expansion, 409–410, 430–432 Spectral distribution, blackbody radiation, 301 Spin excess, 263–264 Spin Hamiltonian, 469 Spinodal curve, 124 and miscibility gap, 127–131 regular solution, 148–152 Spinodal curve, 149–150, 150*f* , 152 van der Waals fluid, 124 Spinor for spin 1/2, 461 Spin-spin interaction, in zero magnetic field, 481 Stability convexity *vs.* concavity of functions enthalpy *H*, 102–103 entropy *S*, 104 Gibbs free energy *G*, 103–104 Helmholtz free energy *F*, 103 internal energy, *U*, 100–102 inequalities resulting from, 101–102 local condition, 100–101 metastable, 97–98, 124, 127, 129–130, 141, 493–494 thermodynamic, 95–107

Stability requirements concave function, 95–96, 100 consequences of, 105–106 convex function, 100–102 Cramer's rule, 99–100 for enthalpy, 102–103 for entropy, 95–100 extension to many variables, 106–107 Gibbs free energy, 103–104 globally unstable, 97–98, 97*f* , 100 Helmholtz free energy, 103 for internal energy, 100–102 Le Chatlier and Le Chatlier-Braun principles, 107 locally stable, 97*f* , 98–99, 98*f* metastable, 97*f* Standard states, 171–173 explicit equilibrium conditions, 175 State, 3 equations of, 20–21, 23, 41, 42, 43–45, 54, 61, 121–124, 137–138, 139, 492, 493 equilibrium, 3 function, entropy, 32 function, internal energy, 15–16 variables, 3, 5 State function, 5–14, 15–17, 31, 35, 38, 44, 47 for infinitesimal changes, 53 and Maxwell relations, 59 relation to partial molar quantities, 71 relation to chemical reactions and Hess's law, 171 and information theory, 247–256 State variables, 15–16 classification of, 6–8 Stationary quantum states, 257 Statistical density operator, 453, 454 assumption of random phases, 454 description of random phases/external influence, 454–455 Statistical mechanics fundamental hypothesis, 258–260 of quantum systems density matrix, 459–465 indistinguishable particles, 465–468

orthonormal external states, 454–455 pure time-dependent state, 451–452 randomphases, 454–455 statistical density operators, 456–458 statistical states, 453–454 time evolution, 455–456 thermodynamics *vs.*, 5–6 Statistical states, 257, 453 Stefan-Boltzmann constant, 301 Stirling's approximation, 261, 261*np*, 286–287, 497–498 accuracy of, 498*t* asymptotic *vs.* convergent series, 500–501 elementary motivation, 498–499 equation, 497, 498 gamma function, 499–500 harmonic oscillators, 266 two-state subsystems, 261 Stirling's asymptotic series, 499–500 Stokes curl theorem on a surface, 516 Summation, over energy levels, 402–403 Surface differential geometry, 509–521 differential operators, 513–515 dipoles, 439 divergence and curl theorems, 511 divergence theorem, 515–516 excess quantities, 187–188 free energy, 188–189, 189*np* gradient, Laplacian, curl, 509 strain, 225*np* stress tensor, 215–216 of tension, 198 Symmetric boson states, 465–466 Symmetry number, 386 Symplectic group, 354, 529–530 transformation, 532–534 System of particles, 10–12

### **T**

Taylor series, 430–431 Temperature, 3–5 absolute, 4 thermodynamic definition, 32*np* dependence of *K(T, p)*, 180, 181

empirical, 4 scales, 3–4 Theorem Eta theorem of Boltzmann, 247, 254–256 Euler theorem of homogeneous functions, 59–60 applied to extensive functions, 60–61 applied to intensive functions, 63–64 factorization of partition function, 312–313 Gauss divergence, 515–516 Herring, 234 integral theorems for surfaces, 515–516 Liouville's, 278–280, 456 virial, 346–348 Wigner-Eckart, 324*np* Wulff, 227–228 Thermal activation of electrons heat capacity, 432–433 sommerfeld expansion, 430–432 Thermal contact, 5 Thermal expansion, isobaric coefficient, 22 Thermionic emission, 439 photoelectric effect, 441–442 Schottky effect, 441 work function, 439 Thermodynamic functions Bose condensation, 416–421 monocomponent systems, 115–118 for van der Waals fluid, 124–127 Thermodynamic perturbation theory classical case, 549–550 quantum case, 550–552 unperturbed Hamiltonian, 549 Thermodynamics, 5 of binary solutions, 137–141 curved solid-fluid interfaces, 227–233 degrees of freedom, 7–8 planar solid-fluid interfaces, 215–221 *vs.* statistical, 5–6 Thermometer, 3–4 Third law of thermodynamics discussion of, 49–50 experimental verification, 49–50 implications of, 50–52

implications re materials properties, 50–52 Maxwell relation, 51–52 statement of, 49–50 Thomson, Sir William (Lord Kelvin) expansion of gas though porous plug, 21 postulate concerning second law, 31–33, 37 Time derivatives, 540–541 revisited, 542–544 Transfer matrix, 480–483 Transformations, canonical general transformation, 529–530 Jacobian value, 354–356, 529–530, 532–533 necessary and sufficient conditions, 530–534 restricted transformation, 534–535 symplectic transformation, 532–534 use of, 354–356 Triple junctions, 226–227 Triple line, 202–205 Triple point, 109, 119*f* Trouton's rule, 46–47, 114–115 Two-state subsystems, 261–264 entropy, 292*f* entropy *vs.* temperature, 264*f* equilibrium of, 523–527 magnetic moment, 290–292, 292*f* paramagnetism, 290–292 spin 1/2, 289–290, 290*f* temperature, 292*f* temperature *vs.* energy, 262*f* , 263*f*

### **U**

Uniform gravitational field, 157–164 binary liquid, 162–164 multicomponent ideal gas, 160–162 Unperturbed Hamiltonian, 549

### **V**

Vacancies, 393–394 definition, 391 ionic crystals, 394–396 in monovalent crystals, 391–393 Vacuum state, 363, 564 Valence band, 442–444, 446, 447*f* , 449 van der Waals, Johannes, 121–131 van der Waals fluid chord construction, 129–130, 129*f* common tangent construction, 127–129, 129*f* constant *a*, 126–127 equation of state, 121–124 *f(v)* Curves, 130 Gibbs free energy, 129–130, 131–135 Helmholtz free energy, 124–125 isotherms, 122–124 isotherms in *p, g* plane, 132*f* isotherms in *v, p* plane, 118–119 liquid vapor equilibrium, 121 Maxwell construction, 133–135 metastable, 130 miscibility gap, 130–131 non-monotonic isotherms, 122–123 phase equilibrium and miscibility gap, 127–131 spinodal curve, 124 stable, 130 thermodynamic functions, 124–127 unstable, 130 van't Hoff, Jacobus, 180 van't Hoff equation, 180 Vapor pressure curve approximation, 111–113 monocomponent, 109–110 Variable, 5 conjugate, 47, 67–68 extensive, 7 intensive, 7 state, 3, 5 Variational formulation, 519–521 Virial coefficients classical canonical ensemble, 348–354 pair distribution function, 349–350, 350*f* expansion, 348, 352 for Fermi and Bose gases, 410–412

ideal Fermi and Bose gases, 410–412 series expansions, 410 theorem, 346–348 time averaging, 346 Virtual variation, 155–156

### **W**

Weighting factors, 453, 468 Weiss molecular field approximation, 471*np* Wien, Wilhelm, 301–302 displacement law, 301–302 Wigner-Eckart theorem, 324*np* Wilson, Kenneth, 488–489 Work, 9–10 dependence on path, 18–19 function, 439–440, 441 mechanical, 9–10, 15 quasistatic, reversible, 17–19 sign convention, 16*np* Wulff construction, 227–228, 521 Wulff planes, 227–228 Wulff theorem, 227–228

### **X**

Xi (ξ)-plot, 227, 228*f* Xi (ξ)-vector, 215–216 alternative formulae for, 509–511 for discontinuous gamma-plot, 228–232 equilibrium shape from, 236–239 fan of vectors, 231*f* for general surfaces, 516–519 Herring sphere, 230*f*

### **Y**

Young's equation, 204

### **Z**

Zero field, 479–480 Zero of energy, 8–9 Zero of entropy, 49–50

| Name and symbol                                      | SI value and units          | cgs value and units            |
|------------------------------------------------------|-----------------------------|--------------------------------|
| Magnitude of electronic charge, e                    | 1.602177×10−19 C            | 4.80324×10−2 esu               |
| Electron volt, eV                                    | 1.602177×10−19 J            | 1.602177×10−12 erg             |
| Boltzmann's constant, kB                             | 1.380649 ×10−23 J<br>K−1    | 1.380649 ×10−16 erg<br>K−1     |
| Boltzmann's constant, kB                             | 8.6173 ×10−5 eV<br>K−1      |                                |
| Planck's constant, h                                 | 6.626070 ×10−34J<br>s       | 6.626070 ×10−27 erg<br>s       |
| Planck's constant, h                                 | 4.135668×10−15 eV<br>s      |                                |
| Planck's constant h-bar, h¯ = h/2π                   | 1.054572 ×10−34 J<br>s      | 1.054572 ×10−27 erg<br>s       |
| Planck's constant h-bar, h¯ = h/2π                   | 6.582120 ×10−16 eV<br>s     |                                |
| Constant in h¯ ω/kBT, h¯ /kB                         | 7.638234 K s                | 7.638234 K s                   |
| Avogadro's number, NA                                | 6.022141 ×1023 mol−1        | 6.022141 ×1023 mol−1           |
| Measure of heat, cal                                 | 1.05587 ×103 J              | 1.05587 ×107 erg               |
| British thermal unit (mean), Btu                     | 4.184 J                     | 4.184 ×107 erg                 |
| Gas constant, R = NAkB                               | 8.31446 J mol−1             | 8.31446 ×107 erg<br>mol−1      |
| Gas constant, R = NAkB                               | 5.189 ×1019 eV<br>mol−1     |                                |
| Gas constant, R = NAkB                               | 1.987 calmol−1              | 1.987 calmol−1                 |
| Measure of pressure, Pa                              | 1Nm−2                       | 10 dyne cm−2                   |
| Standard atmosphere of pressure, atm                 | 1.01325 ×105 Pa             | 1.01325 ×106dyne<br>cm−2       |
| cm of mercury, cmHg                                  | 1.333224×103 Pa             | 1.333224×104 dyne<br>cm−2      |
| Electron rest mass, m                                | 9.109384×10−31 kg           | 9.109384×10−28 g               |
| Proton rest mass, mp                                 | 1.6726×10−27 kg             | 1.6726×10−24 g                 |
| Neutron rest mass, mn                                | 1.674920×10−27 kg           | 1.674920×10−24 g               |
| Ratio of proton mass to electron mass, mp/m          | 1836.153                    | 1836.153                       |
| Atomic mass unit amu, u                              | 1.660539×10−27 kg           | 1.660539×10−24 g               |
| Speed of light, c                                    | 2.99792458×108m<br>s−1      | 2.99792458×1010cm<br>s−1       |
| Bohr magneton, μB<br>= eh¯ /2m                       | 9.2740×10−24 J<br>T−1       |                                |
| Bohr magneton, μB<br>= eh¯ /2m                       | 5.788382 ×10−5 eV<br>T−1    | 5.788382 ×10−9 eV<br>G−1       |
| Bohr magneton, μB<br>= eh¯ /2mc                      |                             | 9.274 ×10−21 erg<br>G −1       |
| Nuclear magneton, μN<br>= eh¯ /2mp                   | 5.050784 ×10−27 J<br>T−1    |                                |
| Nuclear magneton, μN<br>= eh¯ /2mpc                  |                             | 5.050784 ×10−24erg<br>G −1     |
| Steffan-Boltzmann constant, σ = π2k4<br>B/(60h¯ 3c2) | 5.670×10−8 W<br>m−2 K<br>−4 | 5.670×10−5 erg<br>s−1 cm−2 K−4 |
| Reciprocal fine structure constant, α−1 =<br>hc¯ /e2 | 137.036                     | 137.036                        |
| = h¯ 2/mc<br>Electron Compton wavelength, λe         | 3.86159×10−15 m             | 3.86159 ×10−13 cm              |
| = e2/mc2<br>Electron radius, re                      | 2.817940×10−13 m            | 2.817940 ×10−11 cm             |
| kBT = 1 eV                                           | T = 1.16 × 104 K            | T = 1.16 × 104 K               |
| hν = h¯ ω = 1 eV                                     | ν = 2.42 × 1014 Hz          | ω = 2πν = 15.2 × 1014 s−1      |
| Faraday constant, F = eNA                            | 9.648670 ×104 C<br>mol−1    | 9.648670 ×104 C<br>mol−1       |
| Universal gravitational constant, G                  | 6.674 ×10−11 N<br>m2 kg−2   | 6.674 ×10−8 dyne<br>cm2g−2     |

Universal gravitational constant, *G* 6.674 ×10−11 N m2 kg−2 6.674 ×10−8 dyne cm2g−2 Avogadro's number is also known as Lodschmidt's number, *L*. See http://physics.nist.gov/cuu/constants for the latest recommended

values. C= coulomb, cal = calorie, Pa = N m−2 = pascal, W = J/s = watt, G = gauss, T = tesla = 104 G, esu = electrostatic units.